{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD (Singular Value Decomposition）奇异值分解\n",
    "https://zhuanlan.zhihu.com/p/29846048\n",
    "> 优点：简化数据，去除噪声，提高算法的结果\n",
    "> \n",
    "> 缺点：数据的转换可能难以理解\n",
    "> \n",
    "> 适用数据范围：数值型数据\n",
    "利用SVD实现，可以能够用小的多的数据来表示原始数据，如此，实际上是去除了噪声和多余信息。\n",
    "---\n",
    "结合特征分解知识\n",
    "\n",
    "特征值的分解使用于\n",
    "\n",
    "SVD是将任意复杂（注意对比特征分解只能适用于方阵）的矩阵用更小，更简单的3个矩阵的相乘表示，用这3个小矩阵来描述大矩阵的重要特征。\n",
    "\n",
    "利用SVD 可以从稀疏矩阵（矩阵中有大量元素值为0）中提取有价值的信息，减少计算量，在使用线性代数的地方，基本上都要使用SVD。\n",
    "\n",
    "SVD不但应用在PCA、图像压缩、数字水印、推荐系统和文章分类、LSA中，是很多机器学习算法基石。\n",
    "### SVD数学定义\n",
    "与特征值分解不同，SVD不要求原始矩阵为方阵。\n",
    "\n",
    "$$ A=U_{m \\times m} \\Sigma_{m \\times n} V^T_{n \\times n}$$\n",
    "-------\n",
    " A 为$m \\times n$矩阵，$A \\times A^T$ 将得到一个对称矩阵，即$A_{ij}=A_{ji}$\n",
    "*  $U$ 是一个$m \\times m$的矩阵，\n",
    "*  $ \\Sigma$ 是一个 $m \\times n$ 的矩阵，除了主对角线上的元素以外全为0，主对角线上的每个元素都称为奇异值。奇异值矩阵是一个对角矩阵，除了对角元素外其他元素都为0\n",
    "*  $V$ 是一个 $n \\times n$ 的矩阵。\n",
    "*  \n",
    "$U$和$V$ 都是酉矩阵，即满足\n",
    "$U^T U=E_{m \\times m} , V^TV=E_{n \\times n}$\n",
    "\n",
    ">SVD是对数据进行有效特征整理的过程。首先，对于一个m×n矩阵A，我们可以理解为其有m个数据，n个特征，（想象成一个n个特征组成的坐标系中的m个点），然而一般情况下，这n个特征并不是正交的，也就是说这n个特征并不能归纳这个数据集的特征。SVD的作用就相当于是一个坐标系变换的过程，从一个不标准的n维坐标系，转换为一个标准的k维坐标系，并且使这个数据集中的点，到这个新坐标系的欧式距离为最小值（也就是这些点在这个新坐标系中的投影方差最大化），其实就是一个最小二乘的过程。进一步，如何使数据在新坐标系中的投影最大化呢，那么我们就需要让这个新坐标系中的基尽可能的不相关，我们可以用协方差来衡量这种相关性。A^T·A中计算的便是n×n的协方差矩阵，每一个值代表着原来的n个特征之间的相关性。当对这个协方差矩阵进行特征分解之后，我们可以得到奇异值和右奇异矩阵，而这个右奇异矩阵则是一个新的坐标系，奇异值则对应这个新坐标系中每个基对于整体数据的影响大小，我们这时便可以提取奇异值最大的k个基，作为新的坐标，这便是PCA的原理。\n",
    "\n",
    "通过python中np.linga.svd 求奇异分解\n",
    " Python中svd后得到的sigma是一个行向量，Python中为了节省空间只保留了A的奇异值，所以我们需要将它还原为奇异值矩阵。同时需要注意的是，比如一个5*5 大小的矩阵的奇异值只有两个，但是他的奇异值矩阵应该是 5*5的，所以后面的我们需要手动补零，并不能直接使用diag将sigma对角化。\n",
    "————————————————\n",
    "\n",
    "https://blog.csdn.net/Cheese_pop/article/details/78346662"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#笔记\n",
    "\n",
    "<img src=\"https://s1.imagehub.cc/images/2022/09/02/_05.md.png\" align=\"left\"/>\n",
    "<img src=\"https://s1.imagehub.cc/images/2022/09/02/_06.md.png\" align=\"center\"/>\n",
    "<img src=\"https://s1.imagehub.cc/images/2022/09/02/_07.md.png\" align=\"right\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "利用svd定义求解$U \\Sigma V$这三个矩阵\n",
    "\n",
    "1. 首先求出$AA^T$矩阵\n",
    "2. 根据$AA^T=U(\\Sigma)^2U^T$这一个特征值分解，求出$U, \\Sigma$\n",
    "3. 根据特征值对 $\\Sigma$中$\\sigma_i$以及对应$U$中特征向量进行排序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "A=np.array([[1,5,7,6,1],[2,1,10,4,4],[3,6,7,5,2]])\n",
    "print(\"待分解矩阵：\\n\",A)\n",
    "print(\"求A与其转置内积：\")\n",
    "AAt=A@A.T \n",
    "print(AAt)\n",
    "print(\"实现对A的特征值分解\")\n",
    "eig,eigv=np.linalg.eig(AAt)\n",
    "print(\"求得特征值:\",eig)\n",
    "print(\"特征向量构成矩阵，即U: \\n\",eigv)\n",
    "sigma=np.sqrt(np.diag(eig))\n",
    " \n",
    "print(\"求得奇异值对角矩阵：\\n\",sigma)\n",
    "\n",
    "print(\"根据特征值对 $\\Sigma$中$\\sigma_i$以及对应$U$中特征向量进行排序\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://s1.imagehub.cc/images/2022/09/02/_08.md.png\" align=\"left\"/>\n",
    "<img src=\"https://s1.imagehub.cc/images/2022/09/02/_09.md.png\" align=\"center\"/>\n",
    "<img src=\"https://s1.imagehub.cc/images/2022/09/02/_10.md.png\" align=\"right\"/>\n",
    "<img src=\"https://s1.imagehub.cc/images/2022/09/02/_11.md.png\" align=\"left\"/>\n",
    "<img src=\"https://s1.imagehub.cc/images/2022/09/02/_12.md.png\" align=\"center\"/>\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在求得$U \\Sigma V$三个矩阵的基础上利用左、右奇异矩阵降维、奇异值矩阵对原矩阵进行降维\n",
    "包括\n",
    "1. 行压缩数据降维、列压缩数据降维\n",
    "结合笔记，行压缩数据降维简单理解：\n",
    "* 行压缩数据降维，列压缩数据降维分别**独立** 降维\n",
    "* 行压缩降维 $A^{'}=U^T \\times A$ 意味着$A$矩阵通过$U^T$所构成的标准正交空间变换，得到相互不线性相关的向量组合$A^{'}$，\n",
    "\n",
    "由于$A^{'}$中各向量不线性相关就可以根据对应的奇异向量k值，选择信息量大的k行，\n",
    "2. 对矩阵进行整体降维"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原矩阵A大小: (7, 5)\n",
      "左奇异矩阵大小: \n",
      " (7, 7)\n",
      "右奇异矩阵大小：\n",
      " (5, 5)\n",
      "奇异值：\n",
      " [9.64365076e+00 5.29150262e+00 6.49628424e-16 1.43063514e-16\n",
      " 2.79192092e-17]\n",
      "观察奇异值，得到前两个奇异值远大于后面其他奇异值，故选择k=2\n",
      "截取U左奇异矩阵前两列：\n",
      "U转置后选取奇异值最大的的k行: (2, 7)\n",
      "通过U_t(k) 与A进行内积，实现对A的列行的方向的压缩 \n",
      " [[-5.56776436e+00 -5.56776436e+00 -5.56776436e+00  1.66777673e-16\n",
      "   1.66777673e-16]\n",
      " [ 2.16930682e-16  2.16930682e-16  2.16930682e-16 -3.74165739e+00\n",
      "  -3.74165739e+00]]\n",
      "行压缩数据降维后，A的大小 (2, 5)\n",
      "[[ 0.00000000e+00 -2.82842712e+00]\n",
      " [ 0.00000000e+00 -4.24264069e+00]\n",
      " [ 0.00000000e+00 -1.41421356e+00]\n",
      " [-1.73205081e+00  1.23259516e-32]\n",
      " [-3.46410162e+00  2.46519033e-32]\n",
      " [-8.66025404e+00  4.93038066e-32]\n",
      " [-1.73205081e+00  1.23259516e-32]]\n",
      "列压缩数据降维后，A的大小 (7, 2)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "A=np.array([[0,0,0,2,2],[0,0,0,3,3],[0,0,0,1,1],[1,1,1,0,0],[2,2,2,0,0],[5,5,5,0,0],[1,1,1,0,0]])\n",
    "U,sigma,Vt=np.linalg.svd(A)\n",
    "print(\"原矩阵A大小:\",A.shape)\n",
    "print(\"左奇异矩阵大小: \\n\",U.shape)\n",
    "print(\"右奇异矩阵大小：\\n\",Vt.shape)\n",
    "print(\"奇异值：\\n\",sigma)\n",
    "print(\"观察奇异值，得到前两个奇异值远大于后面其他奇异值，故选择k=2\")\n",
    "print(\"截取U左奇异矩阵前两列：\")\n",
    "U2_t=U.T[:2,:]\n",
    "\n",
    "print(\"U转置后选取奇异值最大的的k行:\",U2_t.shape)\n",
    "A_col_2=np.dot(U2_t,A)#U2_t@A\n",
    "print(\"通过U_t(k) 与A进行内积，实现对A的列行的方向的压缩 \\n\",A_col_2)\n",
    "print(\"行压缩数据降维后，A的大小\",A_col_2.shape)\n",
    "Vt2=Vt[:2,:]#选取奇异值最大两个对应的V转置后两行向量 \n",
    "A_row_de=Vt2@A.T\n",
    "print(A_row_de.T)\n",
    "print(\"列压缩数据降维后，A的大小\",A_row_de.T.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 2 2]\n",
      " [0 0 0 3 3]\n",
      " [0 0 0 1 1]\n",
      " [1 1 1 0 0]\n",
      " [2 2 2 0 0]\n",
      " [5 5 5 0 0]\n",
      " [1 1 1 0 0]]\n",
      "<class 'numpy.matrix'>\n",
      "(7, 5)\n",
      "(7, 5)\n",
      "[[-4.64289391e-16 -4.64289391e-16 -4.64289391e-16 -3.12012455e-16\n",
      "  -3.12012455e-16]\n",
      " [ 2.93927860e-32  2.93927860e-32  2.93927860e-32  1.97525843e-32\n",
      "   1.97525843e-32]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [ 1.00000000e+00  1.00000000e+00  1.00000000e+00  6.72021505e-01\n",
      "   6.72021505e-01]\n",
      " [ 2.00000000e+00  2.00000000e+00  2.00000000e+00  1.34404301e+00\n",
      "   1.34404301e+00]\n",
      " [ 5.00000000e+00  5.00000000e+00  5.00000000e+00  3.36010753e+00\n",
      "   3.36010753e+00]\n",
      " [ 1.00000000e+00  1.00000000e+00  1.00000000e+00  6.72021505e-01\n",
      "   6.72021505e-01]]\n"
     ]
    }
   ],
   "source": [
    "# 整体压缩\n",
    "# 选取前k个U(i)*sigma(i)*Vt(i) 计算后相加，得到压缩后的A矩阵\n",
    "print(A)\n",
    "U,sigma,Vt=np.linalg.svd(A)\n",
    "u1=np.mat(U[:,0])\n",
    "print(type(u1))\n",
    "vt1=np.mat(Vt[0,:])\n",
    " \n",
    "sigma1=sigma[0]\n",
    "a1=sigma1*u1.T@vt1\n",
    "print(a1.shape)\n",
    "u2=np.mat(U[:,1])\n",
    " \n",
    "vt1=np.mat(Vt[1,:])\n",
    " \n",
    "sigma2=sigma[1]\n",
    "a2=sigma2*u1.T@vt1\n",
    "print(a2.shape)\n",
    "a12=a1+a2\n",
    "print(a12)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD 应用1 推荐\n",
    "步骤：\n",
    "1. 数据加载\n",
    "2. 定义相似度计算方法\n",
    "3. 对信息进行降维\n",
    "> 由于需要保留菜品信息（列），故采用左奇异矩阵相乘实现原矩阵行降维 \n",
    "  $A_{'}=\\Sigma*(U^T)_k \\dot A$\n",
    "4. 通过评分估计编写推荐算法\n",
    "    对$m$用户\n",
    "   1. $m_x$为未吃过菜品\n",
    "   2. $m_i,m_j$分别代表m对$i,j$菜品打分\n",
    "   3. $sim_{xi},sim_{xj}$为整体$x,i,j$菜品的相似度\n",
    "   4. $m_x= \\frac{m_i\\times sim(xi)+m_j \\times sim(xj)}{ sim(xi)+sim(xj)}$\n",
    "   5. $x=1,2,3...n$代表$m$用户所有没有吃过菜，并计算得到对应$m_x$菜品推断得分。\n",
    "   6. 找到推荐得分最高菜品，推荐给$m$用户"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试相似度计算\n",
      "[[5 1 4]\n",
      " [1 5 2]\n",
      " [5 2 4]\n",
      " [4 1 4]]\n",
      "0.7633073594246896\n",
      "(18, 11)\n",
      "(18, 18) (11,) (11, 11)\n",
      "823.0038413383999\n",
      "[18.00984878 13.34523472 11.52884033 10.1161419   7.13556169  5.86405759]\n",
      "满足信息量保留:0.9,的奇异值数目为:6\n",
      "通过左奇异矩阵对原矩阵进行转换，实现行的降维 \n",
      "\n",
      "[[18.00984878  0.          0.          0.          0.          0.        ]\n",
      " [ 0.         13.34523472  0.          0.          0.          0.        ]\n",
      " [ 0.          0.         11.52884033  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         10.1161419   0.          0.        ]\n",
      " [ 0.          0.          0.          0.          7.13556169  0.        ]\n",
      " [ 0.          0.          0.          0.          0.          5.86405759]]\n",
      "行降维后的评分矩阵大小: (6, 11)\n",
      "[0.6298227  0.67514404 1.         0.72171446 0.65067707 0.60408973\n",
      " 0.91768331 0.61053239 0.75243302 0.53867935 0.54479309]\n",
      "用户:17,对应打分向量:[[0 3 5 1 0 0 4 1 0 0 0]],形状(1, 11)\n",
      "菜品0与其他菜品相关度[1.         0.65231795 0.6298227  0.85376378 0.5932655  0.52783971\n",
      " 0.61112511 0.89769826 0.59027778 0.52660177 0.50862582],对应向量形状(11,)\n",
      "菜品4与其他菜品相关度[0.5932655  0.87882693 0.65067707 0.56067854 1.         0.81019338\n",
      " 0.65792974 0.53343462 0.56908556 0.51058572 0.81750593],对应向量形状(11,)\n",
      "菜品5与其他菜品相关度[0.52783971 0.63375711 0.60408973 0.53260253 0.81019338 1.\n",
      " 0.5961696  0.51796439 0.53711962 0.687694   0.82274861],对应向量形状(11,)\n",
      "菜品8与其他菜品相关度[0.59027778 0.53626618 0.75243302 0.58945751 0.56908556 0.53711962\n",
      " 0.85277813 0.5597481  1.         0.64187609 0.53450328],对应向量形状(11,)\n",
      "菜品9与其他菜品相关度[0.52660177 0.5        0.53867935 0.52492224 0.51058572 0.687694\n",
      " 0.63513711 0.51716557 0.64187609 1.         0.5       ],对应向量形状(11,)\n",
      "菜品10与其他菜品相关度[0.50862582 0.68018749 0.54479309 0.52020305 0.81750593 0.82274861\n",
      " 0.52629152 0.5        0.53450328 0.5        1.        ],对应向量形状(11,)\n",
      "矩阵压缩前，进行推荐计算，第17号顾客没有吃过的菜中： {0: 0.6644307007826169, 4: 0.6868355885972804, 5: 0.5969260906454075, 8: 0.7093772690166512, 9: 0.5554309272790323, 10: 0.5635640753207821}\n",
      "用户:17,对应打分向量:[[0 3 5 1 0 0 4 1 0 0 0]],形状(1, 11)\n",
      "菜品0与其他菜品相关度[1.         0.78712889 0.78873282 0.9817032  0.70146433 0.6238851\n",
      " 0.78837146 0.99385244 0.72813517 0.58698874 0.60787638],对应向量形状(11,)\n",
      "菜品4与其他菜品相关度[0.70146433 0.96611788 0.80240006 0.69355824 1.         0.92279325\n",
      " 0.79903869 0.65321212 0.70536221 0.61737892 0.96075029],对应向量形状(11,)\n",
      "菜品5与其他菜品相关度[0.6238851  0.82589181 0.73534984 0.63035731 0.92279325 1.\n",
      " 0.7413467  0.59249204 0.68530452 0.77470003 0.96020569],对应向量形状(11,)\n",
      "菜品8与其他菜品相关度[0.72813517 0.730485   0.93312301 0.77231249 0.70536221 0.68530452\n",
      " 0.95913865 0.71077996 1.         0.76434827 0.61180751],对应向量形状(11,)\n",
      "菜品9与其他菜品相关度[0.58698874 0.58953488 0.66863165 0.60310978 0.61737892 0.77470003\n",
      " 0.72993902 0.58000266 0.76434827 1.         0.6051641 ],对应向量形状(11,)\n",
      "菜品10与其他菜品相关度[0.60787638 0.86306565 0.68995526 0.59170177 0.96075029 0.96020569\n",
      " 0.67973479 0.56286151 0.61180751 0.6051641  1.        ],对应向量形状(11,)\n",
      "矩阵压缩后，进行推荐计算，第17号顾客没有吃过的菜中： {0: 1.331381903626659, 4: 1.2982521448914948, 5: 1.2178831118711433, 8: 1.4157661645709274, 9: 1.2253828291371067, 10: 1.2187785365605384}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tomis\\.conda\\envs\\luck\\lib\\site-packages\\sklearn\\utils\\validation.py:727: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "c:\\Users\\tomis\\.conda\\envs\\luck\\lib\\site-packages\\sklearn\\utils\\validation.py:727: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "c:\\Users\\tomis\\.conda\\envs\\luck\\lib\\site-packages\\sklearn\\utils\\validation.py:727: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from inspect import Parameter\n",
    "from re import S\n",
    "import numpy as np \n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "def ecludSim(x:np.ndarray,y:np.ndarray)->np.ndarray:\n",
    "    '''欧氏距离\n",
    "    \n",
    "    Paramters:\n",
    "    x: 计算相似度向量\n",
    "    y: 计算相似度向量\n",
    "    \n",
    "    Returns:相似杜结果\n",
    "    \n",
    "    '''\n",
    "    sim=np.linalg.norm(x,y)\n",
    "    sim_norm=1/(1-sim)\n",
    "    return sim_norm \n",
    "def pearSim(x:np.ndarray,y:np.ndarray)->np.ndarray:\n",
    "    '''皮尔逊相关系数\n",
    "    sim=np.corrcoef(x,y)\n",
    "    '''\n",
    "def cosSim(x:np.ndarray,y:np.ndarray)->np.ndarray:\n",
    "    sim=float(x.T@y)/(np.linalg.norm(x)*np.linalg.norm(y))\n",
    "    sim_norm=0.5+0.5*sim\n",
    "    return sim_norm \n",
    "\n",
    "def sigmaPct(sigma,percentage):\n",
    "    n=len(sigma)\n",
    "    sum_n=np.sum(np.square(sigma))\n",
    "    k=0\n",
    "    sum_i=0\n",
    "    for i in range(n):\n",
    "        sum_i=sum_i+np.square(sigma[i]) \n",
    "        k=k+1\n",
    "        if (float(sum_i)/float(sum_n))>=percentage:\n",
    "            print(sum_i)\n",
    "            print(sigma[:k])\n",
    "            return k\n",
    "            break\n",
    "def simScore(data):\n",
    "    len=socretable.shape[1]#菜品打分矩阵列数\n",
    "    sims=[]\n",
    "    for i in range(len):\n",
    "        if i+1<len:\n",
    "            sim=cosSim(data[:,i],data[:,i+1])\n",
    "            sims.append(sim)\n",
    "        else:\n",
    "            break\n",
    "    return sims\n",
    "    \n",
    "def estScore(socretable,userIndex=0):\n",
    "    ''' 推荐菜品计算，输入为没有压缩过的矩阵\n",
    "    Parameter:\n",
    "        scoreData:输入计算矩阵\n",
    "        userIndex:推荐用户id\n",
    "        itemIndex:菜品id\n",
    "    '''    \n",
    "    itemLen=socretable.shape[1]#菜品打分矩阵列数\n",
    " \n",
    " \n",
    "    score_dic={}\n",
    "    #计算菜品之间的相关系数\n",
    "    sims=0.5+0.5*cosine_similarity(socretable.T)# 菜品相似矩阵计算（基于cos）\n",
    "    score=[]\n",
    "    #得到哪些菜itemindex用户没有吃过\n",
    "    score_m=socretable[userIndex,:].flatten()\n",
    "    print(\"用户:{},对应打分向量:{},形状{}\".format(userIndex,score_m,score_m.shape))\n",
    "    for i in range( itemLen):\n",
    "       if score_m[:,i]==0:\n",
    "           simx=sims[i,:]#x菜品与其他菜品（包括自己）的相关性\n",
    "           print(\"菜品{}与其他菜品相关度{},对应向量形状{}\".format(i,simx,simx.shape))\n",
    "           score_x=np.sum(score_m@simx)/np.sum(score_m)\n",
    "           score.append( score_x)\n",
    "           score_dic[i]=score_x\n",
    "    return score_dic\n",
    "            \n",
    "def estScoreSVC(scoreData,scoreSVC,userIndex=0):\n",
    "    ''' 计算菜品itemIndex \n",
    "    Parameters:\n",
    "        scoreData:降维前矩阵\n",
    "        scoreSVC: 将维后矩阵\n",
    "        userIndex:推荐用户id\n",
    "        itemIndex:菜品id\n",
    "    Returns:\n",
    "        返回字典，key为菜的index，value为推荐打分\n",
    "    '''    \n",
    "    itemLen=scoreSVC.shape[1]#菜品打分矩阵列数,代表菜数目\n",
    " \n",
    " \n",
    "    score_dic={}\n",
    "    #计算菜品之间的相关系数\n",
    "    sims=0.5+0.5*cosine_similarity(scoreSVC.T)# 菜品相似矩阵计算（基于cos）\n",
    "     \n",
    "    \n",
    "    score_m=scoreData[userIndex,:].flatten()#得到哪些菜itemindex用户没有吃过\n",
    "    print(\"用户:{},对应打分向量:{},形状{}\".format(userIndex,score_m,score_m.shape))\n",
    "    for i in range( itemLen):\n",
    "       if score_m[:,i]==0:\n",
    "           simx=sims[i,:]#x菜品与其他菜品（包括自己）的相关性\n",
    "           print(\"菜品{}与其他菜品相关度{},对应向量形状{}\".format(i,simx,simx.shape))\n",
    "           score_x=np.sum(score_m@simx)/np.sum(simx)\n",
    "            \n",
    "           score_dic[i]=score_x\n",
    "    return score_dic        \n",
    "    \n",
    "    \n",
    "if __name__=='__main__':\n",
    "    #U,sigma,Vt=np.linalg.svd(data)\n",
    "    #左奇异行向量降维\n",
    "    #k=sigmaPct(sigma,0.8)\n",
    "    print(\"测试相似度计算\")\n",
    "    socretable=np.mat([[5,1,4],[1,5,2],[5,2,4],[4,1,4]])\n",
    "    print(socretable)\n",
    "    sim1=cosSim(socretable[:,0],socretable[:,1])\n",
    "    print(sim1)\n",
    "    scoreData = np.mat([\n",
    "    [5,2,1,4,0,0,2,4,0,0,0],\n",
    "    [0,0,0,0,0,0,0,0,0,3,0],\n",
    "    [1,0,5,2,0,0,3,0,3,0,1],\n",
    "    [0,5,0,0,4,0,1,0,0,0,0],\n",
    "    [0,0,0,0,0,4,0,0,0,4,0],\n",
    "    [0,0,1,0,0,0,1,0,0,5,0],\n",
    "    [5,0,2,4,2,1,0,3,0,1,0],\n",
    "    [0,4,0,0,5,4,0,0,0,0,5],\n",
    "    [0,0,0,0,0,0,4,0,4,5,0],\n",
    "    [0,0,0,4,0,0,1,5,0,0,0],\n",
    "    [0,0,0,0,4,5,0,0,0,0,3],\n",
    "    [4,2,1,4,0,0,2,4,0,0,0],\n",
    "    [0,1,4,1,2,1,5,0,5,0,0],\n",
    "    [0,0,0,0,0,4,0,0,0,4,0],\n",
    "    [2,5,0,0,4,0,0,0,0,0,0],\n",
    "    [5,0,0,0,0,0,0,4,2,0,0],\n",
    "    [0,2,4,0,4,3,4,0,0,0,0],\n",
    "    [0,3,5,1,0,0,4,1,0,0,0]\n",
    "    ])\n",
    "    print(scoreData.shape)\n",
    "    U,sigma,Vt=np.linalg.svd(scoreData)\n",
    "    print(U.shape,sigma.shape,Vt.shape)\n",
    "    k=sigmaPct(sigma,0.9)\n",
    "    print(\"满足信息量保留:{},的奇异值数目为:{}\".format(0.9,k))\n",
    "    print(\"通过左奇异矩阵对原矩阵进行转换，实现行的降维 \\n\")\n",
    "    sigma_k=np.eye(6)*sigma[:6]\n",
    "    print(sigma_k)\n",
    "    scoreData_r=sigma_k*U.T[:6,:]@scoreData\n",
    "    print(\"行降维后的评分矩阵大小:\",scoreData_r.shape)\n",
    "\n",
    "    sims=0.5+0.5*cosine_similarity(scoreData.T)\n",
    "    print(sims[:,2])\n",
    "    score_x=estScore(scoreData,17)\n",
    "    print(\"矩阵压缩前，进行推荐计算，第17号顾客没有吃过的菜中：\",score_x)\n",
    "    score_x2=estScoreSVC(scoreData,scoreData_r,17)\n",
    "    print(\"矩阵压缩后，进行推荐计算，第17号顾客没有吃过的菜中：\",score_x2)\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index:0,score:2.6347116715331165\n",
      "index:4,score:2.9259893459771127\n",
      "index:5,score:2.9337238848085887\n",
      "index:8,score:2.965707317848275\n",
      "index:9,score:2.9057073432965526\n",
      "index:10,score:2.926348465526288\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "scoreData = np.mat([\n",
    "[5,2,1,4,0,0,2,4,0,0,0],\n",
    "[0,0,0,0,0,0,0,0,0,3,0],\n",
    "[1,0,5,2,0,0,3,0,3,0,1],\n",
    "[0,5,0,0,4,0,1,0,0,0,0],\n",
    "[0,0,0,0,0,4,0,0,0,4,0],\n",
    "[0,0,1,0,0,0,1,0,0,5,0],\n",
    "[5,0,2,4,2,1,0,3,0,1,0],\n",
    "[0,4,0,0,5,4,0,0,0,0,5],\n",
    "[0,0,0,0,0,0,4,0,4,5,0],\n",
    "[0,0,0,4,0,0,1,5,0,0,0],\n",
    "[0,0,0,0,4,5,0,0,0,0,3],\n",
    "[4,2,1,4,0,0,2,4,0,0,0],\n",
    "[0,1,4,1,2,1,5,0,5,0,0],\n",
    "[0,0,0,0,0,4,0,0,0,4,0],\n",
    "[2,5,0,0,4,0,0,0,0,0,0],\n",
    "[5,0,0,0,0,0,0,4,2,0,0],\n",
    "[0,2,4,0,4,3,4,0,0,0,0],\n",
    "[0,3,5,1,0,0,4,1,0,0,0]\n",
    "])\n",
    "\n",
    "def cosSim(vec_1, vec_2):\n",
    "    dotProd = float(np.dot(vec_1.T, vec_2))\n",
    "    normProd = np.linalg.norm(vec_1)*np.linalg.norm(vec_2)\n",
    "    return 0.5+0.5*(dotProd/normProd)\n",
    "\n",
    "def estScore(scoreData,scoreDataRC,userIndex,itemIndex):\n",
    "    n = np.shape(scoreData)[1]\n",
    "    simSum = 0\n",
    "    simSumScore = 0\n",
    "    for i in range(n):\n",
    "        userScore = scoreData[userIndex,i]\n",
    "        if userScore == 0 or i == itemIndex:\n",
    "            continue\n",
    "        sim = cosSim(scoreDataRC[:, i], scoreDataRC[:, itemIndex])\n",
    "        simSum = float(simSum + sim)\n",
    "        simSumScore = simSumScore + userScore * sim\n",
    "    if simSum == 0:\n",
    "        return 0\n",
    "    return simSumScore / simSum\n",
    "\n",
    "U, sigma, VT = np.linalg.svd(scoreData)\n",
    "\n",
    "sigmaSum = 0\n",
    "k_num = 0\n",
    "\n",
    "for k in range(len(sigma)):\n",
    "    sigmaSum = sigmaSum + sigma[k] * sigma[k]\n",
    "    if float(sigmaSum)/float(np.sum(sigma ** 2)) > 0.9:\n",
    "        k_num = k+1\n",
    "        break\n",
    "\n",
    "sigma_K = np.mat(np.eye(k_num)*sigma[:k_num])\n",
    "scoreDataRC = sigma_K * U.T[:k_num, :] * scoreData\n",
    "\n",
    "n = np.shape(scoreData)[1]\n",
    "userIndex = 17\n",
    "\n",
    "for i in range(n):\n",
    "    userScore = scoreData[17, i]\n",
    "    if userScore != 0:\n",
    "        continue\n",
    "    print(\"index:{},score:{}\".format(i, estScore(scoreData, scoreDataRC, userIndex, i)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('luck')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7f860de8d2f90ad8cbd5e9027150b9f1852816e89724c40b1a127c39f06d8e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
