{
	"cells": [
		{
			"attachments": {},
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"# pytorch 基础\n",
				"# Keras\n",
				"本课内容包括\n",
				"1. 基本的pytorch入门，以及对应的Keras，但还是以pytorch为主\n",
				"2. pytorch中向量、导数、偏导操作，参考之前线性代数以及微积分\n",
				"3. 基于pytorch构建一个线性回归网络\n",
				"4. 基于pytorch实现class1 对图片的分类以及优化\n",
				"\n",
				"---\n",
				"\n",
				"参考资料\n",
				"\n",
				"1. [ws university pytorch introudction](https://courses.cs.washington.edu/courses/cse446/19au/section9.html)\n",
				"2. [li hong yi](https://www.youtube.com/watch?v=kQeezFrNoOg)\n",
				"3. [pytorch homepage](https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html)\n",
				"4. python 深度学习"
			]
		},
		{
			"attachments": {},
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"## 1.安装pytorch\n",
				"\n",
				"与tensorflow相同，pytorch分为cpu版本与gpu版本，官网有相对于安装代码\n",
				"[安装页面](https://pytorch.org/)\n",
				"\n"
			]
		},
		{
			"attachments": {},
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"\n",
				"pytorch 中torch的作用类似numpy，包括创建数组，进行线性代数运算等，但torch还可以直接进行求导运算\n",
				"\n",
				"numpy 与 torch之间也可以相互转化\n",
				"\n",
				"例如numpy中创建数组与torch中创建tensor张量对比\n",
				"\n",
				"```python \n",
				"np.array([12,3])\n",
				"torch.tensor([12,3])\n",
				"```\n",
				"\n",
				"1. array与tensor相互转换\n"
			]
		},
		{
			"attachments": {},
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"#### 张量\n",
				"\n",
				"之前的深度学习模型中，基于numpy构建模型，但在pytorch与tensorflow等深度学习框架中，使用的是tensor（张量）概念。\n",
				"\n",
				"张量是一种数据结构，可以认为是一种高维数组。结合线性代数，所对照的张量\n",
				"\n",
				"* 标量——0阶张量\n",
				"* 向量——1阶张量\n",
				"* 矩阵——2阶张量\n",
				"* 多维向量组——多阶张量\n",
				"\n",
				"---\n",
				"不同于tensorflow，pytorch中张量表达与计算与numpy基本相同"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"Requirement already satisfied: numpy in c:\\users\\tom\\.conda\\envs\\luck\\lib\\site-packages (1.23.5)\n"
					]
				}
			],
			"source": [
				"!pip install numpy"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"<class 'torch.Tensor'>\n",
						"tensor([2, 3, 2])\n",
						"<class 'numpy.ndarray'>\n",
						"[2 3 2]\n",
						"<class 'numpy.ndarray'>\n",
						"(2, 3)\n",
						"<class 'torch.Tensor'>\n",
						"torch.Size([2, 3])\n"
					]
				}
			],
			"source": [
				"import numpy as np \n",
				"import torch \n",
				"if __name__ == '__main__':\n",
				"    x_tensor=torch.tensor([2,3,2])\n",
				"    print(type(x_tensor))\n",
				"    print(x_tensor)\n",
				"    y_array=x_tensor.numpy()#转换tensor到array\n",
				"    print(type(y_array))\n",
				"    print(y_array)\n",
				"\n",
				"    x_arrray=np.array([[2,2,3],[2,2,2]])\n",
				"    print(type(x_arrray))\n",
				"    print(x_arrray.shape)\n",
				"    y_tensor=torch.from_numpy(x_arrray)\n",
				"    print(type(y_tensor))\n",
				"    print(y_tensor.shape)"
			]
		},
		{
			"attachments": {},
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"2. tensor 中的线性代数计算\n",
				"tensor中的计算与numpy中基本一致，包括加减，内积,求norm等。\n",
				"\n",
				"例如以下代码模拟了一个神经网络affine层中的输入值与权参相乘与偏参相加的计算"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 2,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"tensor([17., 18.], dtype=torch.float64)\n",
						"tensor(24.7588, dtype=torch.float64)\n"
					]
				}
			],
			"source": [
				"# 注意，torch在求norm时，要求数据必须为float数据，故在开始就必须制定向量的数据类型\n",
				"import torch\n",
				"x=torch.tensor([2,3,3],dtype=float)\n",
				"w=torch.tensor([[2,2],[1,2],[3,2]],dtype=float)\n",
				"b=torch.tensor([1,2],dtype=float)\n",
				"z=x@w+b\n",
				"print(z)\n",
				"print(torch.norm(z))"
			]
		},
		{
			"attachments": {},
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"tensor中正态分布、随机值等的生成与numpy也一致\n",
				"\n",
				"```python\n",
				"torch.rand(维度1数，维度2数，维度3数)\n",
				"```\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 3,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"x是一个四阶张量 torch.Size([2, 2, 2, 2])\n",
						"the shape of x torch.Size([2, 2, 2, 2])\n",
						"tensor([[[[0.6151, 0.8784],\n",
						"          [0.7847, 0.5676]],\n",
						"\n",
						"         [[0.4237, 0.1793],\n",
						"          [0.4317, 0.1019]]],\n",
						"\n",
						"\n",
						"        [[[0.6283, 0.8648],\n",
						"          [0.0628, 0.8379]],\n",
						"\n",
						"         [[0.3233, 0.9819],\n",
						"          [0.8989, 0.3853]]]])\n"
					]
				},
				{
					"ename": "NameError",
					"evalue": "name 'np' is not defined",
					"output_type": "error",
					"traceback": [
						"\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
						"\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
						"Cell \u001b[1;32mIn[3], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthe shape of x\u001b[39m\u001b[38;5;124m'\u001b[39m,x\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(x)\n\u001b[1;32m----> 5\u001b[0m x_a\u001b[38;5;241m=\u001b[39m\u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(x_a\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(x_a)\n",
						"\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
					]
				}
			],
			"source": [
				"import numpy as np \n",
				"x=torch.rand(2,2,2,2)\n",
				"print('x是一个四阶张量',x.shape)\n",
				"print('the shape of x',x.shape)\n",
				"print(x)\n",
				"x_a=np.random.rand(2,2,2,2,2)\n",
				"print(x_a.shape)\n",
				"print(x_a) \n"
			]
		},
		{
			"attachments": {},
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"tensor 形状改变\n",
				"* Tensor.view-改变形状\n",
				"* Tensor.flatten-降维为1维\n",
				"\n",
				"We can use the Tensor.view() function to reshape tensors similarly to numpy.reshape()\n",
				"\n",
				"It can also automatically calculate the correct dimension if a -1 is passed in. This is useful if we are working with batches, but the batch size is unknown.\n",
				" \n",
				" "
			]
		},
		{
			"cell_type": "code",
			"execution_count": 6,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"torch.Size([1000, 28, 28])\n",
						"torch.Size([1000, 784])\n",
						"torch.Size([1000, 784])\n",
						"torch.Size([1000, 784])\n",
						"torch.Size([784000])\n"
					]
				}
			],
			"source": [
				"batch=1000\n",
				"img_x=28\n",
				"img_y=28\n",
				"#生成一个（1000，28，29）形状的张量，模拟1000张28*28图像\n",
				"x=torch.rand(batch,img_x,img_y)\n",
				"print(x.shape)\n",
				"#将x变更为(1000,784)形状的张量\n",
				"x2=x.view(batch,img_x*img_y)\n",
				"print(x2.shape)\n",
				"#当不确定某维度的大小（batch大小），可以设为-1，torch将自动赋值\n",
				"x3=x.view(batch,-1)\n",
				"print(x3.shape)\n",
				"x3=x.view(-1,784)\n",
				"print(x3.shape)\n",
				"#将张量降维为1维\n",
				"x_fallten=torch.flatten(x)\n",
				"print(x_fallten.shape)\n"
			]
		},
		{
			"attachments": {},
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"## Computation graphs 计算图\n",
				"\n",
				"参考\n",
				"* [computation graph](https://colah.github.io/posts/2015-08-Backprop/)\n",
				"\n",
				"\n",
				"What's special about PyTorch's tensor object is that it implicitly creates a computation graph in the background. A computation graph is a a way of writing a mathematical expression as a graph. There is an algorithm to compute the gradients of all the variables of a computation graph in time on the same order it is to compute the function itself.\n",
				"\n",
				"---\n",
				"\n",
				"pytorch可以自动实现计算图，Backpropagation反向传播\n",
				"\n",
				"<img src=\"figs\\tree-def.png\" height=\"50%\" width=\"50%\">\n",
				"\n",
				"例如上图对应计算 $e=(a+b) \\times (1+b)$，求$a=1,b=2$时的反向传播\n",
				"\n",
				"为此，在对tensor复制时候，必须设置**requires_grad=True**从而pytroch将会保留计算图\n",
				">we set requires_grad=True to let PyTorch know to keep the graph\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 7,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"tensor(3., grad_fn=<AddBackward0>)\n",
						"tensor(3., grad_fn=<AddBackward0>)\n",
						"tensor(9., grad_fn=<MulBackward0>)\n"
					]
				}
			],
			"source": [
				"a=torch.tensor(1.0,requires_grad=True)\n",
				"b=torch.tensor(2.0,requires_grad=True)\n",
				"c=a+b\n",
				"d=1+b\n",
				"e=c*d\n",
				"print(c)\n",
				"print(d)\n",
				"print(e)\n"
			]
		},
		{
			"attachments": {},
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"## PyTorch as an auto grad framework\n",
				"Now that we have seen that PyTorch keeps the graph around for us, let's use it to compute some gradients for us.\n",
				"\n",
				"Consider the function  $f(x)=(x−2)^2$\n",
				" .\n",
				"\n",
				"Q: Compute  $\\frac{df(x)}{dx}$\n",
				"  and then compute  $f′(1)$\n",
				" .\n",
				"\n",
				"We make a backward() call on the leaf variable (y) in the computation, computing all the gradients of y at once.\n",
				"\n",
				"---\n",
				"实际就是pytorch实现了链式求导：\n",
				"1. pytorch 中，张量具有require_grad属性，该属性为True则将跟踪对此张量的所有计算。\n",
				"2. 完成正向传播计算后，可以对计算结果调用backward（）方法，将自动计算所有梯度，并保存至grad属性中\n",
				"3. 张量的grad_fn属性将指向运算生成该张量的方法。\n",
				"通过pytorch中backward可以求得导函数结果\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 6,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"正向传播forward: tensor(1., grad_fn=<PowBackward0>)\n",
						"反向传播结果 tensor(-2.)\n",
						"对f(x)求导 <PowBackward0 object at 0x00000218BA5628F0>\n",
						"tensor(3., grad_fn=<SubBackward0>)\n"
					]
				},
				{
					"data": {
						"text/plain": [
							"'\\n在PyTorch中，y.grad_fn代表的是梯度函数，也就是用于计算y相对于其输入变量的梯度的函数。这是因为PyTorch使用动态图和自动微分机制来计算梯度，\\n每个张量（Tensor）都有一个.grad_fn属性，该属性引用了创建该张量的Function对象（如果该张量是用户手动创建的，则此属性为None）。\\n\\n在你的代码示例中，y=f(x)通过计算(x-2)**2得到，这个操作背后是一个Pow操作（幂运算），因此y的.grad_fn属性会指向这个Pow操作的梯度函数。\\n当你调用y.backward()时，PyTorch会自动计算y关于x的梯度，并将计算结果存储在x.grad中。\\n\\n简而言之，y.grad_fn是一个指向生成y的操作的梯度函数的引用，它是自动微分系统的一部分，用于在反向传播过程中计算梯度。'"
						]
					},
					"execution_count": 6,
					"metadata": {},
					"output_type": "execute_result"
				}
			],
			"source": [
				"import torch\n",
				"def f(x):\n",
				"    return (x-2)**2\n",
				"x=torch.tensor(1.0,requires_grad=True)\n",
				"y=f(x)\n",
				"print(\"正向传播forward:\",y)\n",
				"y.backward()\n",
				"print(\"反向传播结果\",x.grad)\n",
				"print('对f(x)求导',y.grad_fn)\n",
				"x2=x-x.grad\n",
				"print(x2)\n",
				"'''\n",
				"在PyTorch中，y.grad_fn代表的是梯度函数，也就是用于计算y相对于其输入变量的梯度的函数。这是因为PyTorch使用动态图和自动微分机制来计算梯度，\n",
				"每个张量（Tensor）都有一个.grad_fn属性，该属性引用了创建该张量的Function对象（如果该张量是用户手动创建的，则此属性为None）。\n",
				"\n",
				"在你的代码示例中，y=f(x)通过计算(x-2)**2得到，这个操作背后是一个Pow操作（幂运算），因此y的.grad_fn属性会指向这个Pow操作的梯度函数。\n",
				"当你调用y.backward()时，PyTorch会自动计算y关于x的梯度，并将计算结果存储在x.grad中。\n",
				"\n",
				"简而言之，y.grad_fn是一个指向生成y的操作的梯度函数的引用，它是自动微分系统的一部分，用于在反向传播过程中计算梯度。'''"
			]
		},
		{
			"attachments": {},
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"可以设置一个嵌套函数，并求得不同层变量的导数\n",
				"设\n",
				"$$y=x^2 \\rightarrow z=y+w \\rightarrow e=z\\times 3+5$$\n",
				"其中$x=2,w=3$求位于链式求导叶子节点的$\\frac{de}{dx},\\frac{de}{dw}$"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 10,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"forward result: tensor(21., grad_fn=<MulBackward0>)\n",
						"e函数求梯度方法： <MulBackward0 object at 0x00000298310EF0A0>\n",
						"y函数求梯度方法： <PowBackward0 object at 0x00000298310EF0A0>\n",
						"x的梯度 tensor(12.)\n",
						"w的梯度 tensor(3.)\n"
					]
				}
			],
			"source": [
				"def y(x):\n",
				"    return x**2\n",
				"def z(y,w):\n",
				"    return y+w\n",
				"def e(z):\n",
				"    return z*3\n",
				"\n",
				"if __name__ == '__main__':\n",
				"    x=torch.tensor(2.0,requires_grad=True)\n",
				"    w=torch.tensor(3.0,requires_grad=True)\n",
				"    ##forwad\n",
				"    y=y(x)\n",
				"    z=z(y,w)\n",
				"    e=e(z)\n",
				"    print(\"forward result:\",e)\n",
				"    #backward \n",
				"    e.backward()\n",
				"    print(\"e函数求梯度方法：\",e.grad_fn)\n",
				"    print(\"y函数求梯度方法：\",y.grad_fn)\n",
				"    print(\"x的梯度\",x.grad)\n",
				"    print(\"w的梯度\",w.grad)\n",
				"    "
			]
		},
		{
			"attachments": {},
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"It can also find gradients of functions.\n",
				"\n",
				"Let  $w=[w_1,w_2]^T$\n",
				" \n",
				"Consider  $(w)=2w_1w_2+w_2\\cos(w_1)$\n",
				" \n",
				"Q: Compute  $∇wg(w)$\n",
				"  and verify $ ∇wg([π,1])=[2,π−1]^T$\n",
				"\n",
				"---\n",
				"\n",
				"进一步求得偏导数，并构成梯度向量\n",
				"\n",
				" "
			]
		},
		{
			"cell_type": "code",
			"execution_count": 18,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"the forward result: tensor(5.2832, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
						"the backward method of w <AddBackward0 object at 0x00000218BA5B81C0>\n",
						"the grad of w tensor([2.0000, 5.2832], dtype=torch.float64)\n"
					]
				}
			],
			"source": [
				"import numpy as np \n",
				"import torch\n",
				"def g(w):\n",
				"    return 2*w[0]*w[1]+w[1]*torch.cos(w[0])\n",
				"if __name__ == \"__main__\":\n",
				"     w=torch.tensor([np.pi,1],dtype=float,requires_grad=True)\n",
				"     forward=g(w)\n",
				"     print(\"the forward result:\", forward)\n",
				"     backward_method=g(w).grad_fn\n",
				"     print(\"the backward method of w\", backward_method)\n",
				"     g(w).backward()# backward方法需要显式调用\n",
				"     w_grad=w.grad\n",
				"     print(\"the grad of w\",w_grad)\n",
				"     "
			]
		},
		{
			"cell_type": "code",
			"execution_count": 11,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"forwad\n",
						"tensor(5.2832, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
						"backward\n",
						"tensor([2.0000, 5.2832], dtype=torch.float64)\n"
					]
				}
			],
			"source": [
				"def g(w):\n",
				"    return 2*w[0]*w[1]+w[1]*torch.cos(w[0])\n",
				"if __name__ == '__main__':\n",
				"    w=torch.tensor([torch.pi,1],dtype=float,requires_grad=True)\n",
				"    print(\"forwad\")\n",
				"    g=g(w)\n",
				"    print(g)\n",
				"    print(\"backward\")\n",
				"    g.backward()\n",
				"    print(w.grad)"
			]
		},
		{
			"attachments": {},
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"基于以上torch对backward，梯度计算方式，可以结合实现梯度下降法；\n",
				"\n",
				"---\n",
				"Using the gradients\n",
				"Now that we have gradients, we can use our favorite optimization algorithm: gradient descent!\n",
				"\n",
				"Let  $f$\n",
				"  the same function we defined above.\n",
				"\n",
				"Q: What is the value of $ x$\n",
				"  that minimizes $ f$?\n",
				"\n",
				"  ---\n",
				"\n",
				"  注意在此"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 6,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"tensor([-56.8000])\n",
						"tensor([37.2800])\n",
						"tensor([-19.1680])\n",
						"tensor([14.7008])\n",
						"tensor([-5.6205])\n",
						"tensor([6.5723])\n",
						"tensor([-0.7434])\n",
						"tensor([3.6460])\n",
						"tensor([1.0124])\n",
						"tensor([2.5926])\n",
						"tensor([1.6445])\n",
						"tensor([2.2133])\n",
						"tensor([1.8720])\n",
						"tensor([2.0768])\n",
						"tensor([1.9539])\n",
						"tensor([2.0276])\n",
						"tensor([1.9834])\n",
						"tensor([2.0100])\n",
						"tensor([1.9940])\n",
						"tensor([2.0036])\n",
						"tensor([1.9979])\n",
						"tensor([2.0013])\n",
						"tensor([1.9992])\n",
						"tensor([2.0005])\n",
						"tensor([1.9997])\n",
						"tensor([2.0002])\n",
						"tensor([1.9999])\n",
						"tensor([2.0001])\n",
						"tensor([2.0000])\n",
						"tensor([2.0000])\n",
						"tensor([2.0000])\n",
						"tensor([2.0000])\n",
						"tensor([2.0000])\n",
						"tensor([2.0000])\n",
						"tensor([2.0000])\n",
						"tensor([2.0000])\n",
						"tensor([2.0000])\n",
						"tensor([2.0000])\n",
						"tensor([2.0000])\n",
						"tensor([2.0000])\n",
						"tensor([2.0000])\n",
						"tensor([2.])\n",
						"tensor([2.])\n",
						"tensor([2.])\n",
						"tensor([2.])\n",
						"tensor([2.])\n",
						"tensor([2.])\n",
						"tensor([2.])\n",
						"tensor([2.])\n",
						"tensor([2.])\n",
						"tensor([2.])\n",
						"tensor([2.])\n",
						"tensor([2.])\n",
						"tensor([2.])\n",
						"tensor([2.])\n",
						"tensor([2.])\n",
						"tensor([2.])\n",
						"tensor([2.])\n",
						"tensor([2.])\n",
						"tensor([2.])\n",
						"tensor([2.])\n",
						"tensor([2.])\n",
						"tensor([2.])\n",
						"tensor([2.])\n",
						"tensor([2.])\n",
						"tensor([2.])\n",
						"tensor([2.])\n",
						"tensor([2.])\n",
						"tensor([2.])\n",
						"tensor([2.])\n",
						"tensor([2.])\n",
						"tensor([2.])\n",
						"tensor([2.])\n",
						"tensor([2.])\n",
						"tensor([2.])\n",
						"tensor([2.])\n",
						"tensor([2.])\n",
						"tensor([2.])\n",
						"tensor([2.])\n",
						"tensor([2.])\n",
						"tensor([2.])\n",
						"tensor([2.])\n",
						"tensor([2.])\n",
						"tensor([2.])\n",
						"tensor([2.])\n",
						"tensor([2.])\n",
						"tensor([2.])\n",
						"tensor([2.])\n",
						"tensor([2.])\n",
						"tensor([2.])\n",
						"tensor([2.])\n",
						"tensor([2.])\n",
						"tensor([2.])\n",
						"tensor([2.])\n",
						"tensor([2.])\n",
						"tensor([2.])\n",
						"tensor([2.])\n",
						"tensor([2.])\n",
						"tensor([2.])\n",
						"tensor([2.])\n"
					]
				}
			],
			"source": [
				"def f(x):\n",
				"    return (x-2)**2\n",
				"\n",
				"if __name__=='__main__':\n",
				"    iter=100\n",
				"    learning_rate=0.8\n",
				"    x=torch.tensor([100.0],requires_grad=True)\n",
				"    \n",
				"    for i in range(iter):\n",
				"        y=f(x)\n",
				"        y.backward()\n",
				"        #计算时，必须使用x.data\n",
				"        x.data=x.data-(x.grad)*learning_rate\n",
				"        print(x.data)\n",
				"        \n",
				"        x.grad.zero_() \n"
			]
		},
		{
			"attachments": {},
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"基于Pytorch建立线性方程\n",
				"\n",
				"1. 构建基本的线性方程\n",
				"2. 描述方程各个部分\n",
				"\n",
				"---\n",
				"Linear Module \n",
				" \n",
				"The bread and butter of modules is the Linear module which does a linear transformation with a bias. It takes the input and output dimensions as parameters, and creates the weights in the object.\n",
				"\n",
				"Unlike how we initialized our  w manually, the Linear module automatically initializes the weights randomly. \n",
				"\n",
				"For minimizing non convex（非凸） loss functions (e.g. training neural networks), initialization is important and can affect results. \n",
				"\n",
				"If training isn't working as well as expected, one thing to try is manually initializing the weights to something different from the default. PyTorch implements some common initializations in torch.nn.init.\n",
				"\n",
				"---\n",
				"\n",
				"pytorch 在linear层将会自动初始化权参、偏参的初始值，通过torch.nn.init 实现。\n",
				"\n",
				"---\n",
				"\n",
				"pytorch linear层 就是affine，实现了一个被称为仿射变换（affine transformation）的操作。\n",
				"$$y=xA^{T} +b$$\n",
				"这里，x是输入，A是层的权重矩阵，b是偏置项，y是输出。这个操作包括了两个主要部分：一个是输入x和权重A的矩阵乘法，另一个是加上偏置b。这种操作确实是一个仿射变换，因为它既有线性映射也有平移。"
			]
		},
		{
			"attachments": {},
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"### torch.optim 优化函数\n",
				"PyTorch implements a number of gradient-based optimization methods in torch.optim, including Gradient Descent.\n",
				"\n",
				"* At the minimum, it takes in the model parameters and a learning rate.\n",
				"\n",
				"* Optimizers do not compute the gradients for you, so you must call backward() yourself.\n",
				"\n",
				"* You also must call the optim.zero_grad() function before calling backward() since by default\n",
				"\n",
				" * PyTorch does and inplace add to the .grad member variable rather than overwriting it.\n",
				"\n",
				"* This does both the detach_() and zero_() calls on all tensor's grad variables."
			]
		},
		{
			"cell_type": "code",
			"execution_count": 7,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"初始的tensor，x_t的shape： torch.Size([20, 1])\n",
						"初始的tensor,y_t的shape： torch.Size([20, 1])\n",
						"numpy转换后的数据x_n,shape (1, 20) 变成了一个元组\n",
						"numpy转换后的数据y_n,shape (1, 20) 变成了一个元组\n",
						"通过一次forwad后得到y predict，其形状是 torch.Size([20, 1])\n",
						"模型中参数： <generator object Module.parameters at 0x000001D70C950EB0>\n",
						"初始权参值: Parameter containing:\n",
						"tensor([[0.0827]], requires_grad=True)\n",
						"初始偏参值: Parameter containing:\n",
						"tensor([-0.1795], requires_grad=True)\n",
						"第 0 次epoch\n",
						"第 1 次梯度下降后\n",
						"模型中权参梯度： tensor([[-368.6832]])\n",
						"模型中偏参梯度 tensor([-107.2979])\n",
						"第 2 次梯度下降后\n",
						"模型中权参梯度： tensor([[-360.7643]])\n",
						"模型中偏参梯度 tensor([-105.0278])\n",
						"第 3 次梯度下降后\n",
						"模型中权参梯度： tensor([[-353.0154]])\n",
						"模型中偏参梯度 tensor([-102.8065])\n",
						"第 4 次梯度下降后\n",
						"模型中权参梯度： tensor([[-345.4327]])\n",
						"模型中偏参梯度 tensor([-100.6329])\n",
						"第 5 次梯度下降后\n",
						"模型中权参梯度： tensor([[-338.0126]])\n",
						"模型中偏参梯度 tensor([-98.5058])\n",
						"第 6 次梯度下降后\n",
						"模型中权参梯度： tensor([[-330.7518]])\n",
						"模型中偏参梯度 tensor([-96.4244])\n",
						"第 7 次梯度下降后\n",
						"模型中权参梯度： tensor([[-323.6467]])\n",
						"模型中偏参梯度 tensor([-94.3876])\n",
						"第 8 次梯度下降后\n",
						"模型中权参梯度： tensor([[-316.6941]])\n",
						"模型中偏参梯度 tensor([-92.3945])\n",
						"第 9 次梯度下降后\n",
						"模型中权参梯度： tensor([[-309.8907]])\n",
						"模型中偏参梯度 tensor([-90.4441])\n",
						"第 10 次梯度下降后\n",
						"模型中权参梯度： tensor([[-303.2332]])\n",
						"模型中偏参梯度 tensor([-88.5356])\n",
						"第 11 次梯度下降后\n",
						"模型中权参梯度： tensor([[-296.7185]])\n",
						"模型中偏参梯度 tensor([-86.6680])\n",
						"第 12 次梯度下降后\n",
						"模型中权参梯度： tensor([[-290.3436]])\n",
						"模型中偏参梯度 tensor([-84.8404])\n",
						"第 13 次梯度下降后\n",
						"模型中权参梯度： tensor([[-284.1055]])\n",
						"模型中偏参梯度 tensor([-83.0521])\n",
						"第 14 次梯度下降后\n",
						"模型中权参梯度： tensor([[-278.0012]])\n",
						"模型中偏参梯度 tensor([-81.3021])\n",
						"第 15 次梯度下降后\n",
						"模型中权参梯度： tensor([[-272.0279]])\n",
						"模型中偏参梯度 tensor([-79.5896])\n",
						"第 16 次梯度下降后\n",
						"模型中权参梯度： tensor([[-266.1827]])\n",
						"模型中偏参梯度 tensor([-77.9139])\n",
						"第 17 次梯度下降后\n",
						"模型中权参梯度： tensor([[-260.4630]])\n",
						"模型中偏参梯度 tensor([-76.2741])\n",
						"第 18 次梯度下降后\n",
						"模型中权参梯度： tensor([[-254.8659]])\n",
						"模型中偏参梯度 tensor([-74.6695])\n",
						"第 19 次梯度下降后\n",
						"模型中权参梯度： tensor([[-249.3889]])\n",
						"模型中偏参梯度 tensor([-73.0993])\n",
						"第 20 次梯度下降后\n",
						"模型中权参梯度： tensor([[-244.0295]])\n",
						"模型中偏参梯度 tensor([-71.5627])\n",
						"第 1 次epoch\n",
						"第 21 次梯度下降后\n",
						"模型中权参梯度： tensor([[-238.7850]])\n",
						"模型中偏参梯度 tensor([-70.0591])\n",
						"第 22 次梯度下降后\n",
						"模型中权参梯度： tensor([[-233.6530]])\n",
						"模型中偏参梯度 tensor([-68.5878])\n",
						"第 23 次梯度下降后\n",
						"模型中权参梯度： tensor([[-228.6312]])\n",
						"模型中偏参梯度 tensor([-67.1480])\n",
						"第 24 次梯度下降后\n",
						"模型中权参梯度： tensor([[-223.7171]])\n",
						"模型中偏参梯度 tensor([-65.7391])\n",
						"第 25 次梯度下降后\n",
						"模型中权参梯度： tensor([[-218.9084]])\n",
						"模型中偏参梯度 tensor([-64.3604])\n",
						"第 26 次梯度下降后\n",
						"模型中权参梯度： tensor([[-214.2029]])\n",
						"模型中偏参梯度 tensor([-63.0112])\n",
						"第 27 次梯度下降后\n",
						"模型中权参梯度： tensor([[-209.5984]])\n",
						"模型中偏参梯度 tensor([-61.6910])\n",
						"第 28 次梯度下降后\n",
						"模型中权参梯度： tensor([[-205.0926]])\n",
						"模型中偏参梯度 tensor([-60.3992])\n",
						"第 29 次梯度下降后\n",
						"模型中权参梯度： tensor([[-200.6835]])\n",
						"模型中偏参梯度 tensor([-59.1350])\n",
						"第 30 次梯度下降后\n",
						"模型中权参梯度： tensor([[-196.3690]])\n",
						"模型中偏参梯度 tensor([-57.8979])\n",
						"第 31 次梯度下降后\n",
						"模型中权参梯度： tensor([[-192.1471]])\n",
						"模型中偏参梯度 tensor([-56.6873])\n",
						"第 32 次梯度下降后\n",
						"模型中权参梯度： tensor([[-188.0157]])\n",
						"模型中偏参梯度 tensor([-55.5027])\n",
						"第 33 次梯度下降后\n",
						"模型中权参梯度： tensor([[-183.9730]])\n",
						"模型中偏参梯度 tensor([-54.3435])\n",
						"第 34 次梯度下降后\n",
						"模型中权参梯度： tensor([[-180.0170]])\n",
						"模型中偏参梯度 tensor([-53.2092])\n",
						"第 35 次梯度下降后\n",
						"模型中权参梯度： tensor([[-176.1459]])\n",
						"模型中偏参梯度 tensor([-52.0992])\n",
						"第 36 次梯度下降后\n",
						"模型中权参梯度： tensor([[-172.3578]])\n",
						"模型中偏参梯度 tensor([-51.0130])\n",
						"第 37 次梯度下降后\n",
						"模型中权参梯度： tensor([[-168.6511]])\n",
						"模型中偏参梯度 tensor([-49.9501])\n",
						"第 38 次梯度下降后\n",
						"模型中权参梯度： tensor([[-165.0238]])\n",
						"模型中偏参梯度 tensor([-48.9099])\n",
						"第 39 次梯度下降后\n",
						"模型中权参梯度： tensor([[-161.4744]])\n",
						"模型中偏参梯度 tensor([-47.8921])\n",
						"第 40 次梯度下降后\n",
						"模型中权参梯度： tensor([[-158.0011]])\n",
						"模型中偏参梯度 tensor([-46.8961])\n",
						"第 2 次epoch\n",
						"第 41 次梯度下降后\n",
						"模型中权参梯度： tensor([[-154.6024]])\n",
						"模型中偏参梯度 tensor([-45.9214])\n",
						"第 42 次梯度下降后\n",
						"模型中权参梯度： tensor([[-151.2766]])\n",
						"模型中偏参梯度 tensor([-44.9677])\n",
						"第 43 次梯度下降后\n",
						"模型中权参梯度： tensor([[-148.0221]])\n",
						"模型中偏参梯度 tensor([-44.0344])\n",
						"第 44 次梯度下降后\n",
						"模型中权参梯度： tensor([[-144.8374]])\n",
						"模型中偏参梯度 tensor([-43.1211])\n",
						"第 45 次梯度下降后\n",
						"模型中权参梯度： tensor([[-141.7211]])\n",
						"模型中偏参梯度 tensor([-42.2274])\n",
						"第 46 次梯度下降后\n",
						"模型中权参梯度： tensor([[-138.6716]])\n",
						"模型中偏参梯度 tensor([-41.3528])\n",
						"第 47 次梯度下降后\n",
						"模型中权参梯度： tensor([[-135.6876]])\n",
						"模型中偏参梯度 tensor([-40.4970])\n",
						"第 48 次梯度下降后\n",
						"模型中权参梯度： tensor([[-132.7676]])\n",
						"模型中偏参梯度 tensor([-39.6596])\n",
						"第 49 次梯度下降后\n",
						"模型中权参梯度： tensor([[-129.9102]])\n",
						"模型中偏参梯度 tensor([-38.8401])\n",
						"第 50 次梯度下降后\n",
						"模型中权参梯度： tensor([[-127.1141]])\n",
						"模型中偏参梯度 tensor([-38.0382])\n",
						"第 51 次梯度下降后\n",
						"模型中权参梯度： tensor([[-124.3781]])\n",
						"模型中偏参梯度 tensor([-37.2534])\n",
						"第 52 次梯度下降后\n",
						"模型中权参梯度： tensor([[-121.7007]])\n",
						"模型中偏参梯度 tensor([-36.4855])\n",
						"第 53 次梯度下降后\n",
						"模型中权参梯度： tensor([[-119.0808]])\n",
						"模型中偏参梯度 tensor([-35.7341])\n",
						"第 54 次梯度下降后\n",
						"模型中权参梯度： tensor([[-116.5171]])\n",
						"模型中偏参梯度 tensor([-34.9987])\n",
						"第 55 次梯度下降后\n",
						"模型中权参梯度： tensor([[-114.0083]])\n",
						"模型中偏参梯度 tensor([-34.2791])\n",
						"第 56 次梯度下降后\n",
						"模型中权参梯度： tensor([[-111.5535]])\n",
						"模型中偏参梯度 tensor([-33.5750])\n",
						"第 57 次梯度下降后\n",
						"模型中权参梯度： tensor([[-109.1513]])\n",
						"模型中偏参梯度 tensor([-32.8859])\n",
						"第 58 次梯度下降后\n",
						"模型中权参梯度： tensor([[-106.8006]])\n",
						"模型中偏参梯度 tensor([-32.2116])\n",
						"第 59 次梯度下降后\n",
						"模型中权参梯度： tensor([[-104.5003]])\n",
						"模型中偏参梯度 tensor([-31.5518])\n",
						"第 60 次梯度下降后\n",
						"模型中权参梯度： tensor([[-102.2495]])\n",
						"模型中偏参梯度 tensor([-30.9061])\n",
						"第 3 次epoch\n",
						"第 61 次梯度下降后\n",
						"模型中权参梯度： tensor([[-100.0469]])\n",
						"模型中偏参梯度 tensor([-30.2743])\n",
						"第 62 次梯度下降后\n",
						"模型中权参梯度： tensor([[-97.8915]])\n",
						"模型中偏参梯度 tensor([-29.6559])\n",
						"第 63 次梯度下降后\n",
						"模型中权参梯度： tensor([[-95.7824]])\n",
						"模型中偏参梯度 tensor([-29.0509])\n",
						"第 64 次梯度下降后\n",
						"模型中权参梯度： tensor([[-93.7186]])\n",
						"模型中偏参梯度 tensor([-28.4588])\n",
						"第 65 次梯度下降后\n",
						"模型中权参梯度： tensor([[-91.6990]])\n",
						"模型中偏参梯度 tensor([-27.8794])\n",
						"第 66 次梯度下降后\n",
						"模型中权参梯度： tensor([[-89.7228]])\n",
						"模型中偏参梯度 tensor([-27.3124])\n",
						"第 67 次梯度下降后\n",
						"模型中权参梯度： tensor([[-87.7890]])\n",
						"模型中偏参梯度 tensor([-26.7576])\n",
						"第 68 次梯度下降后\n",
						"模型中权参梯度： tensor([[-85.8967]])\n",
						"模型中偏参梯度 tensor([-26.2147])\n",
						"第 69 次梯度下降后\n",
						"模型中权参梯度： tensor([[-84.0449]])\n",
						"模型中偏参梯度 tensor([-25.6833])\n",
						"第 70 次梯度下降后\n",
						"模型中权参梯度： tensor([[-82.2329]])\n",
						"模型中偏参梯度 tensor([-25.1634])\n",
						"第 71 次梯度下降后\n",
						"模型中权参梯度： tensor([[-80.4598]])\n",
						"模型中偏参梯度 tensor([-24.6547])\n",
						"第 72 次梯度下降后\n",
						"模型中权参梯度： tensor([[-78.7247]])\n",
						"模型中偏参梯度 tensor([-24.1568])\n",
						"第 73 次梯度下降后\n",
						"模型中权参梯度： tensor([[-77.0269]])\n",
						"模型中偏参梯度 tensor([-23.6696])\n",
						"第 74 次梯度下降后\n",
						"模型中权参梯度： tensor([[-75.3655]])\n",
						"模型中偏参梯度 tensor([-23.1928])\n",
						"第 75 次梯度下降后\n",
						"模型中权参梯度： tensor([[-73.7397]])\n",
						"模型中偏参梯度 tensor([-22.7263])\n",
						"第 76 次梯度下降后\n",
						"模型中权参梯度： tensor([[-72.1488]])\n",
						"模型中偏参梯度 tensor([-22.2697])\n",
						"第 77 次梯度下降后\n",
						"模型中权参梯度： tensor([[-70.5920]])\n",
						"模型中偏参梯度 tensor([-21.8229])\n",
						"第 78 次梯度下降后\n",
						"模型中权参梯度： tensor([[-69.0687]])\n",
						"模型中偏参梯度 tensor([-21.3858])\n",
						"第 79 次梯度下降后\n",
						"模型中权参梯度： tensor([[-67.5780]])\n",
						"模型中偏参梯度 tensor([-20.9579])\n",
						"第 80 次梯度下降后\n",
						"模型中权参梯度： tensor([[-66.1193]])\n",
						"模型中偏参梯度 tensor([-20.5393])\n",
						"第 4 次epoch\n",
						"第 81 次梯度下降后\n",
						"模型中权参梯度： tensor([[-64.6919]])\n",
						"模型中偏参梯度 tensor([-20.1296])\n",
						"第 82 次梯度下降后\n",
						"模型中权参梯度： tensor([[-63.2952]])\n",
						"模型中偏参梯度 tensor([-19.7286])\n",
						"第 83 次梯度下降后\n",
						"模型中权参梯度： tensor([[-61.9284]])\n",
						"模型中偏参梯度 tensor([-19.3363])\n",
						"第 84 次梯度下降后\n",
						"模型中权参梯度： tensor([[-60.5909]])\n",
						"模型中偏参梯度 tensor([-18.9524])\n",
						"第 85 次梯度下降后\n",
						"模型中权参梯度： tensor([[-59.2821]])\n",
						"模型中偏参梯度 tensor([-18.5767])\n",
						"第 86 次梯度下降后\n",
						"模型中权参梯度： tensor([[-58.0015]])\n",
						"模型中偏参梯度 tensor([-18.2090])\n",
						"第 87 次梯度下降后\n",
						"模型中权参梯度： tensor([[-56.7483]])\n",
						"模型中偏参梯度 tensor([-17.8493])\n",
						"第 88 次梯度下降后\n",
						"模型中权参梯度： tensor([[-55.5219]])\n",
						"模型中偏参梯度 tensor([-17.4972])\n",
						"第 89 次梯度下降后\n",
						"模型中权参梯度： tensor([[-54.3219]])\n",
						"模型中偏参梯度 tensor([-17.1527])\n",
						"第 90 次梯度下降后\n",
						"模型中权参梯度： tensor([[-53.1477]])\n",
						"模型中偏参梯度 tensor([-16.8155])\n",
						"第 91 次梯度下降后\n",
						"模型中权参梯度： tensor([[-51.9986]])\n",
						"模型中偏参梯度 tensor([-16.4856])\n",
						"第 92 次梯度下降后\n",
						"模型中权参梯度： tensor([[-50.8742]])\n",
						"模型中偏参梯度 tensor([-16.1627])\n",
						"第 93 次梯度下降后\n",
						"模型中权参梯度： tensor([[-49.7739]])\n",
						"模型中偏参梯度 tensor([-15.8468])\n",
						"第 94 次梯度下降后\n",
						"模型中权参梯度： tensor([[-48.6973]])\n",
						"模型中偏参梯度 tensor([-15.5376])\n",
						"第 95 次梯度下降后\n",
						"模型中权参梯度： tensor([[-47.6437]])\n",
						"模型中偏参梯度 tensor([-15.2350])\n",
						"第 96 次梯度下降后\n",
						"模型中权参梯度： tensor([[-46.6127]])\n",
						"模型中偏参梯度 tensor([-14.9389])\n",
						"第 97 次梯度下降后\n",
						"模型中权参梯度： tensor([[-45.6039]])\n",
						"模型中偏参梯度 tensor([-14.6492])\n",
						"第 98 次梯度下降后\n",
						"模型中权参梯度： tensor([[-44.6167]])\n",
						"模型中偏参梯度 tensor([-14.3657])\n",
						"第 99 次梯度下降后\n",
						"模型中权参梯度： tensor([[-43.6507]])\n",
						"模型中偏参梯度 tensor([-14.0882])\n",
						"第 100 次梯度下降后\n",
						"模型中权参梯度： tensor([[-42.7054]])\n",
						"模型中偏参梯度 tensor([-13.8167])\n",
						"第 5 次epoch\n",
						"第 101 次梯度下降后\n",
						"模型中权参梯度： tensor([[-41.7804]])\n",
						"模型中偏参梯度 tensor([-13.5510])\n",
						"第 102 次梯度下降后\n",
						"模型中权参梯度： tensor([[-40.8753]])\n",
						"模型中偏参梯度 tensor([-13.2909])\n",
						"第 103 次梯度下降后\n",
						"模型中权参梯度： tensor([[-39.9895]])\n",
						"模型中偏参梯度 tensor([-13.0365])\n",
						"第 104 次梯度下降后\n",
						"模型中权参梯度： tensor([[-39.1228]])\n",
						"模型中偏参梯度 tensor([-12.7874])\n",
						"第 105 次梯度下降后\n",
						"模型中权参梯度： tensor([[-38.2747]])\n",
						"模型中偏参梯度 tensor([-12.5438])\n",
						"第 106 次梯度下降后\n",
						"模型中权参梯度： tensor([[-37.4448]])\n",
						"模型中偏参梯度 tensor([-12.3053])\n",
						"第 107 次梯度下降后\n",
						"模型中权参梯度： tensor([[-36.6327]])\n",
						"模型中偏参梯度 tensor([-12.0719])\n",
						"第 108 次梯度下降后\n",
						"模型中权参梯度： tensor([[-35.8380]])\n",
						"模型中偏参梯度 tensor([-11.8436])\n",
						"第 109 次梯度下降后\n",
						"模型中权参梯度： tensor([[-35.0603]])\n",
						"模型中偏参梯度 tensor([-11.6201])\n",
						"第 110 次梯度下降后\n",
						"模型中权参梯度： tensor([[-34.2994]])\n",
						"模型中偏参梯度 tensor([-11.4014])\n",
						"第 111 次梯度下降后\n",
						"模型中权参梯度： tensor([[-33.5548]])\n",
						"模型中偏参梯度 tensor([-11.1874])\n",
						"第 112 次梯度下降后\n",
						"模型中权参梯度： tensor([[-32.8261]])\n",
						"模型中偏参梯度 tensor([-10.9779])\n",
						"第 113 次梯度下降后\n",
						"模型中权参梯度： tensor([[-32.1131]])\n",
						"模型中偏参梯度 tensor([-10.7729])\n",
						"第 114 次梯度下降后\n",
						"模型中权参梯度： tensor([[-31.4154]])\n",
						"模型中偏参梯度 tensor([-10.5724])\n",
						"第 115 次梯度下降后\n",
						"模型中权参梯度： tensor([[-30.7327]])\n",
						"模型中偏参梯度 tensor([-10.3761])\n",
						"第 116 次梯度下降后\n",
						"模型中权参梯度： tensor([[-30.0646]])\n",
						"模型中偏参梯度 tensor([-10.1840])\n",
						"第 117 次梯度下降后\n",
						"模型中权参梯度： tensor([[-29.4108]])\n",
						"模型中偏参梯度 tensor([-9.9960])\n",
						"第 118 次梯度下降后\n",
						"模型中权参梯度： tensor([[-28.7711]])\n",
						"模型中偏参梯度 tensor([-9.8121])\n",
						"第 119 次梯度下降后\n",
						"模型中权参梯度： tensor([[-28.1451]])\n",
						"模型中偏参梯度 tensor([-9.6320])\n",
						"第 120 次梯度下降后\n",
						"模型中权参梯度： tensor([[-27.5326]])\n",
						"模型中偏参梯度 tensor([-9.4559])\n",
						"第 6 次epoch\n",
						"第 121 次梯度下降后\n",
						"模型中权参梯度： tensor([[-26.9332]])\n",
						"模型中偏参梯度 tensor([-9.2835])\n",
						"第 122 次梯度下降后\n",
						"模型中权参梯度： tensor([[-26.3466]])\n",
						"模型中偏参梯度 tensor([-9.1147])\n",
						"第 123 次梯度下降后\n",
						"模型中权参梯度： tensor([[-25.7727]])\n",
						"模型中偏参梯度 tensor([-8.9496])\n",
						"第 124 次梯度下降后\n",
						"模型中权参梯度： tensor([[-25.2110]])\n",
						"模型中偏参梯度 tensor([-8.7880])\n",
						"第 125 次梯度下降后\n",
						"模型中权参梯度： tensor([[-24.6614]])\n",
						"模型中偏参梯度 tensor([-8.6299])\n",
						"第 126 次梯度下降后\n",
						"模型中权参梯度： tensor([[-24.1236]])\n",
						"模型中偏参梯度 tensor([-8.4752])\n",
						"第 127 次梯度下降后\n",
						"模型中权参梯度： tensor([[-23.5974]])\n",
						"模型中偏参梯度 tensor([-8.3237])\n",
						"第 128 次梯度下降后\n",
						"模型中权参梯度： tensor([[-23.0824]])\n",
						"模型中偏参梯度 tensor([-8.1755])\n",
						"第 129 次梯度下降后\n",
						"模型中权参梯度： tensor([[-22.5785]])\n",
						"模型中偏参梯度 tensor([-8.0305])\n",
						"第 130 次梯度下降后\n",
						"模型中权参梯度： tensor([[-22.0854]])\n",
						"模型中偏参梯度 tensor([-7.8885])\n",
						"第 131 次梯度下降后\n",
						"模型中权参梯度： tensor([[-21.6029]])\n",
						"模型中偏参梯度 tensor([-7.7496])\n",
						"第 132 次梯度下降后\n",
						"模型中权参梯度： tensor([[-21.1307]])\n",
						"模型中偏参梯度 tensor([-7.6137])\n",
						"第 133 次梯度下降后\n",
						"模型中权参梯度： tensor([[-20.6687]])\n",
						"模型中偏参梯度 tensor([-7.4807])\n",
						"第 134 次梯度下降后\n",
						"模型中权参梯度： tensor([[-20.2166]])\n",
						"模型中偏参梯度 tensor([-7.3505])\n",
						"第 135 次梯度下降后\n",
						"模型中权参梯度： tensor([[-19.7742]])\n",
						"模型中偏参梯度 tensor([-7.2231])\n",
						"第 136 次梯度下降后\n",
						"模型中权参梯度： tensor([[-19.3413]])\n",
						"模型中偏参梯度 tensor([-7.0984])\n",
						"第 137 次梯度下降后\n",
						"模型中权参梯度： tensor([[-18.9177]])\n",
						"模型中偏参梯度 tensor([-6.9764])\n",
						"第 138 次梯度下降后\n",
						"模型中权参梯度： tensor([[-18.5032]])\n",
						"模型中偏参梯度 tensor([-6.8570])\n",
						"第 139 次梯度下降后\n",
						"模型中权参梯度： tensor([[-18.0976]])\n",
						"模型中偏参梯度 tensor([-6.7401])\n",
						"第 140 次梯度下降后\n",
						"模型中权参梯度： tensor([[-17.7006]])\n",
						"模型中偏参梯度 tensor([-6.6257])\n",
						"第 7 次epoch\n",
						"第 141 次梯度下降后\n",
						"模型中权参梯度： tensor([[-17.3123]])\n",
						"模型中偏参梯度 tensor([-6.5138])\n",
						"第 142 次梯度下降后\n",
						"模型中权参梯度： tensor([[-16.9322]])\n",
						"模型中偏参梯度 tensor([-6.4042])\n",
						"第 143 次梯度下降后\n",
						"模型中权参梯度： tensor([[-16.5603]])\n",
						"模型中偏参梯度 tensor([-6.2970])\n",
						"第 144 次梯度下降后\n",
						"模型中权参梯度： tensor([[-16.1963]])\n",
						"模型中偏参梯度 tensor([-6.1921])\n",
						"第 145 次梯度下降后\n",
						"模型中权参梯度： tensor([[-15.8402]])\n",
						"模型中偏参梯度 tensor([-6.0894])\n",
						"第 146 次梯度下降后\n",
						"模型中权参梯度： tensor([[-15.4917]])\n",
						"模型中偏参梯度 tensor([-5.9890])\n",
						"第 147 次梯度下降后\n",
						"模型中权参梯度： tensor([[-15.1507]])\n",
						"模型中偏参梯度 tensor([-5.8906])\n",
						"第 148 次梯度下降后\n",
						"模型中权参梯度： tensor([[-14.8171]])\n",
						"模型中偏参梯度 tensor([-5.7944])\n",
						"第 149 次梯度下降后\n",
						"模型中权参梯度： tensor([[-14.4906]])\n",
						"模型中偏参梯度 tensor([-5.7002])\n",
						"第 150 次梯度下降后\n",
						"模型中权参梯度： tensor([[-14.1711]])\n",
						"模型中偏参梯度 tensor([-5.6080])\n",
						"第 151 次梯度下降后\n",
						"模型中权参梯度： tensor([[-13.8584]])\n",
						"模型中偏参梯度 tensor([-5.5178])\n",
						"第 152 次梯度下降后\n",
						"模型中权参梯度： tensor([[-13.5525]])\n",
						"模型中偏参梯度 tensor([-5.4295])\n",
						"第 153 次梯度下降后\n",
						"模型中权参梯度： tensor([[-13.2531]])\n",
						"模型中偏参梯度 tensor([-5.3431])\n",
						"第 154 次梯度下降后\n",
						"模型中权参梯度： tensor([[-12.9602]])\n",
						"模型中偏参梯度 tensor([-5.2585])\n",
						"第 155 次梯度下降后\n",
						"模型中权参梯度： tensor([[-12.6735]])\n",
						"模型中偏参梯度 tensor([-5.1757])\n",
						"第 156 次梯度下降后\n",
						"模型中权参梯度： tensor([[-12.3930]])\n",
						"模型中偏参梯度 tensor([-5.0947])\n",
						"第 157 次梯度下降后\n",
						"模型中权参梯度： tensor([[-12.1185]])\n",
						"模型中偏参梯度 tensor([-5.0154])\n",
						"第 158 次梯度下降后\n",
						"模型中权参梯度： tensor([[-11.8499]])\n",
						"模型中偏参梯度 tensor([-4.9378])\n",
						"第 159 次梯度下降后\n",
						"模型中权参梯度： tensor([[-11.5871]])\n",
						"模型中偏参梯度 tensor([-4.8619])\n",
						"第 160 次梯度下降后\n",
						"模型中权参梯度： tensor([[-11.3299]])\n",
						"模型中偏参梯度 tensor([-4.7876])\n",
						"第 8 次epoch\n",
						"第 161 次梯度下降后\n",
						"模型中权参梯度： tensor([[-11.0782]])\n",
						"模型中偏参梯度 tensor([-4.7148])\n",
						"第 162 次梯度下降后\n",
						"模型中权参梯度： tensor([[-10.8320]])\n",
						"模型中偏参梯度 tensor([-4.6436])\n",
						"第 163 次梯度下降后\n",
						"模型中权参梯度： tensor([[-10.5910]])\n",
						"模型中偏参梯度 tensor([-4.5740])\n",
						"第 164 次梯度下降后\n",
						"模型中权参梯度： tensor([[-10.3552]])\n",
						"模型中偏参梯度 tensor([-4.5058])\n",
						"第 165 次梯度下降后\n",
						"模型中权参梯度： tensor([[-10.1245]])\n",
						"模型中偏参梯度 tensor([-4.4390])\n",
						"第 166 次梯度下降后\n",
						"模型中权参梯度： tensor([[-9.8987]])\n",
						"模型中偏参梯度 tensor([-4.3737])\n",
						"第 167 次梯度下降后\n",
						"模型中权参梯度： tensor([[-9.6778]])\n",
						"模型中偏参梯度 tensor([-4.3098])\n",
						"第 168 次梯度下降后\n",
						"模型中权参梯度： tensor([[-9.4616]])\n",
						"模型中偏参梯度 tensor([-4.2472])\n",
						"第 169 次梯度下降后\n",
						"模型中权参梯度： tensor([[-9.2500]])\n",
						"模型中偏参梯度 tensor([-4.1860])\n",
						"第 170 次梯度下降后\n",
						"模型中权参梯度： tensor([[-9.0430]])\n",
						"模型中偏参梯度 tensor([-4.1260])\n",
						"第 171 次梯度下降后\n",
						"模型中权参梯度： tensor([[-8.8404]])\n",
						"模型中偏参梯度 tensor([-4.0674])\n",
						"第 172 次梯度下降后\n",
						"模型中权参梯度： tensor([[-8.6422]])\n",
						"模型中偏参梯度 tensor([-4.0099])\n",
						"第 173 次梯度下降后\n",
						"模型中权参梯度： tensor([[-8.4482]])\n",
						"模型中偏参梯度 tensor([-3.9537])\n",
						"第 174 次梯度下降后\n",
						"模型中权参梯度： tensor([[-8.2585]])\n",
						"模型中偏参梯度 tensor([-3.8987])\n",
						"第 175 次梯度下降后\n",
						"模型中权参梯度： tensor([[-8.0727]])\n",
						"模型中偏参梯度 tensor([-3.8449])\n",
						"第 176 次梯度下降后\n",
						"模型中权参梯度： tensor([[-7.8910]])\n",
						"模型中偏参梯度 tensor([-3.7922])\n",
						"第 177 次梯度下降后\n",
						"模型中权参梯度： tensor([[-7.7132]])\n",
						"模型中偏参梯度 tensor([-3.7406])\n",
						"第 178 次梯度下降后\n",
						"模型中权参梯度： tensor([[-7.5392]])\n",
						"模型中偏参梯度 tensor([-3.6901])\n",
						"第 179 次梯度下降后\n",
						"模型中权参梯度： tensor([[-7.3689]])\n",
						"模型中偏参梯度 tensor([-3.6407])\n",
						"第 180 次梯度下降后\n",
						"模型中权参梯度： tensor([[-7.2023]])\n",
						"模型中偏参梯度 tensor([-3.5924])\n",
						"第 9 次epoch\n",
						"第 181 次梯度下降后\n",
						"模型中权参梯度： tensor([[-7.0393]])\n",
						"模型中偏参梯度 tensor([-3.5450])\n",
						"第 182 次梯度下降后\n",
						"模型中权参梯度： tensor([[-6.8797]])\n",
						"模型中偏参梯度 tensor([-3.4987])\n",
						"第 183 次梯度下降后\n",
						"模型中权参梯度： tensor([[-6.7236]])\n",
						"模型中偏参梯度 tensor([-3.4533])\n",
						"第 184 次梯度下降后\n",
						"模型中权参梯度： tensor([[-6.5709]])\n",
						"模型中偏参梯度 tensor([-3.4090])\n",
						"第 185 次梯度下降后\n",
						"模型中权参梯度： tensor([[-6.4214]])\n",
						"模型中偏参梯度 tensor([-3.3655])\n",
						"第 186 次梯度下降后\n",
						"模型中权参梯度： tensor([[-6.2751]])\n",
						"模型中偏参梯度 tensor([-3.3230])\n",
						"第 187 次梯度下降后\n",
						"模型中权参梯度： tensor([[-6.1320]])\n",
						"模型中偏参梯度 tensor([-3.2813])\n",
						"第 188 次梯度下降后\n",
						"模型中权参梯度： tensor([[-5.9919]])\n",
						"模型中偏参梯度 tensor([-3.2406])\n",
						"第 189 次梯度下降后\n",
						"模型中权参梯度： tensor([[-5.8549]])\n",
						"模型中偏参梯度 tensor([-3.2007])\n",
						"第 190 次梯度下降后\n",
						"模型中权参梯度： tensor([[-5.7208]])\n",
						"模型中偏参梯度 tensor([-3.1617])\n",
						"第 191 次梯度下降后\n",
						"模型中权参梯度： tensor([[-5.5896]])\n",
						"模型中偏参梯度 tensor([-3.1234])\n",
						"第 192 次梯度下降后\n",
						"模型中权参梯度： tensor([[-5.4612]])\n",
						"模型中偏参梯度 tensor([-3.0860])\n",
						"第 193 次梯度下降后\n",
						"模型中权参梯度： tensor([[-5.3355]])\n",
						"模型中偏参梯度 tensor([-3.0494])\n",
						"第 194 次梯度下降后\n",
						"模型中权参梯度： tensor([[-5.2126]])\n",
						"模型中偏参梯度 tensor([-3.0136])\n",
						"第 195 次梯度下降后\n",
						"模型中权参梯度： tensor([[-5.0923]])\n",
						"模型中偏参梯度 tensor([-2.9785])\n",
						"第 196 次梯度下降后\n",
						"模型中权参梯度： tensor([[-4.9746]])\n",
						"模型中偏参梯度 tensor([-2.9441])\n",
						"第 197 次梯度下降后\n",
						"模型中权参梯度： tensor([[-4.8594]])\n",
						"模型中偏参梯度 tensor([-2.9105])\n",
						"第 198 次梯度下降后\n",
						"模型中权参梯度： tensor([[-4.7467]])\n",
						"模型中偏参梯度 tensor([-2.8776])\n",
						"第 199 次梯度下降后\n",
						"模型中权参梯度： tensor([[-4.6363]])\n",
						"模型中偏参梯度 tensor([-2.8454])\n",
						"第 200 次梯度下降后\n",
						"模型中权参梯度： tensor([[-4.5284]])\n",
						"模型中偏参梯度 tensor([-2.8138])\n",
						"第 10 次epoch\n",
						"第 201 次梯度下降后\n",
						"模型中权参梯度： tensor([[-4.4228]])\n",
						"模型中偏参梯度 tensor([-2.7830])\n",
						"第 202 次梯度下降后\n",
						"模型中权参梯度： tensor([[-4.3195]])\n",
						"模型中偏参梯度 tensor([-2.7527])\n",
						"第 203 次梯度下降后\n",
						"模型中权参梯度： tensor([[-4.2183]])\n",
						"模型中偏参梯度 tensor([-2.7232])\n",
						"第 204 次梯度下降后\n",
						"模型中权参梯度： tensor([[-4.1194]])\n",
						"模型中偏参梯度 tensor([-2.6942])\n",
						"第 205 次梯度下降后\n",
						"模型中权参梯度： tensor([[-4.0226]])\n",
						"模型中偏参梯度 tensor([-2.6658])\n",
						"第 206 次梯度下降后\n",
						"模型中权参梯度： tensor([[-3.9278]])\n",
						"模型中偏参梯度 tensor([-2.6381])\n",
						"第 207 次梯度下降后\n",
						"模型中权参梯度： tensor([[-3.8351]])\n",
						"模型中偏参梯度 tensor([-2.6109])\n",
						"第 208 次梯度下降后\n",
						"模型中权参梯度： tensor([[-3.7444]])\n",
						"模型中偏参梯度 tensor([-2.5843])\n",
						"第 209 次梯度下降后\n",
						"模型中权参梯度： tensor([[-3.6557]])\n",
						"模型中偏参梯度 tensor([-2.5583])\n",
						"第 210 次梯度下降后\n",
						"模型中权参梯度： tensor([[-3.5688]])\n",
						"模型中偏参梯度 tensor([-2.5328])\n",
						"第 211 次梯度下降后\n",
						"模型中权参梯度： tensor([[-3.4838]])\n",
						"模型中偏参梯度 tensor([-2.5078])\n",
						"第 212 次梯度下降后\n",
						"模型中权参梯度： tensor([[-3.4007]])\n",
						"模型中偏参梯度 tensor([-2.4834])\n",
						"第 213 次梯度下降后\n",
						"模型中权参梯度： tensor([[-3.3193]])\n",
						"模型中偏参梯度 tensor([-2.4594])\n",
						"第 214 次梯度下降后\n",
						"模型中权参梯度： tensor([[-3.2397]])\n",
						"模型中偏参梯度 tensor([-2.4360])\n",
						"第 215 次梯度下降后\n",
						"模型中权参梯度： tensor([[-3.1617]])\n",
						"模型中偏参梯度 tensor([-2.4131])\n",
						"第 216 次梯度下降后\n",
						"模型中权参梯度： tensor([[-3.0855]])\n",
						"模型中偏参梯度 tensor([-2.3906])\n",
						"第 217 次梯度下降后\n",
						"模型中权参梯度： tensor([[-3.0109]])\n",
						"模型中偏参梯度 tensor([-2.3686])\n",
						"第 218 次梯度下降后\n",
						"模型中权参梯度： tensor([[-2.9379]])\n",
						"模型中偏参梯度 tensor([-2.3471])\n",
						"第 219 次梯度下降后\n",
						"模型中权参梯度： tensor([[-2.8665]])\n",
						"模型中偏参梯度 tensor([-2.3260])\n",
						"第 220 次梯度下降后\n",
						"模型中权参梯度： tensor([[-2.7966]])\n",
						"模型中偏参梯度 tensor([-2.3054])\n",
						"第 11 次epoch\n",
						"第 221 次梯度下降后\n",
						"模型中权参梯度： tensor([[-2.7282]])\n",
						"模型中偏参梯度 tensor([-2.2852])\n",
						"第 222 次梯度下降后\n",
						"模型中权参梯度： tensor([[-2.6613]])\n",
						"模型中偏参梯度 tensor([-2.2654])\n",
						"第 223 次梯度下降后\n",
						"模型中权参梯度： tensor([[-2.5959]])\n",
						"模型中偏参梯度 tensor([-2.2461])\n",
						"第 224 次梯度下降后\n",
						"模型中权参梯度： tensor([[-2.5318]])\n",
						"模型中偏参梯度 tensor([-2.2271])\n",
						"第 225 次梯度下降后\n",
						"模型中权参梯度： tensor([[-2.4691]])\n",
						"模型中偏参梯度 tensor([-2.2085])\n",
						"第 226 次梯度下降后\n",
						"模型中权参梯度： tensor([[-2.4078]])\n",
						"模型中偏参梯度 tensor([-2.1903])\n",
						"第 227 次梯度下降后\n",
						"模型中权参梯度： tensor([[-2.3478]])\n",
						"模型中偏参梯度 tensor([-2.1725])\n",
						"第 228 次梯度下降后\n",
						"模型中权参梯度： tensor([[-2.2890]])\n",
						"模型中偏参梯度 tensor([-2.1551])\n",
						"第 229 次梯度下降后\n",
						"模型中权参梯度： tensor([[-2.2316]])\n",
						"模型中偏参梯度 tensor([-2.1380])\n",
						"第 230 次梯度下降后\n",
						"模型中权参梯度： tensor([[-2.1753]])\n",
						"模型中偏参梯度 tensor([-2.1213])\n",
						"第 231 次梯度下降后\n",
						"模型中权参梯度： tensor([[-2.1203]])\n",
						"模型中偏参梯度 tensor([-2.1049])\n",
						"第 232 次梯度下降后\n",
						"模型中权参梯度： tensor([[-2.0665]])\n",
						"模型中偏参梯度 tensor([-2.0889])\n",
						"第 233 次梯度下降后\n",
						"模型中权参梯度： tensor([[-2.0138]])\n",
						"模型中偏参梯度 tensor([-2.0732])\n",
						"第 234 次梯度下降后\n",
						"模型中权参梯度： tensor([[-1.9623]])\n",
						"模型中偏参梯度 tensor([-2.0578])\n",
						"第 235 次梯度下降后\n",
						"模型中权参梯度： tensor([[-1.9118]])\n",
						"模型中偏参梯度 tensor([-2.0428])\n",
						"第 236 次梯度下降后\n",
						"模型中权参梯度： tensor([[-1.8625]])\n",
						"模型中偏参梯度 tensor([-2.0280])\n",
						"第 237 次梯度下降后\n",
						"模型中权参梯度： tensor([[-1.8142]])\n",
						"模型中偏参梯度 tensor([-2.0136])\n",
						"第 238 次梯度下降后\n",
						"模型中权参梯度： tensor([[-1.7670]])\n",
						"模型中偏参梯度 tensor([-1.9995])\n",
						"第 239 次梯度下降后\n",
						"模型中权参梯度： tensor([[-1.7207]])\n",
						"模型中偏参梯度 tensor([-1.9856])\n",
						"第 240 次梯度下降后\n",
						"模型中权参梯度： tensor([[-1.6755]])\n",
						"模型中偏参梯度 tensor([-1.9721])\n",
						"第 12 次epoch\n",
						"第 241 次梯度下降后\n",
						"模型中权参梯度： tensor([[-1.6313]])\n",
						"模型中偏参梯度 tensor([-1.9588])\n",
						"第 242 次梯度下降后\n",
						"模型中权参梯度： tensor([[-1.5880]])\n",
						"模型中偏参梯度 tensor([-1.9458])\n",
						"第 243 次梯度下降后\n",
						"模型中权参梯度： tensor([[-1.5456]])\n",
						"模型中偏参梯度 tensor([-1.9330])\n",
						"第 244 次梯度下降后\n",
						"模型中权参梯度： tensor([[-1.5041]])\n",
						"模型中偏参梯度 tensor([-1.9205])\n",
						"第 245 次梯度下降后\n",
						"模型中权参梯度： tensor([[-1.4635]])\n",
						"模型中偏参梯度 tensor([-1.9083])\n",
						"第 246 次梯度下降后\n",
						"模型中权参梯度： tensor([[-1.4238]])\n",
						"模型中偏参梯度 tensor([-1.8963])\n",
						"第 247 次梯度下降后\n",
						"模型中权参梯度： tensor([[-1.3850]])\n",
						"模型中偏参梯度 tensor([-1.8846])\n",
						"第 248 次梯度下降后\n",
						"模型中权参梯度： tensor([[-1.3470]])\n",
						"模型中偏参梯度 tensor([-1.8731])\n",
						"第 249 次梯度下降后\n",
						"模型中权参梯度： tensor([[-1.3098]])\n",
						"模型中偏参梯度 tensor([-1.8619])\n",
						"第 250 次梯度下降后\n",
						"模型中权参梯度： tensor([[-1.2734]])\n",
						"模型中偏参梯度 tensor([-1.8508])\n",
						"第 251 次梯度下降后\n",
						"模型中权参梯度： tensor([[-1.2378]])\n",
						"模型中偏参梯度 tensor([-1.8400])\n",
						"第 252 次梯度下降后\n",
						"模型中权参梯度： tensor([[-1.2029]])\n",
						"模型中偏参梯度 tensor([-1.8294])\n",
						"第 253 次梯度下降后\n",
						"模型中权参梯度： tensor([[-1.1688]])\n",
						"模型中偏参梯度 tensor([-1.8191])\n",
						"第 254 次梯度下降后\n",
						"模型中权参梯度： tensor([[-1.1355]])\n",
						"模型中偏参梯度 tensor([-1.8089])\n",
						"第 255 次梯度下降后\n",
						"模型中权参梯度： tensor([[-1.1029]])\n",
						"模型中偏参梯度 tensor([-1.7990])\n",
						"第 256 次梯度下降后\n",
						"模型中权参梯度： tensor([[-1.0709]])\n",
						"模型中偏参梯度 tensor([-1.7892])\n",
						"第 257 次梯度下降后\n",
						"模型中权参梯度： tensor([[-1.0397]])\n",
						"模型中偏参梯度 tensor([-1.7797])\n",
						"第 258 次梯度下降后\n",
						"模型中权参梯度： tensor([[-1.0092]])\n",
						"模型中偏参梯度 tensor([-1.7703])\n",
						"第 259 次梯度下降后\n",
						"模型中权参梯度： tensor([[-0.9793]])\n",
						"模型中偏参梯度 tensor([-1.7612])\n",
						"第 260 次梯度下降后\n",
						"模型中权参梯度： tensor([[-0.9500]])\n",
						"模型中偏参梯度 tensor([-1.7522])\n",
						"第 13 次epoch\n",
						"第 261 次梯度下降后\n",
						"模型中权参梯度： tensor([[-0.9214]])\n",
						"模型中偏参梯度 tensor([-1.7434])\n",
						"第 262 次梯度下降后\n",
						"模型中权参梯度： tensor([[-0.8934]])\n",
						"模型中偏参梯度 tensor([-1.7348])\n",
						"第 263 次梯度下降后\n",
						"模型中权参梯度： tensor([[-0.8660]])\n",
						"模型中偏参梯度 tensor([-1.7263])\n",
						"第 264 次梯度下降后\n",
						"模型中权参梯度： tensor([[-0.8391]])\n",
						"模型中偏参梯度 tensor([-1.7180])\n",
						"第 265 次梯度下降后\n",
						"模型中权参梯度： tensor([[-0.8129]])\n",
						"模型中偏参梯度 tensor([-1.7099])\n",
						"第 266 次梯度下降后\n",
						"模型中权参梯度： tensor([[-0.7872]])\n",
						"模型中偏参梯度 tensor([-1.7020])\n",
						"第 267 次梯度下降后\n",
						"模型中权参梯度： tensor([[-0.7621]])\n",
						"模型中偏参梯度 tensor([-1.6942])\n",
						"第 268 次梯度下降后\n",
						"模型中权参梯度： tensor([[-0.7375]])\n",
						"模型中偏参梯度 tensor([-1.6865])\n",
						"第 269 次梯度下降后\n",
						"模型中权参梯度： tensor([[-0.7135]])\n",
						"模型中偏参梯度 tensor([-1.6791])\n",
						"第 270 次梯度下降后\n",
						"模型中权参梯度： tensor([[-0.6899]])\n",
						"模型中偏参梯度 tensor([-1.6717])\n",
						"第 271 次梯度下降后\n",
						"模型中权参梯度： tensor([[-0.6669]])\n",
						"模型中偏参梯度 tensor([-1.6645])\n",
						"第 272 次梯度下降后\n",
						"模型中权参梯度： tensor([[-0.6444]])\n",
						"模型中偏参梯度 tensor([-1.6575])\n",
						"第 273 次梯度下降后\n",
						"模型中权参梯度： tensor([[-0.6223]])\n",
						"模型中偏参梯度 tensor([-1.6506])\n",
						"第 274 次梯度下降后\n",
						"模型中权参梯度： tensor([[-0.6008]])\n",
						"模型中偏参梯度 tensor([-1.6438])\n",
						"第 275 次梯度下降后\n",
						"模型中权参梯度： tensor([[-0.5797]])\n",
						"模型中偏参梯度 tensor([-1.6372])\n",
						"第 276 次梯度下降后\n",
						"模型中权参梯度： tensor([[-0.5591]])\n",
						"模型中偏参梯度 tensor([-1.6307])\n",
						"第 277 次梯度下降后\n",
						"模型中权参梯度： tensor([[-0.5389]])\n",
						"模型中偏参梯度 tensor([-1.6243])\n",
						"第 278 次梯度下降后\n",
						"模型中权参梯度： tensor([[-0.5191]])\n",
						"模型中偏参梯度 tensor([-1.6180])\n",
						"第 279 次梯度下降后\n",
						"模型中权参梯度： tensor([[-0.4998]])\n",
						"模型中偏参梯度 tensor([-1.6119])\n",
						"第 280 次梯度下降后\n",
						"模型中权参梯度： tensor([[-0.4809]])\n",
						"模型中偏参梯度 tensor([-1.6059])\n",
						"第 14 次epoch\n",
						"第 281 次梯度下降后\n",
						"模型中权参梯度： tensor([[-0.4624]])\n",
						"模型中偏参梯度 tensor([-1.6000])\n",
						"第 282 次梯度下降后\n",
						"模型中权参梯度： tensor([[-0.4443]])\n",
						"模型中偏参梯度 tensor([-1.5942])\n",
						"第 283 次梯度下降后\n",
						"模型中权参梯度： tensor([[-0.4266]])\n",
						"模型中偏参梯度 tensor([-1.5886])\n",
						"第 284 次梯度下降后\n",
						"模型中权参梯度： tensor([[-0.4092]])\n",
						"模型中偏参梯度 tensor([-1.5830])\n",
						"第 285 次梯度下降后\n",
						"模型中权参梯度： tensor([[-0.3923]])\n",
						"模型中偏参梯度 tensor([-1.5775])\n",
						"第 286 次梯度下降后\n",
						"模型中权参梯度： tensor([[-0.3757]])\n",
						"模型中偏参梯度 tensor([-1.5722])\n",
						"第 287 次梯度下降后\n",
						"模型中权参梯度： tensor([[-0.3594]])\n",
						"模型中偏参梯度 tensor([-1.5670])\n",
						"第 288 次梯度下降后\n",
						"模型中权参梯度： tensor([[-0.3436]])\n",
						"模型中偏参梯度 tensor([-1.5618])\n",
						"第 289 次梯度下降后\n",
						"模型中权参梯度： tensor([[-0.3281]])\n",
						"模型中偏参梯度 tensor([-1.5568])\n",
						"第 290 次梯度下降后\n",
						"模型中权参梯度： tensor([[-0.3129]])\n",
						"模型中偏参梯度 tensor([-1.5518])\n",
						"第 291 次梯度下降后\n",
						"模型中权参梯度： tensor([[-0.2980]])\n",
						"模型中偏参梯度 tensor([-1.5470])\n",
						"第 292 次梯度下降后\n",
						"模型中权参梯度： tensor([[-0.2835]])\n",
						"模型中偏参梯度 tensor([-1.5422])\n",
						"第 293 次梯度下降后\n",
						"模型中权参梯度： tensor([[-0.2692]])\n",
						"模型中偏参梯度 tensor([-1.5376])\n",
						"第 294 次梯度下降后\n",
						"模型中权参梯度： tensor([[-0.2553]])\n",
						"模型中偏参梯度 tensor([-1.5330])\n",
						"第 295 次梯度下降后\n",
						"模型中权参梯度： tensor([[-0.2417]])\n",
						"模型中偏参梯度 tensor([-1.5285])\n",
						"第 296 次梯度下降后\n",
						"模型中权参梯度： tensor([[-0.2284]])\n",
						"模型中偏参梯度 tensor([-1.5241])\n",
						"第 297 次梯度下降后\n",
						"模型中权参梯度： tensor([[-0.2153]])\n",
						"模型中偏参梯度 tensor([-1.5198])\n",
						"第 298 次梯度下降后\n",
						"模型中权参梯度： tensor([[-0.2026]])\n",
						"模型中偏参梯度 tensor([-1.5155])\n",
						"第 299 次梯度下降后\n",
						"模型中权参梯度： tensor([[-0.1901]])\n",
						"模型中偏参梯度 tensor([-1.5114])\n",
						"第 300 次梯度下降后\n",
						"模型中权参梯度： tensor([[-0.1779]])\n",
						"模型中偏参梯度 tensor([-1.5073])\n",
						"第 15 次epoch\n",
						"第 301 次梯度下降后\n",
						"模型中权参梯度： tensor([[-0.1660]])\n",
						"模型中偏参梯度 tensor([-1.5033])\n",
						"第 302 次梯度下降后\n",
						"模型中权参梯度： tensor([[-0.1543]])\n",
						"模型中偏参梯度 tensor([-1.4994])\n",
						"第 303 次梯度下降后\n",
						"模型中权参梯度： tensor([[-0.1429]])\n",
						"模型中偏参梯度 tensor([-1.4955])\n",
						"第 304 次梯度下降后\n",
						"模型中权参梯度： tensor([[-0.1317]])\n",
						"模型中偏参梯度 tensor([-1.4917])\n",
						"第 305 次梯度下降后\n",
						"模型中权参梯度： tensor([[-0.1208]])\n",
						"模型中偏参梯度 tensor([-1.4880])\n",
						"第 306 次梯度下降后\n",
						"模型中权参梯度： tensor([[-0.1101]])\n",
						"模型中偏参梯度 tensor([-1.4843])\n",
						"第 307 次梯度下降后\n",
						"模型中权参梯度： tensor([[-0.0996]])\n",
						"模型中偏参梯度 tensor([-1.4808])\n",
						"第 308 次梯度下降后\n",
						"模型中权参梯度： tensor([[-0.0894]])\n",
						"模型中偏参梯度 tensor([-1.4772])\n",
						"第 309 次梯度下降后\n",
						"模型中权参梯度： tensor([[-0.0794]])\n",
						"模型中偏参梯度 tensor([-1.4738])\n",
						"第 310 次梯度下降后\n",
						"模型中权参梯度： tensor([[-0.0696]])\n",
						"模型中偏参梯度 tensor([-1.4704])\n",
						"第 311 次梯度下降后\n",
						"模型中权参梯度： tensor([[-0.0600]])\n",
						"模型中偏参梯度 tensor([-1.4671])\n",
						"第 312 次梯度下降后\n",
						"模型中权参梯度： tensor([[-0.0506]])\n",
						"模型中偏参梯度 tensor([-1.4638])\n",
						"第 313 次梯度下降后\n",
						"模型中权参梯度： tensor([[-0.0415]])\n",
						"模型中偏参梯度 tensor([-1.4606])\n",
						"第 314 次梯度下降后\n",
						"模型中权参梯度： tensor([[-0.0325]])\n",
						"模型中偏参梯度 tensor([-1.4574])\n",
						"第 315 次梯度下降后\n",
						"模型中权参梯度： tensor([[-0.0237]])\n",
						"模型中偏参梯度 tensor([-1.4543])\n",
						"第 316 次梯度下降后\n",
						"模型中权参梯度： tensor([[-0.0152]])\n",
						"模型中偏参梯度 tensor([-1.4513])\n",
						"第 317 次梯度下降后\n",
						"模型中权参梯度： tensor([[-0.0068]])\n",
						"模型中偏参梯度 tensor([-1.4483])\n",
						"第 318 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0015]])\n",
						"模型中偏参梯度 tensor([-1.4454])\n",
						"第 319 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0095]])\n",
						"模型中偏参梯度 tensor([-1.4425])\n",
						"第 320 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0173]])\n",
						"模型中偏参梯度 tensor([-1.4397])\n",
						"第 16 次epoch\n",
						"第 321 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0250]])\n",
						"模型中偏参梯度 tensor([-1.4369])\n",
						"第 322 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0325]])\n",
						"模型中偏参梯度 tensor([-1.4342])\n",
						"第 323 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0399]])\n",
						"模型中偏参梯度 tensor([-1.4315])\n",
						"第 324 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0471]])\n",
						"模型中偏参梯度 tensor([-1.4288])\n",
						"第 325 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0541]])\n",
						"模型中偏参梯度 tensor([-1.4262])\n",
						"第 326 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0610]])\n",
						"模型中偏参梯度 tensor([-1.4237])\n",
						"第 327 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0677]])\n",
						"模型中偏参梯度 tensor([-1.4212])\n",
						"第 328 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0743]])\n",
						"模型中偏参梯度 tensor([-1.4187])\n",
						"第 329 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0807]])\n",
						"模型中偏参梯度 tensor([-1.4163])\n",
						"第 330 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0870]])\n",
						"模型中偏参梯度 tensor([-1.4139])\n",
						"第 331 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0932]])\n",
						"模型中偏参梯度 tensor([-1.4116])\n",
						"第 332 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0992]])\n",
						"模型中偏参梯度 tensor([-1.4093])\n",
						"第 333 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1051]])\n",
						"模型中偏参梯度 tensor([-1.4070])\n",
						"第 334 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1108]])\n",
						"模型中偏参梯度 tensor([-1.4048])\n",
						"第 335 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1165]])\n",
						"模型中偏参梯度 tensor([-1.4026])\n",
						"第 336 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1220]])\n",
						"模型中偏参梯度 tensor([-1.4004])\n",
						"第 337 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1274]])\n",
						"模型中偏参梯度 tensor([-1.3983])\n",
						"第 338 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1326]])\n",
						"模型中偏参梯度 tensor([-1.3962])\n",
						"第 339 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1378]])\n",
						"模型中偏参梯度 tensor([-1.3942])\n",
						"第 340 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1428]])\n",
						"模型中偏参梯度 tensor([-1.3921])\n",
						"第 17 次epoch\n",
						"第 341 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1477]])\n",
						"模型中偏参梯度 tensor([-1.3901])\n",
						"第 342 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1526]])\n",
						"模型中偏参梯度 tensor([-1.3882])\n",
						"第 343 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1573]])\n",
						"模型中偏参梯度 tensor([-1.3863])\n",
						"第 344 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1619]])\n",
						"模型中偏参梯度 tensor([-1.3844])\n",
						"第 345 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1664]])\n",
						"模型中偏参梯度 tensor([-1.3825])\n",
						"第 346 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1708]])\n",
						"模型中偏参梯度 tensor([-1.3807])\n",
						"第 347 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1751]])\n",
						"模型中偏参梯度 tensor([-1.3789])\n",
						"第 348 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1793]])\n",
						"模型中偏参梯度 tensor([-1.3771])\n",
						"第 349 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1834]])\n",
						"模型中偏参梯度 tensor([-1.3753])\n",
						"第 350 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1874]])\n",
						"模型中偏参梯度 tensor([-1.3736])\n",
						"第 351 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1914]])\n",
						"模型中偏参梯度 tensor([-1.3719])\n",
						"第 352 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1953]])\n",
						"模型中偏参梯度 tensor([-1.3702])\n",
						"第 353 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1990]])\n",
						"模型中偏参梯度 tensor([-1.3685])\n",
						"第 354 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2027]])\n",
						"模型中偏参梯度 tensor([-1.3669])\n",
						"第 355 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2063]])\n",
						"模型中偏参梯度 tensor([-1.3653])\n",
						"第 356 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2098]])\n",
						"模型中偏参梯度 tensor([-1.3637])\n",
						"第 357 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2133]])\n",
						"模型中偏参梯度 tensor([-1.3622])\n",
						"第 358 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2166]])\n",
						"模型中偏参梯度 tensor([-1.3606])\n",
						"第 359 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2199]])\n",
						"模型中偏参梯度 tensor([-1.3591])\n",
						"第 360 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2231]])\n",
						"模型中偏参梯度 tensor([-1.3576])\n",
						"第 18 次epoch\n",
						"第 361 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2263]])\n",
						"模型中偏参梯度 tensor([-1.3562])\n",
						"第 362 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2293]])\n",
						"模型中偏参梯度 tensor([-1.3547])\n",
						"第 363 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2323]])\n",
						"模型中偏参梯度 tensor([-1.3533])\n",
						"第 364 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2352]])\n",
						"模型中偏参梯度 tensor([-1.3519])\n",
						"第 365 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2381]])\n",
						"模型中偏参梯度 tensor([-1.3505])\n",
						"第 366 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2409]])\n",
						"模型中偏参梯度 tensor([-1.3491])\n",
						"第 367 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2437]])\n",
						"模型中偏参梯度 tensor([-1.3477])\n",
						"第 368 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2463]])\n",
						"模型中偏参梯度 tensor([-1.3464])\n",
						"第 369 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2490]])\n",
						"模型中偏参梯度 tensor([-1.3451])\n",
						"第 370 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2515]])\n",
						"模型中偏参梯度 tensor([-1.3438])\n",
						"第 371 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2540]])\n",
						"模型中偏参梯度 tensor([-1.3425])\n",
						"第 372 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2564]])\n",
						"模型中偏参梯度 tensor([-1.3412])\n",
						"第 373 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2588]])\n",
						"模型中偏参梯度 tensor([-1.3400])\n",
						"第 374 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2612]])\n",
						"模型中偏参梯度 tensor([-1.3387])\n",
						"第 375 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2634]])\n",
						"模型中偏参梯度 tensor([-1.3375])\n",
						"第 376 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2657]])\n",
						"模型中偏参梯度 tensor([-1.3363])\n",
						"第 377 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2678]])\n",
						"模型中偏参梯度 tensor([-1.3351])\n",
						"第 378 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2700]])\n",
						"模型中偏参梯度 tensor([-1.3339])\n",
						"第 379 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2720]])\n",
						"模型中偏参梯度 tensor([-1.3328])\n",
						"第 380 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2741]])\n",
						"模型中偏参梯度 tensor([-1.3316])\n",
						"第 19 次epoch\n",
						"第 381 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2760]])\n",
						"模型中偏参梯度 tensor([-1.3305])\n",
						"第 382 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2780]])\n",
						"模型中偏参梯度 tensor([-1.3294])\n",
						"第 383 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2798]])\n",
						"模型中偏参梯度 tensor([-1.3283])\n",
						"第 384 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2817]])\n",
						"模型中偏参梯度 tensor([-1.3272])\n",
						"第 385 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2835]])\n",
						"模型中偏参梯度 tensor([-1.3261])\n",
						"第 386 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2852]])\n",
						"模型中偏参梯度 tensor([-1.3250])\n",
						"第 387 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2869]])\n",
						"模型中偏参梯度 tensor([-1.3240])\n",
						"第 388 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2886]])\n",
						"模型中偏参梯度 tensor([-1.3229])\n",
						"第 389 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2903]])\n",
						"模型中偏参梯度 tensor([-1.3219])\n",
						"第 390 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2919]])\n",
						"模型中偏参梯度 tensor([-1.3209])\n",
						"第 391 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2935]])\n",
						"模型中偏参梯度 tensor([-1.3198])\n",
						"第 392 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2950]])\n",
						"模型中偏参梯度 tensor([-1.3188])\n",
						"第 393 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2965]])\n",
						"模型中偏参梯度 tensor([-1.3179])\n",
						"第 394 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2979]])\n",
						"模型中偏参梯度 tensor([-1.3169])\n",
						"第 395 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2994]])\n",
						"模型中偏参梯度 tensor([-1.3159])\n",
						"第 396 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3008]])\n",
						"模型中偏参梯度 tensor([-1.3149])\n",
						"第 397 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3021]])\n",
						"模型中偏参梯度 tensor([-1.3140])\n",
						"第 398 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3035]])\n",
						"模型中偏参梯度 tensor([-1.3130])\n",
						"第 399 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3048]])\n",
						"模型中偏参梯度 tensor([-1.3121])\n",
						"第 400 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3060]])\n",
						"模型中偏参梯度 tensor([-1.3112])\n",
						"第 20 次epoch\n",
						"第 401 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3073]])\n",
						"模型中偏参梯度 tensor([-1.3103])\n",
						"第 402 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3085]])\n",
						"模型中偏参梯度 tensor([-1.3093])\n",
						"第 403 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3096]])\n",
						"模型中偏参梯度 tensor([-1.3084])\n",
						"第 404 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3108]])\n",
						"模型中偏参梯度 tensor([-1.3076])\n",
						"第 405 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3119]])\n",
						"模型中偏参梯度 tensor([-1.3067])\n",
						"第 406 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3130]])\n",
						"模型中偏参梯度 tensor([-1.3058])\n",
						"第 407 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3141]])\n",
						"模型中偏参梯度 tensor([-1.3049])\n",
						"第 408 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3151]])\n",
						"模型中偏参梯度 tensor([-1.3041])\n",
						"第 409 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3161]])\n",
						"模型中偏参梯度 tensor([-1.3032])\n",
						"第 410 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3171]])\n",
						"模型中偏参梯度 tensor([-1.3024])\n",
						"第 411 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3181]])\n",
						"模型中偏参梯度 tensor([-1.3015])\n",
						"第 412 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3190]])\n",
						"模型中偏参梯度 tensor([-1.3007])\n",
						"第 413 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3199]])\n",
						"模型中偏参梯度 tensor([-1.2999])\n",
						"第 414 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3208]])\n",
						"模型中偏参梯度 tensor([-1.2991])\n",
						"第 415 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3217]])\n",
						"模型中偏参梯度 tensor([-1.2983])\n",
						"第 416 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3225]])\n",
						"模型中偏参梯度 tensor([-1.2975])\n",
						"第 417 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3234]])\n",
						"模型中偏参梯度 tensor([-1.2967])\n",
						"第 418 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3241]])\n",
						"模型中偏参梯度 tensor([-1.2959])\n",
						"第 419 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3249]])\n",
						"模型中偏参梯度 tensor([-1.2951])\n",
						"第 420 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3257]])\n",
						"模型中偏参梯度 tensor([-1.2943])\n",
						"第 21 次epoch\n",
						"第 421 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3264]])\n",
						"模型中偏参梯度 tensor([-1.2935])\n",
						"第 422 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3272]])\n",
						"模型中偏参梯度 tensor([-1.2928])\n",
						"第 423 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3279]])\n",
						"模型中偏参梯度 tensor([-1.2920])\n",
						"第 424 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3286]])\n",
						"模型中偏参梯度 tensor([-1.2913])\n",
						"第 425 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3292]])\n",
						"模型中偏参梯度 tensor([-1.2905])\n",
						"第 426 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3299]])\n",
						"模型中偏参梯度 tensor([-1.2898])\n",
						"第 427 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3305]])\n",
						"模型中偏参梯度 tensor([-1.2890])\n",
						"第 428 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3312]])\n",
						"模型中偏参梯度 tensor([-1.2883])\n",
						"第 429 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3318]])\n",
						"模型中偏参梯度 tensor([-1.2876])\n",
						"第 430 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3323]])\n",
						"模型中偏参梯度 tensor([-1.2868])\n",
						"第 431 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3329]])\n",
						"模型中偏参梯度 tensor([-1.2861])\n",
						"第 432 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3335]])\n",
						"模型中偏参梯度 tensor([-1.2854])\n",
						"第 433 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3340]])\n",
						"模型中偏参梯度 tensor([-1.2847])\n",
						"第 434 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3345]])\n",
						"模型中偏参梯度 tensor([-1.2840])\n",
						"第 435 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3351]])\n",
						"模型中偏参梯度 tensor([-1.2833])\n",
						"第 436 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3356]])\n",
						"模型中偏参梯度 tensor([-1.2826])\n",
						"第 437 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3361]])\n",
						"模型中偏参梯度 tensor([-1.2819])\n",
						"第 438 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3365]])\n",
						"模型中偏参梯度 tensor([-1.2812])\n",
						"第 439 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3370]])\n",
						"模型中偏参梯度 tensor([-1.2805])\n",
						"第 440 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3374]])\n",
						"模型中偏参梯度 tensor([-1.2798])\n",
						"第 22 次epoch\n",
						"第 441 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3379]])\n",
						"模型中偏参梯度 tensor([-1.2792])\n",
						"第 442 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3383]])\n",
						"模型中偏参梯度 tensor([-1.2785])\n",
						"第 443 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3387]])\n",
						"模型中偏参梯度 tensor([-1.2778])\n",
						"第 444 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3391]])\n",
						"模型中偏参梯度 tensor([-1.2771])\n",
						"第 445 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3395]])\n",
						"模型中偏参梯度 tensor([-1.2765])\n",
						"第 446 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3399]])\n",
						"模型中偏参梯度 tensor([-1.2758])\n",
						"第 447 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3402]])\n",
						"模型中偏参梯度 tensor([-1.2752])\n",
						"第 448 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3406]])\n",
						"模型中偏参梯度 tensor([-1.2745])\n",
						"第 449 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3409]])\n",
						"模型中偏参梯度 tensor([-1.2739])\n",
						"第 450 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3412]])\n",
						"模型中偏参梯度 tensor([-1.2732])\n",
						"第 451 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3416]])\n",
						"模型中偏参梯度 tensor([-1.2726])\n",
						"第 452 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3419]])\n",
						"模型中偏参梯度 tensor([-1.2719])\n",
						"第 453 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3422]])\n",
						"模型中偏参梯度 tensor([-1.2713])\n",
						"第 454 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3425]])\n",
						"模型中偏参梯度 tensor([-1.2706])\n",
						"第 455 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3428]])\n",
						"模型中偏参梯度 tensor([-1.2700])\n",
						"第 456 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3430]])\n",
						"模型中偏参梯度 tensor([-1.2694])\n",
						"第 457 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3433]])\n",
						"模型中偏参梯度 tensor([-1.2688])\n",
						"第 458 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3436]])\n",
						"模型中偏参梯度 tensor([-1.2681])\n",
						"第 459 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3438]])\n",
						"模型中偏参梯度 tensor([-1.2675])\n",
						"第 460 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3440]])\n",
						"模型中偏参梯度 tensor([-1.2669])\n",
						"第 23 次epoch\n",
						"第 461 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3443]])\n",
						"模型中偏参梯度 tensor([-1.2663])\n",
						"第 462 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3445]])\n",
						"模型中偏参梯度 tensor([-1.2657])\n",
						"第 463 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3447]])\n",
						"模型中偏参梯度 tensor([-1.2651])\n",
						"第 464 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3449]])\n",
						"模型中偏参梯度 tensor([-1.2645])\n",
						"第 465 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3451]])\n",
						"模型中偏参梯度 tensor([-1.2639])\n",
						"第 466 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3453]])\n",
						"模型中偏参梯度 tensor([-1.2633])\n",
						"第 467 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3455]])\n",
						"模型中偏参梯度 tensor([-1.2627])\n",
						"第 468 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3457]])\n",
						"模型中偏参梯度 tensor([-1.2621])\n",
						"第 469 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3458]])\n",
						"模型中偏参梯度 tensor([-1.2615])\n",
						"第 470 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3460]])\n",
						"模型中偏参梯度 tensor([-1.2609])\n",
						"第 471 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3462]])\n",
						"模型中偏参梯度 tensor([-1.2603])\n",
						"第 472 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3463]])\n",
						"模型中偏参梯度 tensor([-1.2597])\n",
						"第 473 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3465]])\n",
						"模型中偏参梯度 tensor([-1.2591])\n",
						"第 474 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3466]])\n",
						"模型中偏参梯度 tensor([-1.2585])\n",
						"第 475 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3467]])\n",
						"模型中偏参梯度 tensor([-1.2579])\n",
						"第 476 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3468]])\n",
						"模型中偏参梯度 tensor([-1.2573])\n",
						"第 477 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3469]])\n",
						"模型中偏参梯度 tensor([-1.2568])\n",
						"第 478 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3471]])\n",
						"模型中偏参梯度 tensor([-1.2562])\n",
						"第 479 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3472]])\n",
						"模型中偏参梯度 tensor([-1.2556])\n",
						"第 480 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3473]])\n",
						"模型中偏参梯度 tensor([-1.2550])\n",
						"第 24 次epoch\n",
						"第 481 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3474]])\n",
						"模型中偏参梯度 tensor([-1.2545])\n",
						"第 482 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3475]])\n",
						"模型中偏参梯度 tensor([-1.2539])\n",
						"第 483 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3476]])\n",
						"模型中偏参梯度 tensor([-1.2533])\n",
						"第 484 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3477]])\n",
						"模型中偏参梯度 tensor([-1.2527])\n",
						"第 485 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3478]])\n",
						"模型中偏参梯度 tensor([-1.2522])\n",
						"第 486 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3478]])\n",
						"模型中偏参梯度 tensor([-1.2516])\n",
						"第 487 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3479]])\n",
						"模型中偏参梯度 tensor([-1.2510])\n",
						"第 488 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3480]])\n",
						"模型中偏参梯度 tensor([-1.2505])\n",
						"第 489 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3481]])\n",
						"模型中偏参梯度 tensor([-1.2499])\n",
						"第 490 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3482]])\n",
						"模型中偏参梯度 tensor([-1.2493])\n",
						"第 491 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3482]])\n",
						"模型中偏参梯度 tensor([-1.2488])\n",
						"第 492 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3482]])\n",
						"模型中偏参梯度 tensor([-1.2482])\n",
						"第 493 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3483]])\n",
						"模型中偏参梯度 tensor([-1.2477])\n",
						"第 494 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3483]])\n",
						"模型中偏参梯度 tensor([-1.2471])\n",
						"第 495 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3483]])\n",
						"模型中偏参梯度 tensor([-1.2466])\n",
						"第 496 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3483]])\n",
						"模型中偏参梯度 tensor([-1.2460])\n",
						"第 497 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3483]])\n",
						"模型中偏参梯度 tensor([-1.2455])\n",
						"第 498 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3484]])\n",
						"模型中偏参梯度 tensor([-1.2449])\n",
						"第 499 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3484]])\n",
						"模型中偏参梯度 tensor([-1.2444])\n",
						"第 500 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3484]])\n",
						"模型中偏参梯度 tensor([-1.2439])\n",
						"第 25 次epoch\n",
						"第 501 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3484]])\n",
						"模型中偏参梯度 tensor([-1.2433])\n",
						"第 502 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3484]])\n",
						"模型中偏参梯度 tensor([-1.2428])\n",
						"第 503 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3484]])\n",
						"模型中偏参梯度 tensor([-1.2422])\n",
						"第 504 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3484]])\n",
						"模型中偏参梯度 tensor([-1.2417])\n",
						"第 505 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3484]])\n",
						"模型中偏参梯度 tensor([-1.2412])\n",
						"第 506 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3483]])\n",
						"模型中偏参梯度 tensor([-1.2406])\n",
						"第 507 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3483]])\n",
						"模型中偏参梯度 tensor([-1.2401])\n",
						"第 508 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3483]])\n",
						"模型中偏参梯度 tensor([-1.2396])\n",
						"第 509 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3483]])\n",
						"模型中偏参梯度 tensor([-1.2390])\n",
						"第 510 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3483]])\n",
						"模型中偏参梯度 tensor([-1.2385])\n",
						"第 511 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3482]])\n",
						"模型中偏参梯度 tensor([-1.2380])\n",
						"第 512 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3482]])\n",
						"模型中偏参梯度 tensor([-1.2374])\n",
						"第 513 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3482]])\n",
						"模型中偏参梯度 tensor([-1.2369])\n",
						"第 514 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3481]])\n",
						"模型中偏参梯度 tensor([-1.2364])\n",
						"第 515 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3481]])\n",
						"模型中偏参梯度 tensor([-1.2358])\n",
						"第 516 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3481]])\n",
						"模型中偏参梯度 tensor([-1.2353])\n",
						"第 517 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3481]])\n",
						"模型中偏参梯度 tensor([-1.2348])\n",
						"第 518 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3481]])\n",
						"模型中偏参梯度 tensor([-1.2342])\n",
						"第 519 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3480]])\n",
						"模型中偏参梯度 tensor([-1.2337])\n",
						"第 520 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3480]])\n",
						"模型中偏参梯度 tensor([-1.2332])\n",
						"第 26 次epoch\n",
						"第 521 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3480]])\n",
						"模型中偏参梯度 tensor([-1.2327])\n",
						"第 522 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3480]])\n",
						"模型中偏参梯度 tensor([-1.2321])\n",
						"第 523 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3480]])\n",
						"模型中偏参梯度 tensor([-1.2316])\n",
						"第 524 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3479]])\n",
						"模型中偏参梯度 tensor([-1.2311])\n",
						"第 525 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3479]])\n",
						"模型中偏参梯度 tensor([-1.2305])\n",
						"第 526 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3479]])\n",
						"模型中偏参梯度 tensor([-1.2300])\n",
						"第 527 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3478]])\n",
						"模型中偏参梯度 tensor([-1.2295])\n",
						"第 528 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3478]])\n",
						"模型中偏参梯度 tensor([-1.2290])\n",
						"第 529 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3478]])\n",
						"模型中偏参梯度 tensor([-1.2284])\n",
						"第 530 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3477]])\n",
						"模型中偏参梯度 tensor([-1.2279])\n",
						"第 531 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3477]])\n",
						"模型中偏参梯度 tensor([-1.2274])\n",
						"第 532 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3476]])\n",
						"模型中偏参梯度 tensor([-1.2269])\n",
						"第 533 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3476]])\n",
						"模型中偏参梯度 tensor([-1.2264])\n",
						"第 534 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3475]])\n",
						"模型中偏参梯度 tensor([-1.2258])\n",
						"第 535 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3475]])\n",
						"模型中偏参梯度 tensor([-1.2253])\n",
						"第 536 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3474]])\n",
						"模型中偏参梯度 tensor([-1.2248])\n",
						"第 537 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3473]])\n",
						"模型中偏参梯度 tensor([-1.2243])\n",
						"第 538 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3473]])\n",
						"模型中偏参梯度 tensor([-1.2238])\n",
						"第 539 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3472]])\n",
						"模型中偏参梯度 tensor([-1.2233])\n",
						"第 540 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3471]])\n",
						"模型中偏参梯度 tensor([-1.2228])\n",
						"第 27 次epoch\n",
						"第 541 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3470]])\n",
						"模型中偏参梯度 tensor([-1.2223])\n",
						"第 542 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3470]])\n",
						"模型中偏参梯度 tensor([-1.2217])\n",
						"第 543 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3469]])\n",
						"模型中偏参梯度 tensor([-1.2212])\n",
						"第 544 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3468]])\n",
						"模型中偏参梯度 tensor([-1.2207])\n",
						"第 545 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3467]])\n",
						"模型中偏参梯度 tensor([-1.2202])\n",
						"第 546 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3466]])\n",
						"模型中偏参梯度 tensor([-1.2197])\n",
						"第 547 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3465]])\n",
						"模型中偏参梯度 tensor([-1.2192])\n",
						"第 548 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3464]])\n",
						"模型中偏参梯度 tensor([-1.2187])\n",
						"第 549 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3463]])\n",
						"模型中偏参梯度 tensor([-1.2182])\n",
						"第 550 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3462]])\n",
						"模型中偏参梯度 tensor([-1.2177])\n",
						"第 551 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3461]])\n",
						"模型中偏参梯度 tensor([-1.2172])\n",
						"第 552 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3461]])\n",
						"模型中偏参梯度 tensor([-1.2167])\n",
						"第 553 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3460]])\n",
						"模型中偏参梯度 tensor([-1.2162])\n",
						"第 554 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3459]])\n",
						"模型中偏参梯度 tensor([-1.2157])\n",
						"第 555 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3458]])\n",
						"模型中偏参梯度 tensor([-1.2152])\n",
						"第 556 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3457]])\n",
						"模型中偏参梯度 tensor([-1.2147])\n",
						"第 557 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3457]])\n",
						"模型中偏参梯度 tensor([-1.2142])\n",
						"第 558 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3456]])\n",
						"模型中偏参梯度 tensor([-1.2137])\n",
						"第 559 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3455]])\n",
						"模型中偏参梯度 tensor([-1.2132])\n",
						"第 560 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3454]])\n",
						"模型中偏参梯度 tensor([-1.2127])\n",
						"第 28 次epoch\n",
						"第 561 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3453]])\n",
						"模型中偏参梯度 tensor([-1.2122])\n",
						"第 562 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3452]])\n",
						"模型中偏参梯度 tensor([-1.2117])\n",
						"第 563 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3451]])\n",
						"模型中偏参梯度 tensor([-1.2112])\n",
						"第 564 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3450]])\n",
						"模型中偏参梯度 tensor([-1.2107])\n",
						"第 565 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3449]])\n",
						"模型中偏参梯度 tensor([-1.2102])\n",
						"第 566 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3448]])\n",
						"模型中偏参梯度 tensor([-1.2097])\n",
						"第 567 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3447]])\n",
						"模型中偏参梯度 tensor([-1.2092])\n",
						"第 568 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3446]])\n",
						"模型中偏参梯度 tensor([-1.2087])\n",
						"第 569 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3445]])\n",
						"模型中偏参梯度 tensor([-1.2082])\n",
						"第 570 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3443]])\n",
						"模型中偏参梯度 tensor([-1.2077])\n",
						"第 571 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3442]])\n",
						"模型中偏参梯度 tensor([-1.2072])\n",
						"第 572 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3441]])\n",
						"模型中偏参梯度 tensor([-1.2067])\n",
						"第 573 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3440]])\n",
						"模型中偏参梯度 tensor([-1.2062])\n",
						"第 574 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3439]])\n",
						"模型中偏参梯度 tensor([-1.2057])\n",
						"第 575 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3439]])\n",
						"模型中偏参梯度 tensor([-1.2052])\n",
						"第 576 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3437]])\n",
						"模型中偏参梯度 tensor([-1.2047])\n",
						"第 577 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3437]])\n",
						"模型中偏参梯度 tensor([-1.2042])\n",
						"第 578 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3435]])\n",
						"模型中偏参梯度 tensor([-1.2037])\n",
						"第 579 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3434]])\n",
						"模型中偏参梯度 tensor([-1.2032])\n",
						"第 580 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3433]])\n",
						"模型中偏参梯度 tensor([-1.2027])\n",
						"第 29 次epoch\n",
						"第 581 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3432]])\n",
						"模型中偏参梯度 tensor([-1.2022])\n",
						"第 582 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3431]])\n",
						"模型中偏参梯度 tensor([-1.2018])\n",
						"第 583 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3430]])\n",
						"模型中偏参梯度 tensor([-1.2013])\n",
						"第 584 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3429]])\n",
						"模型中偏参梯度 tensor([-1.2008])\n",
						"第 585 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3427]])\n",
						"模型中偏参梯度 tensor([-1.2003])\n",
						"第 586 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3426]])\n",
						"模型中偏参梯度 tensor([-1.1998])\n",
						"第 587 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3425]])\n",
						"模型中偏参梯度 tensor([-1.1993])\n",
						"第 588 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3424]])\n",
						"模型中偏参梯度 tensor([-1.1988])\n",
						"第 589 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3423]])\n",
						"模型中偏参梯度 tensor([-1.1983])\n",
						"第 590 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3422]])\n",
						"模型中偏参梯度 tensor([-1.1978])\n",
						"第 591 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3421]])\n",
						"模型中偏参梯度 tensor([-1.1974])\n",
						"第 592 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3420]])\n",
						"模型中偏参梯度 tensor([-1.1969])\n",
						"第 593 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3419]])\n",
						"模型中偏参梯度 tensor([-1.1964])\n",
						"第 594 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3417]])\n",
						"模型中偏参梯度 tensor([-1.1959])\n",
						"第 595 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3416]])\n",
						"模型中偏参梯度 tensor([-1.1954])\n",
						"第 596 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3415]])\n",
						"模型中偏参梯度 tensor([-1.1949])\n",
						"第 597 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3414]])\n",
						"模型中偏参梯度 tensor([-1.1944])\n",
						"第 598 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3413]])\n",
						"模型中偏参梯度 tensor([-1.1939])\n",
						"第 599 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3411]])\n",
						"模型中偏参梯度 tensor([-1.1934])\n",
						"第 600 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3410]])\n",
						"模型中偏参梯度 tensor([-1.1930])\n",
						"第 30 次epoch\n",
						"第 601 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3409]])\n",
						"模型中偏参梯度 tensor([-1.1925])\n",
						"第 602 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3408]])\n",
						"模型中偏参梯度 tensor([-1.1920])\n",
						"第 603 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3406]])\n",
						"模型中偏参梯度 tensor([-1.1915])\n",
						"第 604 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3405]])\n",
						"模型中偏参梯度 tensor([-1.1910])\n",
						"第 605 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3404]])\n",
						"模型中偏参梯度 tensor([-1.1906])\n",
						"第 606 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3403]])\n",
						"模型中偏参梯度 tensor([-1.1901])\n",
						"第 607 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3402]])\n",
						"模型中偏参梯度 tensor([-1.1896])\n",
						"第 608 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3400]])\n",
						"模型中偏参梯度 tensor([-1.1891])\n",
						"第 609 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3399]])\n",
						"模型中偏参梯度 tensor([-1.1886])\n",
						"第 610 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3398]])\n",
						"模型中偏参梯度 tensor([-1.1881])\n",
						"第 611 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3397]])\n",
						"模型中偏参梯度 tensor([-1.1876])\n",
						"第 612 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3396]])\n",
						"模型中偏参梯度 tensor([-1.1872])\n",
						"第 613 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3395]])\n",
						"模型中偏参梯度 tensor([-1.1867])\n",
						"第 614 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3393]])\n",
						"模型中偏参梯度 tensor([-1.1862])\n",
						"第 615 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3392]])\n",
						"模型中偏参梯度 tensor([-1.1857])\n",
						"第 616 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3391]])\n",
						"模型中偏参梯度 tensor([-1.1852])\n",
						"第 617 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3389]])\n",
						"模型中偏参梯度 tensor([-1.1848])\n",
						"第 618 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3388]])\n",
						"模型中偏参梯度 tensor([-1.1843])\n",
						"第 619 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3387]])\n",
						"模型中偏参梯度 tensor([-1.1838])\n",
						"第 620 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3385]])\n",
						"模型中偏参梯度 tensor([-1.1833])\n",
						"第 31 次epoch\n",
						"第 621 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3384]])\n",
						"模型中偏参梯度 tensor([-1.1828])\n",
						"第 622 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3383]])\n",
						"模型中偏参梯度 tensor([-1.1824])\n",
						"第 623 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3382]])\n",
						"模型中偏参梯度 tensor([-1.1819])\n",
						"第 624 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3381]])\n",
						"模型中偏参梯度 tensor([-1.1814])\n",
						"第 625 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3380]])\n",
						"模型中偏参梯度 tensor([-1.1809])\n",
						"第 626 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3379]])\n",
						"模型中偏参梯度 tensor([-1.1804])\n",
						"第 627 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3377]])\n",
						"模型中偏参梯度 tensor([-1.1800])\n",
						"第 628 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3376]])\n",
						"模型中偏参梯度 tensor([-1.1795])\n",
						"第 629 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3375]])\n",
						"模型中偏参梯度 tensor([-1.1790])\n",
						"第 630 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3374]])\n",
						"模型中偏参梯度 tensor([-1.1785])\n",
						"第 631 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3372]])\n",
						"模型中偏参梯度 tensor([-1.1781])\n",
						"第 632 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3371]])\n",
						"模型中偏参梯度 tensor([-1.1776])\n",
						"第 633 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3370]])\n",
						"模型中偏参梯度 tensor([-1.1771])\n",
						"第 634 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3368]])\n",
						"模型中偏参梯度 tensor([-1.1766])\n",
						"第 635 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3367]])\n",
						"模型中偏参梯度 tensor([-1.1762])\n",
						"第 636 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3365]])\n",
						"模型中偏参梯度 tensor([-1.1757])\n",
						"第 637 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3364]])\n",
						"模型中偏参梯度 tensor([-1.1752])\n",
						"第 638 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3363]])\n",
						"模型中偏参梯度 tensor([-1.1747])\n",
						"第 639 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3362]])\n",
						"模型中偏参梯度 tensor([-1.1743])\n",
						"第 640 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3361]])\n",
						"模型中偏参梯度 tensor([-1.1738])\n",
						"第 32 次epoch\n",
						"第 641 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3359]])\n",
						"模型中偏参梯度 tensor([-1.1733])\n",
						"第 642 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3358]])\n",
						"模型中偏参梯度 tensor([-1.1728])\n",
						"第 643 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3357]])\n",
						"模型中偏参梯度 tensor([-1.1723])\n",
						"第 644 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3356]])\n",
						"模型中偏参梯度 tensor([-1.1719])\n",
						"第 645 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3354]])\n",
						"模型中偏参梯度 tensor([-1.1714])\n",
						"第 646 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3353]])\n",
						"模型中偏参梯度 tensor([-1.1709])\n",
						"第 647 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3352]])\n",
						"模型中偏参梯度 tensor([-1.1705])\n",
						"第 648 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3350]])\n",
						"模型中偏参梯度 tensor([-1.1700])\n",
						"第 649 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3349]])\n",
						"模型中偏参梯度 tensor([-1.1695])\n",
						"第 650 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3347]])\n",
						"模型中偏参梯度 tensor([-1.1691])\n",
						"第 651 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3346]])\n",
						"模型中偏参梯度 tensor([-1.1686])\n",
						"第 652 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3345]])\n",
						"模型中偏参梯度 tensor([-1.1681])\n",
						"第 653 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3344]])\n",
						"模型中偏参梯度 tensor([-1.1676])\n",
						"第 654 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3342]])\n",
						"模型中偏参梯度 tensor([-1.1672])\n",
						"第 655 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3341]])\n",
						"模型中偏参梯度 tensor([-1.1667])\n",
						"第 656 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3340]])\n",
						"模型中偏参梯度 tensor([-1.1662])\n",
						"第 657 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3339]])\n",
						"模型中偏参梯度 tensor([-1.1657])\n",
						"第 658 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3338]])\n",
						"模型中偏参梯度 tensor([-1.1653])\n",
						"第 659 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3336]])\n",
						"模型中偏参梯度 tensor([-1.1648])\n",
						"第 660 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3335]])\n",
						"模型中偏参梯度 tensor([-1.1643])\n",
						"第 33 次epoch\n",
						"第 661 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3334]])\n",
						"模型中偏参梯度 tensor([-1.1639])\n",
						"第 662 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3332]])\n",
						"模型中偏参梯度 tensor([-1.1634])\n",
						"第 663 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3331]])\n",
						"模型中偏参梯度 tensor([-1.1629])\n",
						"第 664 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3329]])\n",
						"模型中偏参梯度 tensor([-1.1625])\n",
						"第 665 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3328]])\n",
						"模型中偏参梯度 tensor([-1.1620])\n",
						"第 666 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3327]])\n",
						"模型中偏参梯度 tensor([-1.1615])\n",
						"第 667 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3326]])\n",
						"模型中偏参梯度 tensor([-1.1611])\n",
						"第 668 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3324]])\n",
						"模型中偏参梯度 tensor([-1.1606])\n",
						"第 669 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3323]])\n",
						"模型中偏参梯度 tensor([-1.1601])\n",
						"第 670 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3322]])\n",
						"模型中偏参梯度 tensor([-1.1596])\n",
						"第 671 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3321]])\n",
						"模型中偏参梯度 tensor([-1.1592])\n",
						"第 672 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3319]])\n",
						"模型中偏参梯度 tensor([-1.1587])\n",
						"第 673 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3318]])\n",
						"模型中偏参梯度 tensor([-1.1582])\n",
						"第 674 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3317]])\n",
						"模型中偏参梯度 tensor([-1.1578])\n",
						"第 675 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3316]])\n",
						"模型中偏参梯度 tensor([-1.1573])\n",
						"第 676 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3314]])\n",
						"模型中偏参梯度 tensor([-1.1568])\n",
						"第 677 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3313]])\n",
						"模型中偏参梯度 tensor([-1.1564])\n",
						"第 678 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3311]])\n",
						"模型中偏参梯度 tensor([-1.1559])\n",
						"第 679 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3310]])\n",
						"模型中偏参梯度 tensor([-1.1555])\n",
						"第 680 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3308]])\n",
						"模型中偏参梯度 tensor([-1.1550])\n",
						"第 34 次epoch\n",
						"第 681 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3307]])\n",
						"模型中偏参梯度 tensor([-1.1545])\n",
						"第 682 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3306]])\n",
						"模型中偏参梯度 tensor([-1.1541])\n",
						"第 683 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3305]])\n",
						"模型中偏参梯度 tensor([-1.1536])\n",
						"第 684 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3304]])\n",
						"模型中偏参梯度 tensor([-1.1531])\n",
						"第 685 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3302]])\n",
						"模型中偏参梯度 tensor([-1.1526])\n",
						"第 686 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3301]])\n",
						"模型中偏参梯度 tensor([-1.1522])\n",
						"第 687 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3300]])\n",
						"模型中偏参梯度 tensor([-1.1517])\n",
						"第 688 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3298]])\n",
						"模型中偏参梯度 tensor([-1.1513])\n",
						"第 689 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3297]])\n",
						"模型中偏参梯度 tensor([-1.1508])\n",
						"第 690 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3296]])\n",
						"模型中偏参梯度 tensor([-1.1503])\n",
						"第 691 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3294]])\n",
						"模型中偏参梯度 tensor([-1.1499])\n",
						"第 692 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3293]])\n",
						"模型中偏参梯度 tensor([-1.1494])\n",
						"第 693 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3291]])\n",
						"模型中偏参梯度 tensor([-1.1490])\n",
						"第 694 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3290]])\n",
						"模型中偏参梯度 tensor([-1.1485])\n",
						"第 695 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3289]])\n",
						"模型中偏参梯度 tensor([-1.1480])\n",
						"第 696 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3288]])\n",
						"模型中偏参梯度 tensor([-1.1476])\n",
						"第 697 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3287]])\n",
						"模型中偏参梯度 tensor([-1.1471])\n",
						"第 698 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3285]])\n",
						"模型中偏参梯度 tensor([-1.1466])\n",
						"第 699 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3284]])\n",
						"模型中偏参梯度 tensor([-1.1462])\n",
						"第 700 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3283]])\n",
						"模型中偏参梯度 tensor([-1.1457])\n",
						"第 35 次epoch\n",
						"第 701 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3282]])\n",
						"模型中偏参梯度 tensor([-1.1452])\n",
						"第 702 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3280]])\n",
						"模型中偏参梯度 tensor([-1.1448])\n",
						"第 703 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3279]])\n",
						"模型中偏参梯度 tensor([-1.1443])\n",
						"第 704 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3278]])\n",
						"模型中偏参梯度 tensor([-1.1439])\n",
						"第 705 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3276]])\n",
						"模型中偏参梯度 tensor([-1.1434])\n",
						"第 706 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3275]])\n",
						"模型中偏参梯度 tensor([-1.1429])\n",
						"第 707 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3274]])\n",
						"模型中偏参梯度 tensor([-1.1425])\n",
						"第 708 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3272]])\n",
						"模型中偏参梯度 tensor([-1.1420])\n",
						"第 709 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3271]])\n",
						"模型中偏参梯度 tensor([-1.1416])\n",
						"第 710 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3270]])\n",
						"模型中偏参梯度 tensor([-1.1411])\n",
						"第 711 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3268]])\n",
						"模型中偏参梯度 tensor([-1.1406])\n",
						"第 712 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3267]])\n",
						"模型中偏参梯度 tensor([-1.1402])\n",
						"第 713 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3266]])\n",
						"模型中偏参梯度 tensor([-1.1397])\n",
						"第 714 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3265]])\n",
						"模型中偏参梯度 tensor([-1.1393])\n",
						"第 715 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3264]])\n",
						"模型中偏参梯度 tensor([-1.1388])\n",
						"第 716 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3262]])\n",
						"模型中偏参梯度 tensor([-1.1383])\n",
						"第 717 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3261]])\n",
						"模型中偏参梯度 tensor([-1.1379])\n",
						"第 718 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3260]])\n",
						"模型中偏参梯度 tensor([-1.1374])\n",
						"第 719 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3258]])\n",
						"模型中偏参梯度 tensor([-1.1370])\n",
						"第 720 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3257]])\n",
						"模型中偏参梯度 tensor([-1.1365])\n",
						"第 36 次epoch\n",
						"第 721 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3256]])\n",
						"模型中偏参梯度 tensor([-1.1361])\n",
						"第 722 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3254]])\n",
						"模型中偏参梯度 tensor([-1.1356])\n",
						"第 723 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3253]])\n",
						"模型中偏参梯度 tensor([-1.1351])\n",
						"第 724 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3251]])\n",
						"模型中偏参梯度 tensor([-1.1347])\n",
						"第 725 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3250]])\n",
						"模型中偏参梯度 tensor([-1.1342])\n",
						"第 726 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3249]])\n",
						"模型中偏参梯度 tensor([-1.1338])\n",
						"第 727 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3248]])\n",
						"模型中偏参梯度 tensor([-1.1333])\n",
						"第 728 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3247]])\n",
						"模型中偏参梯度 tensor([-1.1329])\n",
						"第 729 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3245]])\n",
						"模型中偏参梯度 tensor([-1.1324])\n",
						"第 730 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3244]])\n",
						"模型中偏参梯度 tensor([-1.1319])\n",
						"第 731 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3243]])\n",
						"模型中偏参梯度 tensor([-1.1315])\n",
						"第 732 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3242]])\n",
						"模型中偏参梯度 tensor([-1.1310])\n",
						"第 733 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3240]])\n",
						"模型中偏参梯度 tensor([-1.1306])\n",
						"第 734 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3239]])\n",
						"模型中偏参梯度 tensor([-1.1301])\n",
						"第 735 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3237]])\n",
						"模型中偏参梯度 tensor([-1.1297])\n",
						"第 736 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3236]])\n",
						"模型中偏参梯度 tensor([-1.1292])\n",
						"第 737 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3235]])\n",
						"模型中偏参梯度 tensor([-1.1288])\n",
						"第 738 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3233]])\n",
						"模型中偏参梯度 tensor([-1.1283])\n",
						"第 739 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3232]])\n",
						"模型中偏参梯度 tensor([-1.1279])\n",
						"第 740 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3231]])\n",
						"模型中偏参梯度 tensor([-1.1274])\n",
						"第 37 次epoch\n",
						"第 741 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3229]])\n",
						"模型中偏参梯度 tensor([-1.1269])\n",
						"第 742 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3228]])\n",
						"模型中偏参梯度 tensor([-1.1265])\n",
						"第 743 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3227]])\n",
						"模型中偏参梯度 tensor([-1.1260])\n",
						"第 744 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3226]])\n",
						"模型中偏参梯度 tensor([-1.1256])\n",
						"第 745 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3225]])\n",
						"模型中偏参梯度 tensor([-1.1251])\n",
						"第 746 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3223]])\n",
						"模型中偏参梯度 tensor([-1.1247])\n",
						"第 747 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3222]])\n",
						"模型中偏参梯度 tensor([-1.1242])\n",
						"第 748 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3221]])\n",
						"模型中偏参梯度 tensor([-1.1238])\n",
						"第 749 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3219]])\n",
						"模型中偏参梯度 tensor([-1.1233])\n",
						"第 750 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3218]])\n",
						"模型中偏参梯度 tensor([-1.1229])\n",
						"第 751 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3216]])\n",
						"模型中偏参梯度 tensor([-1.1224])\n",
						"第 752 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3215]])\n",
						"模型中偏参梯度 tensor([-1.1220])\n",
						"第 753 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3214]])\n",
						"模型中偏参梯度 tensor([-1.1215])\n",
						"第 754 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3213]])\n",
						"模型中偏参梯度 tensor([-1.1211])\n",
						"第 755 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3211]])\n",
						"模型中偏参梯度 tensor([-1.1206])\n",
						"第 756 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3210]])\n",
						"模型中偏参梯度 tensor([-1.1202])\n",
						"第 757 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3209]])\n",
						"模型中偏参梯度 tensor([-1.1197])\n",
						"第 758 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3208]])\n",
						"模型中偏参梯度 tensor([-1.1193])\n",
						"第 759 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3207]])\n",
						"模型中偏参梯度 tensor([-1.1188])\n",
						"第 760 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3205]])\n",
						"模型中偏参梯度 tensor([-1.1183])\n",
						"第 38 次epoch\n",
						"第 761 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3204]])\n",
						"模型中偏参梯度 tensor([-1.1179])\n",
						"第 762 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3203]])\n",
						"模型中偏参梯度 tensor([-1.1174])\n",
						"第 763 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3201]])\n",
						"模型中偏参梯度 tensor([-1.1170])\n",
						"第 764 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3200]])\n",
						"模型中偏参梯度 tensor([-1.1166])\n",
						"第 765 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3199]])\n",
						"模型中偏参梯度 tensor([-1.1161])\n",
						"第 766 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3197]])\n",
						"模型中偏参梯度 tensor([-1.1157])\n",
						"第 767 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3196]])\n",
						"模型中偏参梯度 tensor([-1.1152])\n",
						"第 768 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3195]])\n",
						"模型中偏参梯度 tensor([-1.1148])\n",
						"第 769 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3193]])\n",
						"模型中偏参梯度 tensor([-1.1143])\n",
						"第 770 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3192]])\n",
						"模型中偏参梯度 tensor([-1.1139])\n",
						"第 771 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3191]])\n",
						"模型中偏参梯度 tensor([-1.1134])\n",
						"第 772 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3190]])\n",
						"模型中偏参梯度 tensor([-1.1130])\n",
						"第 773 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3189]])\n",
						"模型中偏参梯度 tensor([-1.1125])\n",
						"第 774 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3187]])\n",
						"模型中偏参梯度 tensor([-1.1121])\n",
						"第 775 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3186]])\n",
						"模型中偏参梯度 tensor([-1.1116])\n",
						"第 776 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3185]])\n",
						"模型中偏参梯度 tensor([-1.1112])\n",
						"第 777 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3184]])\n",
						"模型中偏参梯度 tensor([-1.1107])\n",
						"第 778 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3182]])\n",
						"模型中偏参梯度 tensor([-1.1103])\n",
						"第 779 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3181]])\n",
						"模型中偏参梯度 tensor([-1.1098])\n",
						"第 780 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3179]])\n",
						"模型中偏参梯度 tensor([-1.1094])\n",
						"第 39 次epoch\n",
						"第 781 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3178]])\n",
						"模型中偏参梯度 tensor([-1.1089])\n",
						"第 782 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3177]])\n",
						"模型中偏参梯度 tensor([-1.1085])\n",
						"第 783 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3175]])\n",
						"模型中偏参梯度 tensor([-1.1081])\n",
						"第 784 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3174]])\n",
						"模型中偏参梯度 tensor([-1.1076])\n",
						"第 785 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3173]])\n",
						"模型中偏参梯度 tensor([-1.1072])\n",
						"第 786 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3172]])\n",
						"模型中偏参梯度 tensor([-1.1067])\n",
						"第 787 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3171]])\n",
						"模型中偏参梯度 tensor([-1.1063])\n",
						"第 788 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3170]])\n",
						"模型中偏参梯度 tensor([-1.1058])\n",
						"第 789 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3168]])\n",
						"模型中偏参梯度 tensor([-1.1054])\n",
						"第 790 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3167]])\n",
						"模型中偏参梯度 tensor([-1.1049])\n",
						"第 791 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3166]])\n",
						"模型中偏参梯度 tensor([-1.1045])\n",
						"第 792 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3164]])\n",
						"模型中偏参梯度 tensor([-1.1040])\n",
						"第 793 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3163]])\n",
						"模型中偏参梯度 tensor([-1.1036])\n",
						"第 794 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3162]])\n",
						"模型中偏参梯度 tensor([-1.1031])\n",
						"第 795 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3161]])\n",
						"模型中偏参梯度 tensor([-1.1027])\n",
						"第 796 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3159]])\n",
						"模型中偏参梯度 tensor([-1.1023])\n",
						"第 797 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3158]])\n",
						"模型中偏参梯度 tensor([-1.1018])\n",
						"第 798 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3156]])\n",
						"模型中偏参梯度 tensor([-1.1014])\n",
						"第 799 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3155]])\n",
						"模型中偏参梯度 tensor([-1.1009])\n",
						"第 800 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3154]])\n",
						"模型中偏参梯度 tensor([-1.1005])\n",
						"第 40 次epoch\n",
						"第 801 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3153]])\n",
						"模型中偏参梯度 tensor([-1.1000])\n",
						"第 802 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3152]])\n",
						"模型中偏参梯度 tensor([-1.0996])\n",
						"第 803 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3151]])\n",
						"模型中偏参梯度 tensor([-1.0992])\n",
						"第 804 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3149]])\n",
						"模型中偏参梯度 tensor([-1.0987])\n",
						"第 805 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3148]])\n",
						"模型中偏参梯度 tensor([-1.0983])\n",
						"第 806 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3147]])\n",
						"模型中偏参梯度 tensor([-1.0978])\n",
						"第 807 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3146]])\n",
						"模型中偏参梯度 tensor([-1.0974])\n",
						"第 808 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3144]])\n",
						"模型中偏参梯度 tensor([-1.0969])\n",
						"第 809 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3143]])\n",
						"模型中偏参梯度 tensor([-1.0965])\n",
						"第 810 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3142]])\n",
						"模型中偏参梯度 tensor([-1.0961])\n",
						"第 811 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3140]])\n",
						"模型中偏参梯度 tensor([-1.0956])\n",
						"第 812 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3139]])\n",
						"模型中偏参梯度 tensor([-1.0952])\n",
						"第 813 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3137]])\n",
						"模型中偏参梯度 tensor([-1.0948])\n",
						"第 814 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3136]])\n",
						"模型中偏参梯度 tensor([-1.0943])\n",
						"第 815 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3135]])\n",
						"模型中偏参梯度 tensor([-1.0939])\n",
						"第 816 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3134]])\n",
						"模型中偏参梯度 tensor([-1.0934])\n",
						"第 817 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3133]])\n",
						"模型中偏参梯度 tensor([-1.0930])\n",
						"第 818 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3132]])\n",
						"模型中偏参梯度 tensor([-1.0925])\n",
						"第 819 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3131]])\n",
						"模型中偏参梯度 tensor([-1.0921])\n",
						"第 820 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3129]])\n",
						"模型中偏参梯度 tensor([-1.0917])\n",
						"第 41 次epoch\n",
						"第 821 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3128]])\n",
						"模型中偏参梯度 tensor([-1.0912])\n",
						"第 822 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3127]])\n",
						"模型中偏参梯度 tensor([-1.0908])\n",
						"第 823 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3125]])\n",
						"模型中偏参梯度 tensor([-1.0903])\n",
						"第 824 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3124]])\n",
						"模型中偏参梯度 tensor([-1.0899])\n",
						"第 825 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3123]])\n",
						"模型中偏参梯度 tensor([-1.0895])\n",
						"第 826 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3121]])\n",
						"模型中偏参梯度 tensor([-1.0890])\n",
						"第 827 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3120]])\n",
						"模型中偏参梯度 tensor([-1.0886])\n",
						"第 828 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3119]])\n",
						"模型中偏参梯度 tensor([-1.0882])\n",
						"第 829 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3117]])\n",
						"模型中偏参梯度 tensor([-1.0877])\n",
						"第 830 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3116]])\n",
						"模型中偏参梯度 tensor([-1.0873])\n",
						"第 831 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3115]])\n",
						"模型中偏参梯度 tensor([-1.0869])\n",
						"第 832 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3114]])\n",
						"模型中偏参梯度 tensor([-1.0864])\n",
						"第 833 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3113]])\n",
						"模型中偏参梯度 tensor([-1.0860])\n",
						"第 834 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3111]])\n",
						"模型中偏参梯度 tensor([-1.0855])\n",
						"第 835 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3110]])\n",
						"模型中偏参梯度 tensor([-1.0851])\n",
						"第 836 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3109]])\n",
						"模型中偏参梯度 tensor([-1.0847])\n",
						"第 837 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3108]])\n",
						"模型中偏参梯度 tensor([-1.0842])\n",
						"第 838 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3106]])\n",
						"模型中偏参梯度 tensor([-1.0838])\n",
						"第 839 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3105]])\n",
						"模型中偏参梯度 tensor([-1.0834])\n",
						"第 840 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3104]])\n",
						"模型中偏参梯度 tensor([-1.0829])\n",
						"第 42 次epoch\n",
						"第 841 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3102]])\n",
						"模型中偏参梯度 tensor([-1.0825])\n",
						"第 842 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3101]])\n",
						"模型中偏参梯度 tensor([-1.0821])\n",
						"第 843 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3100]])\n",
						"模型中偏参梯度 tensor([-1.0816])\n",
						"第 844 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3098]])\n",
						"模型中偏参梯度 tensor([-1.0812])\n",
						"第 845 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3097]])\n",
						"模型中偏参梯度 tensor([-1.0808])\n",
						"第 846 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3096]])\n",
						"模型中偏参梯度 tensor([-1.0803])\n",
						"第 847 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3095]])\n",
						"模型中偏参梯度 tensor([-1.0799])\n",
						"第 848 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3094]])\n",
						"模型中偏参梯度 tensor([-1.0794])\n",
						"第 849 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3093]])\n",
						"模型中偏参梯度 tensor([-1.0790])\n",
						"第 850 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3091]])\n",
						"模型中偏参梯度 tensor([-1.0786])\n",
						"第 851 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3090]])\n",
						"模型中偏参梯度 tensor([-1.0781])\n",
						"第 852 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3089]])\n",
						"模型中偏参梯度 tensor([-1.0777])\n",
						"第 853 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3088]])\n",
						"模型中偏参梯度 tensor([-1.0773])\n",
						"第 854 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3086]])\n",
						"模型中偏参梯度 tensor([-1.0768])\n",
						"第 855 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3085]])\n",
						"模型中偏参梯度 tensor([-1.0764])\n",
						"第 856 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3084]])\n",
						"模型中偏参梯度 tensor([-1.0760])\n",
						"第 857 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3082]])\n",
						"模型中偏参梯度 tensor([-1.0755])\n",
						"第 858 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3081]])\n",
						"模型中偏参梯度 tensor([-1.0751])\n",
						"第 859 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3079]])\n",
						"模型中偏参梯度 tensor([-1.0747])\n",
						"第 860 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3078]])\n",
						"模型中偏参梯度 tensor([-1.0742])\n",
						"第 43 次epoch\n",
						"第 861 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3077]])\n",
						"模型中偏参梯度 tensor([-1.0738])\n",
						"第 862 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3076]])\n",
						"模型中偏参梯度 tensor([-1.0734])\n",
						"第 863 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3075]])\n",
						"模型中偏参梯度 tensor([-1.0729])\n",
						"第 864 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3074]])\n",
						"模型中偏参梯度 tensor([-1.0725])\n",
						"第 865 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3073]])\n",
						"模型中偏参梯度 tensor([-1.0721])\n",
						"第 866 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3072]])\n",
						"模型中偏参梯度 tensor([-1.0716])\n",
						"第 867 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3070]])\n",
						"模型中偏参梯度 tensor([-1.0712])\n",
						"第 868 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3069]])\n",
						"模型中偏参梯度 tensor([-1.0708])\n",
						"第 869 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3068]])\n",
						"模型中偏参梯度 tensor([-1.0704])\n",
						"第 870 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3066]])\n",
						"模型中偏参梯度 tensor([-1.0699])\n",
						"第 871 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3065]])\n",
						"模型中偏参梯度 tensor([-1.0695])\n",
						"第 872 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3064]])\n",
						"模型中偏参梯度 tensor([-1.0691])\n",
						"第 873 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3062]])\n",
						"模型中偏参梯度 tensor([-1.0686])\n",
						"第 874 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3061]])\n",
						"模型中偏参梯度 tensor([-1.0682])\n",
						"第 875 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3060]])\n",
						"模型中偏参梯度 tensor([-1.0678])\n",
						"第 876 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3059]])\n",
						"模型中偏参梯度 tensor([-1.0673])\n",
						"第 877 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3058]])\n",
						"模型中偏参梯度 tensor([-1.0669])\n",
						"第 878 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3057]])\n",
						"模型中偏参梯度 tensor([-1.0665])\n",
						"第 879 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3056]])\n",
						"模型中偏参梯度 tensor([-1.0661])\n",
						"第 880 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3054]])\n",
						"模型中偏参梯度 tensor([-1.0656])\n",
						"第 44 次epoch\n",
						"第 881 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3053]])\n",
						"模型中偏参梯度 tensor([-1.0652])\n",
						"第 882 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3052]])\n",
						"模型中偏参梯度 tensor([-1.0648])\n",
						"第 883 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3051]])\n",
						"模型中偏参梯度 tensor([-1.0643])\n",
						"第 884 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3049]])\n",
						"模型中偏参梯度 tensor([-1.0639])\n",
						"第 885 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3048]])\n",
						"模型中偏参梯度 tensor([-1.0635])\n",
						"第 886 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3047]])\n",
						"模型中偏参梯度 tensor([-1.0631])\n",
						"第 887 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3046]])\n",
						"模型中偏参梯度 tensor([-1.0626])\n",
						"第 888 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3044]])\n",
						"模型中偏参梯度 tensor([-1.0622])\n",
						"第 889 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3043]])\n",
						"模型中偏参梯度 tensor([-1.0618])\n",
						"第 890 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3041]])\n",
						"模型中偏参梯度 tensor([-1.0614])\n",
						"第 891 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3040]])\n",
						"模型中偏参梯度 tensor([-1.0609])\n",
						"第 892 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3039]])\n",
						"模型中偏参梯度 tensor([-1.0605])\n",
						"第 893 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3038]])\n",
						"模型中偏参梯度 tensor([-1.0601])\n",
						"第 894 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3037]])\n",
						"模型中偏参梯度 tensor([-1.0596])\n",
						"第 895 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3036]])\n",
						"模型中偏参梯度 tensor([-1.0592])\n",
						"第 896 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3035]])\n",
						"模型中偏参梯度 tensor([-1.0588])\n",
						"第 897 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3034]])\n",
						"模型中偏参梯度 tensor([-1.0584])\n",
						"第 898 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3032]])\n",
						"模型中偏参梯度 tensor([-1.0579])\n",
						"第 899 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3031]])\n",
						"模型中偏参梯度 tensor([-1.0575])\n",
						"第 900 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3030]])\n",
						"模型中偏参梯度 tensor([-1.0571])\n",
						"第 45 次epoch\n",
						"第 901 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3029]])\n",
						"模型中偏参梯度 tensor([-1.0567])\n",
						"第 902 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3027]])\n",
						"模型中偏参梯度 tensor([-1.0562])\n",
						"第 903 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3026]])\n",
						"模型中偏参梯度 tensor([-1.0558])\n",
						"第 904 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3025]])\n",
						"模型中偏参梯度 tensor([-1.0554])\n",
						"第 905 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3023]])\n",
						"模型中偏参梯度 tensor([-1.0550])\n",
						"第 906 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3022]])\n",
						"模型中偏参梯度 tensor([-1.0546])\n",
						"第 907 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3021]])\n",
						"模型中偏参梯度 tensor([-1.0541])\n",
						"第 908 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3020]])\n",
						"模型中偏参梯度 tensor([-1.0537])\n",
						"第 909 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3019]])\n",
						"模型中偏参梯度 tensor([-1.0533])\n",
						"第 910 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3017]])\n",
						"模型中偏参梯度 tensor([-1.0528])\n",
						"第 911 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3016]])\n",
						"模型中偏参梯度 tensor([-1.0524])\n",
						"第 912 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3015]])\n",
						"模型中偏参梯度 tensor([-1.0520])\n",
						"第 913 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3014]])\n",
						"模型中偏参梯度 tensor([-1.0516])\n",
						"第 914 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3013]])\n",
						"模型中偏参梯度 tensor([-1.0511])\n",
						"第 915 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3011]])\n",
						"模型中偏参梯度 tensor([-1.0507])\n",
						"第 916 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3010]])\n",
						"模型中偏参梯度 tensor([-1.0503])\n",
						"第 917 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3009]])\n",
						"模型中偏参梯度 tensor([-1.0499])\n",
						"第 918 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3008]])\n",
						"模型中偏参梯度 tensor([-1.0495])\n",
						"第 919 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3006]])\n",
						"模型中偏参梯度 tensor([-1.0490])\n",
						"第 920 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3005]])\n",
						"模型中偏参梯度 tensor([-1.0486])\n",
						"第 46 次epoch\n",
						"第 921 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3004]])\n",
						"模型中偏参梯度 tensor([-1.0482])\n",
						"第 922 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3003]])\n",
						"模型中偏参梯度 tensor([-1.0478])\n",
						"第 923 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3002]])\n",
						"模型中偏参梯度 tensor([-1.0474])\n",
						"第 924 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.3000]])\n",
						"模型中偏参梯度 tensor([-1.0469])\n",
						"第 925 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2999]])\n",
						"模型中偏参梯度 tensor([-1.0465])\n",
						"第 926 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2998]])\n",
						"模型中偏参梯度 tensor([-1.0461])\n",
						"第 927 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2997]])\n",
						"模型中偏参梯度 tensor([-1.0457])\n",
						"第 928 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2996]])\n",
						"模型中偏参梯度 tensor([-1.0452])\n",
						"第 929 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2995]])\n",
						"模型中偏参梯度 tensor([-1.0448])\n",
						"第 930 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2994]])\n",
						"模型中偏参梯度 tensor([-1.0444])\n",
						"第 931 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2992]])\n",
						"模型中偏参梯度 tensor([-1.0440])\n",
						"第 932 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2991]])\n",
						"模型中偏参梯度 tensor([-1.0436])\n",
						"第 933 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2990]])\n",
						"模型中偏参梯度 tensor([-1.0431])\n",
						"第 934 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2988]])\n",
						"模型中偏参梯度 tensor([-1.0427])\n",
						"第 935 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2987]])\n",
						"模型中偏参梯度 tensor([-1.0423])\n",
						"第 936 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2986]])\n",
						"模型中偏参梯度 tensor([-1.0419])\n",
						"第 937 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2984]])\n",
						"模型中偏参梯度 tensor([-1.0415])\n",
						"第 938 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2983]])\n",
						"模型中偏参梯度 tensor([-1.0411])\n",
						"第 939 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2982]])\n",
						"模型中偏参梯度 tensor([-1.0406])\n",
						"第 940 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2981]])\n",
						"模型中偏参梯度 tensor([-1.0402])\n",
						"第 47 次epoch\n",
						"第 941 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2980]])\n",
						"模型中偏参梯度 tensor([-1.0398])\n",
						"第 942 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2979]])\n",
						"模型中偏参梯度 tensor([-1.0394])\n",
						"第 943 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2978]])\n",
						"模型中偏参梯度 tensor([-1.0389])\n",
						"第 944 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2977]])\n",
						"模型中偏参梯度 tensor([-1.0385])\n",
						"第 945 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2976]])\n",
						"模型中偏参梯度 tensor([-1.0381])\n",
						"第 946 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2974]])\n",
						"模型中偏参梯度 tensor([-1.0377])\n",
						"第 947 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2973]])\n",
						"模型中偏参梯度 tensor([-1.0373])\n",
						"第 948 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2972]])\n",
						"模型中偏参梯度 tensor([-1.0369])\n",
						"第 949 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2971]])\n",
						"模型中偏参梯度 tensor([-1.0364])\n",
						"第 950 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2969]])\n",
						"模型中偏参梯度 tensor([-1.0360])\n",
						"第 951 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2968]])\n",
						"模型中偏参梯度 tensor([-1.0356])\n",
						"第 952 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2967]])\n",
						"模型中偏参梯度 tensor([-1.0352])\n",
						"第 953 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2965]])\n",
						"模型中偏参梯度 tensor([-1.0348])\n",
						"第 954 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2964]])\n",
						"模型中偏参梯度 tensor([-1.0344])\n",
						"第 955 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2963]])\n",
						"模型中偏参梯度 tensor([-1.0340])\n",
						"第 956 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2962]])\n",
						"模型中偏参梯度 tensor([-1.0335])\n",
						"第 957 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2961]])\n",
						"模型中偏参梯度 tensor([-1.0331])\n",
						"第 958 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2960]])\n",
						"模型中偏参梯度 tensor([-1.0327])\n",
						"第 959 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2959]])\n",
						"模型中偏参梯度 tensor([-1.0323])\n",
						"第 960 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2958]])\n",
						"模型中偏参梯度 tensor([-1.0319])\n",
						"第 48 次epoch\n",
						"第 961 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2957]])\n",
						"模型中偏参梯度 tensor([-1.0314])\n",
						"第 962 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2955]])\n",
						"模型中偏参梯度 tensor([-1.0310])\n",
						"第 963 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2954]])\n",
						"模型中偏参梯度 tensor([-1.0306])\n",
						"第 964 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2953]])\n",
						"模型中偏参梯度 tensor([-1.0302])\n",
						"第 965 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2952]])\n",
						"模型中偏参梯度 tensor([-1.0298])\n",
						"第 966 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2950]])\n",
						"模型中偏参梯度 tensor([-1.0294])\n",
						"第 967 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2949]])\n",
						"模型中偏参梯度 tensor([-1.0290])\n",
						"第 968 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2948]])\n",
						"模型中偏参梯度 tensor([-1.0286])\n",
						"第 969 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2946]])\n",
						"模型中偏参梯度 tensor([-1.0281])\n",
						"第 970 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2945]])\n",
						"模型中偏参梯度 tensor([-1.0277])\n",
						"第 971 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2944]])\n",
						"模型中偏参梯度 tensor([-1.0273])\n",
						"第 972 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2943]])\n",
						"模型中偏参梯度 tensor([-1.0269])\n",
						"第 973 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2942]])\n",
						"模型中偏参梯度 tensor([-1.0265])\n",
						"第 974 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2941]])\n",
						"模型中偏参梯度 tensor([-1.0261])\n",
						"第 975 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2940]])\n",
						"模型中偏参梯度 tensor([-1.0256])\n",
						"第 976 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2939]])\n",
						"模型中偏参梯度 tensor([-1.0252])\n",
						"第 977 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2938]])\n",
						"模型中偏参梯度 tensor([-1.0248])\n",
						"第 978 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2936]])\n",
						"模型中偏参梯度 tensor([-1.0244])\n",
						"第 979 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2935]])\n",
						"模型中偏参梯度 tensor([-1.0240])\n",
						"第 980 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2934]])\n",
						"模型中偏参梯度 tensor([-1.0236])\n",
						"第 49 次epoch\n",
						"第 981 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2933]])\n",
						"模型中偏参梯度 tensor([-1.0232])\n",
						"第 982 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2931]])\n",
						"模型中偏参梯度 tensor([-1.0228])\n",
						"第 983 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2930]])\n",
						"模型中偏参梯度 tensor([-1.0224])\n",
						"第 984 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2929]])\n",
						"模型中偏参梯度 tensor([-1.0220])\n",
						"第 985 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2927]])\n",
						"模型中偏参梯度 tensor([-1.0216])\n",
						"第 986 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2926]])\n",
						"模型中偏参梯度 tensor([-1.0211])\n",
						"第 987 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2925]])\n",
						"模型中偏参梯度 tensor([-1.0207])\n",
						"第 988 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2924]])\n",
						"模型中偏参梯度 tensor([-1.0203])\n",
						"第 989 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2923]])\n",
						"模型中偏参梯度 tensor([-1.0199])\n",
						"第 990 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2922]])\n",
						"模型中偏参梯度 tensor([-1.0195])\n",
						"第 991 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2921]])\n",
						"模型中偏参梯度 tensor([-1.0191])\n",
						"第 992 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2920]])\n",
						"模型中偏参梯度 tensor([-1.0187])\n",
						"第 993 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2919]])\n",
						"模型中偏参梯度 tensor([-1.0182])\n",
						"第 994 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2918]])\n",
						"模型中偏参梯度 tensor([-1.0178])\n",
						"第 995 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2916]])\n",
						"模型中偏参梯度 tensor([-1.0174])\n",
						"第 996 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2915]])\n",
						"模型中偏参梯度 tensor([-1.0170])\n",
						"第 997 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2914]])\n",
						"模型中偏参梯度 tensor([-1.0166])\n",
						"第 998 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2913]])\n",
						"模型中偏参梯度 tensor([-1.0162])\n",
						"第 999 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2911]])\n",
						"模型中偏参梯度 tensor([-1.0158])\n",
						"第 1000 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2910]])\n",
						"模型中偏参梯度 tensor([-1.0154])\n",
						"第 50 次epoch\n",
						"第 1001 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2909]])\n",
						"模型中偏参梯度 tensor([-1.0150])\n",
						"第 1002 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2908]])\n",
						"模型中偏参梯度 tensor([-1.0146])\n",
						"第 1003 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2907]])\n",
						"模型中偏参梯度 tensor([-1.0142])\n",
						"第 1004 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2906]])\n",
						"模型中偏参梯度 tensor([-1.0137])\n",
						"第 1005 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2905]])\n",
						"模型中偏参梯度 tensor([-1.0133])\n",
						"第 1006 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2904]])\n",
						"模型中偏参梯度 tensor([-1.0129])\n",
						"第 1007 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2902]])\n",
						"模型中偏参梯度 tensor([-1.0125])\n",
						"第 1008 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2901]])\n",
						"模型中偏参梯度 tensor([-1.0121])\n",
						"第 1009 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2900]])\n",
						"模型中偏参梯度 tensor([-1.0117])\n",
						"第 1010 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2899]])\n",
						"模型中偏参梯度 tensor([-1.0113])\n",
						"第 1011 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2898]])\n",
						"模型中偏参梯度 tensor([-1.0109])\n",
						"第 1012 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2897]])\n",
						"模型中偏参梯度 tensor([-1.0105])\n",
						"第 1013 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2895]])\n",
						"模型中偏参梯度 tensor([-1.0101])\n",
						"第 1014 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2894]])\n",
						"模型中偏参梯度 tensor([-1.0097])\n",
						"第 1015 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2893]])\n",
						"模型中偏参梯度 tensor([-1.0093])\n",
						"第 1016 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2892]])\n",
						"模型中偏参梯度 tensor([-1.0089])\n",
						"第 1017 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2890]])\n",
						"模型中偏参梯度 tensor([-1.0085])\n",
						"第 1018 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2889]])\n",
						"模型中偏参梯度 tensor([-1.0081])\n",
						"第 1019 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2888]])\n",
						"模型中偏参梯度 tensor([-1.0077])\n",
						"第 1020 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2887]])\n",
						"模型中偏参梯度 tensor([-1.0072])\n",
						"第 51 次epoch\n",
						"第 1021 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2886]])\n",
						"模型中偏参梯度 tensor([-1.0068])\n",
						"第 1022 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2885]])\n",
						"模型中偏参梯度 tensor([-1.0064])\n",
						"第 1023 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2884]])\n",
						"模型中偏参梯度 tensor([-1.0060])\n",
						"第 1024 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2883]])\n",
						"模型中偏参梯度 tensor([-1.0056])\n",
						"第 1025 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2882]])\n",
						"模型中偏参梯度 tensor([-1.0052])\n",
						"第 1026 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2880]])\n",
						"模型中偏参梯度 tensor([-1.0048])\n",
						"第 1027 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2879]])\n",
						"模型中偏参梯度 tensor([-1.0044])\n",
						"第 1028 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2878]])\n",
						"模型中偏参梯度 tensor([-1.0040])\n",
						"第 1029 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2877]])\n",
						"模型中偏参梯度 tensor([-1.0036])\n",
						"第 1030 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2876]])\n",
						"模型中偏参梯度 tensor([-1.0032])\n",
						"第 1031 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2874]])\n",
						"模型中偏参梯度 tensor([-1.0028])\n",
						"第 1032 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2873]])\n",
						"模型中偏参梯度 tensor([-1.0024])\n",
						"第 1033 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2872]])\n",
						"模型中偏参梯度 tensor([-1.0020])\n",
						"第 1034 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2870]])\n",
						"模型中偏参梯度 tensor([-1.0016])\n",
						"第 1035 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2869]])\n",
						"模型中偏参梯度 tensor([-1.0012])\n",
						"第 1036 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2868]])\n",
						"模型中偏参梯度 tensor([-1.0008])\n",
						"第 1037 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2867]])\n",
						"模型中偏参梯度 tensor([-1.0004])\n",
						"第 1038 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2866]])\n",
						"模型中偏参梯度 tensor([-1.0000])\n",
						"第 1039 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2865]])\n",
						"模型中偏参梯度 tensor([-0.9996])\n",
						"第 1040 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2864]])\n",
						"模型中偏参梯度 tensor([-0.9992])\n",
						"第 52 次epoch\n",
						"第 1041 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2863]])\n",
						"模型中偏参梯度 tensor([-0.9988])\n",
						"第 1042 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2862]])\n",
						"模型中偏参梯度 tensor([-0.9984])\n",
						"第 1043 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2861]])\n",
						"模型中偏参梯度 tensor([-0.9980])\n",
						"第 1044 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2860]])\n",
						"模型中偏参梯度 tensor([-0.9976])\n",
						"第 1045 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2859]])\n",
						"模型中偏参梯度 tensor([-0.9972])\n",
						"第 1046 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2857]])\n",
						"模型中偏参梯度 tensor([-0.9968])\n",
						"第 1047 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2856]])\n",
						"模型中偏参梯度 tensor([-0.9964])\n",
						"第 1048 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2855]])\n",
						"模型中偏参梯度 tensor([-0.9960])\n",
						"第 1049 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2854]])\n",
						"模型中偏参梯度 tensor([-0.9956])\n",
						"第 1050 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2852]])\n",
						"模型中偏参梯度 tensor([-0.9952])\n",
						"第 1051 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2851]])\n",
						"模型中偏参梯度 tensor([-0.9948])\n",
						"第 1052 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2850]])\n",
						"模型中偏参梯度 tensor([-0.9944])\n",
						"第 1053 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2849]])\n",
						"模型中偏参梯度 tensor([-0.9940])\n",
						"第 1054 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2848]])\n",
						"模型中偏参梯度 tensor([-0.9936])\n",
						"第 1055 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2847]])\n",
						"模型中偏参梯度 tensor([-0.9932])\n",
						"第 1056 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2846]])\n",
						"模型中偏参梯度 tensor([-0.9928])\n",
						"第 1057 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2845]])\n",
						"模型中偏参梯度 tensor([-0.9923])\n",
						"第 1058 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2844]])\n",
						"模型中偏参梯度 tensor([-0.9920])\n",
						"第 1059 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2842]])\n",
						"模型中偏参梯度 tensor([-0.9916])\n",
						"第 1060 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2841]])\n",
						"模型中偏参梯度 tensor([-0.9912])\n",
						"第 53 次epoch\n",
						"第 1061 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2840]])\n",
						"模型中偏参梯度 tensor([-0.9908])\n",
						"第 1062 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2839]])\n",
						"模型中偏参梯度 tensor([-0.9904])\n",
						"第 1063 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2838]])\n",
						"模型中偏参梯度 tensor([-0.9900])\n",
						"第 1064 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2836]])\n",
						"模型中偏参梯度 tensor([-0.9896])\n",
						"第 1065 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2835]])\n",
						"模型中偏参梯度 tensor([-0.9892])\n",
						"第 1066 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2834]])\n",
						"模型中偏参梯度 tensor([-0.9888])\n",
						"第 1067 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2833]])\n",
						"模型中偏参梯度 tensor([-0.9884])\n",
						"第 1068 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2831]])\n",
						"模型中偏参梯度 tensor([-0.9880])\n",
						"第 1069 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2830]])\n",
						"模型中偏参梯度 tensor([-0.9876])\n",
						"第 1070 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2829]])\n",
						"模型中偏参梯度 tensor([-0.9872])\n",
						"第 1071 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2828]])\n",
						"模型中偏参梯度 tensor([-0.9868])\n",
						"第 1072 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2827]])\n",
						"模型中偏参梯度 tensor([-0.9864])\n",
						"第 1073 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2826]])\n",
						"模型中偏参梯度 tensor([-0.9860])\n",
						"第 1074 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2825]])\n",
						"模型中偏参梯度 tensor([-0.9856])\n",
						"第 1075 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2824]])\n",
						"模型中偏参梯度 tensor([-0.9852])\n",
						"第 1076 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2823]])\n",
						"模型中偏参梯度 tensor([-0.9848])\n",
						"第 1077 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2822]])\n",
						"模型中偏参梯度 tensor([-0.9844])\n",
						"第 1078 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2821]])\n",
						"模型中偏参梯度 tensor([-0.9840])\n",
						"第 1079 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2819]])\n",
						"模型中偏参梯度 tensor([-0.9836])\n",
						"第 1080 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2818]])\n",
						"模型中偏参梯度 tensor([-0.9832])\n",
						"第 54 次epoch\n",
						"第 1081 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2817]])\n",
						"模型中偏参梯度 tensor([-0.9828])\n",
						"第 1082 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2816]])\n",
						"模型中偏参梯度 tensor([-0.9824])\n",
						"第 1083 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2814]])\n",
						"模型中偏参梯度 tensor([-0.9820])\n",
						"第 1084 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2813]])\n",
						"模型中偏参梯度 tensor([-0.9817])\n",
						"第 1085 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2812]])\n",
						"模型中偏参梯度 tensor([-0.9813])\n",
						"第 1086 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2811]])\n",
						"模型中偏参梯度 tensor([-0.9809])\n",
						"第 1087 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2810]])\n",
						"模型中偏参梯度 tensor([-0.9805])\n",
						"第 1088 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2809]])\n",
						"模型中偏参梯度 tensor([-0.9801])\n",
						"第 1089 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2808]])\n",
						"模型中偏参梯度 tensor([-0.9797])\n",
						"第 1090 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2807]])\n",
						"模型中偏参梯度 tensor([-0.9793])\n",
						"第 1091 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2806]])\n",
						"模型中偏参梯度 tensor([-0.9789])\n",
						"第 1092 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2805]])\n",
						"模型中偏参梯度 tensor([-0.9785])\n",
						"第 1093 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2804]])\n",
						"模型中偏参梯度 tensor([-0.9781])\n",
						"第 1094 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2803]])\n",
						"模型中偏参梯度 tensor([-0.9777])\n",
						"第 1095 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2801]])\n",
						"模型中偏参梯度 tensor([-0.9773])\n",
						"第 1096 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2800]])\n",
						"模型中偏参梯度 tensor([-0.9769])\n",
						"第 1097 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2799]])\n",
						"模型中偏参梯度 tensor([-0.9765])\n",
						"第 1098 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2798]])\n",
						"模型中偏参梯度 tensor([-0.9761])\n",
						"第 1099 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2797]])\n",
						"模型中偏参梯度 tensor([-0.9757])\n",
						"第 1100 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2795]])\n",
						"模型中偏参梯度 tensor([-0.9753])\n",
						"第 55 次epoch\n",
						"第 1101 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2794]])\n",
						"模型中偏参梯度 tensor([-0.9750])\n",
						"第 1102 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2793]])\n",
						"模型中偏参梯度 tensor([-0.9746])\n",
						"第 1103 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2792]])\n",
						"模型中偏参梯度 tensor([-0.9742])\n",
						"第 1104 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2791]])\n",
						"模型中偏参梯度 tensor([-0.9738])\n",
						"第 1105 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2790]])\n",
						"模型中偏参梯度 tensor([-0.9734])\n",
						"第 1106 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2789]])\n",
						"模型中偏参梯度 tensor([-0.9730])\n",
						"第 1107 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2788]])\n",
						"模型中偏参梯度 tensor([-0.9726])\n",
						"第 1108 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2787]])\n",
						"模型中偏参梯度 tensor([-0.9722])\n",
						"第 1109 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2786]])\n",
						"模型中偏参梯度 tensor([-0.9718])\n",
						"第 1110 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2785]])\n",
						"模型中偏参梯度 tensor([-0.9714])\n",
						"第 1111 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2784]])\n",
						"模型中偏参梯度 tensor([-0.9710])\n",
						"第 1112 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2782]])\n",
						"模型中偏参梯度 tensor([-0.9706])\n",
						"第 1113 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2781]])\n",
						"模型中偏参梯度 tensor([-0.9702])\n",
						"第 1114 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2780]])\n",
						"模型中偏参梯度 tensor([-0.9699])\n",
						"第 1115 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2779]])\n",
						"模型中偏参梯度 tensor([-0.9695])\n",
						"第 1116 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2778]])\n",
						"模型中偏参梯度 tensor([-0.9691])\n",
						"第 1117 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2776]])\n",
						"模型中偏参梯度 tensor([-0.9687])\n",
						"第 1118 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2775]])\n",
						"模型中偏参梯度 tensor([-0.9683])\n",
						"第 1119 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2774]])\n",
						"模型中偏参梯度 tensor([-0.9679])\n",
						"第 1120 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2773]])\n",
						"模型中偏参梯度 tensor([-0.9675])\n",
						"第 56 次epoch\n",
						"第 1121 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2772]])\n",
						"模型中偏参梯度 tensor([-0.9671])\n",
						"第 1122 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2771]])\n",
						"模型中偏参梯度 tensor([-0.9667])\n",
						"第 1123 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2770]])\n",
						"模型中偏参梯度 tensor([-0.9663])\n",
						"第 1124 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2769]])\n",
						"模型中偏参梯度 tensor([-0.9659])\n",
						"第 1125 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2768]])\n",
						"模型中偏参梯度 tensor([-0.9656])\n",
						"第 1126 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2767]])\n",
						"模型中偏参梯度 tensor([-0.9652])\n",
						"第 1127 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2766]])\n",
						"模型中偏参梯度 tensor([-0.9648])\n",
						"第 1128 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2765]])\n",
						"模型中偏参梯度 tensor([-0.9644])\n",
						"第 1129 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2764]])\n",
						"模型中偏参梯度 tensor([-0.9640])\n",
						"第 1130 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2762]])\n",
						"模型中偏参梯度 tensor([-0.9636])\n",
						"第 1131 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2761]])\n",
						"模型中偏参梯度 tensor([-0.9632])\n",
						"第 1132 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2760]])\n",
						"模型中偏参梯度 tensor([-0.9629])\n",
						"第 1133 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2759]])\n",
						"模型中偏参梯度 tensor([-0.9625])\n",
						"第 1134 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2757]])\n",
						"模型中偏参梯度 tensor([-0.9621])\n",
						"第 1135 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2756]])\n",
						"模型中偏参梯度 tensor([-0.9617])\n",
						"第 1136 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2755]])\n",
						"模型中偏参梯度 tensor([-0.9613])\n",
						"第 1137 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2754]])\n",
						"模型中偏参梯度 tensor([-0.9609])\n",
						"第 1138 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2753]])\n",
						"模型中偏参梯度 tensor([-0.9605])\n",
						"第 1139 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2752]])\n",
						"模型中偏参梯度 tensor([-0.9601])\n",
						"第 1140 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2751]])\n",
						"模型中偏参梯度 tensor([-0.9598])\n",
						"第 57 次epoch\n",
						"第 1141 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2750]])\n",
						"模型中偏参梯度 tensor([-0.9594])\n",
						"第 1142 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2749]])\n",
						"模型中偏参梯度 tensor([-0.9590])\n",
						"第 1143 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2748]])\n",
						"模型中偏参梯度 tensor([-0.9586])\n",
						"第 1144 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2747]])\n",
						"模型中偏参梯度 tensor([-0.9582])\n",
						"第 1145 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2746]])\n",
						"模型中偏参梯度 tensor([-0.9578])\n",
						"第 1146 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2744]])\n",
						"模型中偏参梯度 tensor([-0.9574])\n",
						"第 1147 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2743]])\n",
						"模型中偏参梯度 tensor([-0.9571])\n",
						"第 1148 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2742]])\n",
						"模型中偏参梯度 tensor([-0.9567])\n",
						"第 1149 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2741]])\n",
						"模型中偏参梯度 tensor([-0.9563])\n",
						"第 1150 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2740]])\n",
						"模型中偏参梯度 tensor([-0.9559])\n",
						"第 1151 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2738]])\n",
						"模型中偏参梯度 tensor([-0.9555])\n",
						"第 1152 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2737]])\n",
						"模型中偏参梯度 tensor([-0.9552])\n",
						"第 1153 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2736]])\n",
						"模型中偏参梯度 tensor([-0.9548])\n",
						"第 1154 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2735]])\n",
						"模型中偏参梯度 tensor([-0.9544])\n",
						"第 1155 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2734]])\n",
						"模型中偏参梯度 tensor([-0.9540])\n",
						"第 1156 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2733]])\n",
						"模型中偏参梯度 tensor([-0.9536])\n",
						"第 1157 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2732]])\n",
						"模型中偏参梯度 tensor([-0.9532])\n",
						"第 1158 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2731]])\n",
						"模型中偏参梯度 tensor([-0.9528])\n",
						"第 1159 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2730]])\n",
						"模型中偏参梯度 tensor([-0.9525])\n",
						"第 1160 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2729]])\n",
						"模型中偏参梯度 tensor([-0.9521])\n",
						"第 58 次epoch\n",
						"第 1161 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2728]])\n",
						"模型中偏参梯度 tensor([-0.9517])\n",
						"第 1162 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2727]])\n",
						"模型中偏参梯度 tensor([-0.9513])\n",
						"第 1163 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2726]])\n",
						"模型中偏参梯度 tensor([-0.9509])\n",
						"第 1164 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2724]])\n",
						"模型中偏参梯度 tensor([-0.9505])\n",
						"第 1165 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2723]])\n",
						"模型中偏参梯度 tensor([-0.9502])\n",
						"第 1166 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2722]])\n",
						"模型中偏参梯度 tensor([-0.9498])\n",
						"第 1167 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2721]])\n",
						"模型中偏参梯度 tensor([-0.9494])\n",
						"第 1168 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2720]])\n",
						"模型中偏参梯度 tensor([-0.9490])\n",
						"第 1169 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2718]])\n",
						"模型中偏参梯度 tensor([-0.9486])\n",
						"第 1170 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2717]])\n",
						"模型中偏参梯度 tensor([-0.9483])\n",
						"第 1171 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2716]])\n",
						"模型中偏参梯度 tensor([-0.9479])\n",
						"第 1172 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2715]])\n",
						"模型中偏参梯度 tensor([-0.9475])\n",
						"第 1173 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2714]])\n",
						"模型中偏参梯度 tensor([-0.9471])\n",
						"第 1174 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2713]])\n",
						"模型中偏参梯度 tensor([-0.9467])\n",
						"第 1175 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2712]])\n",
						"模型中偏参梯度 tensor([-0.9463])\n",
						"第 1176 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2711]])\n",
						"模型中偏参梯度 tensor([-0.9460])\n",
						"第 1177 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2710]])\n",
						"模型中偏参梯度 tensor([-0.9456])\n",
						"第 1178 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2709]])\n",
						"模型中偏参梯度 tensor([-0.9452])\n",
						"第 1179 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2708]])\n",
						"模型中偏参梯度 tensor([-0.9448])\n",
						"第 1180 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2707]])\n",
						"模型中偏参梯度 tensor([-0.9444])\n",
						"第 59 次epoch\n",
						"第 1181 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2706]])\n",
						"模型中偏参梯度 tensor([-0.9441])\n",
						"第 1182 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2705]])\n",
						"模型中偏参梯度 tensor([-0.9437])\n",
						"第 1183 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2704]])\n",
						"模型中偏参梯度 tensor([-0.9433])\n",
						"第 1184 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2702]])\n",
						"模型中偏参梯度 tensor([-0.9429])\n",
						"第 1185 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2701]])\n",
						"模型中偏参梯度 tensor([-0.9425])\n",
						"第 1186 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2700]])\n",
						"模型中偏参梯度 tensor([-0.9422])\n",
						"第 1187 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2699]])\n",
						"模型中偏参梯度 tensor([-0.9418])\n",
						"第 1188 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2698]])\n",
						"模型中偏参梯度 tensor([-0.9414])\n",
						"第 1189 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2697]])\n",
						"模型中偏参梯度 tensor([-0.9410])\n",
						"第 1190 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2696]])\n",
						"模型中偏参梯度 tensor([-0.9406])\n",
						"第 1191 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2695]])\n",
						"模型中偏参梯度 tensor([-0.9403])\n",
						"第 1192 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2694]])\n",
						"模型中偏参梯度 tensor([-0.9399])\n",
						"第 1193 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2693]])\n",
						"模型中偏参梯度 tensor([-0.9395])\n",
						"第 1194 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2692]])\n",
						"模型中偏参梯度 tensor([-0.9391])\n",
						"第 1195 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2691]])\n",
						"模型中偏参梯度 tensor([-0.9387])\n",
						"第 1196 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2690]])\n",
						"模型中偏参梯度 tensor([-0.9384])\n",
						"第 1197 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2689]])\n",
						"模型中偏参梯度 tensor([-0.9380])\n",
						"第 1198 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2688]])\n",
						"模型中偏参梯度 tensor([-0.9376])\n",
						"第 1199 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2687]])\n",
						"模型中偏参梯度 tensor([-0.9372])\n",
						"第 1200 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2685]])\n",
						"模型中偏参梯度 tensor([-0.9369])\n",
						"第 60 次epoch\n",
						"第 1201 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2684]])\n",
						"模型中偏参梯度 tensor([-0.9365])\n",
						"第 1202 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2683]])\n",
						"模型中偏参梯度 tensor([-0.9361])\n",
						"第 1203 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2682]])\n",
						"模型中偏参梯度 tensor([-0.9357])\n",
						"第 1204 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2681]])\n",
						"模型中偏参梯度 tensor([-0.9354])\n",
						"第 1205 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2679]])\n",
						"模型中偏参梯度 tensor([-0.9350])\n",
						"第 1206 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2678]])\n",
						"模型中偏参梯度 tensor([-0.9346])\n",
						"第 1207 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2678]])\n",
						"模型中偏参梯度 tensor([-0.9342])\n",
						"第 1208 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2677]])\n",
						"模型中偏参梯度 tensor([-0.9339])\n",
						"第 1209 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2676]])\n",
						"模型中偏参梯度 tensor([-0.9335])\n",
						"第 1210 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2675]])\n",
						"模型中偏参梯度 tensor([-0.9331])\n",
						"第 1211 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2674]])\n",
						"模型中偏参梯度 tensor([-0.9327])\n",
						"第 1212 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2673]])\n",
						"模型中偏参梯度 tensor([-0.9323])\n",
						"第 1213 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2672]])\n",
						"模型中偏参梯度 tensor([-0.9320])\n",
						"第 1214 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2671]])\n",
						"模型中偏参梯度 tensor([-0.9316])\n",
						"第 1215 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2669]])\n",
						"模型中偏参梯度 tensor([-0.9312])\n",
						"第 1216 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2668]])\n",
						"模型中偏参梯度 tensor([-0.9308])\n",
						"第 1217 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2667]])\n",
						"模型中偏参梯度 tensor([-0.9305])\n",
						"第 1218 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2666]])\n",
						"模型中偏参梯度 tensor([-0.9301])\n",
						"第 1219 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2665]])\n",
						"模型中偏参梯度 tensor([-0.9297])\n",
						"第 1220 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2664]])\n",
						"模型中偏参梯度 tensor([-0.9294])\n",
						"第 61 次epoch\n",
						"第 1221 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2662]])\n",
						"模型中偏参梯度 tensor([-0.9290])\n",
						"第 1222 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2661]])\n",
						"模型中偏参梯度 tensor([-0.9286])\n",
						"第 1223 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2660]])\n",
						"模型中偏参梯度 tensor([-0.9282])\n",
						"第 1224 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2659]])\n",
						"模型中偏参梯度 tensor([-0.9279])\n",
						"第 1225 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2658]])\n",
						"模型中偏参梯度 tensor([-0.9275])\n",
						"第 1226 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2657]])\n",
						"模型中偏参梯度 tensor([-0.9271])\n",
						"第 1227 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2656]])\n",
						"模型中偏参梯度 tensor([-0.9267])\n",
						"第 1228 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2655]])\n",
						"模型中偏参梯度 tensor([-0.9264])\n",
						"第 1229 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2654]])\n",
						"模型中偏参梯度 tensor([-0.9260])\n",
						"第 1230 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2653]])\n",
						"模型中偏参梯度 tensor([-0.9256])\n",
						"第 1231 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2652]])\n",
						"模型中偏参梯度 tensor([-0.9252])\n",
						"第 1232 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2651]])\n",
						"模型中偏参梯度 tensor([-0.9249])\n",
						"第 1233 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2650]])\n",
						"模型中偏参梯度 tensor([-0.9245])\n",
						"第 1234 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2649]])\n",
						"模型中偏参梯度 tensor([-0.9241])\n",
						"第 1235 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2648]])\n",
						"模型中偏参梯度 tensor([-0.9238])\n",
						"第 1236 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2647]])\n",
						"模型中偏参梯度 tensor([-0.9234])\n",
						"第 1237 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2646]])\n",
						"模型中偏参梯度 tensor([-0.9230])\n",
						"第 1238 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2644]])\n",
						"模型中偏参梯度 tensor([-0.9227])\n",
						"第 1239 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2643]])\n",
						"模型中偏参梯度 tensor([-0.9223])\n",
						"第 1240 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2642]])\n",
						"模型中偏参梯度 tensor([-0.9219])\n",
						"第 62 次epoch\n",
						"第 1241 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2641]])\n",
						"模型中偏参梯度 tensor([-0.9216])\n",
						"第 1242 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2640]])\n",
						"模型中偏参梯度 tensor([-0.9212])\n",
						"第 1243 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2639]])\n",
						"模型中偏参梯度 tensor([-0.9208])\n",
						"第 1244 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2638]])\n",
						"模型中偏参梯度 tensor([-0.9204])\n",
						"第 1245 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2637]])\n",
						"模型中偏参梯度 tensor([-0.9201])\n",
						"第 1246 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2636]])\n",
						"模型中偏参梯度 tensor([-0.9197])\n",
						"第 1247 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2635]])\n",
						"模型中偏参梯度 tensor([-0.9193])\n",
						"第 1248 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2634]])\n",
						"模型中偏参梯度 tensor([-0.9189])\n",
						"第 1249 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2633]])\n",
						"模型中偏参梯度 tensor([-0.9186])\n",
						"第 1250 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2632]])\n",
						"模型中偏参梯度 tensor([-0.9182])\n",
						"第 1251 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2631]])\n",
						"模型中偏参梯度 tensor([-0.9178])\n",
						"第 1252 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2630]])\n",
						"模型中偏参梯度 tensor([-0.9175])\n",
						"第 1253 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2629]])\n",
						"模型中偏参梯度 tensor([-0.9171])\n",
						"第 1254 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2628]])\n",
						"模型中偏参梯度 tensor([-0.9167])\n",
						"第 1255 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2626]])\n",
						"模型中偏参梯度 tensor([-0.9164])\n",
						"第 1256 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2625]])\n",
						"模型中偏参梯度 tensor([-0.9160])\n",
						"第 1257 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2624]])\n",
						"模型中偏参梯度 tensor([-0.9156])\n",
						"第 1258 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2623]])\n",
						"模型中偏参梯度 tensor([-0.9153])\n",
						"第 1259 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2622]])\n",
						"模型中偏参梯度 tensor([-0.9149])\n",
						"第 1260 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2621]])\n",
						"模型中偏参梯度 tensor([-0.9145])\n",
						"第 63 次epoch\n",
						"第 1261 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2620]])\n",
						"模型中偏参梯度 tensor([-0.9142])\n",
						"第 1262 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2619]])\n",
						"模型中偏参梯度 tensor([-0.9138])\n",
						"第 1263 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2618]])\n",
						"模型中偏参梯度 tensor([-0.9134])\n",
						"第 1264 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2617]])\n",
						"模型中偏参梯度 tensor([-0.9130])\n",
						"第 1265 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2616]])\n",
						"模型中偏参梯度 tensor([-0.9127])\n",
						"第 1266 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2615]])\n",
						"模型中偏参梯度 tensor([-0.9123])\n",
						"第 1267 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2614]])\n",
						"模型中偏参梯度 tensor([-0.9119])\n",
						"第 1268 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2613]])\n",
						"模型中偏参梯度 tensor([-0.9116])\n",
						"第 1269 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2612]])\n",
						"模型中偏参梯度 tensor([-0.9112])\n",
						"第 1270 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2611]])\n",
						"模型中偏参梯度 tensor([-0.9108])\n",
						"第 1271 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2610]])\n",
						"模型中偏参梯度 tensor([-0.9105])\n",
						"第 1272 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2608]])\n",
						"模型中偏参梯度 tensor([-0.9101])\n",
						"第 1273 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2607]])\n",
						"模型中偏参梯度 tensor([-0.9097])\n",
						"第 1274 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2606]])\n",
						"模型中偏参梯度 tensor([-0.9094])\n",
						"第 1275 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2605]])\n",
						"模型中偏参梯度 tensor([-0.9090])\n",
						"第 1276 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2604]])\n",
						"模型中偏参梯度 tensor([-0.9087])\n",
						"第 1277 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2603]])\n",
						"模型中偏参梯度 tensor([-0.9083])\n",
						"第 1278 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2602]])\n",
						"模型中偏参梯度 tensor([-0.9079])\n",
						"第 1279 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2601]])\n",
						"模型中偏参梯度 tensor([-0.9076])\n",
						"第 1280 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2600]])\n",
						"模型中偏参梯度 tensor([-0.9072])\n",
						"第 64 次epoch\n",
						"第 1281 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2599]])\n",
						"模型中偏参梯度 tensor([-0.9068])\n",
						"第 1282 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2598]])\n",
						"模型中偏参梯度 tensor([-0.9065])\n",
						"第 1283 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2597]])\n",
						"模型中偏参梯度 tensor([-0.9061])\n",
						"第 1284 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2596]])\n",
						"模型中偏参梯度 tensor([-0.9057])\n",
						"第 1285 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2595]])\n",
						"模型中偏参梯度 tensor([-0.9054])\n",
						"第 1286 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2594]])\n",
						"模型中偏参梯度 tensor([-0.9050])\n",
						"第 1287 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2593]])\n",
						"模型中偏参梯度 tensor([-0.9046])\n",
						"第 1288 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2592]])\n",
						"模型中偏参梯度 tensor([-0.9043])\n",
						"第 1289 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2591]])\n",
						"模型中偏参梯度 tensor([-0.9039])\n",
						"第 1290 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2590]])\n",
						"模型中偏参梯度 tensor([-0.9035])\n",
						"第 1291 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2588]])\n",
						"模型中偏参梯度 tensor([-0.9032])\n",
						"第 1292 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2587]])\n",
						"模型中偏参梯度 tensor([-0.9028])\n",
						"第 1293 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2586]])\n",
						"模型中偏参梯度 tensor([-0.9025])\n",
						"第 1294 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2585]])\n",
						"模型中偏参梯度 tensor([-0.9021])\n",
						"第 1295 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2584]])\n",
						"模型中偏参梯度 tensor([-0.9017])\n",
						"第 1296 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2583]])\n",
						"模型中偏参梯度 tensor([-0.9014])\n",
						"第 1297 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2582]])\n",
						"模型中偏参梯度 tensor([-0.9010])\n",
						"第 1298 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2581]])\n",
						"模型中偏参梯度 tensor([-0.9006])\n",
						"第 1299 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2580]])\n",
						"模型中偏参梯度 tensor([-0.9003])\n",
						"第 1300 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2579]])\n",
						"模型中偏参梯度 tensor([-0.8999])\n",
						"第 65 次epoch\n",
						"第 1301 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2578]])\n",
						"模型中偏参梯度 tensor([-0.8995])\n",
						"第 1302 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2577]])\n",
						"模型中偏参梯度 tensor([-0.8992])\n",
						"第 1303 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2576]])\n",
						"模型中偏参梯度 tensor([-0.8988])\n",
						"第 1304 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2575]])\n",
						"模型中偏参梯度 tensor([-0.8985])\n",
						"第 1305 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2574]])\n",
						"模型中偏参梯度 tensor([-0.8981])\n",
						"第 1306 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2573]])\n",
						"模型中偏参梯度 tensor([-0.8977])\n",
						"第 1307 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2572]])\n",
						"模型中偏参梯度 tensor([-0.8974])\n",
						"第 1308 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2571]])\n",
						"模型中偏参梯度 tensor([-0.8970])\n",
						"第 1309 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2570]])\n",
						"模型中偏参梯度 tensor([-0.8967])\n",
						"第 1310 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2569]])\n",
						"模型中偏参梯度 tensor([-0.8963])\n",
						"第 1311 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2568]])\n",
						"模型中偏参梯度 tensor([-0.8959])\n",
						"第 1312 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2566]])\n",
						"模型中偏参梯度 tensor([-0.8956])\n",
						"第 1313 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2565]])\n",
						"模型中偏参梯度 tensor([-0.8952])\n",
						"第 1314 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2564]])\n",
						"模型中偏参梯度 tensor([-0.8949])\n",
						"第 1315 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2564]])\n",
						"模型中偏参梯度 tensor([-0.8945])\n",
						"第 1316 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2563]])\n",
						"模型中偏参梯度 tensor([-0.8941])\n",
						"第 1317 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2562]])\n",
						"模型中偏参梯度 tensor([-0.8938])\n",
						"第 1318 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2561]])\n",
						"模型中偏参梯度 tensor([-0.8934])\n",
						"第 1319 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2560]])\n",
						"模型中偏参梯度 tensor([-0.8931])\n",
						"第 1320 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2559]])\n",
						"模型中偏参梯度 tensor([-0.8927])\n",
						"第 66 次epoch\n",
						"第 1321 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2558]])\n",
						"模型中偏参梯度 tensor([-0.8923])\n",
						"第 1322 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2557]])\n",
						"模型中偏参梯度 tensor([-0.8920])\n",
						"第 1323 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2556]])\n",
						"模型中偏参梯度 tensor([-0.8916])\n",
						"第 1324 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2555]])\n",
						"模型中偏参梯度 tensor([-0.8913])\n",
						"第 1325 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2554]])\n",
						"模型中偏参梯度 tensor([-0.8909])\n",
						"第 1326 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2553]])\n",
						"模型中偏参梯度 tensor([-0.8905])\n",
						"第 1327 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2552]])\n",
						"模型中偏参梯度 tensor([-0.8902])\n",
						"第 1328 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2551]])\n",
						"模型中偏参梯度 tensor([-0.8898])\n",
						"第 1329 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2549]])\n",
						"模型中偏参梯度 tensor([-0.8895])\n",
						"第 1330 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2548]])\n",
						"模型中偏参梯度 tensor([-0.8891])\n",
						"第 1331 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2547]])\n",
						"模型中偏参梯度 tensor([-0.8888])\n",
						"第 1332 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2546]])\n",
						"模型中偏参梯度 tensor([-0.8884])\n",
						"第 1333 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2545]])\n",
						"模型中偏参梯度 tensor([-0.8881])\n",
						"第 1334 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2544]])\n",
						"模型中偏参梯度 tensor([-0.8877])\n",
						"第 1335 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2543]])\n",
						"模型中偏参梯度 tensor([-0.8873])\n",
						"第 1336 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2542]])\n",
						"模型中偏参梯度 tensor([-0.8870])\n",
						"第 1337 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2541]])\n",
						"模型中偏参梯度 tensor([-0.8866])\n",
						"第 1338 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2540]])\n",
						"模型中偏参梯度 tensor([-0.8862])\n",
						"第 1339 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2540]])\n",
						"模型中偏参梯度 tensor([-0.8859])\n",
						"第 1340 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2539]])\n",
						"模型中偏参梯度 tensor([-0.8855])\n",
						"第 67 次epoch\n",
						"第 1341 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2538]])\n",
						"模型中偏参梯度 tensor([-0.8852])\n",
						"第 1342 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2537]])\n",
						"模型中偏参梯度 tensor([-0.8848])\n",
						"第 1343 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2535]])\n",
						"模型中偏参梯度 tensor([-0.8845])\n",
						"第 1344 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2534]])\n",
						"模型中偏参梯度 tensor([-0.8841])\n",
						"第 1345 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2533]])\n",
						"模型中偏参梯度 tensor([-0.8838])\n",
						"第 1346 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2532]])\n",
						"模型中偏参梯度 tensor([-0.8834])\n",
						"第 1347 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2531]])\n",
						"模型中偏参梯度 tensor([-0.8830])\n",
						"第 1348 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2530]])\n",
						"模型中偏参梯度 tensor([-0.8827])\n",
						"第 1349 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2529]])\n",
						"模型中偏参梯度 tensor([-0.8823])\n",
						"第 1350 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2528]])\n",
						"模型中偏参梯度 tensor([-0.8820])\n",
						"第 1351 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2526]])\n",
						"模型中偏参梯度 tensor([-0.8816])\n",
						"第 1352 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2526]])\n",
						"模型中偏参梯度 tensor([-0.8813])\n",
						"第 1353 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2525]])\n",
						"模型中偏参梯度 tensor([-0.8809])\n",
						"第 1354 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2524]])\n",
						"模型中偏参梯度 tensor([-0.8806])\n",
						"第 1355 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2523]])\n",
						"模型中偏参梯度 tensor([-0.8802])\n",
						"第 1356 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2522]])\n",
						"模型中偏参梯度 tensor([-0.8799])\n",
						"第 1357 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2521]])\n",
						"模型中偏参梯度 tensor([-0.8795])\n",
						"第 1358 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2520]])\n",
						"模型中偏参梯度 tensor([-0.8791])\n",
						"第 1359 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2519]])\n",
						"模型中偏参梯度 tensor([-0.8788])\n",
						"第 1360 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2518]])\n",
						"模型中偏参梯度 tensor([-0.8784])\n",
						"第 68 次epoch\n",
						"第 1361 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2517]])\n",
						"模型中偏参梯度 tensor([-0.8781])\n",
						"第 1362 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2516]])\n",
						"模型中偏参梯度 tensor([-0.8777])\n",
						"第 1363 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2515]])\n",
						"模型中偏参梯度 tensor([-0.8774])\n",
						"第 1364 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2514]])\n",
						"模型中偏参梯度 tensor([-0.8770])\n",
						"第 1365 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2513]])\n",
						"模型中偏参梯度 tensor([-0.8767])\n",
						"第 1366 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2512]])\n",
						"模型中偏参梯度 tensor([-0.8763])\n",
						"第 1367 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2511]])\n",
						"模型中偏参梯度 tensor([-0.8760])\n",
						"第 1368 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2509]])\n",
						"模型中偏参梯度 tensor([-0.8756])\n",
						"第 1369 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2508]])\n",
						"模型中偏参梯度 tensor([-0.8753])\n",
						"第 1370 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2507]])\n",
						"模型中偏参梯度 tensor([-0.8749])\n",
						"第 1371 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2506]])\n",
						"模型中偏参梯度 tensor([-0.8746])\n",
						"第 1372 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2505]])\n",
						"模型中偏参梯度 tensor([-0.8742])\n",
						"第 1373 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2504]])\n",
						"模型中偏参梯度 tensor([-0.8739])\n",
						"第 1374 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2504]])\n",
						"模型中偏参梯度 tensor([-0.8735])\n",
						"第 1375 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2503]])\n",
						"模型中偏参梯度 tensor([-0.8732])\n",
						"第 1376 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2502]])\n",
						"模型中偏参梯度 tensor([-0.8728])\n",
						"第 1377 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2501]])\n",
						"模型中偏参梯度 tensor([-0.8725])\n",
						"第 1378 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2500]])\n",
						"模型中偏参梯度 tensor([-0.8721])\n",
						"第 1379 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2499]])\n",
						"模型中偏参梯度 tensor([-0.8717])\n",
						"第 1380 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2498]])\n",
						"模型中偏参梯度 tensor([-0.8714])\n",
						"第 69 次epoch\n",
						"第 1381 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2497]])\n",
						"模型中偏参梯度 tensor([-0.8710])\n",
						"第 1382 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2496]])\n",
						"模型中偏参梯度 tensor([-0.8707])\n",
						"第 1383 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2495]])\n",
						"模型中偏参梯度 tensor([-0.8704])\n",
						"第 1384 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2494]])\n",
						"模型中偏参梯度 tensor([-0.8700])\n",
						"第 1385 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2492]])\n",
						"模型中偏参梯度 tensor([-0.8697])\n",
						"第 1386 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2491]])\n",
						"模型中偏参梯度 tensor([-0.8693])\n",
						"第 1387 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2490]])\n",
						"模型中偏参梯度 tensor([-0.8690])\n",
						"第 1388 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2489]])\n",
						"模型中偏参梯度 tensor([-0.8686])\n",
						"第 1389 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2488]])\n",
						"模型中偏参梯度 tensor([-0.8683])\n",
						"第 1390 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2487]])\n",
						"模型中偏参梯度 tensor([-0.8679])\n",
						"第 1391 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2486]])\n",
						"模型中偏参梯度 tensor([-0.8676])\n",
						"第 1392 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2486]])\n",
						"模型中偏参梯度 tensor([-0.8672])\n",
						"第 1393 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2485]])\n",
						"模型中偏参梯度 tensor([-0.8669])\n",
						"第 1394 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2484]])\n",
						"模型中偏参梯度 tensor([-0.8665])\n",
						"第 1395 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2483]])\n",
						"模型中偏参梯度 tensor([-0.8662])\n",
						"第 1396 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2482]])\n",
						"模型中偏参梯度 tensor([-0.8658])\n",
						"第 1397 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2481]])\n",
						"模型中偏参梯度 tensor([-0.8655])\n",
						"第 1398 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2480]])\n",
						"模型中偏参梯度 tensor([-0.8651])\n",
						"第 1399 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2479]])\n",
						"模型中偏参梯度 tensor([-0.8648])\n",
						"第 1400 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2478]])\n",
						"模型中偏参梯度 tensor([-0.8644])\n",
						"第 70 次epoch\n",
						"第 1401 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2477]])\n",
						"模型中偏参梯度 tensor([-0.8641])\n",
						"第 1402 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2476]])\n",
						"模型中偏参梯度 tensor([-0.8637])\n",
						"第 1403 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2475]])\n",
						"模型中偏参梯度 tensor([-0.8634])\n",
						"第 1404 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2474]])\n",
						"模型中偏参梯度 tensor([-0.8630])\n",
						"第 1405 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2473]])\n",
						"模型中偏参梯度 tensor([-0.8627])\n",
						"第 1406 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2471]])\n",
						"模型中偏参梯度 tensor([-0.8623])\n",
						"第 1407 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2470]])\n",
						"模型中偏参梯度 tensor([-0.8620])\n",
						"第 1408 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2469]])\n",
						"模型中偏参梯度 tensor([-0.8617])\n",
						"第 1409 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2468]])\n",
						"模型中偏参梯度 tensor([-0.8613])\n",
						"第 1410 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2467]])\n",
						"模型中偏参梯度 tensor([-0.8610])\n",
						"第 1411 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2467]])\n",
						"模型中偏参梯度 tensor([-0.8606])\n",
						"第 1412 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2466]])\n",
						"模型中偏参梯度 tensor([-0.8603])\n",
						"第 1413 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2465]])\n",
						"模型中偏参梯度 tensor([-0.8599])\n",
						"第 1414 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2464]])\n",
						"模型中偏参梯度 tensor([-0.8596])\n",
						"第 1415 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2463]])\n",
						"模型中偏参梯度 tensor([-0.8592])\n",
						"第 1416 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2462]])\n",
						"模型中偏参梯度 tensor([-0.8589])\n",
						"第 1417 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2461]])\n",
						"模型中偏参梯度 tensor([-0.8585])\n",
						"第 1418 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2460]])\n",
						"模型中偏参梯度 tensor([-0.8582])\n",
						"第 1419 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2459]])\n",
						"模型中偏参梯度 tensor([-0.8578])\n",
						"第 1420 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2458]])\n",
						"模型中偏参梯度 tensor([-0.8575])\n",
						"第 71 次epoch\n",
						"第 1421 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2457]])\n",
						"模型中偏参梯度 tensor([-0.8571])\n",
						"第 1422 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2456]])\n",
						"模型中偏参梯度 tensor([-0.8568])\n",
						"第 1423 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2455]])\n",
						"模型中偏参梯度 tensor([-0.8565])\n",
						"第 1424 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2454]])\n",
						"模型中偏参梯度 tensor([-0.8561])\n",
						"第 1425 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2453]])\n",
						"模型中偏参梯度 tensor([-0.8558])\n",
						"第 1426 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2451]])\n",
						"模型中偏参梯度 tensor([-0.8554])\n",
						"第 1427 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2450]])\n",
						"模型中偏参梯度 tensor([-0.8551])\n",
						"第 1428 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2449]])\n",
						"模型中偏参梯度 tensor([-0.8547])\n",
						"第 1429 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2449]])\n",
						"模型中偏参梯度 tensor([-0.8544])\n",
						"第 1430 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2448]])\n",
						"模型中偏参梯度 tensor([-0.8540])\n",
						"第 1431 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2447]])\n",
						"模型中偏参梯度 tensor([-0.8537])\n",
						"第 1432 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2446]])\n",
						"模型中偏参梯度 tensor([-0.8534])\n",
						"第 1433 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2445]])\n",
						"模型中偏参梯度 tensor([-0.8530])\n",
						"第 1434 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2444]])\n",
						"模型中偏参梯度 tensor([-0.8527])\n",
						"第 1435 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2443]])\n",
						"模型中偏参梯度 tensor([-0.8523])\n",
						"第 1436 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2442]])\n",
						"模型中偏参梯度 tensor([-0.8520])\n",
						"第 1437 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2441]])\n",
						"模型中偏参梯度 tensor([-0.8516])\n",
						"第 1438 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2440]])\n",
						"模型中偏参梯度 tensor([-0.8513])\n",
						"第 1439 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2439]])\n",
						"模型中偏参梯度 tensor([-0.8509])\n",
						"第 1440 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2438]])\n",
						"模型中偏参梯度 tensor([-0.8506])\n",
						"第 72 次epoch\n",
						"第 1441 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2437]])\n",
						"模型中偏参梯度 tensor([-0.8503])\n",
						"第 1442 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2436]])\n",
						"模型中偏参梯度 tensor([-0.8499])\n",
						"第 1443 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2435]])\n",
						"模型中偏参梯度 tensor([-0.8496])\n",
						"第 1444 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2434]])\n",
						"模型中偏参梯度 tensor([-0.8493])\n",
						"第 1445 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2433]])\n",
						"模型中偏参梯度 tensor([-0.8489])\n",
						"第 1446 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2432]])\n",
						"模型中偏参梯度 tensor([-0.8486])\n",
						"第 1447 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2431]])\n",
						"模型中偏参梯度 tensor([-0.8482])\n",
						"第 1448 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2430]])\n",
						"模型中偏参梯度 tensor([-0.8479])\n",
						"第 1449 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2429]])\n",
						"模型中偏参梯度 tensor([-0.8475])\n",
						"第 1450 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2428]])\n",
						"模型中偏参梯度 tensor([-0.8472])\n",
						"第 1451 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2428]])\n",
						"模型中偏参梯度 tensor([-0.8469])\n",
						"第 1452 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2427]])\n",
						"模型中偏参梯度 tensor([-0.8465])\n",
						"第 1453 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2426]])\n",
						"模型中偏参梯度 tensor([-0.8462])\n",
						"第 1454 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2425]])\n",
						"模型中偏参梯度 tensor([-0.8458])\n",
						"第 1455 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2424]])\n",
						"模型中偏参梯度 tensor([-0.8455])\n",
						"第 1456 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2423]])\n",
						"模型中偏参梯度 tensor([-0.8451])\n",
						"第 1457 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2422]])\n",
						"模型中偏参梯度 tensor([-0.8448])\n",
						"第 1458 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2421]])\n",
						"模型中偏参梯度 tensor([-0.8445])\n",
						"第 1459 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2420]])\n",
						"模型中偏参梯度 tensor([-0.8441])\n",
						"第 1460 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2419]])\n",
						"模型中偏参梯度 tensor([-0.8438])\n",
						"第 73 次epoch\n",
						"第 1461 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2418]])\n",
						"模型中偏参梯度 tensor([-0.8434])\n",
						"第 1462 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2417]])\n",
						"模型中偏参梯度 tensor([-0.8431])\n",
						"第 1463 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2416]])\n",
						"模型中偏参梯度 tensor([-0.8428])\n",
						"第 1464 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2414]])\n",
						"模型中偏参梯度 tensor([-0.8424])\n",
						"第 1465 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2413]])\n",
						"模型中偏参梯度 tensor([-0.8421])\n",
						"第 1466 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2412]])\n",
						"模型中偏参梯度 tensor([-0.8418])\n",
						"第 1467 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2411]])\n",
						"模型中偏参梯度 tensor([-0.8414])\n",
						"第 1468 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2411]])\n",
						"模型中偏参梯度 tensor([-0.8411])\n",
						"第 1469 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2410]])\n",
						"模型中偏参梯度 tensor([-0.8407])\n",
						"第 1470 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2409]])\n",
						"模型中偏参梯度 tensor([-0.8404])\n",
						"第 1471 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2408]])\n",
						"模型中偏参梯度 tensor([-0.8401])\n",
						"第 1472 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2407]])\n",
						"模型中偏参梯度 tensor([-0.8397])\n",
						"第 1473 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2406]])\n",
						"模型中偏参梯度 tensor([-0.8394])\n",
						"第 1474 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2405]])\n",
						"模型中偏参梯度 tensor([-0.8390])\n",
						"第 1475 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2404]])\n",
						"模型中偏参梯度 tensor([-0.8387])\n",
						"第 1476 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2403]])\n",
						"模型中偏参梯度 tensor([-0.8384])\n",
						"第 1477 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2402]])\n",
						"模型中偏参梯度 tensor([-0.8380])\n",
						"第 1478 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2401]])\n",
						"模型中偏参梯度 tensor([-0.8377])\n",
						"第 1479 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2400]])\n",
						"模型中偏参梯度 tensor([-0.8374])\n",
						"第 1480 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2399]])\n",
						"模型中偏参梯度 tensor([-0.8370])\n",
						"第 74 次epoch\n",
						"第 1481 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2398]])\n",
						"模型中偏参梯度 tensor([-0.8367])\n",
						"第 1482 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2397]])\n",
						"模型中偏参梯度 tensor([-0.8364])\n",
						"第 1483 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2396]])\n",
						"模型中偏参梯度 tensor([-0.8360])\n",
						"第 1484 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2395]])\n",
						"模型中偏参梯度 tensor([-0.8357])\n",
						"第 1485 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2394]])\n",
						"模型中偏参梯度 tensor([-0.8354])\n",
						"第 1486 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2393]])\n",
						"模型中偏参梯度 tensor([-0.8350])\n",
						"第 1487 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2392]])\n",
						"模型中偏参梯度 tensor([-0.8347])\n",
						"第 1488 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2391]])\n",
						"模型中偏参梯度 tensor([-0.8343])\n",
						"第 1489 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2390]])\n",
						"模型中偏参梯度 tensor([-0.8340])\n",
						"第 1490 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2390]])\n",
						"模型中偏参梯度 tensor([-0.8337])\n",
						"第 1491 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2389]])\n",
						"模型中偏参梯度 tensor([-0.8333])\n",
						"第 1492 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2388]])\n",
						"模型中偏参梯度 tensor([-0.8330])\n",
						"第 1493 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2387]])\n",
						"模型中偏参梯度 tensor([-0.8327])\n",
						"第 1494 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2386]])\n",
						"模型中偏参梯度 tensor([-0.8323])\n",
						"第 1495 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2385]])\n",
						"模型中偏参梯度 tensor([-0.8320])\n",
						"第 1496 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2384]])\n",
						"模型中偏参梯度 tensor([-0.8316])\n",
						"第 1497 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2383]])\n",
						"模型中偏参梯度 tensor([-0.8313])\n",
						"第 1498 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2382]])\n",
						"模型中偏参梯度 tensor([-0.8310])\n",
						"第 1499 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2381]])\n",
						"模型中偏参梯度 tensor([-0.8307])\n",
						"第 1500 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2380]])\n",
						"模型中偏参梯度 tensor([-0.8303])\n",
						"第 75 次epoch\n",
						"第 1501 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2379]])\n",
						"模型中偏参梯度 tensor([-0.8300])\n",
						"第 1502 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2378]])\n",
						"模型中偏参梯度 tensor([-0.8297])\n",
						"第 1503 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2377]])\n",
						"模型中偏参梯度 tensor([-0.8293])\n",
						"第 1504 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2376]])\n",
						"模型中偏参梯度 tensor([-0.8290])\n",
						"第 1505 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2375]])\n",
						"模型中偏参梯度 tensor([-0.8287])\n",
						"第 1506 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2374]])\n",
						"模型中偏参梯度 tensor([-0.8283])\n",
						"第 1507 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2373]])\n",
						"模型中偏参梯度 tensor([-0.8280])\n",
						"第 1508 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2372]])\n",
						"模型中偏参梯度 tensor([-0.8277])\n",
						"第 1509 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2371]])\n",
						"模型中偏参梯度 tensor([-0.8273])\n",
						"第 1510 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2371]])\n",
						"模型中偏参梯度 tensor([-0.8270])\n",
						"第 1511 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2370]])\n",
						"模型中偏参梯度 tensor([-0.8266])\n",
						"第 1512 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2369]])\n",
						"模型中偏参梯度 tensor([-0.8263])\n",
						"第 1513 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2368]])\n",
						"模型中偏参梯度 tensor([-0.8260])\n",
						"第 1514 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2367]])\n",
						"模型中偏参梯度 tensor([-0.8256])\n",
						"第 1515 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2366]])\n",
						"模型中偏参梯度 tensor([-0.8253])\n",
						"第 1516 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2365]])\n",
						"模型中偏参梯度 tensor([-0.8250])\n",
						"第 1517 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2364]])\n",
						"模型中偏参梯度 tensor([-0.8246])\n",
						"第 1518 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2363]])\n",
						"模型中偏参梯度 tensor([-0.8243])\n",
						"第 1519 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2362]])\n",
						"模型中偏参梯度 tensor([-0.8240])\n",
						"第 1520 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2361]])\n",
						"模型中偏参梯度 tensor([-0.8237])\n",
						"第 76 次epoch\n",
						"第 1521 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2360]])\n",
						"模型中偏参梯度 tensor([-0.8233])\n",
						"第 1522 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2359]])\n",
						"模型中偏参梯度 tensor([-0.8230])\n",
						"第 1523 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2358]])\n",
						"模型中偏参梯度 tensor([-0.8227])\n",
						"第 1524 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2357]])\n",
						"模型中偏参梯度 tensor([-0.8223])\n",
						"第 1525 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2356]])\n",
						"模型中偏参梯度 tensor([-0.8220])\n",
						"第 1526 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2355]])\n",
						"模型中偏参梯度 tensor([-0.8217])\n",
						"第 1527 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2354]])\n",
						"模型中偏参梯度 tensor([-0.8214])\n",
						"第 1528 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2353]])\n",
						"模型中偏参梯度 tensor([-0.8210])\n",
						"第 1529 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2352]])\n",
						"模型中偏参梯度 tensor([-0.8207])\n",
						"第 1530 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2351]])\n",
						"模型中偏参梯度 tensor([-0.8204])\n",
						"第 1531 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2351]])\n",
						"模型中偏参梯度 tensor([-0.8200])\n",
						"第 1532 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2350]])\n",
						"模型中偏参梯度 tensor([-0.8197])\n",
						"第 1533 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2349]])\n",
						"模型中偏参梯度 tensor([-0.8194])\n",
						"第 1534 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2348]])\n",
						"模型中偏参梯度 tensor([-0.8190])\n",
						"第 1535 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2347]])\n",
						"模型中偏参梯度 tensor([-0.8187])\n",
						"第 1536 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2346]])\n",
						"模型中偏参梯度 tensor([-0.8184])\n",
						"第 1537 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2345]])\n",
						"模型中偏参梯度 tensor([-0.8180])\n",
						"第 1538 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2344]])\n",
						"模型中偏参梯度 tensor([-0.8177])\n",
						"第 1539 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2343]])\n",
						"模型中偏参梯度 tensor([-0.8174])\n",
						"第 1540 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2342]])\n",
						"模型中偏参梯度 tensor([-0.8171])\n",
						"第 77 次epoch\n",
						"第 1541 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2341]])\n",
						"模型中偏参梯度 tensor([-0.8167])\n",
						"第 1542 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2340]])\n",
						"模型中偏参梯度 tensor([-0.8164])\n",
						"第 1543 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2339]])\n",
						"模型中偏参梯度 tensor([-0.8161])\n",
						"第 1544 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2338]])\n",
						"模型中偏参梯度 tensor([-0.8158])\n",
						"第 1545 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2337]])\n",
						"模型中偏参梯度 tensor([-0.8154])\n",
						"第 1546 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2336]])\n",
						"模型中偏参梯度 tensor([-0.8151])\n",
						"第 1547 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2335]])\n",
						"模型中偏参梯度 tensor([-0.8148])\n",
						"第 1548 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2334]])\n",
						"模型中偏参梯度 tensor([-0.8144])\n",
						"第 1549 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2333]])\n",
						"模型中偏参梯度 tensor([-0.8141])\n",
						"第 1550 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2332]])\n",
						"模型中偏参梯度 tensor([-0.8138])\n",
						"第 1551 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2332]])\n",
						"模型中偏参梯度 tensor([-0.8135])\n",
						"第 1552 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2331]])\n",
						"模型中偏参梯度 tensor([-0.8131])\n",
						"第 1553 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2330]])\n",
						"模型中偏参梯度 tensor([-0.8128])\n",
						"第 1554 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2329]])\n",
						"模型中偏参梯度 tensor([-0.8125])\n",
						"第 1555 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2328]])\n",
						"模型中偏参梯度 tensor([-0.8121])\n",
						"第 1556 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2327]])\n",
						"模型中偏参梯度 tensor([-0.8118])\n",
						"第 1557 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2326]])\n",
						"模型中偏参梯度 tensor([-0.8115])\n",
						"第 1558 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2325]])\n",
						"模型中偏参梯度 tensor([-0.8112])\n",
						"第 1559 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2324]])\n",
						"模型中偏参梯度 tensor([-0.8108])\n",
						"第 1560 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2323]])\n",
						"模型中偏参梯度 tensor([-0.8105])\n",
						"第 78 次epoch\n",
						"第 1561 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2322]])\n",
						"模型中偏参梯度 tensor([-0.8102])\n",
						"第 1562 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2321]])\n",
						"模型中偏参梯度 tensor([-0.8099])\n",
						"第 1563 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2320]])\n",
						"模型中偏参梯度 tensor([-0.8095])\n",
						"第 1564 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2319]])\n",
						"模型中偏参梯度 tensor([-0.8092])\n",
						"第 1565 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2318]])\n",
						"模型中偏参梯度 tensor([-0.8089])\n",
						"第 1566 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2317]])\n",
						"模型中偏参梯度 tensor([-0.8086])\n",
						"第 1567 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2316]])\n",
						"模型中偏参梯度 tensor([-0.8082])\n",
						"第 1568 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2315]])\n",
						"模型中偏参梯度 tensor([-0.8079])\n",
						"第 1569 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2315]])\n",
						"模型中偏参梯度 tensor([-0.8076])\n",
						"第 1570 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2314]])\n",
						"模型中偏参梯度 tensor([-0.8073])\n",
						"第 1571 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2313]])\n",
						"模型中偏参梯度 tensor([-0.8069])\n",
						"第 1572 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2312]])\n",
						"模型中偏参梯度 tensor([-0.8066])\n",
						"第 1573 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2311]])\n",
						"模型中偏参梯度 tensor([-0.8063])\n",
						"第 1574 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2310]])\n",
						"模型中偏参梯度 tensor([-0.8060])\n",
						"第 1575 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2310]])\n",
						"模型中偏参梯度 tensor([-0.8056])\n",
						"第 1576 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2309]])\n",
						"模型中偏参梯度 tensor([-0.8053])\n",
						"第 1577 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2308]])\n",
						"模型中偏参梯度 tensor([-0.8050])\n",
						"第 1578 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2307]])\n",
						"模型中偏参梯度 tensor([-0.8047])\n",
						"第 1579 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2306]])\n",
						"模型中偏参梯度 tensor([-0.8043])\n",
						"第 1580 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2305]])\n",
						"模型中偏参梯度 tensor([-0.8040])\n",
						"第 79 次epoch\n",
						"第 1581 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2304]])\n",
						"模型中偏参梯度 tensor([-0.8037])\n",
						"第 1582 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2303]])\n",
						"模型中偏参梯度 tensor([-0.8034])\n",
						"第 1583 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2302]])\n",
						"模型中偏参梯度 tensor([-0.8030])\n",
						"第 1584 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2301]])\n",
						"模型中偏参梯度 tensor([-0.8027])\n",
						"第 1585 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2300]])\n",
						"模型中偏参梯度 tensor([-0.8024])\n",
						"第 1586 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2298]])\n",
						"模型中偏参梯度 tensor([-0.8021])\n",
						"第 1587 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2297]])\n",
						"模型中偏参梯度 tensor([-0.8018])\n",
						"第 1588 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2297]])\n",
						"模型中偏参梯度 tensor([-0.8014])\n",
						"第 1589 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2296]])\n",
						"模型中偏参梯度 tensor([-0.8011])\n",
						"第 1590 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2295]])\n",
						"模型中偏参梯度 tensor([-0.8008])\n",
						"第 1591 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2294]])\n",
						"模型中偏参梯度 tensor([-0.8005])\n",
						"第 1592 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2293]])\n",
						"模型中偏参梯度 tensor([-0.8001])\n",
						"第 1593 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2293]])\n",
						"模型中偏参梯度 tensor([-0.7998])\n",
						"第 1594 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2292]])\n",
						"模型中偏参梯度 tensor([-0.7995])\n",
						"第 1595 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2291]])\n",
						"模型中偏参梯度 tensor([-0.7992])\n",
						"第 1596 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2290]])\n",
						"模型中偏参梯度 tensor([-0.7989])\n",
						"第 1597 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2289]])\n",
						"模型中偏参梯度 tensor([-0.7985])\n",
						"第 1598 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2288]])\n",
						"模型中偏参梯度 tensor([-0.7982])\n",
						"第 1599 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2287]])\n",
						"模型中偏参梯度 tensor([-0.7979])\n",
						"第 1600 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2286]])\n",
						"模型中偏参梯度 tensor([-0.7976])\n",
						"第 80 次epoch\n",
						"第 1601 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2285]])\n",
						"模型中偏参梯度 tensor([-0.7972])\n",
						"第 1602 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2284]])\n",
						"模型中偏参梯度 tensor([-0.7969])\n",
						"第 1603 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2283]])\n",
						"模型中偏参梯度 tensor([-0.7966])\n",
						"第 1604 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2282]])\n",
						"模型中偏参梯度 tensor([-0.7963])\n",
						"第 1605 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2281]])\n",
						"模型中偏参梯度 tensor([-0.7960])\n",
						"第 1606 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2280]])\n",
						"模型中偏参梯度 tensor([-0.7957])\n",
						"第 1607 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2279]])\n",
						"模型中偏参梯度 tensor([-0.7953])\n",
						"第 1608 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2278]])\n",
						"模型中偏参梯度 tensor([-0.7950])\n",
						"第 1609 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2278]])\n",
						"模型中偏参梯度 tensor([-0.7947])\n",
						"第 1610 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2277]])\n",
						"模型中偏参梯度 tensor([-0.7944])\n",
						"第 1611 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2276]])\n",
						"模型中偏参梯度 tensor([-0.7940])\n",
						"第 1612 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2275]])\n",
						"模型中偏参梯度 tensor([-0.7937])\n",
						"第 1613 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2274]])\n",
						"模型中偏参梯度 tensor([-0.7934])\n",
						"第 1614 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2274]])\n",
						"模型中偏参梯度 tensor([-0.7931])\n",
						"第 1615 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2273]])\n",
						"模型中偏参梯度 tensor([-0.7928])\n",
						"第 1616 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2272]])\n",
						"模型中偏参梯度 tensor([-0.7924])\n",
						"第 1617 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2271]])\n",
						"模型中偏参梯度 tensor([-0.7921])\n",
						"第 1618 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2270]])\n",
						"模型中偏参梯度 tensor([-0.7918])\n",
						"第 1619 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2269]])\n",
						"模型中偏参梯度 tensor([-0.7915])\n",
						"第 1620 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2268]])\n",
						"模型中偏参梯度 tensor([-0.7912])\n",
						"第 81 次epoch\n",
						"第 1621 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2267]])\n",
						"模型中偏参梯度 tensor([-0.7909])\n",
						"第 1622 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2266]])\n",
						"模型中偏参梯度 tensor([-0.7905])\n",
						"第 1623 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2265]])\n",
						"模型中偏参梯度 tensor([-0.7902])\n",
						"第 1624 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2264]])\n",
						"模型中偏参梯度 tensor([-0.7899])\n",
						"第 1625 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2263]])\n",
						"模型中偏参梯度 tensor([-0.7896])\n",
						"第 1626 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2262]])\n",
						"模型中偏参梯度 tensor([-0.7893])\n",
						"第 1627 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2261]])\n",
						"模型中偏参梯度 tensor([-0.7890])\n",
						"第 1628 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2260]])\n",
						"模型中偏参梯度 tensor([-0.7886])\n",
						"第 1629 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2259]])\n",
						"模型中偏参梯度 tensor([-0.7883])\n",
						"第 1630 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2259]])\n",
						"模型中偏参梯度 tensor([-0.7880])\n",
						"第 1631 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2258]])\n",
						"模型中偏参梯度 tensor([-0.7877])\n",
						"第 1632 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2257]])\n",
						"模型中偏参梯度 tensor([-0.7874])\n",
						"第 1633 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2256]])\n",
						"模型中偏参梯度 tensor([-0.7870])\n",
						"第 1634 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2255]])\n",
						"模型中偏参梯度 tensor([-0.7867])\n",
						"第 1635 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2255]])\n",
						"模型中偏参梯度 tensor([-0.7864])\n",
						"第 1636 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2254]])\n",
						"模型中偏参梯度 tensor([-0.7861])\n",
						"第 1637 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2253]])\n",
						"模型中偏参梯度 tensor([-0.7858])\n",
						"第 1638 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2252]])\n",
						"模型中偏参梯度 tensor([-0.7854])\n",
						"第 1639 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2251]])\n",
						"模型中偏参梯度 tensor([-0.7851])\n",
						"第 1640 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2250]])\n",
						"模型中偏参梯度 tensor([-0.7848])\n",
						"第 82 次epoch\n",
						"第 1641 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2249]])\n",
						"模型中偏参梯度 tensor([-0.7845])\n",
						"第 1642 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2248]])\n",
						"模型中偏参梯度 tensor([-0.7842])\n",
						"第 1643 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2247]])\n",
						"模型中偏参梯度 tensor([-0.7839])\n",
						"第 1644 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2246]])\n",
						"模型中偏参梯度 tensor([-0.7836])\n",
						"第 1645 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2245]])\n",
						"模型中偏参梯度 tensor([-0.7832])\n",
						"第 1646 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2244]])\n",
						"模型中偏参梯度 tensor([-0.7829])\n",
						"第 1647 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2243]])\n",
						"模型中偏参梯度 tensor([-0.7826])\n",
						"第 1648 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2242]])\n",
						"模型中偏参梯度 tensor([-0.7823])\n",
						"第 1649 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2241]])\n",
						"模型中偏参梯度 tensor([-0.7820])\n",
						"第 1650 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2240]])\n",
						"模型中偏参梯度 tensor([-0.7817])\n",
						"第 1651 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2239]])\n",
						"模型中偏参梯度 tensor([-0.7814])\n",
						"第 1652 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2239]])\n",
						"模型中偏参梯度 tensor([-0.7811])\n",
						"第 1653 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2238]])\n",
						"模型中偏参梯度 tensor([-0.7807])\n",
						"第 1654 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2237]])\n",
						"模型中偏参梯度 tensor([-0.7804])\n",
						"第 1655 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2236]])\n",
						"模型中偏参梯度 tensor([-0.7801])\n",
						"第 1656 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2235]])\n",
						"模型中偏参梯度 tensor([-0.7798])\n",
						"第 1657 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2235]])\n",
						"模型中偏参梯度 tensor([-0.7795])\n",
						"第 1658 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2234]])\n",
						"模型中偏参梯度 tensor([-0.7792])\n",
						"第 1659 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2233]])\n",
						"模型中偏参梯度 tensor([-0.7788])\n",
						"第 1660 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2232]])\n",
						"模型中偏参梯度 tensor([-0.7785])\n",
						"第 83 次epoch\n",
						"第 1661 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2231]])\n",
						"模型中偏参梯度 tensor([-0.7782])\n",
						"第 1662 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2230]])\n",
						"模型中偏参梯度 tensor([-0.7779])\n",
						"第 1663 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2229]])\n",
						"模型中偏参梯度 tensor([-0.7776])\n",
						"第 1664 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2228]])\n",
						"模型中偏参梯度 tensor([-0.7773])\n",
						"第 1665 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2227]])\n",
						"模型中偏参梯度 tensor([-0.7770])\n",
						"第 1666 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2226]])\n",
						"模型中偏参梯度 tensor([-0.7767])\n",
						"第 1667 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2225]])\n",
						"模型中偏参梯度 tensor([-0.7764])\n",
						"第 1668 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2224]])\n",
						"模型中偏参梯度 tensor([-0.7760])\n",
						"第 1669 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2223]])\n",
						"模型中偏参梯度 tensor([-0.7757])\n",
						"第 1670 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2222]])\n",
						"模型中偏参梯度 tensor([-0.7754])\n",
						"第 1671 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2221]])\n",
						"模型中偏参梯度 tensor([-0.7751])\n",
						"第 1672 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2221]])\n",
						"模型中偏参梯度 tensor([-0.7748])\n",
						"第 1673 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2220]])\n",
						"模型中偏参梯度 tensor([-0.7745])\n",
						"第 1674 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2219]])\n",
						"模型中偏参梯度 tensor([-0.7742])\n",
						"第 1675 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2218]])\n",
						"模型中偏参梯度 tensor([-0.7739])\n",
						"第 1676 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2218]])\n",
						"模型中偏参梯度 tensor([-0.7735])\n",
						"第 1677 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2217]])\n",
						"模型中偏参梯度 tensor([-0.7732])\n",
						"第 1678 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2216]])\n",
						"模型中偏参梯度 tensor([-0.7729])\n",
						"第 1679 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2215]])\n",
						"模型中偏参梯度 tensor([-0.7726])\n",
						"第 1680 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2214]])\n",
						"模型中偏参梯度 tensor([-0.7723])\n",
						"第 84 次epoch\n",
						"第 1681 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2213]])\n",
						"模型中偏参梯度 tensor([-0.7720])\n",
						"第 1682 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2212]])\n",
						"模型中偏参梯度 tensor([-0.7717])\n",
						"第 1683 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2212]])\n",
						"模型中偏参梯度 tensor([-0.7714])\n",
						"第 1684 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2211]])\n",
						"模型中偏参梯度 tensor([-0.7710])\n",
						"第 1685 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2210]])\n",
						"模型中偏参梯度 tensor([-0.7707])\n",
						"第 1686 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2209]])\n",
						"模型中偏参梯度 tensor([-0.7704])\n",
						"第 1687 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2208]])\n",
						"模型中偏参梯度 tensor([-0.7701])\n",
						"第 1688 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2207]])\n",
						"模型中偏参梯度 tensor([-0.7698])\n",
						"第 1689 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2206]])\n",
						"模型中偏参梯度 tensor([-0.7695])\n",
						"第 1690 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2205]])\n",
						"模型中偏参梯度 tensor([-0.7692])\n",
						"第 1691 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2204]])\n",
						"模型中偏参梯度 tensor([-0.7689])\n",
						"第 1692 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2203]])\n",
						"模型中偏参梯度 tensor([-0.7686])\n",
						"第 1693 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2202]])\n",
						"模型中偏参梯度 tensor([-0.7683])\n",
						"第 1694 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2201]])\n",
						"模型中偏参梯度 tensor([-0.7680])\n",
						"第 1695 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2200]])\n",
						"模型中偏参梯度 tensor([-0.7677])\n",
						"第 1696 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2200]])\n",
						"模型中偏参梯度 tensor([-0.7673])\n",
						"第 1697 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2199]])\n",
						"模型中偏参梯度 tensor([-0.7670])\n",
						"第 1698 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2198]])\n",
						"模型中偏参梯度 tensor([-0.7667])\n",
						"第 1699 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2197]])\n",
						"模型中偏参梯度 tensor([-0.7664])\n",
						"第 1700 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2196]])\n",
						"模型中偏参梯度 tensor([-0.7661])\n",
						"第 85 次epoch\n",
						"第 1701 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2196]])\n",
						"模型中偏参梯度 tensor([-0.7658])\n",
						"第 1702 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2195]])\n",
						"模型中偏参梯度 tensor([-0.7655])\n",
						"第 1703 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2194]])\n",
						"模型中偏参梯度 tensor([-0.7652])\n",
						"第 1704 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2193]])\n",
						"模型中偏参梯度 tensor([-0.7649])\n",
						"第 1705 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2192]])\n",
						"模型中偏参梯度 tensor([-0.7646])\n",
						"第 1706 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2191]])\n",
						"模型中偏参梯度 tensor([-0.7643])\n",
						"第 1707 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2190]])\n",
						"模型中偏参梯度 tensor([-0.7639])\n",
						"第 1708 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2189]])\n",
						"模型中偏参梯度 tensor([-0.7636])\n",
						"第 1709 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2188]])\n",
						"模型中偏参梯度 tensor([-0.7633])\n",
						"第 1710 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2187]])\n",
						"模型中偏参梯度 tensor([-0.7630])\n",
						"第 1711 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2186]])\n",
						"模型中偏参梯度 tensor([-0.7627])\n",
						"第 1712 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2185]])\n",
						"模型中偏参梯度 tensor([-0.7624])\n",
						"第 1713 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2184]])\n",
						"模型中偏参梯度 tensor([-0.7621])\n",
						"第 1714 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2183]])\n",
						"模型中偏参梯度 tensor([-0.7618])\n",
						"第 1715 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2182]])\n",
						"模型中偏参梯度 tensor([-0.7615])\n",
						"第 1716 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2182]])\n",
						"模型中偏参梯度 tensor([-0.7612])\n",
						"第 1717 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2181]])\n",
						"模型中偏参梯度 tensor([-0.7609])\n",
						"第 1718 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2180]])\n",
						"模型中偏参梯度 tensor([-0.7606])\n",
						"第 1719 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2179]])\n",
						"模型中偏参梯度 tensor([-0.7603])\n",
						"第 1720 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2179]])\n",
						"模型中偏参梯度 tensor([-0.7600])\n",
						"第 86 次epoch\n",
						"第 1721 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2178]])\n",
						"模型中偏参梯度 tensor([-0.7597])\n",
						"第 1722 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2177]])\n",
						"模型中偏参梯度 tensor([-0.7593])\n",
						"第 1723 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2176]])\n",
						"模型中偏参梯度 tensor([-0.7590])\n",
						"第 1724 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2175]])\n",
						"模型中偏参梯度 tensor([-0.7587])\n",
						"第 1725 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2174]])\n",
						"模型中偏参梯度 tensor([-0.7584])\n",
						"第 1726 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2173]])\n",
						"模型中偏参梯度 tensor([-0.7581])\n",
						"第 1727 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2173]])\n",
						"模型中偏参梯度 tensor([-0.7578])\n",
						"第 1728 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2172]])\n",
						"模型中偏参梯度 tensor([-0.7575])\n",
						"第 1729 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2171]])\n",
						"模型中偏参梯度 tensor([-0.7572])\n",
						"第 1730 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2170]])\n",
						"模型中偏参梯度 tensor([-0.7569])\n",
						"第 1731 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2169]])\n",
						"模型中偏参梯度 tensor([-0.7566])\n",
						"第 1732 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2168]])\n",
						"模型中偏参梯度 tensor([-0.7563])\n",
						"第 1733 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2167]])\n",
						"模型中偏参梯度 tensor([-0.7560])\n",
						"第 1734 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2166]])\n",
						"模型中偏参梯度 tensor([-0.7557])\n",
						"第 1735 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2165]])\n",
						"模型中偏参梯度 tensor([-0.7554])\n",
						"第 1736 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2164]])\n",
						"模型中偏参梯度 tensor([-0.7551])\n",
						"第 1737 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2163]])\n",
						"模型中偏参梯度 tensor([-0.7548])\n",
						"第 1738 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2163]])\n",
						"模型中偏参梯度 tensor([-0.7545])\n",
						"第 1739 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2162]])\n",
						"模型中偏参梯度 tensor([-0.7542])\n",
						"第 1740 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2161]])\n",
						"模型中偏参梯度 tensor([-0.7539])\n",
						"第 87 次epoch\n",
						"第 1741 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2160]])\n",
						"模型中偏参梯度 tensor([-0.7536])\n",
						"第 1742 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2160]])\n",
						"模型中偏参梯度 tensor([-0.7533])\n",
						"第 1743 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2159]])\n",
						"模型中偏参梯度 tensor([-0.7530])\n",
						"第 1744 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2158]])\n",
						"模型中偏参梯度 tensor([-0.7526])\n",
						"第 1745 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2157]])\n",
						"模型中偏参梯度 tensor([-0.7523])\n",
						"第 1746 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2156]])\n",
						"模型中偏参梯度 tensor([-0.7520])\n",
						"第 1747 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2155]])\n",
						"模型中偏参梯度 tensor([-0.7517])\n",
						"第 1748 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2154]])\n",
						"模型中偏参梯度 tensor([-0.7514])\n",
						"第 1749 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2153]])\n",
						"模型中偏参梯度 tensor([-0.7511])\n",
						"第 1750 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2153]])\n",
						"模型中偏参梯度 tensor([-0.7508])\n",
						"第 1751 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2152]])\n",
						"模型中偏参梯度 tensor([-0.7505])\n",
						"第 1752 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2151]])\n",
						"模型中偏参梯度 tensor([-0.7502])\n",
						"第 1753 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2150]])\n",
						"模型中偏参梯度 tensor([-0.7499])\n",
						"第 1754 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2149]])\n",
						"模型中偏参梯度 tensor([-0.7496])\n",
						"第 1755 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2148]])\n",
						"模型中偏参梯度 tensor([-0.7493])\n",
						"第 1756 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2147]])\n",
						"模型中偏参梯度 tensor([-0.7490])\n",
						"第 1757 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2146]])\n",
						"模型中偏参梯度 tensor([-0.7487])\n",
						"第 1758 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2145]])\n",
						"模型中偏参梯度 tensor([-0.7485])\n",
						"第 1759 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2144]])\n",
						"模型中偏参梯度 tensor([-0.7481])\n",
						"第 1760 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2143]])\n",
						"模型中偏参梯度 tensor([-0.7478])\n",
						"第 88 次epoch\n",
						"第 1761 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2143]])\n",
						"模型中偏参梯度 tensor([-0.7475])\n",
						"第 1762 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2142]])\n",
						"模型中偏参梯度 tensor([-0.7472])\n",
						"第 1763 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2141]])\n",
						"模型中偏参梯度 tensor([-0.7469])\n",
						"第 1764 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2140]])\n",
						"模型中偏参梯度 tensor([-0.7466])\n",
						"第 1765 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2140]])\n",
						"模型中偏参梯度 tensor([-0.7463])\n",
						"第 1766 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2139]])\n",
						"模型中偏参梯度 tensor([-0.7460])\n",
						"第 1767 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2138]])\n",
						"模型中偏参梯度 tensor([-0.7457])\n",
						"第 1768 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2137]])\n",
						"模型中偏参梯度 tensor([-0.7454])\n",
						"第 1769 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2136]])\n",
						"模型中偏参梯度 tensor([-0.7451])\n",
						"第 1770 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2135]])\n",
						"模型中偏参梯度 tensor([-0.7448])\n",
						"第 1771 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2134]])\n",
						"模型中偏参梯度 tensor([-0.7445])\n",
						"第 1772 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2134]])\n",
						"模型中偏参梯度 tensor([-0.7442])\n",
						"第 1773 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2133]])\n",
						"模型中偏参梯度 tensor([-0.7439])\n",
						"第 1774 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2132]])\n",
						"模型中偏参梯度 tensor([-0.7436])\n",
						"第 1775 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2131]])\n",
						"模型中偏参梯度 tensor([-0.7433])\n",
						"第 1776 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2130]])\n",
						"模型中偏参梯度 tensor([-0.7430])\n",
						"第 1777 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2129]])\n",
						"模型中偏参梯度 tensor([-0.7427])\n",
						"第 1778 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2128]])\n",
						"模型中偏参梯度 tensor([-0.7424])\n",
						"第 1779 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2127]])\n",
						"模型中偏参梯度 tensor([-0.7422])\n",
						"第 1780 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2126]])\n",
						"模型中偏参梯度 tensor([-0.7418])\n",
						"第 89 次epoch\n",
						"第 1781 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2125]])\n",
						"模型中偏参梯度 tensor([-0.7415])\n",
						"第 1782 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2125]])\n",
						"模型中偏参梯度 tensor([-0.7412])\n",
						"第 1783 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2124]])\n",
						"模型中偏参梯度 tensor([-0.7409])\n",
						"第 1784 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2123]])\n",
						"模型中偏参梯度 tensor([-0.7406])\n",
						"第 1785 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2122]])\n",
						"模型中偏参梯度 tensor([-0.7403])\n",
						"第 1786 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2122]])\n",
						"模型中偏参梯度 tensor([-0.7400])\n",
						"第 1787 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2121]])\n",
						"模型中偏参梯度 tensor([-0.7397])\n",
						"第 1788 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2120]])\n",
						"模型中偏参梯度 tensor([-0.7394])\n",
						"第 1789 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2119]])\n",
						"模型中偏参梯度 tensor([-0.7391])\n",
						"第 1790 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2118]])\n",
						"模型中偏参梯度 tensor([-0.7388])\n",
						"第 1791 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2118]])\n",
						"模型中偏参梯度 tensor([-0.7385])\n",
						"第 1792 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2117]])\n",
						"模型中偏参梯度 tensor([-0.7382])\n",
						"第 1793 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2116]])\n",
						"模型中偏参梯度 tensor([-0.7380])\n",
						"第 1794 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2115]])\n",
						"模型中偏参梯度 tensor([-0.7377])\n",
						"第 1795 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2114]])\n",
						"模型中偏参梯度 tensor([-0.7374])\n",
						"第 1796 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2113]])\n",
						"模型中偏参梯度 tensor([-0.7371])\n",
						"第 1797 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2112]])\n",
						"模型中偏参梯度 tensor([-0.7368])\n",
						"第 1798 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2111]])\n",
						"模型中偏参梯度 tensor([-0.7365])\n",
						"第 1799 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2110]])\n",
						"模型中偏参梯度 tensor([-0.7362])\n",
						"第 1800 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2109]])\n",
						"模型中偏参梯度 tensor([-0.7359])\n",
						"第 90 次epoch\n",
						"第 1801 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2108]])\n",
						"模型中偏参梯度 tensor([-0.7356])\n",
						"第 1802 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2107]])\n",
						"模型中偏参梯度 tensor([-0.7353])\n",
						"第 1803 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2107]])\n",
						"模型中偏参梯度 tensor([-0.7350])\n",
						"第 1804 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2106]])\n",
						"模型中偏参梯度 tensor([-0.7347])\n",
						"第 1805 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2105]])\n",
						"模型中偏参梯度 tensor([-0.7344])\n",
						"第 1806 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2104]])\n",
						"模型中偏参梯度 tensor([-0.7341])\n",
						"第 1807 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2104]])\n",
						"模型中偏参梯度 tensor([-0.7338])\n",
						"第 1808 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2103]])\n",
						"模型中偏参梯度 tensor([-0.7335])\n",
						"第 1809 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2102]])\n",
						"模型中偏参梯度 tensor([-0.7332])\n",
						"第 1810 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2101]])\n",
						"模型中偏参梯度 tensor([-0.7329])\n",
						"第 1811 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2101]])\n",
						"模型中偏参梯度 tensor([-0.7326])\n",
						"第 1812 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2100]])\n",
						"模型中偏参梯度 tensor([-0.7323])\n",
						"第 1813 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2099]])\n",
						"模型中偏参梯度 tensor([-0.7320])\n",
						"第 1814 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2098]])\n",
						"模型中偏参梯度 tensor([-0.7317])\n",
						"第 1815 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2097]])\n",
						"模型中偏参梯度 tensor([-0.7314])\n",
						"第 1816 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2096]])\n",
						"模型中偏参梯度 tensor([-0.7312])\n",
						"第 1817 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2095]])\n",
						"模型中偏参梯度 tensor([-0.7309])\n",
						"第 1818 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2095]])\n",
						"模型中偏参梯度 tensor([-0.7306])\n",
						"第 1819 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2094]])\n",
						"模型中偏参梯度 tensor([-0.7303])\n",
						"第 1820 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2093]])\n",
						"模型中偏参梯度 tensor([-0.7300])\n",
						"第 91 次epoch\n",
						"第 1821 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2092]])\n",
						"模型中偏参梯度 tensor([-0.7297])\n",
						"第 1822 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2091]])\n",
						"模型中偏参梯度 tensor([-0.7294])\n",
						"第 1823 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2090]])\n",
						"模型中偏参梯度 tensor([-0.7291])\n",
						"第 1824 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2089]])\n",
						"模型中偏参梯度 tensor([-0.7288])\n",
						"第 1825 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2088]])\n",
						"模型中偏参梯度 tensor([-0.7285])\n",
						"第 1826 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2087]])\n",
						"模型中偏参梯度 tensor([-0.7282])\n",
						"第 1827 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2086]])\n",
						"模型中偏参梯度 tensor([-0.7279])\n",
						"第 1828 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2086]])\n",
						"模型中偏参梯度 tensor([-0.7276])\n",
						"第 1829 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2085]])\n",
						"模型中偏参梯度 tensor([-0.7274])\n",
						"第 1830 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2084]])\n",
						"模型中偏参梯度 tensor([-0.7271])\n",
						"第 1831 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2083]])\n",
						"模型中偏参梯度 tensor([-0.7268])\n",
						"第 1832 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2083]])\n",
						"模型中偏参梯度 tensor([-0.7265])\n",
						"第 1833 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2082]])\n",
						"模型中偏参梯度 tensor([-0.7262])\n",
						"第 1834 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2081]])\n",
						"模型中偏参梯度 tensor([-0.7259])\n",
						"第 1835 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2080]])\n",
						"模型中偏参梯度 tensor([-0.7256])\n",
						"第 1836 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2080]])\n",
						"模型中偏参梯度 tensor([-0.7253])\n",
						"第 1837 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2079]])\n",
						"模型中偏参梯度 tensor([-0.7250])\n",
						"第 1838 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2078]])\n",
						"模型中偏参梯度 tensor([-0.7247])\n",
						"第 1839 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2077]])\n",
						"模型中偏参梯度 tensor([-0.7244])\n",
						"第 1840 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2076]])\n",
						"模型中偏参梯度 tensor([-0.7241])\n",
						"第 92 次epoch\n",
						"第 1841 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2075]])\n",
						"模型中偏参梯度 tensor([-0.7238])\n",
						"第 1842 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2074]])\n",
						"模型中偏参梯度 tensor([-0.7236])\n",
						"第 1843 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2073]])\n",
						"模型中偏参梯度 tensor([-0.7233])\n",
						"第 1844 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2072]])\n",
						"模型中偏参梯度 tensor([-0.7230])\n",
						"第 1845 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2071]])\n",
						"模型中偏参梯度 tensor([-0.7227])\n",
						"第 1846 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2070]])\n",
						"模型中偏参梯度 tensor([-0.7224])\n",
						"第 1847 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2069]])\n",
						"模型中偏参梯度 tensor([-0.7221])\n",
						"第 1848 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2069]])\n",
						"模型中偏参梯度 tensor([-0.7218])\n",
						"第 1849 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2068]])\n",
						"模型中偏参梯度 tensor([-0.7215])\n",
						"第 1850 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2067]])\n",
						"模型中偏参梯度 tensor([-0.7212])\n",
						"第 1851 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2067]])\n",
						"模型中偏参梯度 tensor([-0.7209])\n",
						"第 1852 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2066]])\n",
						"模型中偏参梯度 tensor([-0.7206])\n",
						"第 1853 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2065]])\n",
						"模型中偏参梯度 tensor([-0.7204])\n",
						"第 1854 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2064]])\n",
						"模型中偏参梯度 tensor([-0.7201])\n",
						"第 1855 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2064]])\n",
						"模型中偏参梯度 tensor([-0.7198])\n",
						"第 1856 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2063]])\n",
						"模型中偏参梯度 tensor([-0.7195])\n",
						"第 1857 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2062]])\n",
						"模型中偏参梯度 tensor([-0.7192])\n",
						"第 1858 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2061]])\n",
						"模型中偏参梯度 tensor([-0.7189])\n",
						"第 1859 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2060]])\n",
						"模型中偏参梯度 tensor([-0.7186])\n",
						"第 1860 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2060]])\n",
						"模型中偏参梯度 tensor([-0.7183])\n",
						"第 93 次epoch\n",
						"第 1861 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2059]])\n",
						"模型中偏参梯度 tensor([-0.7180])\n",
						"第 1862 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2058]])\n",
						"模型中偏参梯度 tensor([-0.7177])\n",
						"第 1863 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2057]])\n",
						"模型中偏参梯度 tensor([-0.7175])\n",
						"第 1864 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2056]])\n",
						"模型中偏参梯度 tensor([-0.7172])\n",
						"第 1865 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2055]])\n",
						"模型中偏参梯度 tensor([-0.7169])\n",
						"第 1866 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2054]])\n",
						"模型中偏参梯度 tensor([-0.7166])\n",
						"第 1867 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2053]])\n",
						"模型中偏参梯度 tensor([-0.7163])\n",
						"第 1868 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2052]])\n",
						"模型中偏参梯度 tensor([-0.7160])\n",
						"第 1869 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2051]])\n",
						"模型中偏参梯度 tensor([-0.7157])\n",
						"第 1870 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2050]])\n",
						"模型中偏参梯度 tensor([-0.7155])\n",
						"第 1871 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2050]])\n",
						"模型中偏参梯度 tensor([-0.7152])\n",
						"第 1872 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2049]])\n",
						"模型中偏参梯度 tensor([-0.7149])\n",
						"第 1873 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2048]])\n",
						"模型中偏参梯度 tensor([-0.7146])\n",
						"第 1874 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2048]])\n",
						"模型中偏参梯度 tensor([-0.7143])\n",
						"第 1875 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2047]])\n",
						"模型中偏参梯度 tensor([-0.7140])\n",
						"第 1876 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2046]])\n",
						"模型中偏参梯度 tensor([-0.7137])\n",
						"第 1877 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2046]])\n",
						"模型中偏参梯度 tensor([-0.7134])\n",
						"第 1878 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2045]])\n",
						"模型中偏参梯度 tensor([-0.7131])\n",
						"第 1879 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2044]])\n",
						"模型中偏参梯度 tensor([-0.7128])\n",
						"第 1880 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2043]])\n",
						"模型中偏参梯度 tensor([-0.7126])\n",
						"第 94 次epoch\n",
						"第 1881 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2042]])\n",
						"模型中偏参梯度 tensor([-0.7123])\n",
						"第 1882 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2042]])\n",
						"模型中偏参梯度 tensor([-0.7120])\n",
						"第 1883 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2041]])\n",
						"模型中偏参梯度 tensor([-0.7117])\n",
						"第 1884 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2040]])\n",
						"模型中偏参梯度 tensor([-0.7114])\n",
						"第 1885 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2039]])\n",
						"模型中偏参梯度 tensor([-0.7111])\n",
						"第 1886 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2038]])\n",
						"模型中偏参梯度 tensor([-0.7108])\n",
						"第 1887 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2037]])\n",
						"模型中偏参梯度 tensor([-0.7106])\n",
						"第 1888 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2036]])\n",
						"模型中偏参梯度 tensor([-0.7103])\n",
						"第 1889 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2036]])\n",
						"模型中偏参梯度 tensor([-0.7100])\n",
						"第 1890 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2035]])\n",
						"模型中偏参梯度 tensor([-0.7097])\n",
						"第 1891 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2034]])\n",
						"模型中偏参梯度 tensor([-0.7094])\n",
						"第 1892 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2033]])\n",
						"模型中偏参梯度 tensor([-0.7091])\n",
						"第 1893 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2032]])\n",
						"模型中偏参梯度 tensor([-0.7089])\n",
						"第 1894 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2031]])\n",
						"模型中偏参梯度 tensor([-0.7086])\n",
						"第 1895 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2030]])\n",
						"模型中偏参梯度 tensor([-0.7083])\n",
						"第 1896 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2029]])\n",
						"模型中偏参梯度 tensor([-0.7080])\n",
						"第 1897 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2029]])\n",
						"模型中偏参梯度 tensor([-0.7077])\n",
						"第 1898 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2028]])\n",
						"模型中偏参梯度 tensor([-0.7074])\n",
						"第 1899 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2027]])\n",
						"模型中偏参梯度 tensor([-0.7071])\n",
						"第 1900 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2027]])\n",
						"模型中偏参梯度 tensor([-0.7069])\n",
						"第 95 次epoch\n",
						"第 1901 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2026]])\n",
						"模型中偏参梯度 tensor([-0.7066])\n",
						"第 1902 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2025]])\n",
						"模型中偏参梯度 tensor([-0.7063])\n",
						"第 1903 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2024]])\n",
						"模型中偏参梯度 tensor([-0.7060])\n",
						"第 1904 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2023]])\n",
						"模型中偏参梯度 tensor([-0.7057])\n",
						"第 1905 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2023]])\n",
						"模型中偏参梯度 tensor([-0.7054])\n",
						"第 1906 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2022]])\n",
						"模型中偏参梯度 tensor([-0.7051])\n",
						"第 1907 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2021]])\n",
						"模型中偏参梯度 tensor([-0.7049])\n",
						"第 1908 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2020]])\n",
						"模型中偏参梯度 tensor([-0.7046])\n",
						"第 1909 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2019]])\n",
						"模型中偏参梯度 tensor([-0.7043])\n",
						"第 1910 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2018]])\n",
						"模型中偏参梯度 tensor([-0.7040])\n",
						"第 1911 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2018]])\n",
						"模型中偏参梯度 tensor([-0.7037])\n",
						"第 1912 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2017]])\n",
						"模型中偏参梯度 tensor([-0.7035])\n",
						"第 1913 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2016]])\n",
						"模型中偏参梯度 tensor([-0.7032])\n",
						"第 1914 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2015]])\n",
						"模型中偏参梯度 tensor([-0.7029])\n",
						"第 1915 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2014]])\n",
						"模型中偏参梯度 tensor([-0.7026])\n",
						"第 1916 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2013]])\n",
						"模型中偏参梯度 tensor([-0.7023])\n",
						"第 1917 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2012]])\n",
						"模型中偏参梯度 tensor([-0.7021])\n",
						"第 1918 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2011]])\n",
						"模型中偏参梯度 tensor([-0.7018])\n",
						"第 1919 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2011]])\n",
						"模型中偏参梯度 tensor([-0.7015])\n",
						"第 1920 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2010]])\n",
						"模型中偏参梯度 tensor([-0.7012])\n",
						"第 96 次epoch\n",
						"第 1921 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2009]])\n",
						"模型中偏参梯度 tensor([-0.7009])\n",
						"第 1922 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2009]])\n",
						"模型中偏参梯度 tensor([-0.7006])\n",
						"第 1923 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2008]])\n",
						"模型中偏参梯度 tensor([-0.7003])\n",
						"第 1924 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2007]])\n",
						"模型中偏参梯度 tensor([-0.7001])\n",
						"第 1925 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2006]])\n",
						"模型中偏参梯度 tensor([-0.6998])\n",
						"第 1926 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2006]])\n",
						"模型中偏参梯度 tensor([-0.6995])\n",
						"第 1927 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2005]])\n",
						"模型中偏参梯度 tensor([-0.6992])\n",
						"第 1928 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2004]])\n",
						"模型中偏参梯度 tensor([-0.6989])\n",
						"第 1929 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2003]])\n",
						"模型中偏参梯度 tensor([-0.6986])\n",
						"第 1930 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2002]])\n",
						"模型中偏参梯度 tensor([-0.6984])\n",
						"第 1931 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2002]])\n",
						"模型中偏参梯度 tensor([-0.6981])\n",
						"第 1932 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2001]])\n",
						"模型中偏参梯度 tensor([-0.6978])\n",
						"第 1933 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.2000]])\n",
						"模型中偏参梯度 tensor([-0.6975])\n",
						"第 1934 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1999]])\n",
						"模型中偏参梯度 tensor([-0.6972])\n",
						"第 1935 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1998]])\n",
						"模型中偏参梯度 tensor([-0.6970])\n",
						"第 1936 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1997]])\n",
						"模型中偏参梯度 tensor([-0.6967])\n",
						"第 1937 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1996]])\n",
						"模型中偏参梯度 tensor([-0.6964])\n",
						"第 1938 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1995]])\n",
						"模型中偏参梯度 tensor([-0.6961])\n",
						"第 1939 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1994]])\n",
						"模型中偏参梯度 tensor([-0.6959])\n",
						"第 1940 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1993]])\n",
						"模型中偏参梯度 tensor([-0.6956])\n",
						"第 97 次epoch\n",
						"第 1941 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1992]])\n",
						"模型中偏参梯度 tensor([-0.6953])\n",
						"第 1942 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1992]])\n",
						"模型中偏参梯度 tensor([-0.6950])\n",
						"第 1943 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1991]])\n",
						"模型中偏参梯度 tensor([-0.6947])\n",
						"第 1944 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1990]])\n",
						"模型中偏参梯度 tensor([-0.6945])\n",
						"第 1945 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1990]])\n",
						"模型中偏参梯度 tensor([-0.6942])\n",
						"第 1946 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1989]])\n",
						"模型中偏参梯度 tensor([-0.6939])\n",
						"第 1947 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1988]])\n",
						"模型中偏参梯度 tensor([-0.6936])\n",
						"第 1948 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1988]])\n",
						"模型中偏参梯度 tensor([-0.6933])\n",
						"第 1949 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1987]])\n",
						"模型中偏参梯度 tensor([-0.6931])\n",
						"第 1950 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1986]])\n",
						"模型中偏参梯度 tensor([-0.6928])\n",
						"第 1951 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1985]])\n",
						"模型中偏参梯度 tensor([-0.6925])\n",
						"第 1952 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1985]])\n",
						"模型中偏参梯度 tensor([-0.6922])\n",
						"第 1953 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1984]])\n",
						"模型中偏参梯度 tensor([-0.6919])\n",
						"第 1954 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1983]])\n",
						"模型中偏参梯度 tensor([-0.6917])\n",
						"第 1955 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1982]])\n",
						"模型中偏参梯度 tensor([-0.6914])\n",
						"第 1956 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1981]])\n",
						"模型中偏参梯度 tensor([-0.6911])\n",
						"第 1957 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1981]])\n",
						"模型中偏参梯度 tensor([-0.6908])\n",
						"第 1958 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1980]])\n",
						"模型中偏参梯度 tensor([-0.6906])\n",
						"第 1959 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1979]])\n",
						"模型中偏参梯度 tensor([-0.6903])\n",
						"第 1960 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1978]])\n",
						"模型中偏参梯度 tensor([-0.6900])\n",
						"第 98 次epoch\n",
						"第 1961 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1977]])\n",
						"模型中偏参梯度 tensor([-0.6897])\n",
						"第 1962 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1976]])\n",
						"模型中偏参梯度 tensor([-0.6895])\n",
						"第 1963 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1975]])\n",
						"模型中偏参梯度 tensor([-0.6892])\n",
						"第 1964 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1974]])\n",
						"模型中偏参梯度 tensor([-0.6889])\n",
						"第 1965 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1974]])\n",
						"模型中偏参梯度 tensor([-0.6886])\n",
						"第 1966 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1973]])\n",
						"模型中偏参梯度 tensor([-0.6883])\n",
						"第 1967 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1972]])\n",
						"模型中偏参梯度 tensor([-0.6881])\n",
						"第 1968 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1972]])\n",
						"模型中偏参梯度 tensor([-0.6878])\n",
						"第 1969 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1971]])\n",
						"模型中偏参梯度 tensor([-0.6875])\n",
						"第 1970 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1970]])\n",
						"模型中偏参梯度 tensor([-0.6872])\n",
						"第 1971 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1970]])\n",
						"模型中偏参梯度 tensor([-0.6869])\n",
						"第 1972 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1969]])\n",
						"模型中偏参梯度 tensor([-0.6867])\n",
						"第 1973 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1968]])\n",
						"模型中偏参梯度 tensor([-0.6864])\n",
						"第 1974 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1967]])\n",
						"模型中偏参梯度 tensor([-0.6861])\n",
						"第 1975 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1967]])\n",
						"模型中偏参梯度 tensor([-0.6858])\n",
						"第 1976 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1966]])\n",
						"模型中偏参梯度 tensor([-0.6856])\n",
						"第 1977 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1965]])\n",
						"模型中偏参梯度 tensor([-0.6853])\n",
						"第 1978 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1964]])\n",
						"模型中偏参梯度 tensor([-0.6850])\n",
						"第 1979 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1963]])\n",
						"模型中偏参梯度 tensor([-0.6847])\n",
						"第 1980 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1963]])\n",
						"模型中偏参梯度 tensor([-0.6845])\n",
						"第 99 次epoch\n",
						"第 1981 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1962]])\n",
						"模型中偏参梯度 tensor([-0.6842])\n",
						"第 1982 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1961]])\n",
						"模型中偏参梯度 tensor([-0.6839])\n",
						"第 1983 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1960]])\n",
						"模型中偏参梯度 tensor([-0.6836])\n",
						"第 1984 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1959]])\n",
						"模型中偏参梯度 tensor([-0.6834])\n",
						"第 1985 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1958]])\n",
						"模型中偏参梯度 tensor([-0.6831])\n",
						"第 1986 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1957]])\n",
						"模型中偏参梯度 tensor([-0.6828])\n",
						"第 1987 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1956]])\n",
						"模型中偏参梯度 tensor([-0.6825])\n",
						"第 1988 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1955]])\n",
						"模型中偏参梯度 tensor([-0.6823])\n",
						"第 1989 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1954]])\n",
						"模型中偏参梯度 tensor([-0.6820])\n",
						"第 1990 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1954]])\n",
						"模型中偏参梯度 tensor([-0.6817])\n",
						"第 1991 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1953]])\n",
						"模型中偏参梯度 tensor([-0.6815])\n",
						"第 1992 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1953]])\n",
						"模型中偏参梯度 tensor([-0.6812])\n",
						"第 1993 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1952]])\n",
						"模型中偏参梯度 tensor([-0.6809])\n",
						"第 1994 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1951]])\n",
						"模型中偏参梯度 tensor([-0.6806])\n",
						"第 1995 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1951]])\n",
						"模型中偏参梯度 tensor([-0.6803])\n",
						"第 1996 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1950]])\n",
						"模型中偏参梯度 tensor([-0.6801])\n",
						"第 1997 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1949]])\n",
						"模型中偏参梯度 tensor([-0.6798])\n",
						"第 1998 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1948]])\n",
						"模型中偏参梯度 tensor([-0.6795])\n",
						"第 1999 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1948]])\n",
						"模型中偏参梯度 tensor([-0.6792])\n",
						"第 2000 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1947]])\n",
						"模型中偏参梯度 tensor([-0.6790])\n",
						"第 100 次epoch\n",
						"第 2001 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1946]])\n",
						"模型中偏参梯度 tensor([-0.6787])\n",
						"第 2002 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1945]])\n",
						"模型中偏参梯度 tensor([-0.6784])\n",
						"第 2003 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1945]])\n",
						"模型中偏参梯度 tensor([-0.6781])\n",
						"第 2004 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1944]])\n",
						"模型中偏参梯度 tensor([-0.6779])\n",
						"第 2005 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1943]])\n",
						"模型中偏参梯度 tensor([-0.6776])\n",
						"第 2006 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1942]])\n",
						"模型中偏参梯度 tensor([-0.6773])\n",
						"第 2007 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1941]])\n",
						"模型中偏参梯度 tensor([-0.6771])\n",
						"第 2008 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1940]])\n",
						"模型中偏参梯度 tensor([-0.6768])\n",
						"第 2009 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1939]])\n",
						"模型中偏参梯度 tensor([-0.6765])\n",
						"第 2010 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1938]])\n",
						"模型中偏参梯度 tensor([-0.6763])\n",
						"第 2011 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1937]])\n",
						"模型中偏参梯度 tensor([-0.6760])\n",
						"第 2012 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1937]])\n",
						"模型中偏参梯度 tensor([-0.6757])\n",
						"第 2013 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1936]])\n",
						"模型中偏参梯度 tensor([-0.6755])\n",
						"第 2014 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1935]])\n",
						"模型中偏参梯度 tensor([-0.6752])\n",
						"第 2015 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1934]])\n",
						"模型中偏参梯度 tensor([-0.6749])\n",
						"第 2016 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1934]])\n",
						"模型中偏参梯度 tensor([-0.6746])\n",
						"第 2017 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1933]])\n",
						"模型中偏参梯度 tensor([-0.6744])\n",
						"第 2018 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1932]])\n",
						"模型中偏参梯度 tensor([-0.6741])\n",
						"第 2019 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1932]])\n",
						"模型中偏参梯度 tensor([-0.6738])\n",
						"第 2020 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1931]])\n",
						"模型中偏参梯度 tensor([-0.6735])\n",
						"第 101 次epoch\n",
						"第 2021 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1930]])\n",
						"模型中偏参梯度 tensor([-0.6733])\n",
						"第 2022 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1930]])\n",
						"模型中偏参梯度 tensor([-0.6730])\n",
						"第 2023 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1929]])\n",
						"模型中偏参梯度 tensor([-0.6727])\n",
						"第 2024 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1928]])\n",
						"模型中偏参梯度 tensor([-0.6724])\n",
						"第 2025 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1927]])\n",
						"模型中偏参梯度 tensor([-0.6722])\n",
						"第 2026 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1927]])\n",
						"模型中偏参梯度 tensor([-0.6719])\n",
						"第 2027 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1926]])\n",
						"模型中偏参梯度 tensor([-0.6716])\n",
						"第 2028 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1925]])\n",
						"模型中偏参梯度 tensor([-0.6714])\n",
						"第 2029 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1924]])\n",
						"模型中偏参梯度 tensor([-0.6711])\n",
						"第 2030 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1923]])\n",
						"模型中偏参梯度 tensor([-0.6708])\n",
						"第 2031 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1923]])\n",
						"模型中偏参梯度 tensor([-0.6706])\n",
						"第 2032 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1922]])\n",
						"模型中偏参梯度 tensor([-0.6703])\n",
						"第 2033 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1921]])\n",
						"模型中偏参梯度 tensor([-0.6700])\n",
						"第 2034 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1920]])\n",
						"模型中偏参梯度 tensor([-0.6698])\n",
						"第 2035 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1919]])\n",
						"模型中偏参梯度 tensor([-0.6695])\n",
						"第 2036 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1918]])\n",
						"模型中偏参梯度 tensor([-0.6692])\n",
						"第 2037 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1917]])\n",
						"模型中偏参梯度 tensor([-0.6690])\n",
						"第 2038 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1916]])\n",
						"模型中偏参梯度 tensor([-0.6687])\n",
						"第 2039 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1916]])\n",
						"模型中偏参梯度 tensor([-0.6684])\n",
						"第 2040 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1915]])\n",
						"模型中偏参梯度 tensor([-0.6682])\n",
						"第 102 次epoch\n",
						"第 2041 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1914]])\n",
						"模型中偏参梯度 tensor([-0.6679])\n",
						"第 2042 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1914]])\n",
						"模型中偏参梯度 tensor([-0.6676])\n",
						"第 2043 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1913]])\n",
						"模型中偏参梯度 tensor([-0.6673])\n",
						"第 2044 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1912]])\n",
						"模型中偏参梯度 tensor([-0.6671])\n",
						"第 2045 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1912]])\n",
						"模型中偏参梯度 tensor([-0.6668])\n",
						"第 2046 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1911]])\n",
						"模型中偏参梯度 tensor([-0.6665])\n",
						"第 2047 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1910]])\n",
						"模型中偏参梯度 tensor([-0.6663])\n",
						"第 2048 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1910]])\n",
						"模型中偏参梯度 tensor([-0.6660])\n",
						"第 2049 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1909]])\n",
						"模型中偏参梯度 tensor([-0.6657])\n",
						"第 2050 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1908]])\n",
						"模型中偏参梯度 tensor([-0.6654])\n",
						"第 2051 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1907]])\n",
						"模型中偏参梯度 tensor([-0.6652])\n",
						"第 2052 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1906]])\n",
						"模型中偏参梯度 tensor([-0.6649])\n",
						"第 2053 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1906]])\n",
						"模型中偏参梯度 tensor([-0.6646])\n",
						"第 2054 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1905]])\n",
						"模型中偏参梯度 tensor([-0.6644])\n",
						"第 2055 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1904]])\n",
						"模型中偏参梯度 tensor([-0.6641])\n",
						"第 2056 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1903]])\n",
						"模型中偏参梯度 tensor([-0.6638])\n",
						"第 2057 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1902]])\n",
						"模型中偏参梯度 tensor([-0.6636])\n",
						"第 2058 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1901]])\n",
						"模型中偏参梯度 tensor([-0.6633])\n",
						"第 2059 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1901]])\n",
						"模型中偏参梯度 tensor([-0.6631])\n",
						"第 2060 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1900]])\n",
						"模型中偏参梯度 tensor([-0.6628])\n",
						"第 103 次epoch\n",
						"第 2061 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1899]])\n",
						"模型中偏参梯度 tensor([-0.6625])\n",
						"第 2062 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1898]])\n",
						"模型中偏参梯度 tensor([-0.6623])\n",
						"第 2063 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1897]])\n",
						"模型中偏参梯度 tensor([-0.6620])\n",
						"第 2064 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1896]])\n",
						"模型中偏参梯度 tensor([-0.6617])\n",
						"第 2065 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1896]])\n",
						"模型中偏参梯度 tensor([-0.6615])\n",
						"第 2066 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1895]])\n",
						"模型中偏参梯度 tensor([-0.6612])\n",
						"第 2067 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1894]])\n",
						"模型中偏参梯度 tensor([-0.6609])\n",
						"第 2068 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1894]])\n",
						"模型中偏参梯度 tensor([-0.6607])\n",
						"第 2069 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1893]])\n",
						"模型中偏参梯度 tensor([-0.6604])\n",
						"第 2070 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1892]])\n",
						"模型中偏参梯度 tensor([-0.6601])\n",
						"第 2071 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1892]])\n",
						"模型中偏参梯度 tensor([-0.6599])\n",
						"第 2072 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1891]])\n",
						"模型中偏参梯度 tensor([-0.6596])\n",
						"第 2073 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1890]])\n",
						"模型中偏参梯度 tensor([-0.6593])\n",
						"第 2074 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1890]])\n",
						"模型中偏参梯度 tensor([-0.6591])\n",
						"第 2075 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1889]])\n",
						"模型中偏参梯度 tensor([-0.6588])\n",
						"第 2076 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1888]])\n",
						"模型中偏参梯度 tensor([-0.6585])\n",
						"第 2077 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1887]])\n",
						"模型中偏参梯度 tensor([-0.6583])\n",
						"第 2078 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1886]])\n",
						"模型中偏参梯度 tensor([-0.6580])\n",
						"第 2079 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1886]])\n",
						"模型中偏参梯度 tensor([-0.6577])\n",
						"第 2080 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1885]])\n",
						"模型中偏参梯度 tensor([-0.6575])\n",
						"第 104 次epoch\n",
						"第 2081 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1884]])\n",
						"模型中偏参梯度 tensor([-0.6572])\n",
						"第 2082 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1883]])\n",
						"模型中偏参梯度 tensor([-0.6569])\n",
						"第 2083 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1882]])\n",
						"模型中偏参梯度 tensor([-0.6567])\n",
						"第 2084 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1881]])\n",
						"模型中偏参梯度 tensor([-0.6564])\n",
						"第 2085 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1880]])\n",
						"模型中偏参梯度 tensor([-0.6562])\n",
						"第 2086 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1879]])\n",
						"模型中偏参梯度 tensor([-0.6559])\n",
						"第 2087 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1879]])\n",
						"模型中偏参梯度 tensor([-0.6556])\n",
						"第 2088 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1878]])\n",
						"模型中偏参梯度 tensor([-0.6554])\n",
						"第 2089 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1877]])\n",
						"模型中偏参梯度 tensor([-0.6551])\n",
						"第 2090 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1877]])\n",
						"模型中偏参梯度 tensor([-0.6548])\n",
						"第 2091 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1876]])\n",
						"模型中偏参梯度 tensor([-0.6546])\n",
						"第 2092 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1876]])\n",
						"模型中偏参梯度 tensor([-0.6543])\n",
						"第 2093 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1875]])\n",
						"模型中偏参梯度 tensor([-0.6540])\n",
						"第 2094 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1874]])\n",
						"模型中偏参梯度 tensor([-0.6538])\n",
						"第 2095 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1874]])\n",
						"模型中偏参梯度 tensor([-0.6535])\n",
						"第 2096 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1873]])\n",
						"模型中偏参梯度 tensor([-0.6532])\n",
						"第 2097 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1872]])\n",
						"模型中偏参梯度 tensor([-0.6530])\n",
						"第 2098 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1872]])\n",
						"模型中偏参梯度 tensor([-0.6527])\n",
						"第 2099 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1871]])\n",
						"模型中偏参梯度 tensor([-0.6524])\n",
						"第 2100 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1870]])\n",
						"模型中偏参梯度 tensor([-0.6522])\n",
						"第 105 次epoch\n",
						"第 2101 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1869]])\n",
						"模型中偏参梯度 tensor([-0.6519])\n",
						"第 2102 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1869]])\n",
						"模型中偏参梯度 tensor([-0.6517])\n",
						"第 2103 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1868]])\n",
						"模型中偏参梯度 tensor([-0.6514])\n",
						"第 2104 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1867]])\n",
						"模型中偏参梯度 tensor([-0.6511])\n",
						"第 2105 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1866]])\n",
						"模型中偏参梯度 tensor([-0.6509])\n",
						"第 2106 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1865]])\n",
						"模型中偏参梯度 tensor([-0.6506])\n",
						"第 2107 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1865]])\n",
						"模型中偏参梯度 tensor([-0.6504])\n",
						"第 2108 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1864]])\n",
						"模型中偏参梯度 tensor([-0.6501])\n",
						"第 2109 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1863]])\n",
						"模型中偏参梯度 tensor([-0.6498])\n",
						"第 2110 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1862]])\n",
						"模型中偏参梯度 tensor([-0.6496])\n",
						"第 2111 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1861]])\n",
						"模型中偏参梯度 tensor([-0.6493])\n",
						"第 2112 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1860]])\n",
						"模型中偏参梯度 tensor([-0.6491])\n",
						"第 2113 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1859]])\n",
						"模型中偏参梯度 tensor([-0.6488])\n",
						"第 2114 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1859]])\n",
						"模型中偏参梯度 tensor([-0.6486])\n",
						"第 2115 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1858]])\n",
						"模型中偏参梯度 tensor([-0.6483])\n",
						"第 2116 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1857]])\n",
						"模型中偏参梯度 tensor([-0.6480])\n",
						"第 2117 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1857]])\n",
						"模型中偏参梯度 tensor([-0.6478])\n",
						"第 2118 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1856]])\n",
						"模型中偏参梯度 tensor([-0.6475])\n",
						"第 2119 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1856]])\n",
						"模型中偏参梯度 tensor([-0.6472])\n",
						"第 2120 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1855]])\n",
						"模型中偏参梯度 tensor([-0.6470])\n",
						"第 106 次epoch\n",
						"第 2121 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1854]])\n",
						"模型中偏参梯度 tensor([-0.6467])\n",
						"第 2122 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1854]])\n",
						"模型中偏参梯度 tensor([-0.6464])\n",
						"第 2123 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1853]])\n",
						"模型中偏参梯度 tensor([-0.6462])\n",
						"第 2124 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1852]])\n",
						"模型中偏参梯度 tensor([-0.6459])\n",
						"第 2125 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1851]])\n",
						"模型中偏参梯度 tensor([-0.6457])\n",
						"第 2126 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1851]])\n",
						"模型中偏参梯度 tensor([-0.6454])\n",
						"第 2127 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1850]])\n",
						"模型中偏参梯度 tensor([-0.6451])\n",
						"第 2128 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1849]])\n",
						"模型中偏参梯度 tensor([-0.6449])\n",
						"第 2129 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1848]])\n",
						"模型中偏参梯度 tensor([-0.6446])\n",
						"第 2130 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1848]])\n",
						"模型中偏参梯度 tensor([-0.6444])\n",
						"第 2131 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1847]])\n",
						"模型中偏参梯度 tensor([-0.6441])\n",
						"第 2132 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1846]])\n",
						"模型中偏参梯度 tensor([-0.6438])\n",
						"第 2133 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1845]])\n",
						"模型中偏参梯度 tensor([-0.6436])\n",
						"第 2134 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1844]])\n",
						"模型中偏参梯度 tensor([-0.6433])\n",
						"第 2135 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1843]])\n",
						"模型中偏参梯度 tensor([-0.6431])\n",
						"第 2136 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1842]])\n",
						"模型中偏参梯度 tensor([-0.6428])\n",
						"第 2137 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1842]])\n",
						"模型中偏参梯度 tensor([-0.6426])\n",
						"第 2138 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1841]])\n",
						"模型中偏参梯度 tensor([-0.6423])\n",
						"第 2139 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1840]])\n",
						"模型中偏参梯度 tensor([-0.6421])\n",
						"第 2140 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1839]])\n",
						"模型中偏参梯度 tensor([-0.6418])\n",
						"第 107 次epoch\n",
						"第 2141 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1839]])\n",
						"模型中偏参梯度 tensor([-0.6415])\n",
						"第 2142 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1838]])\n",
						"模型中偏参梯度 tensor([-0.6413])\n",
						"第 2143 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1837]])\n",
						"模型中偏参梯度 tensor([-0.6410])\n",
						"第 2144 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1837]])\n",
						"模型中偏参梯度 tensor([-0.6408])\n",
						"第 2145 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1836]])\n",
						"模型中偏参梯度 tensor([-0.6405])\n",
						"第 2146 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1835]])\n",
						"模型中偏参梯度 tensor([-0.6402])\n",
						"第 2147 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1835]])\n",
						"模型中偏参梯度 tensor([-0.6400])\n",
						"第 2148 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1834]])\n",
						"模型中偏参梯度 tensor([-0.6397])\n",
						"第 2149 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1833]])\n",
						"模型中偏参梯度 tensor([-0.6395])\n",
						"第 2150 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1833]])\n",
						"模型中偏参梯度 tensor([-0.6392])\n",
						"第 2151 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1832]])\n",
						"模型中偏参梯度 tensor([-0.6389])\n",
						"第 2152 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1831]])\n",
						"模型中偏参梯度 tensor([-0.6387])\n",
						"第 2153 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1831]])\n",
						"模型中偏参梯度 tensor([-0.6384])\n",
						"第 2154 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1830]])\n",
						"模型中偏参梯度 tensor([-0.6382])\n",
						"第 2155 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1829]])\n",
						"模型中偏参梯度 tensor([-0.6379])\n",
						"第 2156 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1828]])\n",
						"模型中偏参梯度 tensor([-0.6377])\n",
						"第 2157 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1827]])\n",
						"模型中偏参梯度 tensor([-0.6374])\n",
						"第 2158 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1827]])\n",
						"模型中偏参梯度 tensor([-0.6372])\n",
						"第 2159 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1826]])\n",
						"模型中偏参梯度 tensor([-0.6369])\n",
						"第 2160 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1825]])\n",
						"模型中偏参梯度 tensor([-0.6366])\n",
						"第 108 次epoch\n",
						"第 2161 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1824]])\n",
						"模型中偏参梯度 tensor([-0.6364])\n",
						"第 2162 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1823]])\n",
						"模型中偏参梯度 tensor([-0.6361])\n",
						"第 2163 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1822]])\n",
						"模型中偏参梯度 tensor([-0.6359])\n",
						"第 2164 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1821]])\n",
						"模型中偏参梯度 tensor([-0.6356])\n",
						"第 2165 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1821]])\n",
						"模型中偏参梯度 tensor([-0.6354])\n",
						"第 2166 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1820]])\n",
						"模型中偏参梯度 tensor([-0.6351])\n",
						"第 2167 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1820]])\n",
						"模型中偏参梯度 tensor([-0.6349])\n",
						"第 2168 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1819]])\n",
						"模型中偏参梯度 tensor([-0.6346])\n",
						"第 2169 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1818]])\n",
						"模型中偏参梯度 tensor([-0.6343])\n",
						"第 2170 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1818]])\n",
						"模型中偏参梯度 tensor([-0.6341])\n",
						"第 2171 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1817]])\n",
						"模型中偏参梯度 tensor([-0.6338])\n",
						"第 2172 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1817]])\n",
						"模型中偏参梯度 tensor([-0.6336])\n",
						"第 2173 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1816]])\n",
						"模型中偏参梯度 tensor([-0.6333])\n",
						"第 2174 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1815]])\n",
						"模型中偏参梯度 tensor([-0.6331])\n",
						"第 2175 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1815]])\n",
						"模型中偏参梯度 tensor([-0.6328])\n",
						"第 2176 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1814]])\n",
						"模型中偏参梯度 tensor([-0.6325])\n",
						"第 2177 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1813]])\n",
						"模型中偏参梯度 tensor([-0.6323])\n",
						"第 2178 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1812]])\n",
						"模型中偏参梯度 tensor([-0.6320])\n",
						"第 2179 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1812]])\n",
						"模型中偏参梯度 tensor([-0.6318])\n",
						"第 2180 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1811]])\n",
						"模型中偏参梯度 tensor([-0.6315])\n",
						"第 109 次epoch\n",
						"第 2181 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1810]])\n",
						"模型中偏参梯度 tensor([-0.6313])\n",
						"第 2182 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1809]])\n",
						"模型中偏参梯度 tensor([-0.6310])\n",
						"第 2183 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1809]])\n",
						"模型中偏参梯度 tensor([-0.6308])\n",
						"第 2184 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1808]])\n",
						"模型中偏参梯度 tensor([-0.6305])\n",
						"第 2185 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1807]])\n",
						"模型中偏参梯度 tensor([-0.6303])\n",
						"第 2186 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1806]])\n",
						"模型中偏参梯度 tensor([-0.6300])\n",
						"第 2187 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1805]])\n",
						"模型中偏参梯度 tensor([-0.6298])\n",
						"第 2188 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1804]])\n",
						"模型中偏参梯度 tensor([-0.6295])\n",
						"第 2189 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1803]])\n",
						"模型中偏参梯度 tensor([-0.6293])\n",
						"第 2190 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1802]])\n",
						"模型中偏参梯度 tensor([-0.6290])\n",
						"第 2191 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1802]])\n",
						"模型中偏参梯度 tensor([-0.6288])\n",
						"第 2192 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1801]])\n",
						"模型中偏参梯度 tensor([-0.6285])\n",
						"第 2193 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1801]])\n",
						"模型中偏参梯度 tensor([-0.6283])\n",
						"第 2194 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1800]])\n",
						"模型中偏参梯度 tensor([-0.6280])\n",
						"第 2195 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1799]])\n",
						"模型中偏参梯度 tensor([-0.6277])\n",
						"第 2196 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1799]])\n",
						"模型中偏参梯度 tensor([-0.6275])\n",
						"第 2197 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1798]])\n",
						"模型中偏参梯度 tensor([-0.6272])\n",
						"第 2198 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1798]])\n",
						"模型中偏参梯度 tensor([-0.6270])\n",
						"第 2199 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1797]])\n",
						"模型中偏参梯度 tensor([-0.6267])\n",
						"第 2200 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1796]])\n",
						"模型中偏参梯度 tensor([-0.6265])\n",
						"第 110 次epoch\n",
						"第 2201 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1796]])\n",
						"模型中偏参梯度 tensor([-0.6262])\n",
						"第 2202 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1795]])\n",
						"模型中偏参梯度 tensor([-0.6260])\n",
						"第 2203 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1794]])\n",
						"模型中偏参梯度 tensor([-0.6257])\n",
						"第 2204 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1793]])\n",
						"模型中偏参梯度 tensor([-0.6255])\n",
						"第 2205 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1793]])\n",
						"模型中偏参梯度 tensor([-0.6252])\n",
						"第 2206 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1792]])\n",
						"模型中偏参梯度 tensor([-0.6250])\n",
						"第 2207 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1791]])\n",
						"模型中偏参梯度 tensor([-0.6247])\n",
						"第 2208 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1790]])\n",
						"模型中偏参梯度 tensor([-0.6245])\n",
						"第 2209 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1790]])\n",
						"模型中偏参梯度 tensor([-0.6242])\n",
						"第 2210 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1789]])\n",
						"模型中偏参梯度 tensor([-0.6240])\n",
						"第 2211 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1788]])\n",
						"模型中偏参梯度 tensor([-0.6237])\n",
						"第 2212 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1787]])\n",
						"模型中偏参梯度 tensor([-0.6235])\n",
						"第 2213 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1786]])\n",
						"模型中偏参梯度 tensor([-0.6232])\n",
						"第 2214 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1786]])\n",
						"模型中偏参梯度 tensor([-0.6230])\n",
						"第 2215 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1785]])\n",
						"模型中偏参梯度 tensor([-0.6227])\n",
						"第 2216 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1784]])\n",
						"模型中偏参梯度 tensor([-0.6225])\n",
						"第 2217 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1783]])\n",
						"模型中偏参梯度 tensor([-0.6222])\n",
						"第 2218 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1782]])\n",
						"模型中偏参梯度 tensor([-0.6220])\n",
						"第 2219 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1782]])\n",
						"模型中偏参梯度 tensor([-0.6217])\n",
						"第 2220 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1781]])\n",
						"模型中偏参梯度 tensor([-0.6215])\n",
						"第 111 次epoch\n",
						"第 2221 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1781]])\n",
						"模型中偏参梯度 tensor([-0.6212])\n",
						"第 2222 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1780]])\n",
						"模型中偏参梯度 tensor([-0.6210])\n",
						"第 2223 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1779]])\n",
						"模型中偏参梯度 tensor([-0.6207])\n",
						"第 2224 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1779]])\n",
						"模型中偏参梯度 tensor([-0.6204])\n",
						"第 2225 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1778]])\n",
						"模型中偏参梯度 tensor([-0.6202])\n",
						"第 2226 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1778]])\n",
						"模型中偏参梯度 tensor([-0.6199])\n",
						"第 2227 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1777]])\n",
						"模型中偏参梯度 tensor([-0.6197])\n",
						"第 2228 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1776]])\n",
						"模型中偏参梯度 tensor([-0.6194])\n",
						"第 2229 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1775]])\n",
						"模型中偏参梯度 tensor([-0.6192])\n",
						"第 2230 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1775]])\n",
						"模型中偏参梯度 tensor([-0.6189])\n",
						"第 2231 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1774]])\n",
						"模型中偏参梯度 tensor([-0.6187])\n",
						"第 2232 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1773]])\n",
						"模型中偏参梯度 tensor([-0.6184])\n",
						"第 2233 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1773]])\n",
						"模型中偏参梯度 tensor([-0.6182])\n",
						"第 2234 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1772]])\n",
						"模型中偏参梯度 tensor([-0.6180])\n",
						"第 2235 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1771]])\n",
						"模型中偏参梯度 tensor([-0.6177])\n",
						"第 2236 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1770]])\n",
						"模型中偏参梯度 tensor([-0.6175])\n",
						"第 2237 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1770]])\n",
						"模型中偏参梯度 tensor([-0.6172])\n",
						"第 2238 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1769]])\n",
						"模型中偏参梯度 tensor([-0.6170])\n",
						"第 2239 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1768]])\n",
						"模型中偏参梯度 tensor([-0.6167])\n",
						"第 2240 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1767]])\n",
						"模型中偏参梯度 tensor([-0.6165])\n",
						"第 112 次epoch\n",
						"第 2241 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1766]])\n",
						"模型中偏参梯度 tensor([-0.6162])\n",
						"第 2242 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1765]])\n",
						"模型中偏参梯度 tensor([-0.6160])\n",
						"第 2243 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1764]])\n",
						"模型中偏参梯度 tensor([-0.6157])\n",
						"第 2244 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1763]])\n",
						"模型中偏参梯度 tensor([-0.6155])\n",
						"第 2245 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1763]])\n",
						"模型中偏参梯度 tensor([-0.6153])\n",
						"第 2246 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1762]])\n",
						"模型中偏参梯度 tensor([-0.6150])\n",
						"第 2247 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1762]])\n",
						"模型中偏参梯度 tensor([-0.6147])\n",
						"第 2248 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1761]])\n",
						"模型中偏参梯度 tensor([-0.6145])\n",
						"第 2249 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1761]])\n",
						"模型中偏参梯度 tensor([-0.6142])\n",
						"第 2250 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1760]])\n",
						"模型中偏参梯度 tensor([-0.6140])\n",
						"第 2251 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1760]])\n",
						"模型中偏参梯度 tensor([-0.6137])\n",
						"第 2252 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1759]])\n",
						"模型中偏参梯度 tensor([-0.6135])\n",
						"第 2253 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1758]])\n",
						"模型中偏参梯度 tensor([-0.6132])\n",
						"第 2254 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1758]])\n",
						"模型中偏参梯度 tensor([-0.6130])\n",
						"第 2255 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1757]])\n",
						"模型中偏参梯度 tensor([-0.6128])\n",
						"第 2256 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1756]])\n",
						"模型中偏参梯度 tensor([-0.6125])\n",
						"第 2257 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1756]])\n",
						"模型中偏参梯度 tensor([-0.6123])\n",
						"第 2258 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1755]])\n",
						"模型中偏参梯度 tensor([-0.6120])\n",
						"第 2259 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1754]])\n",
						"模型中偏参梯度 tensor([-0.6118])\n",
						"第 2260 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1753]])\n",
						"模型中偏参梯度 tensor([-0.6115])\n",
						"第 113 次epoch\n",
						"第 2261 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1753]])\n",
						"模型中偏参梯度 tensor([-0.6113])\n",
						"第 2262 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1752]])\n",
						"模型中偏参梯度 tensor([-0.6110])\n",
						"第 2263 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1751]])\n",
						"模型中偏参梯度 tensor([-0.6108])\n",
						"第 2264 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1750]])\n",
						"模型中偏参梯度 tensor([-0.6105])\n",
						"第 2265 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1749]])\n",
						"模型中偏参梯度 tensor([-0.6103])\n",
						"第 2266 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1749]])\n",
						"模型中偏参梯度 tensor([-0.6101])\n",
						"第 2267 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1748]])\n",
						"模型中偏参梯度 tensor([-0.6098])\n",
						"第 2268 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1747]])\n",
						"模型中偏参梯度 tensor([-0.6096])\n",
						"第 2269 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1746]])\n",
						"模型中偏参梯度 tensor([-0.6093])\n",
						"第 2270 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1745]])\n",
						"模型中偏参梯度 tensor([-0.6091])\n",
						"第 2271 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1744]])\n",
						"模型中偏参梯度 tensor([-0.6089])\n",
						"第 2272 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1744]])\n",
						"模型中偏参梯度 tensor([-0.6086])\n",
						"第 2273 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1743]])\n",
						"模型中偏参梯度 tensor([-0.6084])\n",
						"第 2274 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1743]])\n",
						"模型中偏参梯度 tensor([-0.6081])\n",
						"第 2275 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1742]])\n",
						"模型中偏参梯度 tensor([-0.6079])\n",
						"第 2276 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1742]])\n",
						"模型中偏参梯度 tensor([-0.6076])\n",
						"第 2277 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1741]])\n",
						"模型中偏参梯度 tensor([-0.6074])\n",
						"第 2278 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1740]])\n",
						"模型中偏参梯度 tensor([-0.6071])\n",
						"第 2279 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1740]])\n",
						"模型中偏参梯度 tensor([-0.6069])\n",
						"第 2280 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1739]])\n",
						"模型中偏参梯度 tensor([-0.6066])\n",
						"第 114 次epoch\n",
						"第 2281 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1738]])\n",
						"模型中偏参梯度 tensor([-0.6064])\n",
						"第 2282 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1738]])\n",
						"模型中偏参梯度 tensor([-0.6061])\n",
						"第 2283 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1737]])\n",
						"模型中偏参梯度 tensor([-0.6059])\n",
						"第 2284 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1737]])\n",
						"模型中偏参梯度 tensor([-0.6056])\n",
						"第 2285 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1736]])\n",
						"模型中偏参梯度 tensor([-0.6054])\n",
						"第 2286 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1735]])\n",
						"模型中偏参梯度 tensor([-0.6052])\n",
						"第 2287 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1734]])\n",
						"模型中偏参梯度 tensor([-0.6049])\n",
						"第 2288 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1734]])\n",
						"模型中偏参梯度 tensor([-0.6047])\n",
						"第 2289 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1733]])\n",
						"模型中偏参梯度 tensor([-0.6044])\n",
						"第 2290 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1732]])\n",
						"模型中偏参梯度 tensor([-0.6042])\n",
						"第 2291 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1731]])\n",
						"模型中偏参梯度 tensor([-0.6039])\n",
						"第 2292 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1731]])\n",
						"模型中偏参梯度 tensor([-0.6037])\n",
						"第 2293 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1730]])\n",
						"模型中偏参梯度 tensor([-0.6035])\n",
						"第 2294 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1729]])\n",
						"模型中偏参梯度 tensor([-0.6032])\n",
						"第 2295 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1728]])\n",
						"模型中偏参梯度 tensor([-0.6030])\n",
						"第 2296 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1727]])\n",
						"模型中偏参梯度 tensor([-0.6028])\n",
						"第 2297 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1726]])\n",
						"模型中偏参梯度 tensor([-0.6025])\n",
						"第 2298 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1726]])\n",
						"模型中偏参梯度 tensor([-0.6023])\n",
						"第 2299 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1725]])\n",
						"模型中偏参梯度 tensor([-0.6020])\n",
						"第 2300 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1725]])\n",
						"模型中偏参梯度 tensor([-0.6018])\n",
						"第 115 次epoch\n",
						"第 2301 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1724]])\n",
						"模型中偏参梯度 tensor([-0.6015])\n",
						"第 2302 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1723]])\n",
						"模型中偏参梯度 tensor([-0.6013])\n",
						"第 2303 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1723]])\n",
						"模型中偏参梯度 tensor([-0.6010])\n",
						"第 2304 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1722]])\n",
						"模型中偏参梯度 tensor([-0.6008])\n",
						"第 2305 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1722]])\n",
						"模型中偏参梯度 tensor([-0.6006])\n",
						"第 2306 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1721]])\n",
						"模型中偏参梯度 tensor([-0.6003])\n",
						"第 2307 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1721]])\n",
						"模型中偏参梯度 tensor([-0.6001])\n",
						"第 2308 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1720]])\n",
						"模型中偏参梯度 tensor([-0.5998])\n",
						"第 2309 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1719]])\n",
						"模型中偏参梯度 tensor([-0.5996])\n",
						"第 2310 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1719]])\n",
						"模型中偏参梯度 tensor([-0.5993])\n",
						"第 2311 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1718]])\n",
						"模型中偏参梯度 tensor([-0.5991])\n",
						"第 2312 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1717]])\n",
						"模型中偏参梯度 tensor([-0.5989])\n",
						"第 2313 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1716]])\n",
						"模型中偏参梯度 tensor([-0.5986])\n",
						"第 2314 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1716]])\n",
						"模型中偏参梯度 tensor([-0.5984])\n",
						"第 2315 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1715]])\n",
						"模型中偏参梯度 tensor([-0.5981])\n",
						"第 2316 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1714]])\n",
						"模型中偏参梯度 tensor([-0.5979])\n",
						"第 2317 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1714]])\n",
						"模型中偏参梯度 tensor([-0.5977])\n",
						"第 2318 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1713]])\n",
						"模型中偏参梯度 tensor([-0.5974])\n",
						"第 2319 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1712]])\n",
						"模型中偏参梯度 tensor([-0.5972])\n",
						"第 2320 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1711]])\n",
						"模型中偏参梯度 tensor([-0.5969])\n",
						"第 116 次epoch\n",
						"第 2321 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1710]])\n",
						"模型中偏参梯度 tensor([-0.5967])\n",
						"第 2322 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1710]])\n",
						"模型中偏参梯度 tensor([-0.5965])\n",
						"第 2323 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1709]])\n",
						"模型中偏参梯度 tensor([-0.5962])\n",
						"第 2324 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1708]])\n",
						"模型中偏参梯度 tensor([-0.5960])\n",
						"第 2325 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1707]])\n",
						"模型中偏参梯度 tensor([-0.5958])\n",
						"第 2326 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1706]])\n",
						"模型中偏参梯度 tensor([-0.5955])\n",
						"第 2327 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1706]])\n",
						"模型中偏参梯度 tensor([-0.5953])\n",
						"第 2328 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1706]])\n",
						"模型中偏参梯度 tensor([-0.5950])\n",
						"第 2329 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1705]])\n",
						"模型中偏参梯度 tensor([-0.5948])\n",
						"第 2330 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1704]])\n",
						"模型中偏参梯度 tensor([-0.5945])\n",
						"第 2331 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1704]])\n",
						"模型中偏参梯度 tensor([-0.5943])\n",
						"第 2332 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1703]])\n",
						"模型中偏参梯度 tensor([-0.5941])\n",
						"第 2333 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1703]])\n",
						"模型中偏参梯度 tensor([-0.5938])\n",
						"第 2334 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1702]])\n",
						"模型中偏参梯度 tensor([-0.5936])\n",
						"第 2335 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1701]])\n",
						"模型中偏参梯度 tensor([-0.5933])\n",
						"第 2336 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1701]])\n",
						"模型中偏参梯度 tensor([-0.5931])\n",
						"第 2337 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1700]])\n",
						"模型中偏参梯度 tensor([-0.5929])\n",
						"第 2338 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1699]])\n",
						"模型中偏参梯度 tensor([-0.5926])\n",
						"第 2339 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1699]])\n",
						"模型中偏参梯度 tensor([-0.5924])\n",
						"第 2340 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1698]])\n",
						"模型中偏参梯度 tensor([-0.5921])\n",
						"第 117 次epoch\n",
						"第 2341 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1697]])\n",
						"模型中偏参梯度 tensor([-0.5919])\n",
						"第 2342 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1697]])\n",
						"模型中偏参梯度 tensor([-0.5917])\n",
						"第 2343 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1696]])\n",
						"模型中偏参梯度 tensor([-0.5914])\n",
						"第 2344 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1695]])\n",
						"模型中偏参梯度 tensor([-0.5912])\n",
						"第 2345 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1695]])\n",
						"模型中偏参梯度 tensor([-0.5910])\n",
						"第 2346 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1694]])\n",
						"模型中偏参梯度 tensor([-0.5907])\n",
						"第 2347 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1693]])\n",
						"模型中偏参梯度 tensor([-0.5905])\n",
						"第 2348 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1692]])\n",
						"模型中偏参梯度 tensor([-0.5903])\n",
						"第 2349 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1691]])\n",
						"模型中偏参梯度 tensor([-0.5900])\n",
						"第 2350 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1691]])\n",
						"模型中偏参梯度 tensor([-0.5898])\n",
						"第 2351 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1690]])\n",
						"模型中偏参梯度 tensor([-0.5895])\n",
						"第 2352 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1689]])\n",
						"模型中偏参梯度 tensor([-0.5893])\n",
						"第 2353 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1688]])\n",
						"模型中偏参梯度 tensor([-0.5891])\n",
						"第 2354 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1687]])\n",
						"模型中偏参梯度 tensor([-0.5889])\n",
						"第 2355 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1687]])\n",
						"模型中偏参梯度 tensor([-0.5886])\n",
						"第 2356 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1686]])\n",
						"模型中偏参梯度 tensor([-0.5884])\n",
						"第 2357 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1686]])\n",
						"模型中偏参梯度 tensor([-0.5881])\n",
						"第 2358 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1685]])\n",
						"模型中偏参梯度 tensor([-0.5879])\n",
						"第 2359 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1685]])\n",
						"模型中偏参梯度 tensor([-0.5876])\n",
						"第 2360 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1684]])\n",
						"模型中偏参梯度 tensor([-0.5874])\n",
						"第 118 次epoch\n",
						"第 2361 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1683]])\n",
						"模型中偏参梯度 tensor([-0.5872])\n",
						"第 2362 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1683]])\n",
						"模型中偏参梯度 tensor([-0.5869])\n",
						"第 2363 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1682]])\n",
						"模型中偏参梯度 tensor([-0.5867])\n",
						"第 2364 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1682]])\n",
						"模型中偏参梯度 tensor([-0.5865])\n",
						"第 2365 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1681]])\n",
						"模型中偏参梯度 tensor([-0.5862])\n",
						"第 2366 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1680]])\n",
						"模型中偏参梯度 tensor([-0.5860])\n",
						"第 2367 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1680]])\n",
						"模型中偏参梯度 tensor([-0.5857])\n",
						"第 2368 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1679]])\n",
						"模型中偏参梯度 tensor([-0.5855])\n",
						"第 2369 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1678]])\n",
						"模型中偏参梯度 tensor([-0.5853])\n",
						"第 2370 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1677]])\n",
						"模型中偏参梯度 tensor([-0.5850])\n",
						"第 2371 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1677]])\n",
						"模型中偏参梯度 tensor([-0.5848])\n",
						"第 2372 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1676]])\n",
						"模型中偏参梯度 tensor([-0.5846])\n",
						"第 2373 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1675]])\n",
						"模型中偏参梯度 tensor([-0.5843])\n",
						"第 2374 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1675]])\n",
						"模型中偏参梯度 tensor([-0.5841])\n",
						"第 2375 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1674]])\n",
						"模型中偏参梯度 tensor([-0.5839])\n",
						"第 2376 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1673]])\n",
						"模型中偏参梯度 tensor([-0.5836])\n",
						"第 2377 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1672]])\n",
						"模型中偏参梯度 tensor([-0.5834])\n",
						"第 2378 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1671]])\n",
						"模型中偏参梯度 tensor([-0.5832])\n",
						"第 2379 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1671]])\n",
						"模型中偏参梯度 tensor([-0.5830])\n",
						"第 2380 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1670]])\n",
						"模型中偏参梯度 tensor([-0.5827])\n",
						"第 119 次epoch\n",
						"第 2381 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1669]])\n",
						"模型中偏参梯度 tensor([-0.5825])\n",
						"第 2382 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1668]])\n",
						"模型中偏参梯度 tensor([-0.5823])\n",
						"第 2383 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1668]])\n",
						"模型中偏参梯度 tensor([-0.5820])\n",
						"第 2384 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1667]])\n",
						"模型中偏参梯度 tensor([-0.5818])\n",
						"第 2385 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1667]])\n",
						"模型中偏参梯度 tensor([-0.5815])\n",
						"第 2386 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1666]])\n",
						"模型中偏参梯度 tensor([-0.5813])\n",
						"第 2387 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1666]])\n",
						"模型中偏参梯度 tensor([-0.5811])\n",
						"第 2388 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1665]])\n",
						"模型中偏参梯度 tensor([-0.5808])\n",
						"第 2389 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1664]])\n",
						"模型中偏参梯度 tensor([-0.5806])\n",
						"第 2390 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1664]])\n",
						"模型中偏参梯度 tensor([-0.5804])\n",
						"第 2391 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1663]])\n",
						"模型中偏参梯度 tensor([-0.5801])\n",
						"第 2392 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1663]])\n",
						"模型中偏参梯度 tensor([-0.5799])\n",
						"第 2393 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1662]])\n",
						"模型中偏参梯度 tensor([-0.5797])\n",
						"第 2394 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1661]])\n",
						"模型中偏参梯度 tensor([-0.5794])\n",
						"第 2395 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1661]])\n",
						"模型中偏参梯度 tensor([-0.5792])\n",
						"第 2396 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1660]])\n",
						"模型中偏参梯度 tensor([-0.5789])\n",
						"第 2397 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1659]])\n",
						"模型中偏参梯度 tensor([-0.5787])\n",
						"第 2398 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1659]])\n",
						"模型中偏参梯度 tensor([-0.5785])\n",
						"第 2399 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1658]])\n",
						"模型中偏参梯度 tensor([-0.5783])\n",
						"第 2400 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1657]])\n",
						"模型中偏参梯度 tensor([-0.5780])\n",
						"第 120 次epoch\n",
						"第 2401 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1657]])\n",
						"模型中偏参梯度 tensor([-0.5778])\n",
						"第 2402 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1656]])\n",
						"模型中偏参梯度 tensor([-0.5776])\n",
						"第 2403 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1655]])\n",
						"模型中偏参梯度 tensor([-0.5773])\n",
						"第 2404 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1654]])\n",
						"模型中偏参梯度 tensor([-0.5771])\n",
						"第 2405 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1654]])\n",
						"模型中偏参梯度 tensor([-0.5769])\n",
						"第 2406 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1653]])\n",
						"模型中偏参梯度 tensor([-0.5766])\n",
						"第 2407 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1652]])\n",
						"模型中偏参梯度 tensor([-0.5764])\n",
						"第 2408 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1651]])\n",
						"模型中偏参梯度 tensor([-0.5762])\n",
						"第 2409 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1650]])\n",
						"模型中偏参梯度 tensor([-0.5760])\n",
						"第 2410 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1650]])\n",
						"模型中偏参梯度 tensor([-0.5757])\n",
						"第 2411 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1649]])\n",
						"模型中偏参梯度 tensor([-0.5755])\n",
						"第 2412 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1649]])\n",
						"模型中偏参梯度 tensor([-0.5753])\n",
						"第 2413 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1648]])\n",
						"模型中偏参梯度 tensor([-0.5750])\n",
						"第 2414 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1648]])\n",
						"模型中偏参梯度 tensor([-0.5748])\n",
						"第 2415 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1647]])\n",
						"模型中偏参梯度 tensor([-0.5746])\n",
						"第 2416 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1646]])\n",
						"模型中偏参梯度 tensor([-0.5743])\n",
						"第 2417 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1646]])\n",
						"模型中偏参梯度 tensor([-0.5741])\n",
						"第 2418 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1645]])\n",
						"模型中偏参梯度 tensor([-0.5739])\n",
						"第 2419 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1645]])\n",
						"模型中偏参梯度 tensor([-0.5736])\n",
						"第 2420 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1644]])\n",
						"模型中偏参梯度 tensor([-0.5734])\n",
						"第 121 次epoch\n",
						"第 2421 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1644]])\n",
						"模型中偏参梯度 tensor([-0.5732])\n",
						"第 2422 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1643]])\n",
						"模型中偏参梯度 tensor([-0.5729])\n",
						"第 2423 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1642]])\n",
						"模型中偏参梯度 tensor([-0.5727])\n",
						"第 2424 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1642]])\n",
						"模型中偏参梯度 tensor([-0.5725])\n",
						"第 2425 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1641]])\n",
						"模型中偏参梯度 tensor([-0.5722])\n",
						"第 2426 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1640]])\n",
						"模型中偏参梯度 tensor([-0.5720])\n",
						"第 2427 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1640]])\n",
						"模型中偏参梯度 tensor([-0.5718])\n",
						"第 2428 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1639]])\n",
						"模型中偏参梯度 tensor([-0.5715])\n",
						"第 2429 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1638]])\n",
						"模型中偏参梯度 tensor([-0.5713])\n",
						"第 2430 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1638]])\n",
						"模型中偏参梯度 tensor([-0.5711])\n",
						"第 2431 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1637]])\n",
						"模型中偏参梯度 tensor([-0.5709])\n",
						"第 2432 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1636]])\n",
						"模型中偏参梯度 tensor([-0.5706])\n",
						"第 2433 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1635]])\n",
						"模型中偏参梯度 tensor([-0.5704])\n",
						"第 2434 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1635]])\n",
						"模型中偏参梯度 tensor([-0.5702])\n",
						"第 2435 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1634]])\n",
						"模型中偏参梯度 tensor([-0.5699])\n",
						"第 2436 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1633]])\n",
						"模型中偏参梯度 tensor([-0.5697])\n",
						"第 2437 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1632]])\n",
						"模型中偏参梯度 tensor([-0.5695])\n",
						"第 2438 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1631]])\n",
						"模型中偏参梯度 tensor([-0.5693])\n",
						"第 2439 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1631]])\n",
						"模型中偏参梯度 tensor([-0.5690])\n",
						"第 2440 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1630]])\n",
						"模型中偏参梯度 tensor([-0.5688])\n",
						"第 122 次epoch\n",
						"第 2441 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1630]])\n",
						"模型中偏参梯度 tensor([-0.5686])\n",
						"第 2442 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1629]])\n",
						"模型中偏参梯度 tensor([-0.5683])\n",
						"第 2443 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1629]])\n",
						"模型中偏参梯度 tensor([-0.5681])\n",
						"第 2444 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1628]])\n",
						"模型中偏参梯度 tensor([-0.5679])\n",
						"第 2445 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1628]])\n",
						"模型中偏参梯度 tensor([-0.5677])\n",
						"第 2446 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1627]])\n",
						"模型中偏参梯度 tensor([-0.5674])\n",
						"第 2447 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1626]])\n",
						"模型中偏参梯度 tensor([-0.5672])\n",
						"第 2448 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1626]])\n",
						"模型中偏参梯度 tensor([-0.5670])\n",
						"第 2449 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1625]])\n",
						"模型中偏参梯度 tensor([-0.5667])\n",
						"第 2450 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1625]])\n",
						"模型中偏参梯度 tensor([-0.5665])\n",
						"第 2451 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1624]])\n",
						"模型中偏参梯度 tensor([-0.5663])\n",
						"第 2452 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1623]])\n",
						"模型中偏参梯度 tensor([-0.5660])\n",
						"第 2453 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1623]])\n",
						"模型中偏参梯度 tensor([-0.5658])\n",
						"第 2454 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1622]])\n",
						"模型中偏参梯度 tensor([-0.5656])\n",
						"第 2455 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1622]])\n",
						"模型中偏参梯度 tensor([-0.5654])\n",
						"第 2456 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1621]])\n",
						"模型中偏参梯度 tensor([-0.5651])\n",
						"第 2457 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1620]])\n",
						"模型中偏参梯度 tensor([-0.5649])\n",
						"第 2458 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1619]])\n",
						"模型中偏参梯度 tensor([-0.5647])\n",
						"第 2459 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1619]])\n",
						"模型中偏参梯度 tensor([-0.5645])\n",
						"第 2460 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1618]])\n",
						"模型中偏参梯度 tensor([-0.5642])\n",
						"第 123 次epoch\n",
						"第 2461 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1617]])\n",
						"模型中偏参梯度 tensor([-0.5640])\n",
						"第 2462 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1617]])\n",
						"模型中偏参梯度 tensor([-0.5638])\n",
						"第 2463 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1616]])\n",
						"模型中偏参梯度 tensor([-0.5636])\n",
						"第 2464 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1615]])\n",
						"模型中偏参梯度 tensor([-0.5633])\n",
						"第 2465 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1614]])\n",
						"模型中偏参梯度 tensor([-0.5631])\n",
						"第 2466 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1613]])\n",
						"模型中偏参梯度 tensor([-0.5629])\n",
						"第 2467 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1613]])\n",
						"模型中偏参梯度 tensor([-0.5627])\n",
						"第 2468 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1612]])\n",
						"模型中偏参梯度 tensor([-0.5624])\n",
						"第 2469 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1611]])\n",
						"模型中偏参梯度 tensor([-0.5622])\n",
						"第 2470 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1610]])\n",
						"模型中偏参梯度 tensor([-0.5620])\n",
						"第 2471 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1610]])\n",
						"模型中偏参梯度 tensor([-0.5618])\n",
						"第 2472 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1609]])\n",
						"模型中偏参梯度 tensor([-0.5615])\n",
						"第 2473 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1609]])\n",
						"模型中偏参梯度 tensor([-0.5613])\n",
						"第 2474 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1608]])\n",
						"模型中偏参梯度 tensor([-0.5611])\n",
						"第 2475 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1608]])\n",
						"模型中偏参梯度 tensor([-0.5608])\n",
						"第 2476 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1607]])\n",
						"模型中偏参梯度 tensor([-0.5606])\n",
						"第 2477 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1607]])\n",
						"模型中偏参梯度 tensor([-0.5604])\n",
						"第 2478 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1606]])\n",
						"模型中偏参梯度 tensor([-0.5602])\n",
						"第 2479 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1606]])\n",
						"模型中偏参梯度 tensor([-0.5599])\n",
						"第 2480 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1605]])\n",
						"模型中偏参梯度 tensor([-0.5597])\n",
						"第 124 次epoch\n",
						"第 2481 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1604]])\n",
						"模型中偏参梯度 tensor([-0.5595])\n",
						"第 2482 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1604]])\n",
						"模型中偏参梯度 tensor([-0.5593])\n",
						"第 2483 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1603]])\n",
						"模型中偏参梯度 tensor([-0.5590])\n",
						"第 2484 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1603]])\n",
						"模型中偏参梯度 tensor([-0.5588])\n",
						"第 2485 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1602]])\n",
						"模型中偏参梯度 tensor([-0.5586])\n",
						"第 2486 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1601]])\n",
						"模型中偏参梯度 tensor([-0.5584])\n",
						"第 2487 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1600]])\n",
						"模型中偏参梯度 tensor([-0.5581])\n",
						"第 2488 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1600]])\n",
						"模型中偏参梯度 tensor([-0.5579])\n",
						"第 2489 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1599]])\n",
						"模型中偏参梯度 tensor([-0.5577])\n",
						"第 2490 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1598]])\n",
						"模型中偏参梯度 tensor([-0.5575])\n",
						"第 2491 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1598]])\n",
						"模型中偏参梯度 tensor([-0.5572])\n",
						"第 2492 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1597]])\n",
						"模型中偏参梯度 tensor([-0.5570])\n",
						"第 2493 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1596]])\n",
						"模型中偏参梯度 tensor([-0.5568])\n",
						"第 2494 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1595]])\n",
						"模型中偏参梯度 tensor([-0.5566])\n",
						"第 2495 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1595]])\n",
						"模型中偏参梯度 tensor([-0.5564])\n",
						"第 2496 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1594]])\n",
						"模型中偏参梯度 tensor([-0.5561])\n",
						"第 2497 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1593]])\n",
						"模型中偏参梯度 tensor([-0.5559])\n",
						"第 2498 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1592]])\n",
						"模型中偏参梯度 tensor([-0.5557])\n",
						"第 2499 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1592]])\n",
						"模型中偏参梯度 tensor([-0.5555])\n",
						"第 2500 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1591]])\n",
						"模型中偏参梯度 tensor([-0.5552])\n",
						"第 125 次epoch\n",
						"第 2501 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1591]])\n",
						"模型中偏参梯度 tensor([-0.5550])\n",
						"第 2502 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1590]])\n",
						"模型中偏参梯度 tensor([-0.5548])\n",
						"第 2503 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1590]])\n",
						"模型中偏参梯度 tensor([-0.5546])\n",
						"第 2504 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1589]])\n",
						"模型中偏参梯度 tensor([-0.5543])\n",
						"第 2505 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1589]])\n",
						"模型中偏参梯度 tensor([-0.5541])\n",
						"第 2506 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1588]])\n",
						"模型中偏参梯度 tensor([-0.5539])\n",
						"第 2507 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1588]])\n",
						"模型中偏参梯度 tensor([-0.5537])\n",
						"第 2508 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1587]])\n",
						"模型中偏参梯度 tensor([-0.5534])\n",
						"第 2509 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1586]])\n",
						"模型中偏参梯度 tensor([-0.5532])\n",
						"第 2510 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1586]])\n",
						"模型中偏参梯度 tensor([-0.5530])\n",
						"第 2511 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1585]])\n",
						"模型中偏参梯度 tensor([-0.5528])\n",
						"第 2512 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1585]])\n",
						"模型中偏参梯度 tensor([-0.5525])\n",
						"第 2513 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1584]])\n",
						"模型中偏参梯度 tensor([-0.5523])\n",
						"第 2514 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1583]])\n",
						"模型中偏参梯度 tensor([-0.5521])\n",
						"第 2515 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1583]])\n",
						"模型中偏参梯度 tensor([-0.5519])\n",
						"第 2516 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1582]])\n",
						"模型中偏参梯度 tensor([-0.5517])\n",
						"第 2517 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1581]])\n",
						"模型中偏参梯度 tensor([-0.5514])\n",
						"第 2518 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1581]])\n",
						"模型中偏参梯度 tensor([-0.5512])\n",
						"第 2519 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1580]])\n",
						"模型中偏参梯度 tensor([-0.5510])\n",
						"第 2520 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1579]])\n",
						"模型中偏参梯度 tensor([-0.5508])\n",
						"第 126 次epoch\n",
						"第 2521 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1579]])\n",
						"模型中偏参梯度 tensor([-0.5506])\n",
						"第 2522 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1578]])\n",
						"模型中偏参梯度 tensor([-0.5503])\n",
						"第 2523 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1577]])\n",
						"模型中偏参梯度 tensor([-0.5501])\n",
						"第 2524 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1576]])\n",
						"模型中偏参梯度 tensor([-0.5499])\n",
						"第 2525 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1576]])\n",
						"模型中偏参梯度 tensor([-0.5497])\n",
						"第 2526 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1575]])\n",
						"模型中偏参梯度 tensor([-0.5495])\n",
						"第 2527 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1574]])\n",
						"模型中偏参梯度 tensor([-0.5492])\n",
						"第 2528 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1573]])\n",
						"模型中偏参梯度 tensor([-0.5490])\n",
						"第 2529 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1573]])\n",
						"模型中偏参梯度 tensor([-0.5488])\n",
						"第 2530 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1572]])\n",
						"模型中偏参梯度 tensor([-0.5486])\n",
						"第 2531 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1572]])\n",
						"模型中偏参梯度 tensor([-0.5484])\n",
						"第 2532 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1571]])\n",
						"模型中偏参梯度 tensor([-0.5481])\n",
						"第 2533 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1571]])\n",
						"模型中偏参梯度 tensor([-0.5479])\n",
						"第 2534 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1570]])\n",
						"模型中偏参梯度 tensor([-0.5477])\n",
						"第 2535 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1570]])\n",
						"模型中偏参梯度 tensor([-0.5475])\n",
						"第 2536 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1569]])\n",
						"模型中偏参梯度 tensor([-0.5472])\n",
						"第 2537 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1569]])\n",
						"模型中偏参梯度 tensor([-0.5470])\n",
						"第 2538 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1568]])\n",
						"模型中偏参梯度 tensor([-0.5468])\n",
						"第 2539 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1568]])\n",
						"模型中偏参梯度 tensor([-0.5466])\n",
						"第 2540 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1567]])\n",
						"模型中偏参梯度 tensor([-0.5463])\n",
						"第 127 次epoch\n",
						"第 2541 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1566]])\n",
						"模型中偏参梯度 tensor([-0.5461])\n",
						"第 2542 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1566]])\n",
						"模型中偏参梯度 tensor([-0.5459])\n",
						"第 2543 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1565]])\n",
						"模型中偏参梯度 tensor([-0.5457])\n",
						"第 2544 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1564]])\n",
						"模型中偏参梯度 tensor([-0.5455])\n",
						"第 2545 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1564]])\n",
						"模型中偏参梯度 tensor([-0.5452])\n",
						"第 2546 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1563]])\n",
						"模型中偏参梯度 tensor([-0.5450])\n",
						"第 2547 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1562]])\n",
						"模型中偏参梯度 tensor([-0.5448])\n",
						"第 2548 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1562]])\n",
						"模型中偏参梯度 tensor([-0.5446])\n",
						"第 2549 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1561]])\n",
						"模型中偏参梯度 tensor([-0.5444])\n",
						"第 2550 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1560]])\n",
						"模型中偏参梯度 tensor([-0.5442])\n",
						"第 2551 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1560]])\n",
						"模型中偏参梯度 tensor([-0.5439])\n",
						"第 2552 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1559]])\n",
						"模型中偏参梯度 tensor([-0.5437])\n",
						"第 2553 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1558]])\n",
						"模型中偏参梯度 tensor([-0.5435])\n",
						"第 2554 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1557]])\n",
						"模型中偏参梯度 tensor([-0.5433])\n",
						"第 2555 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1557]])\n",
						"模型中偏参梯度 tensor([-0.5431])\n",
						"第 2556 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1556]])\n",
						"模型中偏参梯度 tensor([-0.5429])\n",
						"第 2557 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1555]])\n",
						"模型中偏参梯度 tensor([-0.5427])\n",
						"第 2558 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1554]])\n",
						"模型中偏参梯度 tensor([-0.5424])\n",
						"第 2559 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1554]])\n",
						"模型中偏参梯度 tensor([-0.5422])\n",
						"第 2560 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1553]])\n",
						"模型中偏参梯度 tensor([-0.5420])\n",
						"第 128 次epoch\n",
						"第 2561 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1553]])\n",
						"模型中偏参梯度 tensor([-0.5418])\n",
						"第 2562 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1553]])\n",
						"模型中偏参梯度 tensor([-0.5415])\n",
						"第 2563 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1552]])\n",
						"模型中偏参梯度 tensor([-0.5413])\n",
						"第 2564 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1552]])\n",
						"模型中偏参梯度 tensor([-0.5411])\n",
						"第 2565 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1551]])\n",
						"模型中偏参梯度 tensor([-0.5409])\n",
						"第 2566 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1551]])\n",
						"模型中偏参梯度 tensor([-0.5407])\n",
						"第 2567 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1550]])\n",
						"模型中偏参梯度 tensor([-0.5404])\n",
						"第 2568 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1549]])\n",
						"模型中偏参梯度 tensor([-0.5402])\n",
						"第 2569 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1549]])\n",
						"模型中偏参梯度 tensor([-0.5400])\n",
						"第 2570 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1548]])\n",
						"模型中偏参梯度 tensor([-0.5398])\n",
						"第 2571 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1548]])\n",
						"模型中偏参梯度 tensor([-0.5396])\n",
						"第 2572 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1547]])\n",
						"模型中偏参梯度 tensor([-0.5394])\n",
						"第 2573 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1546]])\n",
						"模型中偏参梯度 tensor([-0.5391])\n",
						"第 2574 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1546]])\n",
						"模型中偏参梯度 tensor([-0.5389])\n",
						"第 2575 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1545]])\n",
						"模型中偏参梯度 tensor([-0.5387])\n",
						"第 2576 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1545]])\n",
						"模型中偏参梯度 tensor([-0.5385])\n",
						"第 2577 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1544]])\n",
						"模型中偏参梯度 tensor([-0.5383])\n",
						"第 2578 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1543]])\n",
						"模型中偏参梯度 tensor([-0.5381])\n",
						"第 2579 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1543]])\n",
						"模型中偏参梯度 tensor([-0.5378])\n",
						"第 2580 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1542]])\n",
						"模型中偏参梯度 tensor([-0.5376])\n",
						"第 129 次epoch\n",
						"第 2581 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1541]])\n",
						"模型中偏参梯度 tensor([-0.5374])\n",
						"第 2582 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1540]])\n",
						"模型中偏参梯度 tensor([-0.5372])\n",
						"第 2583 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1540]])\n",
						"模型中偏参梯度 tensor([-0.5370])\n",
						"第 2584 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1539]])\n",
						"模型中偏参梯度 tensor([-0.5368])\n",
						"第 2585 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1538]])\n",
						"模型中偏参梯度 tensor([-0.5366])\n",
						"第 2586 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1537]])\n",
						"模型中偏参梯度 tensor([-0.5363])\n",
						"第 2587 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1537]])\n",
						"模型中偏参梯度 tensor([-0.5361])\n",
						"第 2588 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1536]])\n",
						"模型中偏参梯度 tensor([-0.5359])\n",
						"第 2589 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1535]])\n",
						"模型中偏参梯度 tensor([-0.5357])\n",
						"第 2590 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1535]])\n",
						"模型中偏参梯度 tensor([-0.5355])\n",
						"第 2591 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1534]])\n",
						"模型中偏参梯度 tensor([-0.5353])\n",
						"第 2592 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1534]])\n",
						"模型中偏参梯度 tensor([-0.5351])\n",
						"第 2593 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1533]])\n",
						"模型中偏参梯度 tensor([-0.5348])\n",
						"第 2594 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1533]])\n",
						"模型中偏参梯度 tensor([-0.5346])\n",
						"第 2595 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1532]])\n",
						"模型中偏参梯度 tensor([-0.5344])\n",
						"第 2596 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1532]])\n",
						"模型中偏参梯度 tensor([-0.5342])\n",
						"第 2597 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1531]])\n",
						"模型中偏参梯度 tensor([-0.5340])\n",
						"第 2598 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1531]])\n",
						"模型中偏参梯度 tensor([-0.5337])\n",
						"第 2599 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1530]])\n",
						"模型中偏参梯度 tensor([-0.5335])\n",
						"第 2600 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1530]])\n",
						"模型中偏参梯度 tensor([-0.5333])\n",
						"第 130 次epoch\n",
						"第 2601 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1529]])\n",
						"模型中偏参梯度 tensor([-0.5331])\n",
						"第 2602 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1529]])\n",
						"模型中偏参梯度 tensor([-0.5329])\n",
						"第 2603 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1528]])\n",
						"模型中偏参梯度 tensor([-0.5327])\n",
						"第 2604 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1527]])\n",
						"模型中偏参梯度 tensor([-0.5324])\n",
						"第 2605 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1527]])\n",
						"模型中偏参梯度 tensor([-0.5322])\n",
						"第 2606 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1526]])\n",
						"模型中偏参梯度 tensor([-0.5320])\n",
						"第 2607 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1525]])\n",
						"模型中偏参梯度 tensor([-0.5318])\n",
						"第 2608 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1525]])\n",
						"模型中偏参梯度 tensor([-0.5316])\n",
						"第 2609 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1524]])\n",
						"模型中偏参梯度 tensor([-0.5314])\n",
						"第 2610 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1523]])\n",
						"模型中偏参梯度 tensor([-0.5312])\n",
						"第 2611 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1523]])\n",
						"模型中偏参梯度 tensor([-0.5310])\n",
						"第 2612 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1522]])\n",
						"模型中偏参梯度 tensor([-0.5307])\n",
						"第 2613 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1521]])\n",
						"模型中偏参梯度 tensor([-0.5305])\n",
						"第 2614 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1521]])\n",
						"模型中偏参梯度 tensor([-0.5303])\n",
						"第 2615 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1520]])\n",
						"模型中偏参梯度 tensor([-0.5301])\n",
						"第 2616 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1519]])\n",
						"模型中偏参梯度 tensor([-0.5299])\n",
						"第 2617 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1518]])\n",
						"模型中偏参梯度 tensor([-0.5297])\n",
						"第 2618 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1518]])\n",
						"模型中偏参梯度 tensor([-0.5295])\n",
						"第 2619 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1517]])\n",
						"模型中偏参梯度 tensor([-0.5293])\n",
						"第 2620 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1516]])\n",
						"模型中偏参梯度 tensor([-0.5291])\n",
						"第 131 次epoch\n",
						"第 2621 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1516]])\n",
						"模型中偏参梯度 tensor([-0.5289])\n",
						"第 2622 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1515]])\n",
						"模型中偏参梯度 tensor([-0.5286])\n",
						"第 2623 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1515]])\n",
						"模型中偏参梯度 tensor([-0.5284])\n",
						"第 2624 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1514]])\n",
						"模型中偏参梯度 tensor([-0.5282])\n",
						"第 2625 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1514]])\n",
						"模型中偏参梯度 tensor([-0.5280])\n",
						"第 2626 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1513]])\n",
						"模型中偏参梯度 tensor([-0.5278])\n",
						"第 2627 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1513]])\n",
						"模型中偏参梯度 tensor([-0.5276])\n",
						"第 2628 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1512]])\n",
						"模型中偏参梯度 tensor([-0.5273])\n",
						"第 2629 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1512]])\n",
						"模型中偏参梯度 tensor([-0.5271])\n",
						"第 2630 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1511]])\n",
						"模型中偏参梯度 tensor([-0.5269])\n",
						"第 2631 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1511]])\n",
						"模型中偏参梯度 tensor([-0.5267])\n",
						"第 2632 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1510]])\n",
						"模型中偏参梯度 tensor([-0.5265])\n",
						"第 2633 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1510]])\n",
						"模型中偏参梯度 tensor([-0.5263])\n",
						"第 2634 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1509]])\n",
						"模型中偏参梯度 tensor([-0.5261])\n",
						"第 2635 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1509]])\n",
						"模型中偏参梯度 tensor([-0.5258])\n",
						"第 2636 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1508]])\n",
						"模型中偏参梯度 tensor([-0.5256])\n",
						"第 2637 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1507]])\n",
						"模型中偏参梯度 tensor([-0.5254])\n",
						"第 2638 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1507]])\n",
						"模型中偏参梯度 tensor([-0.5252])\n",
						"第 2639 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1506]])\n",
						"模型中偏参梯度 tensor([-0.5250])\n",
						"第 2640 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1505]])\n",
						"模型中偏参梯度 tensor([-0.5248])\n",
						"第 132 次epoch\n",
						"第 2641 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1505]])\n",
						"模型中偏参梯度 tensor([-0.5246])\n",
						"第 2642 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1504]])\n",
						"模型中偏参梯度 tensor([-0.5244])\n",
						"第 2643 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1503]])\n",
						"模型中偏参梯度 tensor([-0.5242])\n",
						"第 2644 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1503]])\n",
						"模型中偏参梯度 tensor([-0.5240])\n",
						"第 2645 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1502]])\n",
						"模型中偏参梯度 tensor([-0.5237])\n",
						"第 2646 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1501]])\n",
						"模型中偏参梯度 tensor([-0.5235])\n",
						"第 2647 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1500]])\n",
						"模型中偏参梯度 tensor([-0.5233])\n",
						"第 2648 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1500]])\n",
						"模型中偏参梯度 tensor([-0.5231])\n",
						"第 2649 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1499]])\n",
						"模型中偏参梯度 tensor([-0.5229])\n",
						"第 2650 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1498]])\n",
						"模型中偏参梯度 tensor([-0.5227])\n",
						"第 2651 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1497]])\n",
						"模型中偏参梯度 tensor([-0.5225])\n",
						"第 2652 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1497]])\n",
						"模型中偏参梯度 tensor([-0.5223])\n",
						"第 2653 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1496]])\n",
						"模型中偏参梯度 tensor([-0.5221])\n",
						"第 2654 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1496]])\n",
						"模型中偏参梯度 tensor([-0.5219])\n",
						"第 2655 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1495]])\n",
						"模型中偏参梯度 tensor([-0.5217])\n",
						"第 2656 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1495]])\n",
						"模型中偏参梯度 tensor([-0.5214])\n",
						"第 2657 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1494]])\n",
						"模型中偏参梯度 tensor([-0.5212])\n",
						"第 2658 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1494]])\n",
						"模型中偏参梯度 tensor([-0.5210])\n",
						"第 2659 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1493]])\n",
						"模型中偏参梯度 tensor([-0.5208])\n",
						"第 2660 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1493]])\n",
						"模型中偏参梯度 tensor([-0.5206])\n",
						"第 133 次epoch\n",
						"第 2661 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1492]])\n",
						"模型中偏参梯度 tensor([-0.5204])\n",
						"第 2662 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1492]])\n",
						"模型中偏参梯度 tensor([-0.5202])\n",
						"第 2663 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1491]])\n",
						"模型中偏参梯度 tensor([-0.5200])\n",
						"第 2664 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1491]])\n",
						"模型中偏参梯度 tensor([-0.5198])\n",
						"第 2665 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1490]])\n",
						"模型中偏参梯度 tensor([-0.5195])\n",
						"第 2666 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1490]])\n",
						"模型中偏参梯度 tensor([-0.5193])\n",
						"第 2667 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1489]])\n",
						"模型中偏参梯度 tensor([-0.5191])\n",
						"第 2668 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1488]])\n",
						"模型中偏参梯度 tensor([-0.5189])\n",
						"第 2669 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1488]])\n",
						"模型中偏参梯度 tensor([-0.5187])\n",
						"第 2670 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1487]])\n",
						"模型中偏参梯度 tensor([-0.5185])\n",
						"第 2671 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1487]])\n",
						"模型中偏参梯度 tensor([-0.5183])\n",
						"第 2672 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1486]])\n",
						"模型中偏参梯度 tensor([-0.5181])\n",
						"第 2673 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1485]])\n",
						"模型中偏参梯度 tensor([-0.5179])\n",
						"第 2674 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1485]])\n",
						"模型中偏参梯度 tensor([-0.5177])\n",
						"第 2675 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1484]])\n",
						"模型中偏参梯度 tensor([-0.5175])\n",
						"第 2676 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1483]])\n",
						"模型中偏参梯度 tensor([-0.5173])\n",
						"第 2677 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1483]])\n",
						"模型中偏参梯度 tensor([-0.5171])\n",
						"第 2678 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1482]])\n",
						"模型中偏参梯度 tensor([-0.5168])\n",
						"第 2679 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1481]])\n",
						"模型中偏参梯度 tensor([-0.5166])\n",
						"第 2680 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1480]])\n",
						"模型中偏参梯度 tensor([-0.5164])\n",
						"第 134 次epoch\n",
						"第 2681 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1480]])\n",
						"模型中偏参梯度 tensor([-0.5162])\n",
						"第 2682 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1479]])\n",
						"模型中偏参梯度 tensor([-0.5160])\n",
						"第 2683 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1478]])\n",
						"模型中偏参梯度 tensor([-0.5158])\n",
						"第 2684 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1478]])\n",
						"模型中偏参梯度 tensor([-0.5156])\n",
						"第 2685 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1477]])\n",
						"模型中偏参梯度 tensor([-0.5154])\n",
						"第 2686 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1477]])\n",
						"模型中偏参梯度 tensor([-0.5152])\n",
						"第 2687 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1476]])\n",
						"模型中偏参梯度 tensor([-0.5150])\n",
						"第 2688 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1476]])\n",
						"模型中偏参梯度 tensor([-0.5148])\n",
						"第 2689 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1475]])\n",
						"模型中偏参梯度 tensor([-0.5146])\n",
						"第 2690 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1475]])\n",
						"模型中偏参梯度 tensor([-0.5143])\n",
						"第 2691 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1475]])\n",
						"模型中偏参梯度 tensor([-0.5141])\n",
						"第 2692 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1474]])\n",
						"模型中偏参梯度 tensor([-0.5139])\n",
						"第 2693 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1473]])\n",
						"模型中偏参梯度 tensor([-0.5137])\n",
						"第 2694 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1473]])\n",
						"模型中偏参梯度 tensor([-0.5135])\n",
						"第 2695 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1472]])\n",
						"模型中偏参梯度 tensor([-0.5133])\n",
						"第 2696 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1472]])\n",
						"模型中偏参梯度 tensor([-0.5131])\n",
						"第 2697 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1471]])\n",
						"模型中偏参梯度 tensor([-0.5129])\n",
						"第 2698 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1471]])\n",
						"模型中偏参梯度 tensor([-0.5127])\n",
						"第 2699 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1470]])\n",
						"模型中偏参梯度 tensor([-0.5125])\n",
						"第 2700 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1470]])\n",
						"模型中偏参梯度 tensor([-0.5123])\n",
						"第 135 次epoch\n",
						"第 2701 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1469]])\n",
						"模型中偏参梯度 tensor([-0.5121])\n",
						"第 2702 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1468]])\n",
						"模型中偏参梯度 tensor([-0.5119])\n",
						"第 2703 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1468]])\n",
						"模型中偏参梯度 tensor([-0.5117])\n",
						"第 2704 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1467]])\n",
						"模型中偏参梯度 tensor([-0.5114])\n",
						"第 2705 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1466]])\n",
						"模型中偏参梯度 tensor([-0.5112])\n",
						"第 2706 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1466]])\n",
						"模型中偏参梯度 tensor([-0.5110])\n",
						"第 2707 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1465]])\n",
						"模型中偏参梯度 tensor([-0.5108])\n",
						"第 2708 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1464]])\n",
						"模型中偏参梯度 tensor([-0.5106])\n",
						"第 2709 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1464]])\n",
						"模型中偏参梯度 tensor([-0.5104])\n",
						"第 2710 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1463]])\n",
						"模型中偏参梯度 tensor([-0.5102])\n",
						"第 2711 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1462]])\n",
						"模型中偏参梯度 tensor([-0.5100])\n",
						"第 2712 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1462]])\n",
						"模型中偏参梯度 tensor([-0.5098])\n",
						"第 2713 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1461]])\n",
						"模型中偏参梯度 tensor([-0.5096])\n",
						"第 2714 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1460]])\n",
						"模型中偏参梯度 tensor([-0.5094])\n",
						"第 2715 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1459]])\n",
						"模型中偏参梯度 tensor([-0.5092])\n",
						"第 2716 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1459]])\n",
						"模型中偏参梯度 tensor([-0.5090])\n",
						"第 2717 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1458]])\n",
						"模型中偏参梯度 tensor([-0.5088])\n",
						"第 2718 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1458]])\n",
						"模型中偏参梯度 tensor([-0.5086])\n",
						"第 2719 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1457]])\n",
						"模型中偏参梯度 tensor([-0.5084])\n",
						"第 2720 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1457]])\n",
						"模型中偏参梯度 tensor([-0.5082])\n",
						"第 136 次epoch\n",
						"第 2721 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1456]])\n",
						"模型中偏参梯度 tensor([-0.5080])\n",
						"第 2722 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1456]])\n",
						"模型中偏参梯度 tensor([-0.5078])\n",
						"第 2723 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1456]])\n",
						"模型中偏参梯度 tensor([-0.5076])\n",
						"第 2724 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1455]])\n",
						"模型中偏参梯度 tensor([-0.5074])\n",
						"第 2725 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1454]])\n",
						"模型中偏参梯度 tensor([-0.5072])\n",
						"第 2726 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1454]])\n",
						"模型中偏参梯度 tensor([-0.5069])\n",
						"第 2727 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1454]])\n",
						"模型中偏参梯度 tensor([-0.5067])\n",
						"第 2728 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1453]])\n",
						"模型中偏参梯度 tensor([-0.5065])\n",
						"第 2729 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1452]])\n",
						"模型中偏参梯度 tensor([-0.5063])\n",
						"第 2730 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1452]])\n",
						"模型中偏参梯度 tensor([-0.5061])\n",
						"第 2731 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1451]])\n",
						"模型中偏参梯度 tensor([-0.5059])\n",
						"第 2732 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1451]])\n",
						"模型中偏参梯度 tensor([-0.5057])\n",
						"第 2733 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1450]])\n",
						"模型中偏参梯度 tensor([-0.5055])\n",
						"第 2734 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1450]])\n",
						"模型中偏参梯度 tensor([-0.5053])\n",
						"第 2735 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1449]])\n",
						"模型中偏参梯度 tensor([-0.5051])\n",
						"第 2736 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1448]])\n",
						"模型中偏参梯度 tensor([-0.5049])\n",
						"第 2737 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1448]])\n",
						"模型中偏参梯度 tensor([-0.5047])\n",
						"第 2738 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1447]])\n",
						"模型中偏参梯度 tensor([-0.5045])\n",
						"第 2739 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1446]])\n",
						"模型中偏参梯度 tensor([-0.5043])\n",
						"第 2740 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1446]])\n",
						"模型中偏参梯度 tensor([-0.5041])\n",
						"第 137 次epoch\n",
						"第 2741 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1445]])\n",
						"模型中偏参梯度 tensor([-0.5039])\n",
						"第 2742 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1444]])\n",
						"模型中偏参梯度 tensor([-0.5037])\n",
						"第 2743 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1444]])\n",
						"模型中偏参梯度 tensor([-0.5035])\n",
						"第 2744 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1443]])\n",
						"模型中偏参梯度 tensor([-0.5033])\n",
						"第 2745 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1442]])\n",
						"模型中偏参梯度 tensor([-0.5031])\n",
						"第 2746 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1441]])\n",
						"模型中偏参梯度 tensor([-0.5029])\n",
						"第 2747 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1441]])\n",
						"模型中偏参梯度 tensor([-0.5027])\n",
						"第 2748 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1440]])\n",
						"模型中偏参梯度 tensor([-0.5025])\n",
						"第 2749 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1440]])\n",
						"模型中偏参梯度 tensor([-0.5023])\n",
						"第 2750 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1439]])\n",
						"模型中偏参梯度 tensor([-0.5021])\n",
						"第 2751 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1439]])\n",
						"模型中偏参梯度 tensor([-0.5019])\n",
						"第 2752 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1438]])\n",
						"模型中偏参梯度 tensor([-0.5017])\n",
						"第 2753 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1438]])\n",
						"模型中偏参梯度 tensor([-0.5015])\n",
						"第 2754 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1437]])\n",
						"模型中偏参梯度 tensor([-0.5013])\n",
						"第 2755 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1437]])\n",
						"模型中偏参梯度 tensor([-0.5011])\n",
						"第 2756 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1437]])\n",
						"模型中偏参梯度 tensor([-0.5009])\n",
						"第 2757 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1436]])\n",
						"模型中偏参梯度 tensor([-0.5007])\n",
						"第 2758 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1435]])\n",
						"模型中偏参梯度 tensor([-0.5005])\n",
						"第 2759 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1435]])\n",
						"模型中偏参梯度 tensor([-0.5003])\n",
						"第 2760 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1435]])\n",
						"模型中偏参梯度 tensor([-0.5000])\n",
						"第 138 次epoch\n",
						"第 2761 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1434]])\n",
						"模型中偏参梯度 tensor([-0.4998])\n",
						"第 2762 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1433]])\n",
						"模型中偏参梯度 tensor([-0.4996])\n",
						"第 2763 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1433]])\n",
						"模型中偏参梯度 tensor([-0.4994])\n",
						"第 2764 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1432]])\n",
						"模型中偏参梯度 tensor([-0.4992])\n",
						"第 2765 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1432]])\n",
						"模型中偏参梯度 tensor([-0.4990])\n",
						"第 2766 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1431]])\n",
						"模型中偏参梯度 tensor([-0.4988])\n",
						"第 2767 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1431]])\n",
						"模型中偏参梯度 tensor([-0.4986])\n",
						"第 2768 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1430]])\n",
						"模型中偏参梯度 tensor([-0.4984])\n",
						"第 2769 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1429]])\n",
						"模型中偏参梯度 tensor([-0.4982])\n",
						"第 2770 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1429]])\n",
						"模型中偏参梯度 tensor([-0.4980])\n",
						"第 2771 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1428]])\n",
						"模型中偏参梯度 tensor([-0.4978])\n",
						"第 2772 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1427]])\n",
						"模型中偏参梯度 tensor([-0.4976])\n",
						"第 2773 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1427]])\n",
						"模型中偏参梯度 tensor([-0.4974])\n",
						"第 2774 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1426]])\n",
						"模型中偏参梯度 tensor([-0.4972])\n",
						"第 2775 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1425]])\n",
						"模型中偏参梯度 tensor([-0.4971])\n",
						"第 2776 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1425]])\n",
						"模型中偏参梯度 tensor([-0.4969])\n",
						"第 2777 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1424]])\n",
						"模型中偏参梯度 tensor([-0.4967])\n",
						"第 2778 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1423]])\n",
						"模型中偏参梯度 tensor([-0.4965])\n",
						"第 2779 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1423]])\n",
						"模型中偏参梯度 tensor([-0.4963])\n",
						"第 2780 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1422]])\n",
						"模型中偏参梯度 tensor([-0.4961])\n",
						"第 139 次epoch\n",
						"第 2781 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1421]])\n",
						"模型中偏参梯度 tensor([-0.4959])\n",
						"第 2782 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1420]])\n",
						"模型中偏参梯度 tensor([-0.4957])\n",
						"第 2783 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1420]])\n",
						"模型中偏参梯度 tensor([-0.4955])\n",
						"第 2784 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1420]])\n",
						"模型中偏参梯度 tensor([-0.4953])\n",
						"第 2785 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1419]])\n",
						"模型中偏参梯度 tensor([-0.4951])\n",
						"第 2786 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1419]])\n",
						"模型中偏参梯度 tensor([-0.4949])\n",
						"第 2787 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1418]])\n",
						"模型中偏参梯度 tensor([-0.4947])\n",
						"第 2788 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1418]])\n",
						"模型中偏参梯度 tensor([-0.4945])\n",
						"第 2789 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1417]])\n",
						"模型中偏参梯度 tensor([-0.4943])\n",
						"第 2790 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1417]])\n",
						"模型中偏参梯度 tensor([-0.4941])\n",
						"第 2791 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1416]])\n",
						"模型中偏参梯度 tensor([-0.4939])\n",
						"第 2792 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1416]])\n",
						"模型中偏参梯度 tensor([-0.4937])\n",
						"第 2793 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1415]])\n",
						"模型中偏参梯度 tensor([-0.4935])\n",
						"第 2794 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1415]])\n",
						"模型中偏参梯度 tensor([-0.4933])\n",
						"第 2795 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1414]])\n",
						"模型中偏参梯度 tensor([-0.4931])\n",
						"第 2796 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1414]])\n",
						"模型中偏参梯度 tensor([-0.4929])\n",
						"第 2797 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1413]])\n",
						"模型中偏参梯度 tensor([-0.4927])\n",
						"第 2798 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1413]])\n",
						"模型中偏参梯度 tensor([-0.4925])\n",
						"第 2799 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1412]])\n",
						"模型中偏参梯度 tensor([-0.4923])\n",
						"第 2800 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1412]])\n",
						"模型中偏参梯度 tensor([-0.4921])\n",
						"第 140 次epoch\n",
						"第 2801 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1411]])\n",
						"模型中偏参梯度 tensor([-0.4919])\n",
						"第 2802 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1410]])\n",
						"模型中偏参梯度 tensor([-0.4917])\n",
						"第 2803 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1410]])\n",
						"模型中偏参梯度 tensor([-0.4915])\n",
						"第 2804 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1409]])\n",
						"模型中偏参梯度 tensor([-0.4913])\n",
						"第 2805 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1409]])\n",
						"模型中偏参梯度 tensor([-0.4911])\n",
						"第 2806 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1408]])\n",
						"模型中偏参梯度 tensor([-0.4909])\n",
						"第 2807 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1407]])\n",
						"模型中偏参梯度 tensor([-0.4907])\n",
						"第 2808 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1406]])\n",
						"模型中偏参梯度 tensor([-0.4905])\n",
						"第 2809 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1406]])\n",
						"模型中偏参梯度 tensor([-0.4903])\n",
						"第 2810 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1405]])\n",
						"模型中偏参梯度 tensor([-0.4901])\n",
						"第 2811 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1404]])\n",
						"模型中偏参梯度 tensor([-0.4899])\n",
						"第 2812 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1404]])\n",
						"模型中偏参梯度 tensor([-0.4897])\n",
						"第 2813 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1403]])\n",
						"模型中偏参梯度 tensor([-0.4895])\n",
						"第 2814 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1402]])\n",
						"模型中偏参梯度 tensor([-0.4893])\n",
						"第 2815 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1402]])\n",
						"模型中偏参梯度 tensor([-0.4891])\n",
						"第 2816 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1401]])\n",
						"模型中偏参梯度 tensor([-0.4889])\n",
						"第 2817 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1401]])\n",
						"模型中偏参梯度 tensor([-0.4887])\n",
						"第 2818 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1400]])\n",
						"模型中偏参梯度 tensor([-0.4885])\n",
						"第 2819 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1400]])\n",
						"模型中偏参梯度 tensor([-0.4883])\n",
						"第 2820 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1400]])\n",
						"模型中偏参梯度 tensor([-0.4881])\n",
						"第 141 次epoch\n",
						"第 2821 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1399]])\n",
						"模型中偏参梯度 tensor([-0.4879])\n",
						"第 2822 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1399]])\n",
						"模型中偏参梯度 tensor([-0.4877])\n",
						"第 2823 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1398]])\n",
						"模型中偏参梯度 tensor([-0.4875])\n",
						"第 2824 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1398]])\n",
						"模型中偏参梯度 tensor([-0.4873])\n",
						"第 2825 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1397]])\n",
						"模型中偏参梯度 tensor([-0.4871])\n",
						"第 2826 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1397]])\n",
						"模型中偏参梯度 tensor([-0.4869])\n",
						"第 2827 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1396]])\n",
						"模型中偏参梯度 tensor([-0.4867])\n",
						"第 2828 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1396]])\n",
						"模型中偏参梯度 tensor([-0.4866])\n",
						"第 2829 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1395]])\n",
						"模型中偏参梯度 tensor([-0.4864])\n",
						"第 2830 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1395]])\n",
						"模型中偏参梯度 tensor([-0.4862])\n",
						"第 2831 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1394]])\n",
						"模型中偏参梯度 tensor([-0.4860])\n",
						"第 2832 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1394]])\n",
						"模型中偏参梯度 tensor([-0.4858])\n",
						"第 2833 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1393]])\n",
						"模型中偏参梯度 tensor([-0.4856])\n",
						"第 2834 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1392]])\n",
						"模型中偏参梯度 tensor([-0.4854])\n",
						"第 2835 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1392]])\n",
						"模型中偏参梯度 tensor([-0.4852])\n",
						"第 2836 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1391]])\n",
						"模型中偏参梯度 tensor([-0.4850])\n",
						"第 2837 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1391]])\n",
						"模型中偏参梯度 tensor([-0.4848])\n",
						"第 2838 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1390]])\n",
						"模型中偏参梯度 tensor([-0.4846])\n",
						"第 2839 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1389]])\n",
						"模型中偏参梯度 tensor([-0.4844])\n",
						"第 2840 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1389]])\n",
						"模型中偏参梯度 tensor([-0.4842])\n",
						"第 142 次epoch\n",
						"第 2841 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1388]])\n",
						"模型中偏参梯度 tensor([-0.4840])\n",
						"第 2842 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1387]])\n",
						"模型中偏参梯度 tensor([-0.4838])\n",
						"第 2843 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1387]])\n",
						"模型中偏参梯度 tensor([-0.4836])\n",
						"第 2844 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1386]])\n",
						"模型中偏参梯度 tensor([-0.4834])\n",
						"第 2845 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1385]])\n",
						"模型中偏参梯度 tensor([-0.4833])\n",
						"第 2846 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1385]])\n",
						"模型中偏参梯度 tensor([-0.4831])\n",
						"第 2847 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1384]])\n",
						"模型中偏参梯度 tensor([-0.4829])\n",
						"第 2848 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1383]])\n",
						"模型中偏参梯度 tensor([-0.4827])\n",
						"第 2849 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1383]])\n",
						"模型中偏参梯度 tensor([-0.4825])\n",
						"第 2850 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1382]])\n",
						"模型中偏参梯度 tensor([-0.4823])\n",
						"第 2851 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1382]])\n",
						"模型中偏参梯度 tensor([-0.4821])\n",
						"第 2852 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1381]])\n",
						"模型中偏参梯度 tensor([-0.4819])\n",
						"第 2853 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1381]])\n",
						"模型中偏参梯度 tensor([-0.4817])\n",
						"第 2854 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1381]])\n",
						"模型中偏参梯度 tensor([-0.4815])\n",
						"第 2855 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1380]])\n",
						"模型中偏参梯度 tensor([-0.4813])\n",
						"第 2856 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1380]])\n",
						"模型中偏参梯度 tensor([-0.4811])\n",
						"第 2857 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1379]])\n",
						"模型中偏参梯度 tensor([-0.4809])\n",
						"第 2858 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1379]])\n",
						"模型中偏参梯度 tensor([-0.4807])\n",
						"第 2859 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1378]])\n",
						"模型中偏参梯度 tensor([-0.4805])\n",
						"第 2860 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1378]])\n",
						"模型中偏参梯度 tensor([-0.4803])\n",
						"第 143 次epoch\n",
						"第 2861 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1377]])\n",
						"模型中偏参梯度 tensor([-0.4801])\n",
						"第 2862 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1377]])\n",
						"模型中偏参梯度 tensor([-0.4799])\n",
						"第 2863 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1376]])\n",
						"模型中偏参梯度 tensor([-0.4797])\n",
						"第 2864 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1376]])\n",
						"模型中偏参梯度 tensor([-0.4796])\n",
						"第 2865 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1375]])\n",
						"模型中偏参梯度 tensor([-0.4794])\n",
						"第 2866 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1375]])\n",
						"模型中偏参梯度 tensor([-0.4792])\n",
						"第 2867 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1374]])\n",
						"模型中偏参梯度 tensor([-0.4790])\n",
						"第 2868 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1374]])\n",
						"模型中偏参梯度 tensor([-0.4788])\n",
						"第 2869 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1373]])\n",
						"模型中偏参梯度 tensor([-0.4786])\n",
						"第 2870 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1372]])\n",
						"模型中偏参梯度 tensor([-0.4784])\n",
						"第 2871 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1372]])\n",
						"模型中偏参梯度 tensor([-0.4782])\n",
						"第 2872 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1371]])\n",
						"模型中偏参梯度 tensor([-0.4780])\n",
						"第 2873 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1371]])\n",
						"模型中偏参梯度 tensor([-0.4778])\n",
						"第 2874 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1370]])\n",
						"模型中偏参梯度 tensor([-0.4776])\n",
						"第 2875 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1369]])\n",
						"模型中偏参梯度 tensor([-0.4774])\n",
						"第 2876 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1369]])\n",
						"模型中偏参梯度 tensor([-0.4773])\n",
						"第 2877 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1368]])\n",
						"模型中偏参梯度 tensor([-0.4771])\n",
						"第 2878 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1367]])\n",
						"模型中偏参梯度 tensor([-0.4769])\n",
						"第 2879 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1367]])\n",
						"模型中偏参梯度 tensor([-0.4767])\n",
						"第 2880 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1366]])\n",
						"模型中偏参梯度 tensor([-0.4765])\n",
						"第 144 次epoch\n",
						"第 2881 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1365]])\n",
						"模型中偏参梯度 tensor([-0.4763])\n",
						"第 2882 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1365]])\n",
						"模型中偏参梯度 tensor([-0.4761])\n",
						"第 2883 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1364]])\n",
						"模型中偏参梯度 tensor([-0.4759])\n",
						"第 2884 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1363]])\n",
						"模型中偏参梯度 tensor([-0.4758])\n",
						"第 2885 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1363]])\n",
						"模型中偏参梯度 tensor([-0.4756])\n",
						"第 2886 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1362]])\n",
						"模型中偏参梯度 tensor([-0.4754])\n",
						"第 2887 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1362]])\n",
						"模型中偏参梯度 tensor([-0.4752])\n",
						"第 2888 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1361]])\n",
						"模型中偏参梯度 tensor([-0.4750])\n",
						"第 2889 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1361]])\n",
						"模型中偏参梯度 tensor([-0.4748])\n",
						"第 2890 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1361]])\n",
						"模型中偏参梯度 tensor([-0.4746])\n",
						"第 2891 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1360]])\n",
						"模型中偏参梯度 tensor([-0.4744])\n",
						"第 2892 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1360]])\n",
						"模型中偏参梯度 tensor([-0.4742])\n",
						"第 2893 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1359]])\n",
						"模型中偏参梯度 tensor([-0.4740])\n",
						"第 2894 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1359]])\n",
						"模型中偏参梯度 tensor([-0.4738])\n",
						"第 2895 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1358]])\n",
						"模型中偏参梯度 tensor([-0.4736])\n",
						"第 2896 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1358]])\n",
						"模型中偏参梯度 tensor([-0.4734])\n",
						"第 2897 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1358]])\n",
						"模型中偏参梯度 tensor([-0.4732])\n",
						"第 2898 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1357]])\n",
						"模型中偏参梯度 tensor([-0.4730])\n",
						"第 2899 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1356]])\n",
						"模型中偏参梯度 tensor([-0.4728])\n",
						"第 2900 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1356]])\n",
						"模型中偏参梯度 tensor([-0.4727])\n",
						"第 145 次epoch\n",
						"第 2901 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1355]])\n",
						"模型中偏参梯度 tensor([-0.4725])\n",
						"第 2902 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1355]])\n",
						"模型中偏参梯度 tensor([-0.4723])\n",
						"第 2903 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1354]])\n",
						"模型中偏参梯度 tensor([-0.4721])\n",
						"第 2904 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1354]])\n",
						"模型中偏参梯度 tensor([-0.4719])\n",
						"第 2905 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1353]])\n",
						"模型中偏参梯度 tensor([-0.4717])\n",
						"第 2906 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1353]])\n",
						"模型中偏参梯度 tensor([-0.4715])\n",
						"第 2907 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1352]])\n",
						"模型中偏参梯度 tensor([-0.4713])\n",
						"第 2908 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1351]])\n",
						"模型中偏参梯度 tensor([-0.4711])\n",
						"第 2909 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1351]])\n",
						"模型中偏参梯度 tensor([-0.4710])\n",
						"第 2910 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1350]])\n",
						"模型中偏参梯度 tensor([-0.4708])\n",
						"第 2911 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1349]])\n",
						"模型中偏参梯度 tensor([-0.4706])\n",
						"第 2912 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1349]])\n",
						"模型中偏参梯度 tensor([-0.4704])\n",
						"第 2913 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1348]])\n",
						"模型中偏参梯度 tensor([-0.4702])\n",
						"第 2914 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1347]])\n",
						"模型中偏参梯度 tensor([-0.4700])\n",
						"第 2915 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1347]])\n",
						"模型中偏参梯度 tensor([-0.4698])\n",
						"第 2916 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1346]])\n",
						"模型中偏参梯度 tensor([-0.4697])\n",
						"第 2917 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1345]])\n",
						"模型中偏参梯度 tensor([-0.4695])\n",
						"第 2918 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1345]])\n",
						"模型中偏参梯度 tensor([-0.4693])\n",
						"第 2919 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1344]])\n",
						"模型中偏参梯度 tensor([-0.4691])\n",
						"第 2920 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1344]])\n",
						"模型中偏参梯度 tensor([-0.4689])\n",
						"第 146 次epoch\n",
						"第 2921 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1344]])\n",
						"模型中偏参梯度 tensor([-0.4687])\n",
						"第 2922 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1343]])\n",
						"模型中偏参梯度 tensor([-0.4685])\n",
						"第 2923 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1343]])\n",
						"模型中偏参梯度 tensor([-0.4683])\n",
						"第 2924 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1342]])\n",
						"模型中偏参梯度 tensor([-0.4681])\n",
						"第 2925 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1342]])\n",
						"模型中偏参梯度 tensor([-0.4679])\n",
						"第 2926 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1342]])\n",
						"模型中偏参梯度 tensor([-0.4677])\n",
						"第 2927 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1341]])\n",
						"模型中偏参梯度 tensor([-0.4676])\n",
						"第 2928 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1341]])\n",
						"模型中偏参梯度 tensor([-0.4674])\n",
						"第 2929 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1340]])\n",
						"模型中偏参梯度 tensor([-0.4672])\n",
						"第 2930 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1340]])\n",
						"模型中偏参梯度 tensor([-0.4670])\n",
						"第 2931 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1339]])\n",
						"模型中偏参梯度 tensor([-0.4668])\n",
						"第 2932 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1339]])\n",
						"模型中偏参梯度 tensor([-0.4666])\n",
						"第 2933 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1338]])\n",
						"模型中偏参梯度 tensor([-0.4664])\n",
						"第 2934 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1338]])\n",
						"模型中偏参梯度 tensor([-0.4662])\n",
						"第 2935 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1337]])\n",
						"模型中偏参梯度 tensor([-0.4660])\n",
						"第 2936 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1337]])\n",
						"模型中偏参梯度 tensor([-0.4659])\n",
						"第 2937 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1336]])\n",
						"模型中偏参梯度 tensor([-0.4657])\n",
						"第 2938 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1336]])\n",
						"模型中偏参梯度 tensor([-0.4655])\n",
						"第 2939 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1335]])\n",
						"模型中偏参梯度 tensor([-0.4653])\n",
						"第 2940 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1335]])\n",
						"模型中偏参梯度 tensor([-0.4651])\n",
						"第 147 次epoch\n",
						"第 2941 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1334]])\n",
						"模型中偏参梯度 tensor([-0.4649])\n",
						"第 2942 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1333]])\n",
						"模型中偏参梯度 tensor([-0.4647])\n",
						"第 2943 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1333]])\n",
						"模型中偏参梯度 tensor([-0.4645])\n",
						"第 2944 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1332]])\n",
						"模型中偏参梯度 tensor([-0.4644])\n",
						"第 2945 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1332]])\n",
						"模型中偏参梯度 tensor([-0.4642])\n",
						"第 2946 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1331]])\n",
						"模型中偏参梯度 tensor([-0.4640])\n",
						"第 2947 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1330]])\n",
						"模型中偏参梯度 tensor([-0.4638])\n",
						"第 2948 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1330]])\n",
						"模型中偏参梯度 tensor([-0.4636])\n",
						"第 2949 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1329]])\n",
						"模型中偏参梯度 tensor([-0.4634])\n",
						"第 2950 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1328]])\n",
						"模型中偏参梯度 tensor([-0.4633])\n",
						"第 2951 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1328]])\n",
						"模型中偏参梯度 tensor([-0.4631])\n",
						"第 2952 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1327]])\n",
						"模型中偏参梯度 tensor([-0.4629])\n",
						"第 2953 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1326]])\n",
						"模型中偏参梯度 tensor([-0.4627])\n",
						"第 2954 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1325]])\n",
						"模型中偏参梯度 tensor([-0.4625])\n",
						"第 2955 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1325]])\n",
						"模型中偏参梯度 tensor([-0.4623])\n",
						"第 2956 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1325]])\n",
						"模型中偏参梯度 tensor([-0.4622])\n",
						"第 2957 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1324]])\n",
						"模型中偏参梯度 tensor([-0.4620])\n",
						"第 2958 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1324]])\n",
						"模型中偏参梯度 tensor([-0.4618])\n",
						"第 2959 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1324]])\n",
						"模型中偏参梯度 tensor([-0.4616])\n",
						"第 2960 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1323]])\n",
						"模型中偏参梯度 tensor([-0.4614])\n",
						"第 148 次epoch\n",
						"第 2961 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1323]])\n",
						"模型中偏参梯度 tensor([-0.4612])\n",
						"第 2962 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1322]])\n",
						"模型中偏参梯度 tensor([-0.4610])\n",
						"第 2963 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1322]])\n",
						"模型中偏参梯度 tensor([-0.4608])\n",
						"第 2964 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1322]])\n",
						"模型中偏参梯度 tensor([-0.4606])\n",
						"第 2965 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1321]])\n",
						"模型中偏参梯度 tensor([-0.4605])\n",
						"第 2966 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1321]])\n",
						"模型中偏参梯度 tensor([-0.4603])\n",
						"第 2967 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1320]])\n",
						"模型中偏参梯度 tensor([-0.4601])\n",
						"第 2968 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1320]])\n",
						"模型中偏参梯度 tensor([-0.4599])\n",
						"第 2969 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1319]])\n",
						"模型中偏参梯度 tensor([-0.4597])\n",
						"第 2970 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1319]])\n",
						"模型中偏参梯度 tensor([-0.4595])\n",
						"第 2971 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1318]])\n",
						"模型中偏参梯度 tensor([-0.4593])\n",
						"第 2972 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1318]])\n",
						"模型中偏参梯度 tensor([-0.4591])\n",
						"第 2973 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1317]])\n",
						"模型中偏参梯度 tensor([-0.4590])\n",
						"第 2974 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1317]])\n",
						"模型中偏参梯度 tensor([-0.4588])\n",
						"第 2975 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1316]])\n",
						"模型中偏参梯度 tensor([-0.4586])\n",
						"第 2976 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1315]])\n",
						"模型中偏参梯度 tensor([-0.4584])\n",
						"第 2977 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1315]])\n",
						"模型中偏参梯度 tensor([-0.4582])\n",
						"第 2978 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1314]])\n",
						"模型中偏参梯度 tensor([-0.4580])\n",
						"第 2979 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1314]])\n",
						"模型中偏参梯度 tensor([-0.4579])\n",
						"第 2980 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1313]])\n",
						"模型中偏参梯度 tensor([-0.4577])\n",
						"第 149 次epoch\n",
						"第 2981 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1312]])\n",
						"模型中偏参梯度 tensor([-0.4575])\n",
						"第 2982 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1312]])\n",
						"模型中偏参梯度 tensor([-0.4573])\n",
						"第 2983 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1311]])\n",
						"模型中偏参梯度 tensor([-0.4571])\n",
						"第 2984 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1311]])\n",
						"模型中偏参梯度 tensor([-0.4570])\n",
						"第 2985 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1310]])\n",
						"模型中偏参梯度 tensor([-0.4568])\n",
						"第 2986 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1309]])\n",
						"模型中偏参梯度 tensor([-0.4566])\n",
						"第 2987 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1309]])\n",
						"模型中偏参梯度 tensor([-0.4564])\n",
						"第 2988 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1308]])\n",
						"模型中偏参梯度 tensor([-0.4562])\n",
						"第 2989 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1307]])\n",
						"模型中偏参梯度 tensor([-0.4561])\n",
						"第 2990 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1306]])\n",
						"模型中偏参梯度 tensor([-0.4559])\n",
						"第 2991 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1306]])\n",
						"模型中偏参梯度 tensor([-0.4557])\n",
						"第 2992 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1306]])\n",
						"模型中偏参梯度 tensor([-0.4555])\n",
						"第 2993 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1305]])\n",
						"模型中偏参梯度 tensor([-0.4553])\n",
						"第 2994 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1305]])\n",
						"模型中偏参梯度 tensor([-0.4551])\n",
						"第 2995 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1305]])\n",
						"模型中偏参梯度 tensor([-0.4549])\n",
						"第 2996 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1304]])\n",
						"模型中偏参梯度 tensor([-0.4548])\n",
						"第 2997 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1304]])\n",
						"模型中偏参梯度 tensor([-0.4546])\n",
						"第 2998 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1303]])\n",
						"模型中偏参梯度 tensor([-0.4544])\n",
						"第 2999 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1303]])\n",
						"模型中偏参梯度 tensor([-0.4542])\n",
						"第 3000 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1303]])\n",
						"模型中偏参梯度 tensor([-0.4540])\n",
						"第 150 次epoch\n",
						"第 3001 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1302]])\n",
						"模型中偏参梯度 tensor([-0.4538])\n",
						"第 3002 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1302]])\n",
						"模型中偏参梯度 tensor([-0.4536])\n",
						"第 3003 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1301]])\n",
						"模型中偏参梯度 tensor([-0.4535])\n",
						"第 3004 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1301]])\n",
						"模型中偏参梯度 tensor([-0.4533])\n",
						"第 3005 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1300]])\n",
						"模型中偏参梯度 tensor([-0.4531])\n",
						"第 3006 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1300]])\n",
						"模型中偏参梯度 tensor([-0.4529])\n",
						"第 3007 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1299]])\n",
						"模型中偏参梯度 tensor([-0.4527])\n",
						"第 3008 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1299]])\n",
						"模型中偏参梯度 tensor([-0.4525])\n",
						"第 3009 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1298]])\n",
						"模型中偏参梯度 tensor([-0.4524])\n",
						"第 3010 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1298]])\n",
						"模型中偏参梯度 tensor([-0.4522])\n",
						"第 3011 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1297]])\n",
						"模型中偏参梯度 tensor([-0.4520])\n",
						"第 3012 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1297]])\n",
						"模型中偏参梯度 tensor([-0.4518])\n",
						"第 3013 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1296]])\n",
						"模型中偏参梯度 tensor([-0.4516])\n",
						"第 3014 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1295]])\n",
						"模型中偏参梯度 tensor([-0.4515])\n",
						"第 3015 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1295]])\n",
						"模型中偏参梯度 tensor([-0.4513])\n",
						"第 3016 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1294]])\n",
						"模型中偏参梯度 tensor([-0.4511])\n",
						"第 3017 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1294]])\n",
						"模型中偏参梯度 tensor([-0.4509])\n",
						"第 3018 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1293]])\n",
						"模型中偏参梯度 tensor([-0.4507])\n",
						"第 3019 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1292]])\n",
						"模型中偏参梯度 tensor([-0.4506])\n",
						"第 3020 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1292]])\n",
						"模型中偏参梯度 tensor([-0.4504])\n",
						"第 151 次epoch\n",
						"第 3021 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1291]])\n",
						"模型中偏参梯度 tensor([-0.4502])\n",
						"第 3022 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1291]])\n",
						"模型中偏参梯度 tensor([-0.4500])\n",
						"第 3023 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1290]])\n",
						"模型中偏参梯度 tensor([-0.4498])\n",
						"第 3024 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1289]])\n",
						"模型中偏参梯度 tensor([-0.4497])\n",
						"第 3025 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1288]])\n",
						"模型中偏参梯度 tensor([-0.4495])\n",
						"第 3026 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1288]])\n",
						"模型中偏参梯度 tensor([-0.4493])\n",
						"第 3027 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1287]])\n",
						"模型中偏参梯度 tensor([-0.4491])\n",
						"第 3028 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1287]])\n",
						"模型中偏参梯度 tensor([-0.4490])\n",
						"第 3029 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1286]])\n",
						"模型中偏参梯度 tensor([-0.4488])\n",
						"第 3030 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1286]])\n",
						"模型中偏参梯度 tensor([-0.4486])\n",
						"第 3031 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1286]])\n",
						"模型中偏参梯度 tensor([-0.4484])\n",
						"第 3032 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1285]])\n",
						"模型中偏参梯度 tensor([-0.4482])\n",
						"第 3033 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1285]])\n",
						"模型中偏参梯度 tensor([-0.4480])\n",
						"第 3034 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1285]])\n",
						"模型中偏参梯度 tensor([-0.4479])\n",
						"第 3035 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1284]])\n",
						"模型中偏参梯度 tensor([-0.4477])\n",
						"第 3036 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1284]])\n",
						"模型中偏参梯度 tensor([-0.4475])\n",
						"第 3037 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1283]])\n",
						"模型中偏参梯度 tensor([-0.4473])\n",
						"第 3038 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1283]])\n",
						"模型中偏参梯度 tensor([-0.4471])\n",
						"第 3039 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1282]])\n",
						"模型中偏参梯度 tensor([-0.4469])\n",
						"第 3040 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1282]])\n",
						"模型中偏参梯度 tensor([-0.4468])\n",
						"第 152 次epoch\n",
						"第 3041 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1281]])\n",
						"模型中偏参梯度 tensor([-0.4466])\n",
						"第 3042 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1281]])\n",
						"模型中偏参梯度 tensor([-0.4464])\n",
						"第 3043 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1280]])\n",
						"模型中偏参梯度 tensor([-0.4462])\n",
						"第 3044 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1280]])\n",
						"模型中偏参梯度 tensor([-0.4460])\n",
						"第 3045 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1280]])\n",
						"模型中偏参梯度 tensor([-0.4459])\n",
						"第 3046 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1279]])\n",
						"模型中偏参梯度 tensor([-0.4457])\n",
						"第 3047 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1278]])\n",
						"模型中偏参梯度 tensor([-0.4455])\n",
						"第 3048 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1278]])\n",
						"模型中偏参梯度 tensor([-0.4453])\n",
						"第 3049 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1277]])\n",
						"模型中偏参梯度 tensor([-0.4451])\n",
						"第 3050 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1277]])\n",
						"模型中偏参梯度 tensor([-0.4450])\n",
						"第 3051 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1276]])\n",
						"模型中偏参梯度 tensor([-0.4448])\n",
						"第 3052 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1276]])\n",
						"模型中偏参梯度 tensor([-0.4446])\n",
						"第 3053 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1275]])\n",
						"模型中偏参梯度 tensor([-0.4444])\n",
						"第 3054 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1274]])\n",
						"模型中偏参梯度 tensor([-0.4443])\n",
						"第 3055 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1274]])\n",
						"模型中偏参梯度 tensor([-0.4441])\n",
						"第 3056 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1273]])\n",
						"模型中偏参梯度 tensor([-0.4439])\n",
						"第 3057 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1273]])\n",
						"模型中偏参梯度 tensor([-0.4437])\n",
						"第 3058 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1272]])\n",
						"模型中偏参梯度 tensor([-0.4436])\n",
						"第 3059 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1271]])\n",
						"模型中偏参梯度 tensor([-0.4434])\n",
						"第 3060 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1271]])\n",
						"模型中偏参梯度 tensor([-0.4432])\n",
						"第 153 次epoch\n",
						"第 3061 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1270]])\n",
						"模型中偏参梯度 tensor([-0.4430])\n",
						"第 3062 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1269]])\n",
						"模型中偏参梯度 tensor([-0.4429])\n",
						"第 3063 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1269]])\n",
						"模型中偏参梯度 tensor([-0.4427])\n",
						"第 3064 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1268]])\n",
						"模型中偏参梯度 tensor([-0.4425])\n",
						"第 3065 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1268]])\n",
						"模型中偏参梯度 tensor([-0.4423])\n",
						"第 3066 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1267]])\n",
						"模型中偏参梯度 tensor([-0.4421])\n",
						"第 3067 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1267]])\n",
						"模型中偏参梯度 tensor([-0.4420])\n",
						"第 3068 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1267]])\n",
						"模型中偏参梯度 tensor([-0.4418])\n",
						"第 3069 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1266]])\n",
						"模型中偏参梯度 tensor([-0.4416])\n",
						"第 3070 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1266]])\n",
						"模型中偏参梯度 tensor([-0.4414])\n",
						"第 3071 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1265]])\n",
						"模型中偏参梯度 tensor([-0.4412])\n",
						"第 3072 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1265]])\n",
						"模型中偏参梯度 tensor([-0.4411])\n",
						"第 3073 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1265]])\n",
						"模型中偏参梯度 tensor([-0.4409])\n",
						"第 3074 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1264]])\n",
						"模型中偏参梯度 tensor([-0.4407])\n",
						"第 3075 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1264]])\n",
						"模型中偏参梯度 tensor([-0.4405])\n",
						"第 3076 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1263]])\n",
						"模型中偏参梯度 tensor([-0.4403])\n",
						"第 3077 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1263]])\n",
						"模型中偏参梯度 tensor([-0.4402])\n",
						"第 3078 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1262]])\n",
						"模型中偏参梯度 tensor([-0.4400])\n",
						"第 3079 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1262]])\n",
						"模型中偏参梯度 tensor([-0.4398])\n",
						"第 3080 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1262]])\n",
						"模型中偏参梯度 tensor([-0.4396])\n",
						"第 154 次epoch\n",
						"第 3081 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1261]])\n",
						"模型中偏参梯度 tensor([-0.4394])\n",
						"第 3082 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1260]])\n",
						"模型中偏参梯度 tensor([-0.4393])\n",
						"第 3083 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1260]])\n",
						"模型中偏参梯度 tensor([-0.4391])\n",
						"第 3084 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1259]])\n",
						"模型中偏参梯度 tensor([-0.4389])\n",
						"第 3085 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1259]])\n",
						"模型中偏参梯度 tensor([-0.4387])\n",
						"第 3086 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1258]])\n",
						"模型中偏参梯度 tensor([-0.4386])\n",
						"第 3087 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1258]])\n",
						"模型中偏参梯度 tensor([-0.4384])\n",
						"第 3088 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1257]])\n",
						"模型中偏参梯度 tensor([-0.4382])\n",
						"第 3089 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1257]])\n",
						"模型中偏参梯度 tensor([-0.4380])\n",
						"第 3090 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1256]])\n",
						"模型中偏参梯度 tensor([-0.4379])\n",
						"第 3091 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1256]])\n",
						"模型中偏参梯度 tensor([-0.4377])\n",
						"第 3092 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1255]])\n",
						"模型中偏参梯度 tensor([-0.4375])\n",
						"第 3093 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1254]])\n",
						"模型中偏参梯度 tensor([-0.4373])\n",
						"第 3094 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1254]])\n",
						"模型中偏参梯度 tensor([-0.4372])\n",
						"第 3095 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1253]])\n",
						"模型中偏参梯度 tensor([-0.4370])\n",
						"第 3096 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1253]])\n",
						"模型中偏参梯度 tensor([-0.4368])\n",
						"第 3097 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1252]])\n",
						"模型中偏参梯度 tensor([-0.4367])\n",
						"第 3098 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1251]])\n",
						"模型中偏参梯度 tensor([-0.4365])\n",
						"第 3099 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1251]])\n",
						"模型中偏参梯度 tensor([-0.4363])\n",
						"第 3100 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1250]])\n",
						"模型中偏参梯度 tensor([-0.4361])\n",
						"第 155 次epoch\n",
						"第 3101 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1249]])\n",
						"模型中偏参梯度 tensor([-0.4360])\n",
						"第 3102 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1249]])\n",
						"模型中偏参梯度 tensor([-0.4358])\n",
						"第 3103 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1249]])\n",
						"模型中偏参梯度 tensor([-0.4356])\n",
						"第 3104 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1248]])\n",
						"模型中偏参梯度 tensor([-0.4354])\n",
						"第 3105 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1248]])\n",
						"模型中偏参梯度 tensor([-0.4352])\n",
						"第 3106 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1248]])\n",
						"模型中偏参梯度 tensor([-0.4351])\n",
						"第 3107 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1247]])\n",
						"模型中偏参梯度 tensor([-0.4349])\n",
						"第 3108 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1247]])\n",
						"模型中偏参梯度 tensor([-0.4347])\n",
						"第 3109 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1246]])\n",
						"模型中偏参梯度 tensor([-0.4345])\n",
						"第 3110 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1246]])\n",
						"模型中偏参梯度 tensor([-0.4344])\n",
						"第 3111 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1246]])\n",
						"模型中偏参梯度 tensor([-0.4342])\n",
						"第 3112 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1245]])\n",
						"模型中偏参梯度 tensor([-0.4340])\n",
						"第 3113 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1245]])\n",
						"模型中偏参梯度 tensor([-0.4338])\n",
						"第 3114 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1244]])\n",
						"模型中偏参梯度 tensor([-0.4336])\n",
						"第 3115 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1244]])\n",
						"模型中偏参梯度 tensor([-0.4335])\n",
						"第 3116 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1243]])\n",
						"模型中偏参梯度 tensor([-0.4333])\n",
						"第 3117 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1243]])\n",
						"模型中偏参梯度 tensor([-0.4331])\n",
						"第 3118 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1243]])\n",
						"模型中偏参梯度 tensor([-0.4329])\n",
						"第 3119 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1242]])\n",
						"模型中偏参梯度 tensor([-0.4328])\n",
						"第 3120 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1242]])\n",
						"模型中偏参梯度 tensor([-0.4326])\n",
						"第 156 次epoch\n",
						"第 3121 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1241]])\n",
						"模型中偏参梯度 tensor([-0.4324])\n",
						"第 3122 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1241]])\n",
						"模型中偏参梯度 tensor([-0.4323])\n",
						"第 3123 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1240]])\n",
						"模型中偏参梯度 tensor([-0.4321])\n",
						"第 3124 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1240]])\n",
						"模型中偏参梯度 tensor([-0.4319])\n",
						"第 3125 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1239]])\n",
						"模型中偏参梯度 tensor([-0.4317])\n",
						"第 3126 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1238]])\n",
						"模型中偏参梯度 tensor([-0.4316])\n",
						"第 3127 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1238]])\n",
						"模型中偏参梯度 tensor([-0.4314])\n",
						"第 3128 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1237]])\n",
						"模型中偏参梯度 tensor([-0.4312])\n",
						"第 3129 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1237]])\n",
						"模型中偏参梯度 tensor([-0.4310])\n",
						"第 3130 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1236]])\n",
						"模型中偏参梯度 tensor([-0.4309])\n",
						"第 3131 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1236]])\n",
						"模型中偏参梯度 tensor([-0.4307])\n",
						"第 3132 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1235]])\n",
						"模型中偏参梯度 tensor([-0.4305])\n",
						"第 3133 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1234]])\n",
						"模型中偏参梯度 tensor([-0.4304])\n",
						"第 3134 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1234]])\n",
						"模型中偏参梯度 tensor([-0.4302])\n",
						"第 3135 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1233]])\n",
						"模型中偏参梯度 tensor([-0.4300])\n",
						"第 3136 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1232]])\n",
						"模型中偏参梯度 tensor([-0.4299])\n",
						"第 3137 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1232]])\n",
						"模型中偏参梯度 tensor([-0.4297])\n",
						"第 3138 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1231]])\n",
						"模型中偏参梯度 tensor([-0.4295])\n",
						"第 3139 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1230]])\n",
						"模型中偏参梯度 tensor([-0.4294])\n",
						"第 3140 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1230]])\n",
						"模型中偏参梯度 tensor([-0.4292])\n",
						"第 157 次epoch\n",
						"第 3141 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1229]])\n",
						"模型中偏参梯度 tensor([-0.4290])\n",
						"第 3142 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1229]])\n",
						"模型中偏参梯度 tensor([-0.4288])\n",
						"第 3143 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1229]])\n",
						"模型中偏参梯度 tensor([-0.4287])\n",
						"第 3144 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1228]])\n",
						"模型中偏参梯度 tensor([-0.4285])\n",
						"第 3145 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1228]])\n",
						"模型中偏参梯度 tensor([-0.4283])\n",
						"第 3146 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1228]])\n",
						"模型中偏参梯度 tensor([-0.4281])\n",
						"第 3147 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1227]])\n",
						"模型中偏参梯度 tensor([-0.4279])\n",
						"第 3148 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1227]])\n",
						"模型中偏参梯度 tensor([-0.4278])\n",
						"第 3149 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1227]])\n",
						"模型中偏参梯度 tensor([-0.4276])\n",
						"第 3150 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1226]])\n",
						"模型中偏参梯度 tensor([-0.4274])\n",
						"第 3151 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1226]])\n",
						"模型中偏参梯度 tensor([-0.4272])\n",
						"第 3152 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1225]])\n",
						"模型中偏参梯度 tensor([-0.4271])\n",
						"第 3153 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1225]])\n",
						"模型中偏参梯度 tensor([-0.4269])\n",
						"第 3154 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1224]])\n",
						"模型中偏参梯度 tensor([-0.4267])\n",
						"第 3155 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1224]])\n",
						"模型中偏参梯度 tensor([-0.4266])\n",
						"第 3156 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1224]])\n",
						"模型中偏参梯度 tensor([-0.4264])\n",
						"第 3157 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1223]])\n",
						"模型中偏参梯度 tensor([-0.4262])\n",
						"第 3158 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1223]])\n",
						"模型中偏参梯度 tensor([-0.4260])\n",
						"第 3159 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1222]])\n",
						"模型中偏参梯度 tensor([-0.4259])\n",
						"第 3160 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1222]])\n",
						"模型中偏参梯度 tensor([-0.4257])\n",
						"第 158 次epoch\n",
						"第 3161 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1221]])\n",
						"模型中偏参梯度 tensor([-0.4255])\n",
						"第 3162 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1221]])\n",
						"模型中偏参梯度 tensor([-0.4254])\n",
						"第 3163 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1220]])\n",
						"模型中偏参梯度 tensor([-0.4252])\n",
						"第 3164 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1220]])\n",
						"模型中偏参梯度 tensor([-0.4250])\n",
						"第 3165 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1219]])\n",
						"模型中偏参梯度 tensor([-0.4248])\n",
						"第 3166 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1219]])\n",
						"模型中偏参梯度 tensor([-0.4247])\n",
						"第 3167 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1218]])\n",
						"模型中偏参梯度 tensor([-0.4245])\n",
						"第 3168 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1217]])\n",
						"模型中偏参梯度 tensor([-0.4243])\n",
						"第 3169 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1217]])\n",
						"模型中偏参梯度 tensor([-0.4242])\n",
						"第 3170 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1216]])\n",
						"模型中偏参梯度 tensor([-0.4240])\n",
						"第 3171 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1216]])\n",
						"模型中偏参梯度 tensor([-0.4238])\n",
						"第 3172 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1215]])\n",
						"模型中偏参梯度 tensor([-0.4237])\n",
						"第 3173 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1214]])\n",
						"模型中偏参梯度 tensor([-0.4235])\n",
						"第 3174 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1214]])\n",
						"模型中偏参梯度 tensor([-0.4233])\n",
						"第 3175 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1213]])\n",
						"模型中偏参梯度 tensor([-0.4232])\n",
						"第 3176 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1212]])\n",
						"模型中偏参梯度 tensor([-0.4230])\n",
						"第 3177 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1212]])\n",
						"模型中偏参梯度 tensor([-0.4228])\n",
						"第 3178 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1211]])\n",
						"模型中偏参梯度 tensor([-0.4227])\n",
						"第 3179 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1211]])\n",
						"模型中偏参梯度 tensor([-0.4225])\n",
						"第 3180 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1210]])\n",
						"模型中偏参梯度 tensor([-0.4223])\n",
						"第 159 次epoch\n",
						"第 3181 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1210]])\n",
						"模型中偏参梯度 tensor([-0.4221])\n",
						"第 3182 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1210]])\n",
						"模型中偏参梯度 tensor([-0.4220])\n",
						"第 3183 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1210]])\n",
						"模型中偏参梯度 tensor([-0.4218])\n",
						"第 3184 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1209]])\n",
						"模型中偏参梯度 tensor([-0.4216])\n",
						"第 3185 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1209]])\n",
						"模型中偏参梯度 tensor([-0.4214])\n",
						"第 3186 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1208]])\n",
						"模型中偏参梯度 tensor([-0.4213])\n",
						"第 3187 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1208]])\n",
						"模型中偏参梯度 tensor([-0.4211])\n",
						"第 3188 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1208]])\n",
						"模型中偏参梯度 tensor([-0.4209])\n",
						"第 3189 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1207]])\n",
						"模型中偏参梯度 tensor([-0.4208])\n",
						"第 3190 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1207]])\n",
						"模型中偏参梯度 tensor([-0.4206])\n",
						"第 3191 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1206]])\n",
						"模型中偏参梯度 tensor([-0.4204])\n",
						"第 3192 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1206]])\n",
						"模型中偏参梯度 tensor([-0.4202])\n",
						"第 3193 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1206]])\n",
						"模型中偏参梯度 tensor([-0.4201])\n",
						"第 3194 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1205]])\n",
						"模型中偏参梯度 tensor([-0.4199])\n",
						"第 3195 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1205]])\n",
						"模型中偏参梯度 tensor([-0.4197])\n",
						"第 3196 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1204]])\n",
						"模型中偏参梯度 tensor([-0.4196])\n",
						"第 3197 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1204]])\n",
						"模型中偏参梯度 tensor([-0.4194])\n",
						"第 3198 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1203]])\n",
						"模型中偏参梯度 tensor([-0.4192])\n",
						"第 3199 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1203]])\n",
						"模型中偏参梯度 tensor([-0.4191])\n",
						"第 3200 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1202]])\n",
						"模型中偏参梯度 tensor([-0.4189])\n",
						"第 160 次epoch\n",
						"第 3201 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1202]])\n",
						"模型中偏参梯度 tensor([-0.4187])\n",
						"第 3202 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1201]])\n",
						"模型中偏参梯度 tensor([-0.4186])\n",
						"第 3203 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1201]])\n",
						"模型中偏参梯度 tensor([-0.4184])\n",
						"第 3204 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1200]])\n",
						"模型中偏参梯度 tensor([-0.4182])\n",
						"第 3205 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1200]])\n",
						"模型中偏参梯度 tensor([-0.4181])\n",
						"第 3206 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1199]])\n",
						"模型中偏参梯度 tensor([-0.4179])\n",
						"第 3207 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1199]])\n",
						"模型中偏参梯度 tensor([-0.4177])\n",
						"第 3208 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1198]])\n",
						"模型中偏参梯度 tensor([-0.4176])\n",
						"第 3209 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1197]])\n",
						"模型中偏参梯度 tensor([-0.4174])\n",
						"第 3210 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1197]])\n",
						"模型中偏参梯度 tensor([-0.4172])\n",
						"第 3211 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1196]])\n",
						"模型中偏参梯度 tensor([-0.4171])\n",
						"第 3212 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1196]])\n",
						"模型中偏参梯度 tensor([-0.4169])\n",
						"第 3213 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1195]])\n",
						"模型中偏参梯度 tensor([-0.4167])\n",
						"第 3214 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1194]])\n",
						"模型中偏参梯度 tensor([-0.4166])\n",
						"第 3215 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1194]])\n",
						"模型中偏参梯度 tensor([-0.4164])\n",
						"第 3216 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1193]])\n",
						"模型中偏参梯度 tensor([-0.4162])\n",
						"第 3217 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1193]])\n",
						"模型中偏参梯度 tensor([-0.4161])\n",
						"第 3218 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1192]])\n",
						"模型中偏参梯度 tensor([-0.4159])\n",
						"第 3219 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1192]])\n",
						"模型中偏参梯度 tensor([-0.4157])\n",
						"第 3220 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1191]])\n",
						"模型中偏参梯度 tensor([-0.4156])\n",
						"第 161 次epoch\n",
						"第 3221 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1191]])\n",
						"模型中偏参梯度 tensor([-0.4154])\n",
						"第 3222 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1191]])\n",
						"模型中偏参梯度 tensor([-0.4152])\n",
						"第 3223 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1190]])\n",
						"模型中偏参梯度 tensor([-0.4151])\n",
						"第 3224 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1190]])\n",
						"模型中偏参梯度 tensor([-0.4149])\n",
						"第 3225 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1190]])\n",
						"模型中偏参梯度 tensor([-0.4147])\n",
						"第 3226 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1189]])\n",
						"模型中偏参梯度 tensor([-0.4145])\n",
						"第 3227 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1189]])\n",
						"模型中偏参梯度 tensor([-0.4144])\n",
						"第 3228 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1188]])\n",
						"模型中偏参梯度 tensor([-0.4142])\n",
						"第 3229 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1188]])\n",
						"模型中偏参梯度 tensor([-0.4140])\n",
						"第 3230 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1188]])\n",
						"模型中偏参梯度 tensor([-0.4139])\n",
						"第 3231 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1187]])\n",
						"模型中偏参梯度 tensor([-0.4137])\n",
						"第 3232 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1187]])\n",
						"模型中偏参梯度 tensor([-0.4135])\n",
						"第 3233 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1186]])\n",
						"模型中偏参梯度 tensor([-0.4134])\n",
						"第 3234 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1186]])\n",
						"模型中偏参梯度 tensor([-0.4132])\n",
						"第 3235 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1186]])\n",
						"模型中偏参梯度 tensor([-0.4130])\n",
						"第 3236 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1185]])\n",
						"模型中偏参梯度 tensor([-0.4129])\n",
						"第 3237 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1185]])\n",
						"模型中偏参梯度 tensor([-0.4127])\n",
						"第 3238 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1184]])\n",
						"模型中偏参梯度 tensor([-0.4125])\n",
						"第 3239 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1184]])\n",
						"模型中偏参梯度 tensor([-0.4124])\n",
						"第 3240 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1183]])\n",
						"模型中偏参梯度 tensor([-0.4122])\n",
						"第 162 次epoch\n",
						"第 3241 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1183]])\n",
						"模型中偏参梯度 tensor([-0.4120])\n",
						"第 3242 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1182]])\n",
						"模型中偏参梯度 tensor([-0.4119])\n",
						"第 3243 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1182]])\n",
						"模型中偏参梯度 tensor([-0.4117])\n",
						"第 3244 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1181]])\n",
						"模型中偏参梯度 tensor([-0.4115])\n",
						"第 3245 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1181]])\n",
						"模型中偏参梯度 tensor([-0.4114])\n",
						"第 3246 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1180]])\n",
						"模型中偏参梯度 tensor([-0.4112])\n",
						"第 3247 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1180]])\n",
						"模型中偏参梯度 tensor([-0.4111])\n",
						"第 3248 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1179]])\n",
						"模型中偏参梯度 tensor([-0.4109])\n",
						"第 3249 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1178]])\n",
						"模型中偏参梯度 tensor([-0.4107])\n",
						"第 3250 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1178]])\n",
						"模型中偏参梯度 tensor([-0.4106])\n",
						"第 3251 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1177]])\n",
						"模型中偏参梯度 tensor([-0.4104])\n",
						"第 3252 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1177]])\n",
						"模型中偏参梯度 tensor([-0.4102])\n",
						"第 3253 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1176]])\n",
						"模型中偏参梯度 tensor([-0.4101])\n",
						"第 3254 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1175]])\n",
						"模型中偏参梯度 tensor([-0.4099])\n",
						"第 3255 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1175]])\n",
						"模型中偏参梯度 tensor([-0.4098])\n",
						"第 3256 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1174]])\n",
						"模型中偏参梯度 tensor([-0.4096])\n",
						"第 3257 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1173]])\n",
						"模型中偏参梯度 tensor([-0.4094])\n",
						"第 3258 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1173]])\n",
						"模型中偏参梯度 tensor([-0.4093])\n",
						"第 3259 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1172]])\n",
						"模型中偏参梯度 tensor([-0.4091])\n",
						"第 3260 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1172]])\n",
						"模型中偏参梯度 tensor([-0.4089])\n",
						"第 163 次epoch\n",
						"第 3261 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1172]])\n",
						"模型中偏参梯度 tensor([-0.4088])\n",
						"第 3262 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1172]])\n",
						"模型中偏参梯度 tensor([-0.4086])\n",
						"第 3263 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1171]])\n",
						"模型中偏参梯度 tensor([-0.4084])\n",
						"第 3264 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1171]])\n",
						"模型中偏参梯度 tensor([-0.4083])\n",
						"第 3265 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1171]])\n",
						"模型中偏参梯度 tensor([-0.4081])\n",
						"第 3266 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1170]])\n",
						"模型中偏参梯度 tensor([-0.4079])\n",
						"第 3267 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1170]])\n",
						"模型中偏参梯度 tensor([-0.4078])\n",
						"第 3268 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1169]])\n",
						"模型中偏参梯度 tensor([-0.4076])\n",
						"第 3269 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1169]])\n",
						"模型中偏参梯度 tensor([-0.4074])\n",
						"第 3270 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1169]])\n",
						"模型中偏参梯度 tensor([-0.4073])\n",
						"第 3271 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1168]])\n",
						"模型中偏参梯度 tensor([-0.4071])\n",
						"第 3272 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1168]])\n",
						"模型中偏参梯度 tensor([-0.4069])\n",
						"第 3273 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1167]])\n",
						"模型中偏参梯度 tensor([-0.4068])\n",
						"第 3274 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1167]])\n",
						"模型中偏参梯度 tensor([-0.4066])\n",
						"第 3275 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1167]])\n",
						"模型中偏参梯度 tensor([-0.4064])\n",
						"第 3276 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1166]])\n",
						"模型中偏参梯度 tensor([-0.4063])\n",
						"第 3277 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1166]])\n",
						"模型中偏参梯度 tensor([-0.4061])\n",
						"第 3278 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1165]])\n",
						"模型中偏参梯度 tensor([-0.4059])\n",
						"第 3279 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1165]])\n",
						"模型中偏参梯度 tensor([-0.4058])\n",
						"第 3280 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1164]])\n",
						"模型中偏参梯度 tensor([-0.4056])\n",
						"第 164 次epoch\n",
						"第 3281 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1164]])\n",
						"模型中偏参梯度 tensor([-0.4055])\n",
						"第 3282 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1163]])\n",
						"模型中偏参梯度 tensor([-0.4053])\n",
						"第 3283 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1163]])\n",
						"模型中偏参梯度 tensor([-0.4051])\n",
						"第 3284 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1162]])\n",
						"模型中偏参梯度 tensor([-0.4050])\n",
						"第 3285 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1162]])\n",
						"模型中偏参梯度 tensor([-0.4048])\n",
						"第 3286 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1161]])\n",
						"模型中偏参梯度 tensor([-0.4046])\n",
						"第 3287 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1161]])\n",
						"模型中偏参梯度 tensor([-0.4045])\n",
						"第 3288 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1160]])\n",
						"模型中偏参梯度 tensor([-0.4043])\n",
						"第 3289 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1160]])\n",
						"模型中偏参梯度 tensor([-0.4042])\n",
						"第 3290 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1159]])\n",
						"模型中偏参梯度 tensor([-0.4040])\n",
						"第 3291 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1158]])\n",
						"模型中偏参梯度 tensor([-0.4038])\n",
						"第 3292 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1158]])\n",
						"模型中偏参梯度 tensor([-0.4037])\n",
						"第 3293 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1157]])\n",
						"模型中偏参梯度 tensor([-0.4035])\n",
						"第 3294 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1157]])\n",
						"模型中偏参梯度 tensor([-0.4034])\n",
						"第 3295 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1156]])\n",
						"模型中偏参梯度 tensor([-0.4032])\n",
						"第 3296 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1155]])\n",
						"模型中偏参梯度 tensor([-0.4031])\n",
						"第 3297 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1155]])\n",
						"模型中偏参梯度 tensor([-0.4029])\n",
						"第 3298 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1154]])\n",
						"模型中偏参梯度 tensor([-0.4027])\n",
						"第 3299 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1153]])\n",
						"模型中偏参梯度 tensor([-0.4026])\n",
						"第 3300 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1153]])\n",
						"模型中偏参梯度 tensor([-0.4024])\n",
						"第 165 次epoch\n",
						"第 3301 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1153]])\n",
						"模型中偏参梯度 tensor([-0.4023])\n",
						"第 3302 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1153]])\n",
						"模型中偏参梯度 tensor([-0.4021])\n",
						"第 3303 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1152]])\n",
						"模型中偏参梯度 tensor([-0.4019])\n",
						"第 3304 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1152]])\n",
						"模型中偏参梯度 tensor([-0.4018])\n",
						"第 3305 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1152]])\n",
						"模型中偏参梯度 tensor([-0.4016])\n",
						"第 3306 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1151]])\n",
						"模型中偏参梯度 tensor([-0.4014])\n",
						"第 3307 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1151]])\n",
						"模型中偏参梯度 tensor([-0.4013])\n",
						"第 3308 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1151]])\n",
						"模型中偏参梯度 tensor([-0.4011])\n",
						"第 3309 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1150]])\n",
						"模型中偏参梯度 tensor([-0.4009])\n",
						"第 3310 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1150]])\n",
						"模型中偏参梯度 tensor([-0.4008])\n",
						"第 3311 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1150]])\n",
						"模型中偏参梯度 tensor([-0.4006])\n",
						"第 3312 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1149]])\n",
						"模型中偏参梯度 tensor([-0.4004])\n",
						"第 3313 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1149]])\n",
						"模型中偏参梯度 tensor([-0.4003])\n",
						"第 3314 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1148]])\n",
						"模型中偏参梯度 tensor([-0.4001])\n",
						"第 3315 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1148]])\n",
						"模型中偏参梯度 tensor([-0.3999])\n",
						"第 3316 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1147]])\n",
						"模型中偏参梯度 tensor([-0.3998])\n",
						"第 3317 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1147]])\n",
						"模型中偏参梯度 tensor([-0.3996])\n",
						"第 3318 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1147]])\n",
						"模型中偏参梯度 tensor([-0.3995])\n",
						"第 3319 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1146]])\n",
						"模型中偏参梯度 tensor([-0.3993])\n",
						"第 3320 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1146]])\n",
						"模型中偏参梯度 tensor([-0.3991])\n",
						"第 166 次epoch\n",
						"第 3321 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1145]])\n",
						"模型中偏参梯度 tensor([-0.3990])\n",
						"第 3322 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1145]])\n",
						"模型中偏参梯度 tensor([-0.3988])\n",
						"第 3323 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1144]])\n",
						"模型中偏参梯度 tensor([-0.3987])\n",
						"第 3324 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1144]])\n",
						"模型中偏参梯度 tensor([-0.3985])\n",
						"第 3325 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1143]])\n",
						"模型中偏参梯度 tensor([-0.3983])\n",
						"第 3326 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1143]])\n",
						"模型中偏参梯度 tensor([-0.3982])\n",
						"第 3327 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1142]])\n",
						"模型中偏参梯度 tensor([-0.3980])\n",
						"第 3328 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1142]])\n",
						"模型中偏参梯度 tensor([-0.3979])\n",
						"第 3329 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1141]])\n",
						"模型中偏参梯度 tensor([-0.3977])\n",
						"第 3330 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1141]])\n",
						"模型中偏参梯度 tensor([-0.3976])\n",
						"第 3331 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1140]])\n",
						"模型中偏参梯度 tensor([-0.3974])\n",
						"第 3332 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1139]])\n",
						"模型中偏参梯度 tensor([-0.3972])\n",
						"第 3333 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1139]])\n",
						"模型中偏参梯度 tensor([-0.3971])\n",
						"第 3334 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1138]])\n",
						"模型中偏参梯度 tensor([-0.3969])\n",
						"第 3335 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1138]])\n",
						"模型中偏参梯度 tensor([-0.3968])\n",
						"第 3336 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1137]])\n",
						"模型中偏参梯度 tensor([-0.3966])\n",
						"第 3337 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1136]])\n",
						"模型中偏参梯度 tensor([-0.3965])\n",
						"第 3338 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1136]])\n",
						"模型中偏参梯度 tensor([-0.3963])\n",
						"第 3339 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1135]])\n",
						"模型中偏参梯度 tensor([-0.3962])\n",
						"第 3340 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1135]])\n",
						"模型中偏参梯度 tensor([-0.3960])\n",
						"第 167 次epoch\n",
						"第 3341 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1134]])\n",
						"模型中偏参梯度 tensor([-0.3958])\n",
						"第 3342 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1134]])\n",
						"模型中偏参梯度 tensor([-0.3957])\n",
						"第 3343 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1134]])\n",
						"模型中偏参梯度 tensor([-0.3955])\n",
						"第 3344 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1133]])\n",
						"模型中偏参梯度 tensor([-0.3953])\n",
						"第 3345 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1133]])\n",
						"模型中偏参梯度 tensor([-0.3952])\n",
						"第 3346 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1133]])\n",
						"模型中偏参梯度 tensor([-0.3950])\n",
						"第 3347 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1132]])\n",
						"模型中偏参梯度 tensor([-0.3949])\n",
						"第 3348 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1132]])\n",
						"模型中偏参梯度 tensor([-0.3947])\n",
						"第 3349 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1132]])\n",
						"模型中偏参梯度 tensor([-0.3945])\n",
						"第 3350 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1131]])\n",
						"模型中偏参梯度 tensor([-0.3944])\n",
						"第 3351 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1131]])\n",
						"模型中偏参梯度 tensor([-0.3942])\n",
						"第 3352 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1131]])\n",
						"模型中偏参梯度 tensor([-0.3940])\n",
						"第 3353 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1130]])\n",
						"模型中偏参梯度 tensor([-0.3939])\n",
						"第 3354 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1130]])\n",
						"模型中偏参梯度 tensor([-0.3937])\n",
						"第 3355 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1130]])\n",
						"模型中偏参梯度 tensor([-0.3936])\n",
						"第 3356 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1129]])\n",
						"模型中偏参梯度 tensor([-0.3934])\n",
						"第 3357 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1129]])\n",
						"模型中偏参梯度 tensor([-0.3932])\n",
						"第 3358 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1128]])\n",
						"模型中偏参梯度 tensor([-0.3931])\n",
						"第 3359 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1128]])\n",
						"模型中偏参梯度 tensor([-0.3929])\n",
						"第 3360 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1127]])\n",
						"模型中偏参梯度 tensor([-0.3928])\n",
						"第 168 次epoch\n",
						"第 3361 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1127]])\n",
						"模型中偏参梯度 tensor([-0.3926])\n",
						"第 3362 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1127]])\n",
						"模型中偏参梯度 tensor([-0.3925])\n",
						"第 3363 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1126]])\n",
						"模型中偏参梯度 tensor([-0.3923])\n",
						"第 3364 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1126]])\n",
						"模型中偏参梯度 tensor([-0.3921])\n",
						"第 3365 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1125]])\n",
						"模型中偏参梯度 tensor([-0.3920])\n",
						"第 3366 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1125]])\n",
						"模型中偏参梯度 tensor([-0.3918])\n",
						"第 3367 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1124]])\n",
						"模型中偏参梯度 tensor([-0.3917])\n",
						"第 3368 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1124]])\n",
						"模型中偏参梯度 tensor([-0.3915])\n",
						"第 3369 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1123]])\n",
						"模型中偏参梯度 tensor([-0.3914])\n",
						"第 3370 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1123]])\n",
						"模型中偏参梯度 tensor([-0.3912])\n",
						"第 3371 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1122]])\n",
						"模型中偏参梯度 tensor([-0.3910])\n",
						"第 3372 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1121]])\n",
						"模型中偏参梯度 tensor([-0.3909])\n",
						"第 3373 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1121]])\n",
						"模型中偏参梯度 tensor([-0.3907])\n",
						"第 3374 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1120]])\n",
						"模型中偏参梯度 tensor([-0.3906])\n",
						"第 3375 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1120]])\n",
						"模型中偏参梯度 tensor([-0.3904])\n",
						"第 3376 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1119]])\n",
						"模型中偏参梯度 tensor([-0.3903])\n",
						"第 3377 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1119]])\n",
						"模型中偏参梯度 tensor([-0.3901])\n",
						"第 3378 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1118]])\n",
						"模型中偏参梯度 tensor([-0.3900])\n",
						"第 3379 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1117]])\n",
						"模型中偏参梯度 tensor([-0.3898])\n",
						"第 3380 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1117]])\n",
						"模型中偏参梯度 tensor([-0.3897])\n",
						"第 169 次epoch\n",
						"第 3381 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1116]])\n",
						"模型中偏参梯度 tensor([-0.3895])\n",
						"第 3382 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1116]])\n",
						"模型中偏参梯度 tensor([-0.3894])\n",
						"第 3383 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1115]])\n",
						"模型中偏参梯度 tensor([-0.3892])\n",
						"第 3384 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1115]])\n",
						"模型中偏参梯度 tensor([-0.3890])\n",
						"第 3385 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1115]])\n",
						"模型中偏参梯度 tensor([-0.3889])\n",
						"第 3386 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1114]])\n",
						"模型中偏参梯度 tensor([-0.3887])\n",
						"第 3387 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1114]])\n",
						"模型中偏参梯度 tensor([-0.3886])\n",
						"第 3388 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1114]])\n",
						"模型中偏参梯度 tensor([-0.3884])\n",
						"第 3389 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1114]])\n",
						"模型中偏参梯度 tensor([-0.3882])\n",
						"第 3390 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1113]])\n",
						"模型中偏参梯度 tensor([-0.3881])\n",
						"第 3391 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1113]])\n",
						"模型中偏参梯度 tensor([-0.3879])\n",
						"第 3392 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1113]])\n",
						"模型中偏参梯度 tensor([-0.3878])\n",
						"第 3393 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1112]])\n",
						"模型中偏参梯度 tensor([-0.3876])\n",
						"第 3394 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1112]])\n",
						"模型中偏参梯度 tensor([-0.3874])\n",
						"第 3395 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1111]])\n",
						"模型中偏参梯度 tensor([-0.3873])\n",
						"第 3396 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1111]])\n",
						"模型中偏参梯度 tensor([-0.3871])\n",
						"第 3397 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1111]])\n",
						"模型中偏参梯度 tensor([-0.3870])\n",
						"第 3398 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1110]])\n",
						"模型中偏参梯度 tensor([-0.3868])\n",
						"第 3399 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1110]])\n",
						"模型中偏参梯度 tensor([-0.3867])\n",
						"第 3400 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1110]])\n",
						"模型中偏参梯度 tensor([-0.3865])\n",
						"第 170 次epoch\n",
						"第 3401 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1109]])\n",
						"模型中偏参梯度 tensor([-0.3863])\n",
						"第 3402 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1109]])\n",
						"模型中偏参梯度 tensor([-0.3862])\n",
						"第 3403 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1108]])\n",
						"模型中偏参梯度 tensor([-0.3860])\n",
						"第 3404 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1108]])\n",
						"模型中偏参梯度 tensor([-0.3859])\n",
						"第 3405 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1107]])\n",
						"模型中偏参梯度 tensor([-0.3857])\n",
						"第 3406 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1107]])\n",
						"模型中偏参梯度 tensor([-0.3856])\n",
						"第 3407 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1106]])\n",
						"模型中偏参梯度 tensor([-0.3854])\n",
						"第 3408 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1106]])\n",
						"模型中偏参梯度 tensor([-0.3853])\n",
						"第 3409 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1105]])\n",
						"模型中偏参梯度 tensor([-0.3851])\n",
						"第 3410 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1105]])\n",
						"模型中偏参梯度 tensor([-0.3849])\n",
						"第 3411 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1104]])\n",
						"模型中偏参梯度 tensor([-0.3848])\n",
						"第 3412 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1104]])\n",
						"模型中偏参梯度 tensor([-0.3846])\n",
						"第 3413 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1103]])\n",
						"模型中偏参梯度 tensor([-0.3845])\n",
						"第 3414 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1103]])\n",
						"模型中偏参梯度 tensor([-0.3843])\n",
						"第 3415 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1102]])\n",
						"模型中偏参梯度 tensor([-0.3842])\n",
						"第 3416 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1102]])\n",
						"模型中偏参梯度 tensor([-0.3840])\n",
						"第 3417 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1101]])\n",
						"模型中偏参梯度 tensor([-0.3839])\n",
						"第 3418 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1101]])\n",
						"模型中偏参梯度 tensor([-0.3837])\n",
						"第 3419 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1100]])\n",
						"模型中偏参梯度 tensor([-0.3836])\n",
						"第 3420 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1100]])\n",
						"模型中偏参梯度 tensor([-0.3834])\n",
						"第 171 次epoch\n",
						"第 3421 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1099]])\n",
						"模型中偏参梯度 tensor([-0.3833])\n",
						"第 3422 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1098]])\n",
						"模型中偏参梯度 tensor([-0.3831])\n",
						"第 3423 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1098]])\n",
						"模型中偏参梯度 tensor([-0.3830])\n",
						"第 3424 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1097]])\n",
						"模型中偏参梯度 tensor([-0.3828])\n",
						"第 3425 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1097]])\n",
						"模型中偏参梯度 tensor([-0.3827])\n",
						"第 3426 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1096]])\n",
						"模型中偏参梯度 tensor([-0.3825])\n",
						"第 3427 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1096]])\n",
						"模型中偏参梯度 tensor([-0.3824])\n",
						"第 3428 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1096]])\n",
						"模型中偏参梯度 tensor([-0.3822])\n",
						"第 3429 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1095]])\n",
						"模型中偏参梯度 tensor([-0.3820])\n",
						"第 3430 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1095]])\n",
						"模型中偏参梯度 tensor([-0.3819])\n",
						"第 3431 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1095]])\n",
						"模型中偏参梯度 tensor([-0.3817])\n",
						"第 3432 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1095]])\n",
						"模型中偏参梯度 tensor([-0.3816])\n",
						"第 3433 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1094]])\n",
						"模型中偏参梯度 tensor([-0.3814])\n",
						"第 3434 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1094]])\n",
						"模型中偏参梯度 tensor([-0.3813])\n",
						"第 3435 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1094]])\n",
						"模型中偏参梯度 tensor([-0.3811])\n",
						"第 3436 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1093]])\n",
						"模型中偏参梯度 tensor([-0.3809])\n",
						"第 3437 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1093]])\n",
						"模型中偏参梯度 tensor([-0.3808])\n",
						"第 3438 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1093]])\n",
						"模型中偏参梯度 tensor([-0.3806])\n",
						"第 3439 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1092]])\n",
						"模型中偏参梯度 tensor([-0.3805])\n",
						"第 3440 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1092]])\n",
						"模型中偏参梯度 tensor([-0.3803])\n",
						"第 172 次epoch\n",
						"第 3441 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1091]])\n",
						"模型中偏参梯度 tensor([-0.3802])\n",
						"第 3442 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1091]])\n",
						"模型中偏参梯度 tensor([-0.3800])\n",
						"第 3443 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1091]])\n",
						"模型中偏参梯度 tensor([-0.3799])\n",
						"第 3444 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1090]])\n",
						"模型中偏参梯度 tensor([-0.3797])\n",
						"第 3445 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1090]])\n",
						"模型中偏参梯度 tensor([-0.3796])\n",
						"第 3446 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1089]])\n",
						"模型中偏参梯度 tensor([-0.3794])\n",
						"第 3447 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1089]])\n",
						"模型中偏参梯度 tensor([-0.3792])\n",
						"第 3448 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1089]])\n",
						"模型中偏参梯度 tensor([-0.3791])\n",
						"第 3449 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1088]])\n",
						"模型中偏参梯度 tensor([-0.3789])\n",
						"第 3450 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1088]])\n",
						"模型中偏参梯度 tensor([-0.3788])\n",
						"第 3451 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1087]])\n",
						"模型中偏参梯度 tensor([-0.3786])\n",
						"第 3452 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1087]])\n",
						"模型中偏参梯度 tensor([-0.3785])\n",
						"第 3453 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1086]])\n",
						"模型中偏参梯度 tensor([-0.3783])\n",
						"第 3454 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1086]])\n",
						"模型中偏参梯度 tensor([-0.3782])\n",
						"第 3455 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1085]])\n",
						"模型中偏参梯度 tensor([-0.3780])\n",
						"第 3456 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1085]])\n",
						"模型中偏参梯度 tensor([-0.3779])\n",
						"第 3457 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1084]])\n",
						"模型中偏参梯度 tensor([-0.3777])\n",
						"第 3458 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1084]])\n",
						"模型中偏参梯度 tensor([-0.3776])\n",
						"第 3459 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1083]])\n",
						"模型中偏参梯度 tensor([-0.3774])\n",
						"第 3460 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1083]])\n",
						"模型中偏参梯度 tensor([-0.3773])\n",
						"第 173 次epoch\n",
						"第 3461 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1082]])\n",
						"模型中偏参梯度 tensor([-0.3771])\n",
						"第 3462 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1081]])\n",
						"模型中偏参梯度 tensor([-0.3770])\n",
						"第 3463 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1081]])\n",
						"模型中偏参梯度 tensor([-0.3768])\n",
						"第 3464 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1080]])\n",
						"模型中偏参梯度 tensor([-0.3767])\n",
						"第 3465 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1080]])\n",
						"模型中偏参梯度 tensor([-0.3766])\n",
						"第 3466 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1079]])\n",
						"模型中偏参梯度 tensor([-0.3764])\n",
						"第 3467 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1078]])\n",
						"模型中偏参梯度 tensor([-0.3763])\n",
						"第 3468 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1078]])\n",
						"模型中偏参梯度 tensor([-0.3761])\n",
						"第 3469 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1077]])\n",
						"模型中偏参梯度 tensor([-0.3760])\n",
						"第 3470 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1077]])\n",
						"模型中偏参梯度 tensor([-0.3758])\n",
						"第 3471 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1077]])\n",
						"模型中偏参梯度 tensor([-0.3757])\n",
						"第 3472 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1076]])\n",
						"模型中偏参梯度 tensor([-0.3755])\n",
						"第 3473 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1076]])\n",
						"模型中偏参梯度 tensor([-0.3753])\n",
						"第 3474 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1076]])\n",
						"模型中偏参梯度 tensor([-0.3752])\n",
						"第 3475 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1076]])\n",
						"模型中偏参梯度 tensor([-0.3750])\n",
						"第 3476 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1075]])\n",
						"模型中偏参梯度 tensor([-0.3749])\n",
						"第 3477 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1075]])\n",
						"模型中偏参梯度 tensor([-0.3747])\n",
						"第 3478 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1075]])\n",
						"模型中偏参梯度 tensor([-0.3746])\n",
						"第 3479 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1074]])\n",
						"模型中偏参梯度 tensor([-0.3744])\n",
						"第 3480 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1074]])\n",
						"模型中偏参梯度 tensor([-0.3743])\n",
						"第 174 次epoch\n",
						"第 3481 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1074]])\n",
						"模型中偏参梯度 tensor([-0.3741])\n",
						"第 3482 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1073]])\n",
						"模型中偏参梯度 tensor([-0.3740])\n",
						"第 3483 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1073]])\n",
						"模型中偏参梯度 tensor([-0.3738])\n",
						"第 3484 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1073]])\n",
						"模型中偏参梯度 tensor([-0.3737])\n",
						"第 3485 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1072]])\n",
						"模型中偏参梯度 tensor([-0.3735])\n",
						"第 3486 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1072]])\n",
						"模型中偏参梯度 tensor([-0.3733])\n",
						"第 3487 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1071]])\n",
						"模型中偏参梯度 tensor([-0.3732])\n",
						"第 3488 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1071]])\n",
						"模型中偏参梯度 tensor([-0.3730])\n",
						"第 3489 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1071]])\n",
						"模型中偏参梯度 tensor([-0.3729])\n",
						"第 3490 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1070]])\n",
						"模型中偏参梯度 tensor([-0.3727])\n",
						"第 3491 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1070]])\n",
						"模型中偏参梯度 tensor([-0.3726])\n",
						"第 3492 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1069]])\n",
						"模型中偏参梯度 tensor([-0.3724])\n",
						"第 3493 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1069]])\n",
						"模型中偏参梯度 tensor([-0.3723])\n",
						"第 3494 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1068]])\n",
						"模型中偏参梯度 tensor([-0.3721])\n",
						"第 3495 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1068]])\n",
						"模型中偏参梯度 tensor([-0.3720])\n",
						"第 3496 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1068]])\n",
						"模型中偏参梯度 tensor([-0.3718])\n",
						"第 3497 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1067]])\n",
						"模型中偏参梯度 tensor([-0.3717])\n",
						"第 3498 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1067]])\n",
						"模型中偏参梯度 tensor([-0.3716])\n",
						"第 3499 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1066]])\n",
						"模型中偏参梯度 tensor([-0.3714])\n",
						"第 3500 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1066]])\n",
						"模型中偏参梯度 tensor([-0.3713])\n",
						"第 175 次epoch\n",
						"第 3501 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1065]])\n",
						"模型中偏参梯度 tensor([-0.3711])\n",
						"第 3502 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1065]])\n",
						"模型中偏参梯度 tensor([-0.3710])\n",
						"第 3503 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1064]])\n",
						"模型中偏参梯度 tensor([-0.3708])\n",
						"第 3504 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1064]])\n",
						"模型中偏参梯度 tensor([-0.3707])\n",
						"第 3505 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1063]])\n",
						"模型中偏参梯度 tensor([-0.3705])\n",
						"第 3506 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1062]])\n",
						"模型中偏参梯度 tensor([-0.3704])\n",
						"第 3507 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1062]])\n",
						"模型中偏参梯度 tensor([-0.3702])\n",
						"第 3508 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1061]])\n",
						"模型中偏参梯度 tensor([-0.3701])\n",
						"第 3509 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1061]])\n",
						"模型中偏参梯度 tensor([-0.3699])\n",
						"第 3510 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1060]])\n",
						"模型中偏参梯度 tensor([-0.3698])\n",
						"第 3511 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1060]])\n",
						"模型中偏参梯度 tensor([-0.3697])\n",
						"第 3512 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1059]])\n",
						"模型中偏参梯度 tensor([-0.3695])\n",
						"第 3513 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1058]])\n",
						"模型中偏参梯度 tensor([-0.3694])\n",
						"第 3514 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1058]])\n",
						"模型中偏参梯度 tensor([-0.3692])\n",
						"第 3515 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1058]])\n",
						"模型中偏参梯度 tensor([-0.3691])\n",
						"第 3516 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1058]])\n",
						"模型中偏参梯度 tensor([-0.3689])\n",
						"第 3517 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1057]])\n",
						"模型中偏参梯度 tensor([-0.3688])\n",
						"第 3518 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1057]])\n",
						"模型中偏参梯度 tensor([-0.3686])\n",
						"第 3519 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1057]])\n",
						"模型中偏参梯度 tensor([-0.3684])\n",
						"第 3520 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1056]])\n",
						"模型中偏参梯度 tensor([-0.3683])\n",
						"第 176 次epoch\n",
						"第 3521 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1056]])\n",
						"模型中偏参梯度 tensor([-0.3681])\n",
						"第 3522 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1056]])\n",
						"模型中偏参梯度 tensor([-0.3680])\n",
						"第 3523 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1056]])\n",
						"模型中偏参梯度 tensor([-0.3678])\n",
						"第 3524 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1055]])\n",
						"模型中偏参梯度 tensor([-0.3677])\n",
						"第 3525 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1055]])\n",
						"模型中偏参梯度 tensor([-0.3675])\n",
						"第 3526 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1055]])\n",
						"模型中偏参梯度 tensor([-0.3674])\n",
						"第 3527 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1054]])\n",
						"模型中偏参梯度 tensor([-0.3672])\n",
						"第 3528 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1054]])\n",
						"模型中偏参梯度 tensor([-0.3671])\n",
						"第 3529 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1053]])\n",
						"模型中偏参梯度 tensor([-0.3669])\n",
						"第 3530 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1053]])\n",
						"模型中偏参梯度 tensor([-0.3668])\n",
						"第 3531 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1053]])\n",
						"模型中偏参梯度 tensor([-0.3666])\n",
						"第 3532 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1052]])\n",
						"模型中偏参梯度 tensor([-0.3665])\n",
						"第 3533 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1052]])\n",
						"模型中偏参梯度 tensor([-0.3663])\n",
						"第 3534 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1052]])\n",
						"模型中偏参梯度 tensor([-0.3662])\n",
						"第 3535 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1051]])\n",
						"模型中偏参梯度 tensor([-0.3661])\n",
						"第 3536 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1051]])\n",
						"模型中偏参梯度 tensor([-0.3659])\n",
						"第 3537 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1050]])\n",
						"模型中偏参梯度 tensor([-0.3658])\n",
						"第 3538 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1050]])\n",
						"模型中偏参梯度 tensor([-0.3656])\n",
						"第 3539 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1049]])\n",
						"模型中偏参梯度 tensor([-0.3655])\n",
						"第 3540 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1049]])\n",
						"模型中偏参梯度 tensor([-0.3653])\n",
						"第 177 次epoch\n",
						"第 3541 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1048]])\n",
						"模型中偏参梯度 tensor([-0.3652])\n",
						"第 3542 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1048]])\n",
						"模型中偏参梯度 tensor([-0.3650])\n",
						"第 3543 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1048]])\n",
						"模型中偏参梯度 tensor([-0.3649])\n",
						"第 3544 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1047]])\n",
						"模型中偏参梯度 tensor([-0.3647])\n",
						"第 3545 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1047]])\n",
						"模型中偏参梯度 tensor([-0.3646])\n",
						"第 3546 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1046]])\n",
						"模型中偏参梯度 tensor([-0.3644])\n",
						"第 3547 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1046]])\n",
						"模型中偏参梯度 tensor([-0.3643])\n",
						"第 3548 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1045]])\n",
						"模型中偏参梯度 tensor([-0.3642])\n",
						"第 3549 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1044]])\n",
						"模型中偏参梯度 tensor([-0.3640])\n",
						"第 3550 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1044]])\n",
						"模型中偏参梯度 tensor([-0.3639])\n",
						"第 3551 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1043]])\n",
						"模型中偏参梯度 tensor([-0.3637])\n",
						"第 3552 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1043]])\n",
						"模型中偏参梯度 tensor([-0.3636])\n",
						"第 3553 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1042]])\n",
						"模型中偏参梯度 tensor([-0.3634])\n",
						"第 3554 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1042]])\n",
						"模型中偏参梯度 tensor([-0.3633])\n",
						"第 3555 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1041]])\n",
						"模型中偏参梯度 tensor([-0.3632])\n",
						"第 3556 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1041]])\n",
						"模型中偏参梯度 tensor([-0.3630])\n",
						"第 3557 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1040]])\n",
						"模型中偏参梯度 tensor([-0.3629])\n",
						"第 3558 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1039]])\n",
						"模型中偏参梯度 tensor([-0.3627])\n",
						"第 3559 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1039]])\n",
						"模型中偏参梯度 tensor([-0.3626])\n",
						"第 3560 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1039]])\n",
						"模型中偏参梯度 tensor([-0.3624])\n",
						"第 178 次epoch\n",
						"第 3561 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1039]])\n",
						"模型中偏参梯度 tensor([-0.3623])\n",
						"第 3562 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1038]])\n",
						"模型中偏参梯度 tensor([-0.3621])\n",
						"第 3563 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1038]])\n",
						"模型中偏参梯度 tensor([-0.3620])\n",
						"第 3564 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1038]])\n",
						"模型中偏参梯度 tensor([-0.3618])\n",
						"第 3565 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1038]])\n",
						"模型中偏参梯度 tensor([-0.3617])\n",
						"第 3566 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1037]])\n",
						"模型中偏参梯度 tensor([-0.3615])\n",
						"第 3567 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1037]])\n",
						"模型中偏参梯度 tensor([-0.3614])\n",
						"第 3568 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1037]])\n",
						"模型中偏参梯度 tensor([-0.3612])\n",
						"第 3569 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1036]])\n",
						"模型中偏参梯度 tensor([-0.3611])\n",
						"第 3570 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1036]])\n",
						"模型中偏参梯度 tensor([-0.3609])\n",
						"第 3571 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1036]])\n",
						"模型中偏参梯度 tensor([-0.3608])\n",
						"第 3572 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1035]])\n",
						"模型中偏参梯度 tensor([-0.3606])\n",
						"第 3573 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1035]])\n",
						"模型中偏参梯度 tensor([-0.3605])\n",
						"第 3574 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1035]])\n",
						"模型中偏参梯度 tensor([-0.3604])\n",
						"第 3575 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1034]])\n",
						"模型中偏参梯度 tensor([-0.3602])\n",
						"第 3576 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1034]])\n",
						"模型中偏参梯度 tensor([-0.3601])\n",
						"第 3577 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1034]])\n",
						"模型中偏参梯度 tensor([-0.3599])\n",
						"第 3578 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1033]])\n",
						"模型中偏参梯度 tensor([-0.3598])\n",
						"第 3579 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1033]])\n",
						"模型中偏参梯度 tensor([-0.3596])\n",
						"第 3580 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1032]])\n",
						"模型中偏参梯度 tensor([-0.3595])\n",
						"第 179 次epoch\n",
						"第 3581 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1032]])\n",
						"模型中偏参梯度 tensor([-0.3593])\n",
						"第 3582 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1032]])\n",
						"模型中偏参梯度 tensor([-0.3592])\n",
						"第 3583 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1031]])\n",
						"模型中偏参梯度 tensor([-0.3590])\n",
						"第 3584 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1031]])\n",
						"模型中偏参梯度 tensor([-0.3589])\n",
						"第 3585 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1030]])\n",
						"模型中偏参梯度 tensor([-0.3588])\n",
						"第 3586 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1030]])\n",
						"模型中偏参梯度 tensor([-0.3586])\n",
						"第 3587 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1029]])\n",
						"模型中偏参梯度 tensor([-0.3585])\n",
						"第 3588 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1029]])\n",
						"模型中偏参梯度 tensor([-0.3583])\n",
						"第 3589 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1028]])\n",
						"模型中偏参梯度 tensor([-0.3582])\n",
						"第 3590 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1028]])\n",
						"模型中偏参梯度 tensor([-0.3580])\n",
						"第 3591 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1027]])\n",
						"模型中偏参梯度 tensor([-0.3579])\n",
						"第 3592 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1027]])\n",
						"模型中偏参梯度 tensor([-0.3578])\n",
						"第 3593 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1027]])\n",
						"模型中偏参梯度 tensor([-0.3576])\n",
						"第 3594 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1026]])\n",
						"模型中偏参梯度 tensor([-0.3575])\n",
						"第 3595 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1025]])\n",
						"模型中偏参梯度 tensor([-0.3573])\n",
						"第 3596 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1025]])\n",
						"模型中偏参梯度 tensor([-0.3572])\n",
						"第 3597 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1024]])\n",
						"模型中偏参梯度 tensor([-0.3571])\n",
						"第 3598 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1024]])\n",
						"模型中偏参梯度 tensor([-0.3569])\n",
						"第 3599 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1023]])\n",
						"模型中偏参梯度 tensor([-0.3568])\n",
						"第 3600 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1023]])\n",
						"模型中偏参梯度 tensor([-0.3566])\n",
						"第 180 次epoch\n",
						"第 3601 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1022]])\n",
						"模型中偏参梯度 tensor([-0.3565])\n",
						"第 3602 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1022]])\n",
						"模型中偏参梯度 tensor([-0.3564])\n",
						"第 3603 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1021]])\n",
						"模型中偏参梯度 tensor([-0.3562])\n",
						"第 3604 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1020]])\n",
						"模型中偏参梯度 tensor([-0.3561])\n",
						"第 3605 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1020]])\n",
						"模型中偏参梯度 tensor([-0.3559])\n",
						"第 3606 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1020]])\n",
						"模型中偏参梯度 tensor([-0.3558])\n",
						"第 3607 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1020]])\n",
						"模型中偏参梯度 tensor([-0.3556])\n",
						"第 3608 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1019]])\n",
						"模型中偏参梯度 tensor([-0.3555])\n",
						"第 3609 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1019]])\n",
						"模型中偏参梯度 tensor([-0.3553])\n",
						"第 3610 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1019]])\n",
						"模型中偏参梯度 tensor([-0.3552])\n",
						"第 3611 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1019]])\n",
						"模型中偏参梯度 tensor([-0.3550])\n",
						"第 3612 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1018]])\n",
						"模型中偏参梯度 tensor([-0.3549])\n",
						"第 3613 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1018]])\n",
						"模型中偏参梯度 tensor([-0.3548])\n",
						"第 3614 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1018]])\n",
						"模型中偏参梯度 tensor([-0.3546])\n",
						"第 3615 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1017]])\n",
						"模型中偏参梯度 tensor([-0.3545])\n",
						"第 3616 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1017]])\n",
						"模型中偏参梯度 tensor([-0.3543])\n",
						"第 3617 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1017]])\n",
						"模型中偏参梯度 tensor([-0.3542])\n",
						"第 3618 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1017]])\n",
						"模型中偏参梯度 tensor([-0.3540])\n",
						"第 3619 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1016]])\n",
						"模型中偏参梯度 tensor([-0.3539])\n",
						"第 3620 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1016]])\n",
						"模型中偏参梯度 tensor([-0.3537])\n",
						"第 181 次epoch\n",
						"第 3621 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1015]])\n",
						"模型中偏参梯度 tensor([-0.3536])\n",
						"第 3622 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1015]])\n",
						"模型中偏参梯度 tensor([-0.3535])\n",
						"第 3623 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1015]])\n",
						"模型中偏参梯度 tensor([-0.3533])\n",
						"第 3624 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1014]])\n",
						"模型中偏参梯度 tensor([-0.3532])\n",
						"第 3625 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1014]])\n",
						"模型中偏参梯度 tensor([-0.3530])\n",
						"第 3626 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1014]])\n",
						"模型中偏参梯度 tensor([-0.3529])\n",
						"第 3627 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1013]])\n",
						"模型中偏参梯度 tensor([-0.3527])\n",
						"第 3628 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1013]])\n",
						"模型中偏参梯度 tensor([-0.3526])\n",
						"第 3629 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1012]])\n",
						"模型中偏参梯度 tensor([-0.3525])\n",
						"第 3630 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1012]])\n",
						"模型中偏参梯度 tensor([-0.3523])\n",
						"第 3631 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1012]])\n",
						"模型中偏参梯度 tensor([-0.3522])\n",
						"第 3632 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1011]])\n",
						"模型中偏参梯度 tensor([-0.3520])\n",
						"第 3633 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1011]])\n",
						"模型中偏参梯度 tensor([-0.3519])\n",
						"第 3634 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1010]])\n",
						"模型中偏参梯度 tensor([-0.3518])\n",
						"第 3635 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1010]])\n",
						"模型中偏参梯度 tensor([-0.3516])\n",
						"第 3636 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1009]])\n",
						"模型中偏参梯度 tensor([-0.3515])\n",
						"第 3637 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1009]])\n",
						"模型中偏参梯度 tensor([-0.3513])\n",
						"第 3638 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1008]])\n",
						"模型中偏参梯度 tensor([-0.3512])\n",
						"第 3639 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1008]])\n",
						"模型中偏参梯度 tensor([-0.3511])\n",
						"第 3640 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1007]])\n",
						"模型中偏参梯度 tensor([-0.3509])\n",
						"第 182 次epoch\n",
						"第 3641 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1007]])\n",
						"模型中偏参梯度 tensor([-0.3508])\n",
						"第 3642 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1006]])\n",
						"模型中偏参梯度 tensor([-0.3506])\n",
						"第 3643 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1006]])\n",
						"模型中偏参梯度 tensor([-0.3505])\n",
						"第 3644 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1005]])\n",
						"模型中偏参梯度 tensor([-0.3504])\n",
						"第 3645 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1005]])\n",
						"模型中偏参梯度 tensor([-0.3502])\n",
						"第 3646 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1004]])\n",
						"模型中偏参梯度 tensor([-0.3501])\n",
						"第 3647 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1004]])\n",
						"模型中偏参梯度 tensor([-0.3500])\n",
						"第 3648 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1003]])\n",
						"模型中偏参梯度 tensor([-0.3498])\n",
						"第 3649 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1002]])\n",
						"模型中偏参梯度 tensor([-0.3497])\n",
						"第 3650 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1002]])\n",
						"模型中偏参梯度 tensor([-0.3495])\n",
						"第 3651 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1001]])\n",
						"模型中偏参梯度 tensor([-0.3494])\n",
						"第 3652 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1001]])\n",
						"模型中偏参梯度 tensor([-0.3493])\n",
						"第 3653 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1001]])\n",
						"模型中偏参梯度 tensor([-0.3491])\n",
						"第 3654 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1001]])\n",
						"模型中偏参梯度 tensor([-0.3490])\n",
						"第 3655 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1000]])\n",
						"模型中偏参梯度 tensor([-0.3488])\n",
						"第 3656 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1000]])\n",
						"模型中偏参梯度 tensor([-0.3487])\n",
						"第 3657 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1000]])\n",
						"模型中偏参梯度 tensor([-0.3485])\n",
						"第 3658 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.1000]])\n",
						"模型中偏参梯度 tensor([-0.3484])\n",
						"第 3659 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0999]])\n",
						"模型中偏参梯度 tensor([-0.3483])\n",
						"第 3660 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0999]])\n",
						"模型中偏参梯度 tensor([-0.3481])\n",
						"第 183 次epoch\n",
						"第 3661 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0999]])\n",
						"模型中偏参梯度 tensor([-0.3480])\n",
						"第 3662 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0999]])\n",
						"模型中偏参梯度 tensor([-0.3478])\n",
						"第 3663 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0998]])\n",
						"模型中偏参梯度 tensor([-0.3477])\n",
						"第 3664 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0998]])\n",
						"模型中偏参梯度 tensor([-0.3475])\n",
						"第 3665 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0998]])\n",
						"模型中偏参梯度 tensor([-0.3474])\n",
						"第 3666 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0997]])\n",
						"模型中偏参梯度 tensor([-0.3473])\n",
						"第 3667 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0997]])\n",
						"模型中偏参梯度 tensor([-0.3471])\n",
						"第 3668 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0997]])\n",
						"模型中偏参梯度 tensor([-0.3470])\n",
						"第 3669 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0996]])\n",
						"模型中偏参梯度 tensor([-0.3468])\n",
						"第 3670 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0996]])\n",
						"模型中偏参梯度 tensor([-0.3467])\n",
						"第 3671 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0995]])\n",
						"模型中偏参梯度 tensor([-0.3465])\n",
						"第 3672 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0995]])\n",
						"模型中偏参梯度 tensor([-0.3464])\n",
						"第 3673 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0995]])\n",
						"模型中偏参梯度 tensor([-0.3463])\n",
						"第 3674 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0994]])\n",
						"模型中偏参梯度 tensor([-0.3461])\n",
						"第 3675 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0994]])\n",
						"模型中偏参梯度 tensor([-0.3460])\n",
						"第 3676 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0994]])\n",
						"模型中偏参梯度 tensor([-0.3459])\n",
						"第 3677 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0993]])\n",
						"模型中偏参梯度 tensor([-0.3457])\n",
						"第 3678 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0993]])\n",
						"模型中偏参梯度 tensor([-0.3456])\n",
						"第 3679 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0992]])\n",
						"模型中偏参梯度 tensor([-0.3454])\n",
						"第 3680 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0992]])\n",
						"模型中偏参梯度 tensor([-0.3453])\n",
						"第 184 次epoch\n",
						"第 3681 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0991]])\n",
						"模型中偏参梯度 tensor([-0.3452])\n",
						"第 3682 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0991]])\n",
						"模型中偏参梯度 tensor([-0.3450])\n",
						"第 3683 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0990]])\n",
						"模型中偏参梯度 tensor([-0.3449])\n",
						"第 3684 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0990]])\n",
						"模型中偏参梯度 tensor([-0.3447])\n",
						"第 3685 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0990]])\n",
						"模型中偏参梯度 tensor([-0.3446])\n",
						"第 3686 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0989]])\n",
						"模型中偏参梯度 tensor([-0.3445])\n",
						"第 3687 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0989]])\n",
						"模型中偏参梯度 tensor([-0.3443])\n",
						"第 3688 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0988]])\n",
						"模型中偏参梯度 tensor([-0.3442])\n",
						"第 3689 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0988]])\n",
						"模型中偏参梯度 tensor([-0.3441])\n",
						"第 3690 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0987]])\n",
						"模型中偏参梯度 tensor([-0.3439])\n",
						"第 3691 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0987]])\n",
						"模型中偏参梯度 tensor([-0.3438])\n",
						"第 3692 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0986]])\n",
						"模型中偏参梯度 tensor([-0.3437])\n",
						"第 3693 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0985]])\n",
						"模型中偏参梯度 tensor([-0.3435])\n",
						"第 3694 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0985]])\n",
						"模型中偏参梯度 tensor([-0.3434])\n",
						"第 3695 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0984]])\n",
						"模型中偏参梯度 tensor([-0.3433])\n",
						"第 3696 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0984]])\n",
						"模型中偏参梯度 tensor([-0.3431])\n",
						"第 3697 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0983]])\n",
						"模型中偏参梯度 tensor([-0.3430])\n",
						"第 3698 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0983]])\n",
						"模型中偏参梯度 tensor([-0.3429])\n",
						"第 3699 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0982]])\n",
						"模型中偏参梯度 tensor([-0.3427])\n",
						"第 3700 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0982]])\n",
						"模型中偏参梯度 tensor([-0.3426])\n",
						"第 185 次epoch\n",
						"第 3701 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0982]])\n",
						"模型中偏参梯度 tensor([-0.3424])\n",
						"第 3702 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0981]])\n",
						"模型中偏参梯度 tensor([-0.3423])\n",
						"第 3703 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0981]])\n",
						"模型中偏参梯度 tensor([-0.3422])\n",
						"第 3704 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0981]])\n",
						"模型中偏参梯度 tensor([-0.3420])\n",
						"第 3705 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0981]])\n",
						"模型中偏参梯度 tensor([-0.3419])\n",
						"第 3706 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0980]])\n",
						"模型中偏参梯度 tensor([-0.3417])\n",
						"第 3707 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0980]])\n",
						"模型中偏参梯度 tensor([-0.3416])\n",
						"第 3708 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0980]])\n",
						"模型中偏参梯度 tensor([-0.3415])\n",
						"第 3709 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0980]])\n",
						"模型中偏参梯度 tensor([-0.3413])\n",
						"第 3710 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0979]])\n",
						"模型中偏参梯度 tensor([-0.3412])\n",
						"第 3711 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0979]])\n",
						"模型中偏参梯度 tensor([-0.3410])\n",
						"第 3712 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0979]])\n",
						"模型中偏参梯度 tensor([-0.3409])\n",
						"第 3713 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0978]])\n",
						"模型中偏参梯度 tensor([-0.3408])\n",
						"第 3714 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0978]])\n",
						"模型中偏参梯度 tensor([-0.3406])\n",
						"第 3715 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0978]])\n",
						"模型中偏参梯度 tensor([-0.3405])\n",
						"第 3716 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0978]])\n",
						"模型中偏参梯度 tensor([-0.3403])\n",
						"第 3717 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0977]])\n",
						"模型中偏参梯度 tensor([-0.3402])\n",
						"第 3718 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0977]])\n",
						"模型中偏参梯度 tensor([-0.3401])\n",
						"第 3719 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0976]])\n",
						"模型中偏参梯度 tensor([-0.3399])\n",
						"第 3720 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0976]])\n",
						"模型中偏参梯度 tensor([-0.3398])\n",
						"第 186 次epoch\n",
						"第 3721 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0976]])\n",
						"模型中偏参梯度 tensor([-0.3396])\n",
						"第 3722 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0975]])\n",
						"模型中偏参梯度 tensor([-0.3395])\n",
						"第 3723 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0975]])\n",
						"模型中偏参梯度 tensor([-0.3394])\n",
						"第 3724 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0975]])\n",
						"模型中偏参梯度 tensor([-0.3392])\n",
						"第 3725 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0974]])\n",
						"模型中偏参梯度 tensor([-0.3391])\n",
						"第 3726 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0974]])\n",
						"模型中偏参梯度 tensor([-0.3390])\n",
						"第 3727 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0973]])\n",
						"模型中偏参梯度 tensor([-0.3388])\n",
						"第 3728 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0973]])\n",
						"模型中偏参梯度 tensor([-0.3387])\n",
						"第 3729 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0972]])\n",
						"模型中偏参梯度 tensor([-0.3386])\n",
						"第 3730 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0972]])\n",
						"模型中偏参梯度 tensor([-0.3384])\n",
						"第 3731 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0972]])\n",
						"模型中偏参梯度 tensor([-0.3383])\n",
						"第 3732 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0971]])\n",
						"模型中偏参梯度 tensor([-0.3382])\n",
						"第 3733 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0971]])\n",
						"模型中偏参梯度 tensor([-0.3380])\n",
						"第 3734 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0970]])\n",
						"模型中偏参梯度 tensor([-0.3379])\n",
						"第 3735 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0970]])\n",
						"模型中偏参梯度 tensor([-0.3378])\n",
						"第 3736 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0969]])\n",
						"模型中偏参梯度 tensor([-0.3376])\n",
						"第 3737 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0969]])\n",
						"模型中偏参梯度 tensor([-0.3375])\n",
						"第 3738 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0968]])\n",
						"模型中偏参梯度 tensor([-0.3374])\n",
						"第 3739 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0968]])\n",
						"模型中偏参梯度 tensor([-0.3372])\n",
						"第 3740 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0967]])\n",
						"模型中偏参梯度 tensor([-0.3371])\n",
						"第 187 次epoch\n",
						"第 3741 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0967]])\n",
						"模型中偏参梯度 tensor([-0.3370])\n",
						"第 3742 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0966]])\n",
						"模型中偏参梯度 tensor([-0.3368])\n",
						"第 3743 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0966]])\n",
						"模型中偏参梯度 tensor([-0.3367])\n",
						"第 3744 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0965]])\n",
						"模型中偏参梯度 tensor([-0.3366])\n",
						"第 3745 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0965]])\n",
						"模型中偏参梯度 tensor([-0.3364])\n",
						"第 3746 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0964]])\n",
						"模型中偏参梯度 tensor([-0.3363])\n",
						"第 3747 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0963]])\n",
						"模型中偏参梯度 tensor([-0.3362])\n",
						"第 3748 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0963]])\n",
						"模型中偏参梯度 tensor([-0.3360])\n",
						"第 3749 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0963]])\n",
						"模型中偏参梯度 tensor([-0.3359])\n",
						"第 3750 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0962]])\n",
						"模型中偏参梯度 tensor([-0.3358])\n",
						"第 3751 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0962]])\n",
						"模型中偏参梯度 tensor([-0.3356])\n",
						"第 3752 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0962]])\n",
						"模型中偏参梯度 tensor([-0.3355])\n",
						"第 3753 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0962]])\n",
						"模型中偏参梯度 tensor([-0.3353])\n",
						"第 3754 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0961]])\n",
						"模型中偏参梯度 tensor([-0.3352])\n",
						"第 3755 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0961]])\n",
						"模型中偏参梯度 tensor([-0.3351])\n",
						"第 3756 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0961]])\n",
						"模型中偏参梯度 tensor([-0.3349])\n",
						"第 3757 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0961]])\n",
						"模型中偏参梯度 tensor([-0.3348])\n",
						"第 3758 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0960]])\n",
						"模型中偏参梯度 tensor([-0.3346])\n",
						"第 3759 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0960]])\n",
						"模型中偏参梯度 tensor([-0.3345])\n",
						"第 3760 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0960]])\n",
						"模型中偏参梯度 tensor([-0.3344])\n",
						"第 188 次epoch\n",
						"第 3761 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0960]])\n",
						"模型中偏参梯度 tensor([-0.3342])\n",
						"第 3762 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0959]])\n",
						"模型中偏参梯度 tensor([-0.3341])\n",
						"第 3763 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0959]])\n",
						"模型中偏参梯度 tensor([-0.3340])\n",
						"第 3764 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0959]])\n",
						"模型中偏参梯度 tensor([-0.3338])\n",
						"第 3765 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0958]])\n",
						"模型中偏参梯度 tensor([-0.3337])\n",
						"第 3766 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0958]])\n",
						"模型中偏参梯度 tensor([-0.3336])\n",
						"第 3767 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0958]])\n",
						"模型中偏参梯度 tensor([-0.3334])\n",
						"第 3768 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0957]])\n",
						"模型中偏参梯度 tensor([-0.3333])\n",
						"第 3769 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0957]])\n",
						"模型中偏参梯度 tensor([-0.3332])\n",
						"第 3770 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0957]])\n",
						"模型中偏参梯度 tensor([-0.3330])\n",
						"第 3771 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0956]])\n",
						"模型中偏参梯度 tensor([-0.3329])\n",
						"第 3772 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0956]])\n",
						"模型中偏参梯度 tensor([-0.3327])\n",
						"第 3773 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0955]])\n",
						"模型中偏参梯度 tensor([-0.3326])\n",
						"第 3774 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0955]])\n",
						"模型中偏参梯度 tensor([-0.3325])\n",
						"第 3775 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0955]])\n",
						"模型中偏参梯度 tensor([-0.3323])\n",
						"第 3776 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0954]])\n",
						"模型中偏参梯度 tensor([-0.3322])\n",
						"第 3777 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0954]])\n",
						"模型中偏参梯度 tensor([-0.3321])\n",
						"第 3778 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0953]])\n",
						"模型中偏参梯度 tensor([-0.3319])\n",
						"第 3779 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0953]])\n",
						"模型中偏参梯度 tensor([-0.3318])\n",
						"第 3780 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0953]])\n",
						"模型中偏参梯度 tensor([-0.3317])\n",
						"第 189 次epoch\n",
						"第 3781 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0952]])\n",
						"模型中偏参梯度 tensor([-0.3316])\n",
						"第 3782 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0952]])\n",
						"模型中偏参梯度 tensor([-0.3314])\n",
						"第 3783 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0951]])\n",
						"模型中偏参梯度 tensor([-0.3313])\n",
						"第 3784 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0951]])\n",
						"模型中偏参梯度 tensor([-0.3312])\n",
						"第 3785 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0950]])\n",
						"模型中偏参梯度 tensor([-0.3310])\n",
						"第 3786 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0950]])\n",
						"模型中偏参梯度 tensor([-0.3309])\n",
						"第 3787 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0949]])\n",
						"模型中偏参梯度 tensor([-0.3308])\n",
						"第 3788 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0949]])\n",
						"模型中偏参梯度 tensor([-0.3306])\n",
						"第 3789 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0948]])\n",
						"模型中偏参梯度 tensor([-0.3305])\n",
						"第 3790 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0948]])\n",
						"模型中偏参梯度 tensor([-0.3304])\n",
						"第 3791 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0947]])\n",
						"模型中偏参梯度 tensor([-0.3303])\n",
						"第 3792 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0947]])\n",
						"模型中偏参梯度 tensor([-0.3301])\n",
						"第 3793 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0946]])\n",
						"模型中偏参梯度 tensor([-0.3300])\n",
						"第 3794 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0946]])\n",
						"模型中偏参梯度 tensor([-0.3299])\n",
						"第 3795 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0945]])\n",
						"模型中偏参梯度 tensor([-0.3297])\n",
						"第 3796 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0945]])\n",
						"模型中偏参梯度 tensor([-0.3296])\n",
						"第 3797 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0944]])\n",
						"模型中偏参梯度 tensor([-0.3295])\n",
						"第 3798 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0944]])\n",
						"模型中偏参梯度 tensor([-0.3293])\n",
						"第 3799 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0944]])\n",
						"模型中偏参梯度 tensor([-0.3292])\n",
						"第 3800 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0943]])\n",
						"模型中偏参梯度 tensor([-0.3291])\n",
						"第 190 次epoch\n",
						"第 3801 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0943]])\n",
						"模型中偏参梯度 tensor([-0.3289])\n",
						"第 3802 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0943]])\n",
						"模型中偏参梯度 tensor([-0.3288])\n",
						"第 3803 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0943]])\n",
						"模型中偏参梯度 tensor([-0.3287])\n",
						"第 3804 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0943]])\n",
						"模型中偏参梯度 tensor([-0.3285])\n",
						"第 3805 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0942]])\n",
						"模型中偏参梯度 tensor([-0.3284])\n",
						"第 3806 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0942]])\n",
						"模型中偏参梯度 tensor([-0.3282])\n",
						"第 3807 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0942]])\n",
						"模型中偏参梯度 tensor([-0.3281])\n",
						"第 3808 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0941]])\n",
						"模型中偏参梯度 tensor([-0.3280])\n",
						"第 3809 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0941]])\n",
						"模型中偏参梯度 tensor([-0.3278])\n",
						"第 3810 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0941]])\n",
						"模型中偏参梯度 tensor([-0.3277])\n",
						"第 3811 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0941]])\n",
						"模型中偏参梯度 tensor([-0.3276])\n",
						"第 3812 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0940]])\n",
						"模型中偏参梯度 tensor([-0.3274])\n",
						"第 3813 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0940]])\n",
						"模型中偏参梯度 tensor([-0.3273])\n",
						"第 3814 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0940]])\n",
						"模型中偏参梯度 tensor([-0.3272])\n",
						"第 3815 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0939]])\n",
						"模型中偏参梯度 tensor([-0.3270])\n",
						"第 3816 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0939]])\n",
						"模型中偏参梯度 tensor([-0.3269])\n",
						"第 3817 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0939]])\n",
						"模型中偏参梯度 tensor([-0.3268])\n",
						"第 3818 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0938]])\n",
						"模型中偏参梯度 tensor([-0.3266])\n",
						"第 3819 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0938]])\n",
						"模型中偏参梯度 tensor([-0.3265])\n",
						"第 3820 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0938]])\n",
						"模型中偏参梯度 tensor([-0.3264])\n",
						"第 191 次epoch\n",
						"第 3821 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0937]])\n",
						"模型中偏参梯度 tensor([-0.3262])\n",
						"第 3822 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0937]])\n",
						"模型中偏参梯度 tensor([-0.3261])\n",
						"第 3823 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0937]])\n",
						"模型中偏参梯度 tensor([-0.3260])\n",
						"第 3824 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0936]])\n",
						"模型中偏参梯度 tensor([-0.3259])\n",
						"第 3825 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0936]])\n",
						"模型中偏参梯度 tensor([-0.3257])\n",
						"第 3826 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0935]])\n",
						"模型中偏参梯度 tensor([-0.3256])\n",
						"第 3827 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0935]])\n",
						"模型中偏参梯度 tensor([-0.3255])\n",
						"第 3828 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0935]])\n",
						"模型中偏参梯度 tensor([-0.3253])\n",
						"第 3829 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0934]])\n",
						"模型中偏参梯度 tensor([-0.3252])\n",
						"第 3830 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0934]])\n",
						"模型中偏参梯度 tensor([-0.3251])\n",
						"第 3831 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0933]])\n",
						"模型中偏参梯度 tensor([-0.3249])\n",
						"第 3832 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0933]])\n",
						"模型中偏参梯度 tensor([-0.3248])\n",
						"第 3833 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0932]])\n",
						"模型中偏参梯度 tensor([-0.3247])\n",
						"第 3834 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0932]])\n",
						"模型中偏参梯度 tensor([-0.3246])\n",
						"第 3835 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0932]])\n",
						"模型中偏参梯度 tensor([-0.3244])\n",
						"第 3836 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0931]])\n",
						"模型中偏参梯度 tensor([-0.3243])\n",
						"第 3837 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0931]])\n",
						"模型中偏参梯度 tensor([-0.3242])\n",
						"第 3838 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0930]])\n",
						"模型中偏参梯度 tensor([-0.3240])\n",
						"第 3839 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0930]])\n",
						"模型中偏参梯度 tensor([-0.3239])\n",
						"第 3840 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0929]])\n",
						"模型中偏参梯度 tensor([-0.3238])\n",
						"第 192 次epoch\n",
						"第 3841 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0929]])\n",
						"模型中偏参梯度 tensor([-0.3237])\n",
						"第 3842 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0928]])\n",
						"模型中偏参梯度 tensor([-0.3235])\n",
						"第 3843 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0928]])\n",
						"模型中偏参梯度 tensor([-0.3234])\n",
						"第 3844 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0927]])\n",
						"模型中偏参梯度 tensor([-0.3233])\n",
						"第 3845 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0927]])\n",
						"模型中偏参梯度 tensor([-0.3232])\n",
						"第 3846 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0926]])\n",
						"模型中偏参梯度 tensor([-0.3230])\n",
						"第 3847 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0925]])\n",
						"模型中偏参梯度 tensor([-0.3229])\n",
						"第 3848 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0925]])\n",
						"模型中偏参梯度 tensor([-0.3228])\n",
						"第 3849 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0925]])\n",
						"模型中偏参梯度 tensor([-0.3227])\n",
						"第 3850 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0925]])\n",
						"模型中偏参梯度 tensor([-0.3225])\n",
						"第 3851 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0924]])\n",
						"模型中偏参梯度 tensor([-0.3224])\n",
						"第 3852 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0924]])\n",
						"模型中偏参梯度 tensor([-0.3222])\n",
						"第 3853 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0924]])\n",
						"模型中偏参梯度 tensor([-0.3221])\n",
						"第 3854 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0924]])\n",
						"模型中偏参梯度 tensor([-0.3220])\n",
						"第 3855 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0923]])\n",
						"模型中偏参梯度 tensor([-0.3218])\n",
						"第 3856 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0923]])\n",
						"模型中偏参梯度 tensor([-0.3217])\n",
						"第 3857 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0923]])\n",
						"模型中偏参梯度 tensor([-0.3216])\n",
						"第 3858 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0923]])\n",
						"模型中偏参梯度 tensor([-0.3214])\n",
						"第 3859 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0922]])\n",
						"模型中偏参梯度 tensor([-0.3213])\n",
						"第 3860 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0922]])\n",
						"模型中偏参梯度 tensor([-0.3212])\n",
						"第 193 次epoch\n",
						"第 3861 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0922]])\n",
						"模型中偏参梯度 tensor([-0.3211])\n",
						"第 3862 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0922]])\n",
						"模型中偏参梯度 tensor([-0.3209])\n",
						"第 3863 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0921]])\n",
						"模型中偏参梯度 tensor([-0.3208])\n",
						"第 3864 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0921]])\n",
						"模型中偏参梯度 tensor([-0.3207])\n",
						"第 3865 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0921]])\n",
						"模型中偏参梯度 tensor([-0.3205])\n",
						"第 3866 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0920]])\n",
						"模型中偏参梯度 tensor([-0.3204])\n",
						"第 3867 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0920]])\n",
						"模型中偏参梯度 tensor([-0.3203])\n",
						"第 3868 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0920]])\n",
						"模型中偏参梯度 tensor([-0.3201])\n",
						"第 3869 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0919]])\n",
						"模型中偏参梯度 tensor([-0.3200])\n",
						"第 3870 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0919]])\n",
						"模型中偏参梯度 tensor([-0.3199])\n",
						"第 3871 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0919]])\n",
						"模型中偏参梯度 tensor([-0.3197])\n",
						"第 3872 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0918]])\n",
						"模型中偏参梯度 tensor([-0.3196])\n",
						"第 3873 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0918]])\n",
						"模型中偏参梯度 tensor([-0.3195])\n",
						"第 3874 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0918]])\n",
						"模型中偏参梯度 tensor([-0.3194])\n",
						"第 3875 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0917]])\n",
						"模型中偏参梯度 tensor([-0.3192])\n",
						"第 3876 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0917]])\n",
						"模型中偏参梯度 tensor([-0.3191])\n",
						"第 3877 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0917]])\n",
						"模型中偏参梯度 tensor([-0.3190])\n",
						"第 3878 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0916]])\n",
						"模型中偏参梯度 tensor([-0.3188])\n",
						"第 3879 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0916]])\n",
						"模型中偏参梯度 tensor([-0.3187])\n",
						"第 3880 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0915]])\n",
						"模型中偏参梯度 tensor([-0.3186])\n",
						"第 194 次epoch\n",
						"第 3881 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0915]])\n",
						"模型中偏参梯度 tensor([-0.3185])\n",
						"第 3882 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0914]])\n",
						"模型中偏参梯度 tensor([-0.3183])\n",
						"第 3883 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0914]])\n",
						"模型中偏参梯度 tensor([-0.3182])\n",
						"第 3884 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0914]])\n",
						"模型中偏参梯度 tensor([-0.3181])\n",
						"第 3885 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0913]])\n",
						"模型中偏参梯度 tensor([-0.3180])\n",
						"第 3886 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0913]])\n",
						"模型中偏参梯度 tensor([-0.3178])\n",
						"第 3887 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0912]])\n",
						"模型中偏参梯度 tensor([-0.3177])\n",
						"第 3888 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0912]])\n",
						"模型中偏参梯度 tensor([-0.3176])\n",
						"第 3889 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0911]])\n",
						"模型中偏参梯度 tensor([-0.3175])\n",
						"第 3890 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0911]])\n",
						"模型中偏参梯度 tensor([-0.3173])\n",
						"第 3891 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0910]])\n",
						"模型中偏参梯度 tensor([-0.3172])\n",
						"第 3892 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0910]])\n",
						"模型中偏参梯度 tensor([-0.3171])\n",
						"第 3893 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0909]])\n",
						"模型中偏参梯度 tensor([-0.3170])\n",
						"第 3894 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0909]])\n",
						"模型中偏参梯度 tensor([-0.3168])\n",
						"第 3895 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0908]])\n",
						"模型中偏参梯度 tensor([-0.3167])\n",
						"第 3896 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0908]])\n",
						"模型中偏参梯度 tensor([-0.3166])\n",
						"第 3897 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0907]])\n",
						"模型中偏参梯度 tensor([-0.3165])\n",
						"第 3898 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0907]])\n",
						"模型中偏参梯度 tensor([-0.3163])\n",
						"第 3899 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0906]])\n",
						"模型中偏参梯度 tensor([-0.3162])\n",
						"第 3900 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0906]])\n",
						"模型中偏参梯度 tensor([-0.3161])\n",
						"第 195 次epoch\n",
						"第 3901 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0906]])\n",
						"模型中偏参梯度 tensor([-0.3160])\n",
						"第 3902 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0905]])\n",
						"模型中偏参梯度 tensor([-0.3158])\n",
						"第 3903 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0905]])\n",
						"模型中偏参梯度 tensor([-0.3157])\n",
						"第 3904 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0905]])\n",
						"模型中偏参梯度 tensor([-0.3156])\n",
						"第 3905 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0905]])\n",
						"模型中偏参梯度 tensor([-0.3154])\n",
						"第 3906 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0905]])\n",
						"模型中偏参梯度 tensor([-0.3153])\n",
						"第 3907 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0904]])\n",
						"模型中偏参梯度 tensor([-0.3152])\n",
						"第 3908 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0904]])\n",
						"模型中偏参梯度 tensor([-0.3151])\n",
						"第 3909 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0904]])\n",
						"模型中偏参梯度 tensor([-0.3149])\n",
						"第 3910 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0904]])\n",
						"模型中偏参梯度 tensor([-0.3148])\n",
						"第 3911 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0903]])\n",
						"模型中偏参梯度 tensor([-0.3147])\n",
						"第 3912 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0903]])\n",
						"模型中偏参梯度 tensor([-0.3145])\n",
						"第 3913 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0903]])\n",
						"模型中偏参梯度 tensor([-0.3144])\n",
						"第 3914 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0903]])\n",
						"模型中偏参梯度 tensor([-0.3143])\n",
						"第 3915 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0902]])\n",
						"模型中偏参梯度 tensor([-0.3141])\n",
						"第 3916 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0902]])\n",
						"模型中偏参梯度 tensor([-0.3140])\n",
						"第 3917 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0902]])\n",
						"模型中偏参梯度 tensor([-0.3139])\n",
						"第 3918 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0901]])\n",
						"模型中偏参梯度 tensor([-0.3138])\n",
						"第 3919 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0901]])\n",
						"模型中偏参梯度 tensor([-0.3136])\n",
						"第 3920 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0901]])\n",
						"模型中偏参梯度 tensor([-0.3135])\n",
						"第 196 次epoch\n",
						"第 3921 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0900]])\n",
						"模型中偏参梯度 tensor([-0.3134])\n",
						"第 3922 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0900]])\n",
						"模型中偏参梯度 tensor([-0.3133])\n",
						"第 3923 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0900]])\n",
						"模型中偏参梯度 tensor([-0.3131])\n",
						"第 3924 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0899]])\n",
						"模型中偏参梯度 tensor([-0.3130])\n",
						"第 3925 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0899]])\n",
						"模型中偏参梯度 tensor([-0.3129])\n",
						"第 3926 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0899]])\n",
						"模型中偏参梯度 tensor([-0.3127])\n",
						"第 3927 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0898]])\n",
						"模型中偏参梯度 tensor([-0.3126])\n",
						"第 3928 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0898]])\n",
						"模型中偏参梯度 tensor([-0.3125])\n",
						"第 3929 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0898]])\n",
						"模型中偏参梯度 tensor([-0.3124])\n",
						"第 3930 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0897]])\n",
						"模型中偏参梯度 tensor([-0.3122])\n",
						"第 3931 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0897]])\n",
						"模型中偏参梯度 tensor([-0.3121])\n",
						"第 3932 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0896]])\n",
						"模型中偏参梯度 tensor([-0.3120])\n",
						"第 3933 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0896]])\n",
						"模型中偏参梯度 tensor([-0.3119])\n",
						"第 3934 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0896]])\n",
						"模型中偏参梯度 tensor([-0.3117])\n",
						"第 3935 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0895]])\n",
						"模型中偏参梯度 tensor([-0.3116])\n",
						"第 3936 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0895]])\n",
						"模型中偏参梯度 tensor([-0.3115])\n",
						"第 3937 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0894]])\n",
						"模型中偏参梯度 tensor([-0.3114])\n",
						"第 3938 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0894]])\n",
						"模型中偏参梯度 tensor([-0.3113])\n",
						"第 3939 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0893]])\n",
						"模型中偏参梯度 tensor([-0.3111])\n",
						"第 3940 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0893]])\n",
						"模型中偏参梯度 tensor([-0.3110])\n",
						"第 197 次epoch\n",
						"第 3941 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0893]])\n",
						"模型中偏参梯度 tensor([-0.3109])\n",
						"第 3942 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0892]])\n",
						"模型中偏参梯度 tensor([-0.3108])\n",
						"第 3943 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0892]])\n",
						"模型中偏参梯度 tensor([-0.3106])\n",
						"第 3944 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0891]])\n",
						"模型中偏参梯度 tensor([-0.3105])\n",
						"第 3945 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0891]])\n",
						"模型中偏参梯度 tensor([-0.3104])\n",
						"第 3946 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0890]])\n",
						"模型中偏参梯度 tensor([-0.3103])\n",
						"第 3947 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0890]])\n",
						"模型中偏参梯度 tensor([-0.3102])\n",
						"第 3948 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0889]])\n",
						"模型中偏参梯度 tensor([-0.3100])\n",
						"第 3949 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0889]])\n",
						"模型中偏参梯度 tensor([-0.3099])\n",
						"第 3950 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0888]])\n",
						"模型中偏参梯度 tensor([-0.3098])\n",
						"第 3951 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0888]])\n",
						"模型中偏参梯度 tensor([-0.3097])\n",
						"第 3952 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0887]])\n",
						"模型中偏参梯度 tensor([-0.3096])\n",
						"第 3953 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0887]])\n",
						"模型中偏参梯度 tensor([-0.3094])\n",
						"第 3954 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0887]])\n",
						"模型中偏参梯度 tensor([-0.3093])\n",
						"第 3955 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0886]])\n",
						"模型中偏参梯度 tensor([-0.3092])\n",
						"第 3956 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0886]])\n",
						"模型中偏参梯度 tensor([-0.3090])\n",
						"第 3957 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0886]])\n",
						"模型中偏参梯度 tensor([-0.3089])\n",
						"第 3958 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0886]])\n",
						"模型中偏参梯度 tensor([-0.3088])\n",
						"第 3959 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0886]])\n",
						"模型中偏参梯度 tensor([-0.3087])\n",
						"第 3960 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0885]])\n",
						"模型中偏参梯度 tensor([-0.3085])\n",
						"第 198 次epoch\n",
						"第 3961 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0885]])\n",
						"模型中偏参梯度 tensor([-0.3084])\n",
						"第 3962 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0885]])\n",
						"模型中偏参梯度 tensor([-0.3083])\n",
						"第 3963 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0885]])\n",
						"模型中偏参梯度 tensor([-0.3081])\n",
						"第 3964 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0885]])\n",
						"模型中偏参梯度 tensor([-0.3080])\n",
						"第 3965 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0884]])\n",
						"模型中偏参梯度 tensor([-0.3079])\n",
						"第 3966 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0884]])\n",
						"模型中偏参梯度 tensor([-0.3078])\n",
						"第 3967 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0884]])\n",
						"模型中偏参梯度 tensor([-0.3076])\n",
						"第 3968 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0883]])\n",
						"模型中偏参梯度 tensor([-0.3075])\n",
						"第 3969 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0883]])\n",
						"模型中偏参梯度 tensor([-0.3074])\n",
						"第 3970 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0883]])\n",
						"模型中偏参梯度 tensor([-0.3073])\n",
						"第 3971 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0883]])\n",
						"模型中偏参梯度 tensor([-0.3071])\n",
						"第 3972 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0882]])\n",
						"模型中偏参梯度 tensor([-0.3070])\n",
						"第 3973 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0882]])\n",
						"模型中偏参梯度 tensor([-0.3069])\n",
						"第 3974 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0882]])\n",
						"模型中偏参梯度 tensor([-0.3068])\n",
						"第 3975 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0881]])\n",
						"模型中偏参梯度 tensor([-0.3066])\n",
						"第 3976 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0881]])\n",
						"模型中偏参梯度 tensor([-0.3065])\n",
						"第 3977 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0881]])\n",
						"模型中偏参梯度 tensor([-0.3064])\n",
						"第 3978 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0880]])\n",
						"模型中偏参梯度 tensor([-0.3063])\n",
						"第 3979 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0880]])\n",
						"模型中偏参梯度 tensor([-0.3061])\n",
						"第 3980 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0880]])\n",
						"模型中偏参梯度 tensor([-0.3060])\n",
						"第 199 次epoch\n",
						"第 3981 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0879]])\n",
						"模型中偏参梯度 tensor([-0.3059])\n",
						"第 3982 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0879]])\n",
						"模型中偏参梯度 tensor([-0.3058])\n",
						"第 3983 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0879]])\n",
						"模型中偏参梯度 tensor([-0.3056])\n",
						"第 3984 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0878]])\n",
						"模型中偏参梯度 tensor([-0.3055])\n",
						"第 3985 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0878]])\n",
						"模型中偏参梯度 tensor([-0.3054])\n",
						"第 3986 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0877]])\n",
						"模型中偏参梯度 tensor([-0.3053])\n",
						"第 3987 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0877]])\n",
						"模型中偏参梯度 tensor([-0.3052])\n",
						"第 3988 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0877]])\n",
						"模型中偏参梯度 tensor([-0.3050])\n",
						"第 3989 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0876]])\n",
						"模型中偏参梯度 tensor([-0.3049])\n",
						"第 3990 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0876]])\n",
						"模型中偏参梯度 tensor([-0.3048])\n",
						"第 3991 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0875]])\n",
						"模型中偏参梯度 tensor([-0.3047])\n",
						"第 3992 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0875]])\n",
						"模型中偏参梯度 tensor([-0.3046])\n",
						"第 3993 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0874]])\n",
						"模型中偏参梯度 tensor([-0.3044])\n",
						"第 3994 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0874]])\n",
						"模型中偏参梯度 tensor([-0.3043])\n",
						"第 3995 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0874]])\n",
						"模型中偏参梯度 tensor([-0.3042])\n",
						"第 3996 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0873]])\n",
						"模型中偏参梯度 tensor([-0.3041])\n",
						"第 3997 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0873]])\n",
						"模型中偏参梯度 tensor([-0.3040])\n",
						"第 3998 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0872]])\n",
						"模型中偏参梯度 tensor([-0.3038])\n",
						"第 3999 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0872]])\n",
						"模型中偏参梯度 tensor([-0.3037])\n",
						"第 4000 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0871]])\n",
						"模型中偏参梯度 tensor([-0.3036])\n",
						"第 200 次epoch\n",
						"第 4001 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0871]])\n",
						"模型中偏参梯度 tensor([-0.3035])\n",
						"第 4002 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0870]])\n",
						"模型中偏参梯度 tensor([-0.3034])\n",
						"第 4003 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0870]])\n",
						"模型中偏参梯度 tensor([-0.3033])\n",
						"第 4004 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0869]])\n",
						"模型中偏参梯度 tensor([-0.3031])\n",
						"第 4005 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0869]])\n",
						"模型中偏参梯度 tensor([-0.3030])\n",
						"第 4006 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0868]])\n",
						"模型中偏参梯度 tensor([-0.3029])\n",
						"第 4007 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0868]])\n",
						"模型中偏参梯度 tensor([-0.3028])\n",
						"第 4008 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0867]])\n",
						"模型中偏参梯度 tensor([-0.3027])\n",
						"第 4009 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0867]])\n",
						"模型中偏参梯度 tensor([-0.3025])\n",
						"第 4010 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0867]])\n",
						"模型中偏参梯度 tensor([-0.3024])\n",
						"第 4011 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0867]])\n",
						"模型中偏参梯度 tensor([-0.3023])\n",
						"第 4012 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0867]])\n",
						"模型中偏参梯度 tensor([-0.3022])\n",
						"第 4013 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0866]])\n",
						"模型中偏参梯度 tensor([-0.3020])\n",
						"第 4014 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0866]])\n",
						"模型中偏参梯度 tensor([-0.3019])\n",
						"第 4015 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0866]])\n",
						"模型中偏参梯度 tensor([-0.3018])\n",
						"第 4016 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0866]])\n",
						"模型中偏参梯度 tensor([-0.3017])\n",
						"第 4017 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0866]])\n",
						"模型中偏参梯度 tensor([-0.3015])\n",
						"第 4018 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0865]])\n",
						"模型中偏参梯度 tensor([-0.3014])\n",
						"第 4019 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0865]])\n",
						"模型中偏参梯度 tensor([-0.3013])\n",
						"第 4020 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0865]])\n",
						"模型中偏参梯度 tensor([-0.3012])\n",
						"第 201 次epoch\n",
						"第 4021 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0865]])\n",
						"模型中偏参梯度 tensor([-0.3010])\n",
						"第 4022 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0864]])\n",
						"模型中偏参梯度 tensor([-0.3009])\n",
						"第 4023 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0864]])\n",
						"模型中偏参梯度 tensor([-0.3008])\n",
						"第 4024 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0864]])\n",
						"模型中偏参梯度 tensor([-0.3007])\n",
						"第 4025 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0864]])\n",
						"模型中偏参梯度 tensor([-0.3005])\n",
						"第 4026 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0863]])\n",
						"模型中偏参梯度 tensor([-0.3004])\n",
						"第 4027 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0863]])\n",
						"模型中偏参梯度 tensor([-0.3003])\n",
						"第 4028 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0863]])\n",
						"模型中偏参梯度 tensor([-0.3002])\n",
						"第 4029 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0862]])\n",
						"模型中偏参梯度 tensor([-0.3000])\n",
						"第 4030 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0862]])\n",
						"模型中偏参梯度 tensor([-0.2999])\n",
						"第 4031 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0862]])\n",
						"模型中偏参梯度 tensor([-0.2998])\n",
						"第 4032 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0861]])\n",
						"模型中偏参梯度 tensor([-0.2997])\n",
						"第 4033 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0861]])\n",
						"模型中偏参梯度 tensor([-0.2996])\n",
						"第 4034 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0861]])\n",
						"模型中偏参梯度 tensor([-0.2994])\n",
						"第 4035 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0860]])\n",
						"模型中偏参梯度 tensor([-0.2993])\n",
						"第 4036 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0860]])\n",
						"模型中偏参梯度 tensor([-0.2992])\n",
						"第 4037 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0860]])\n",
						"模型中偏参梯度 tensor([-0.2991])\n",
						"第 4038 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0859]])\n",
						"模型中偏参梯度 tensor([-0.2990])\n",
						"第 4039 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0859]])\n",
						"模型中偏参梯度 tensor([-0.2988])\n",
						"第 4040 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0859]])\n",
						"模型中偏参梯度 tensor([-0.2987])\n",
						"第 202 次epoch\n",
						"第 4041 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0858]])\n",
						"模型中偏参梯度 tensor([-0.2986])\n",
						"第 4042 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0858]])\n",
						"模型中偏参梯度 tensor([-0.2985])\n",
						"第 4043 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0857]])\n",
						"模型中偏参梯度 tensor([-0.2984])\n",
						"第 4044 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0857]])\n",
						"模型中偏参梯度 tensor([-0.2982])\n",
						"第 4045 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0856]])\n",
						"模型中偏参梯度 tensor([-0.2981])\n",
						"第 4046 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0856]])\n",
						"模型中偏参梯度 tensor([-0.2980])\n",
						"第 4047 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0856]])\n",
						"模型中偏参梯度 tensor([-0.2979])\n",
						"第 4048 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0855]])\n",
						"模型中偏参梯度 tensor([-0.2978])\n",
						"第 4049 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0855]])\n",
						"模型中偏参梯度 tensor([-0.2977])\n",
						"第 4050 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0854]])\n",
						"模型中偏参梯度 tensor([-0.2975])\n",
						"第 4051 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0854]])\n",
						"模型中偏参梯度 tensor([-0.2974])\n",
						"第 4052 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0853]])\n",
						"模型中偏参梯度 tensor([-0.2973])\n",
						"第 4053 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0853]])\n",
						"模型中偏参梯度 tensor([-0.2972])\n",
						"第 4054 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0852]])\n",
						"模型中偏参梯度 tensor([-0.2971])\n",
						"第 4055 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0852]])\n",
						"模型中偏参梯度 tensor([-0.2970])\n",
						"第 4056 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0851]])\n",
						"模型中偏参梯度 tensor([-0.2969])\n",
						"第 4057 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0851]])\n",
						"模型中偏参梯度 tensor([-0.2967])\n",
						"第 4058 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0850]])\n",
						"模型中偏参梯度 tensor([-0.2966])\n",
						"第 4059 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0850]])\n",
						"模型中偏参梯度 tensor([-0.2965])\n",
						"第 4060 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0849]])\n",
						"模型中偏参梯度 tensor([-0.2964])\n",
						"第 203 次epoch\n",
						"第 4061 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0849]])\n",
						"模型中偏参梯度 tensor([-0.2963])\n",
						"第 4062 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0848]])\n",
						"模型中偏参梯度 tensor([-0.2962])\n",
						"第 4063 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0848]])\n",
						"模型中偏参梯度 tensor([-0.2960])\n",
						"第 4064 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0848]])\n",
						"模型中偏参梯度 tensor([-0.2959])\n",
						"第 4065 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0848]])\n",
						"模型中偏参梯度 tensor([-0.2958])\n",
						"第 4066 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0848]])\n",
						"模型中偏参梯度 tensor([-0.2957])\n",
						"第 4067 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0848]])\n",
						"模型中偏参梯度 tensor([-0.2955])\n",
						"第 4068 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0847]])\n",
						"模型中偏参梯度 tensor([-0.2954])\n",
						"第 4069 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0847]])\n",
						"模型中偏参梯度 tensor([-0.2953])\n",
						"第 4070 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0847]])\n",
						"模型中偏参梯度 tensor([-0.2952])\n",
						"第 4071 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0847]])\n",
						"模型中偏参梯度 tensor([-0.2951])\n",
						"第 4072 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0847]])\n",
						"模型中偏参梯度 tensor([-0.2949])\n",
						"第 4073 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0846]])\n",
						"模型中偏参梯度 tensor([-0.2948])\n",
						"第 4074 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0846]])\n",
						"模型中偏参梯度 tensor([-0.2947])\n",
						"第 4075 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0846]])\n",
						"模型中偏参梯度 tensor([-0.2946])\n",
						"第 4076 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0846]])\n",
						"模型中偏参梯度 tensor([-0.2944])\n",
						"第 4077 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0845]])\n",
						"模型中偏参梯度 tensor([-0.2943])\n",
						"第 4078 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0845]])\n",
						"模型中偏参梯度 tensor([-0.2942])\n",
						"第 4079 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0845]])\n",
						"模型中偏参梯度 tensor([-0.2941])\n",
						"第 4080 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0845]])\n",
						"模型中偏参梯度 tensor([-0.2940])\n",
						"第 204 次epoch\n",
						"第 4081 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0844]])\n",
						"模型中偏参梯度 tensor([-0.2938])\n",
						"第 4082 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0844]])\n",
						"模型中偏参梯度 tensor([-0.2937])\n",
						"第 4083 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0844]])\n",
						"模型中偏参梯度 tensor([-0.2936])\n",
						"第 4084 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0843]])\n",
						"模型中偏参梯度 tensor([-0.2935])\n",
						"第 4085 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0843]])\n",
						"模型中偏参梯度 tensor([-0.2934])\n",
						"第 4086 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0843]])\n",
						"模型中偏参梯度 tensor([-0.2932])\n",
						"第 4087 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0842]])\n",
						"模型中偏参梯度 tensor([-0.2931])\n",
						"第 4088 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0842]])\n",
						"模型中偏参梯度 tensor([-0.2930])\n",
						"第 4089 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0842]])\n",
						"模型中偏参梯度 tensor([-0.2929])\n",
						"第 4090 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0842]])\n",
						"模型中偏参梯度 tensor([-0.2928])\n",
						"第 4091 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0841]])\n",
						"模型中偏参梯度 tensor([-0.2927])\n",
						"第 4092 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0841]])\n",
						"模型中偏参梯度 tensor([-0.2925])\n",
						"第 4093 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0840]])\n",
						"模型中偏参梯度 tensor([-0.2924])\n",
						"第 4094 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0840]])\n",
						"模型中偏参梯度 tensor([-0.2923])\n",
						"第 4095 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0840]])\n",
						"模型中偏参梯度 tensor([-0.2922])\n",
						"第 4096 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0839]])\n",
						"模型中偏参梯度 tensor([-0.2921])\n",
						"第 4097 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0839]])\n",
						"模型中偏参梯度 tensor([-0.2920])\n",
						"第 4098 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0839]])\n",
						"模型中偏参梯度 tensor([-0.2918])\n",
						"第 4099 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0838]])\n",
						"模型中偏参梯度 tensor([-0.2917])\n",
						"第 4100 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0838]])\n",
						"模型中偏参梯度 tensor([-0.2916])\n",
						"第 205 次epoch\n",
						"第 4101 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0837]])\n",
						"模型中偏参梯度 tensor([-0.2915])\n",
						"第 4102 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0837]])\n",
						"模型中偏参梯度 tensor([-0.2914])\n",
						"第 4103 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0837]])\n",
						"模型中偏参梯度 tensor([-0.2913])\n",
						"第 4104 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0836]])\n",
						"模型中偏参梯度 tensor([-0.2911])\n",
						"第 4105 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0836]])\n",
						"模型中偏参梯度 tensor([-0.2910])\n",
						"第 4106 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0835]])\n",
						"模型中偏参梯度 tensor([-0.2909])\n",
						"第 4107 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0835]])\n",
						"模型中偏参梯度 tensor([-0.2908])\n",
						"第 4108 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0834]])\n",
						"模型中偏参梯度 tensor([-0.2907])\n",
						"第 4109 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0834]])\n",
						"模型中偏参梯度 tensor([-0.2906])\n",
						"第 4110 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0833]])\n",
						"模型中偏参梯度 tensor([-0.2905])\n",
						"第 4111 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0833]])\n",
						"模型中偏参梯度 tensor([-0.2903])\n",
						"第 4112 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0833]])\n",
						"模型中偏参梯度 tensor([-0.2902])\n",
						"第 4113 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0832]])\n",
						"模型中偏参梯度 tensor([-0.2901])\n",
						"第 4114 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0832]])\n",
						"模型中偏参梯度 tensor([-0.2900])\n",
						"第 4115 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0831]])\n",
						"模型中偏参梯度 tensor([-0.2899])\n",
						"第 4116 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0831]])\n",
						"模型中偏参梯度 tensor([-0.2898])\n",
						"第 4117 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0830]])\n",
						"模型中偏参梯度 tensor([-0.2897])\n",
						"第 4118 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0829]])\n",
						"模型中偏参梯度 tensor([-0.2896])\n",
						"第 4119 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0829]])\n",
						"模型中偏参梯度 tensor([-0.2894])\n",
						"第 4120 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0829]])\n",
						"模型中偏参梯度 tensor([-0.2893])\n",
						"第 206 次epoch\n",
						"第 4121 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0829]])\n",
						"模型中偏参梯度 tensor([-0.2892])\n",
						"第 4122 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0829]])\n",
						"模型中偏参梯度 tensor([-0.2891])\n",
						"第 4123 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0829]])\n",
						"模型中偏参梯度 tensor([-0.2890])\n",
						"第 4124 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0828]])\n",
						"模型中偏参梯度 tensor([-0.2888])\n",
						"第 4125 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0828]])\n",
						"模型中偏参梯度 tensor([-0.2887])\n",
						"第 4126 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0828]])\n",
						"模型中偏参梯度 tensor([-0.2886])\n",
						"第 4127 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0828]])\n",
						"模型中偏参梯度 tensor([-0.2885])\n",
						"第 4128 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0828]])\n",
						"模型中偏参梯度 tensor([-0.2884])\n",
						"第 4129 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0828]])\n",
						"模型中偏参梯度 tensor([-0.2882])\n",
						"第 4130 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0827]])\n",
						"模型中偏参梯度 tensor([-0.2881])\n",
						"第 4131 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0827]])\n",
						"模型中偏参梯度 tensor([-0.2880])\n",
						"第 4132 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0827]])\n",
						"模型中偏参梯度 tensor([-0.2879])\n",
						"第 4133 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0827]])\n",
						"模型中偏参梯度 tensor([-0.2878])\n",
						"第 4134 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0826]])\n",
						"模型中偏参梯度 tensor([-0.2876])\n",
						"第 4135 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0826]])\n",
						"模型中偏参梯度 tensor([-0.2875])\n",
						"第 4136 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0826]])\n",
						"模型中偏参梯度 tensor([-0.2874])\n",
						"第 4137 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0826]])\n",
						"模型中偏参梯度 tensor([-0.2873])\n",
						"第 4138 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0825]])\n",
						"模型中偏参梯度 tensor([-0.2872])\n",
						"第 4139 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0825]])\n",
						"模型中偏参梯度 tensor([-0.2871])\n",
						"第 4140 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0825]])\n",
						"模型中偏参梯度 tensor([-0.2869])\n",
						"第 207 次epoch\n",
						"第 4141 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0824]])\n",
						"模型中偏参梯度 tensor([-0.2868])\n",
						"第 4142 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0824]])\n",
						"模型中偏参梯度 tensor([-0.2867])\n",
						"第 4143 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0824]])\n",
						"模型中偏参梯度 tensor([-0.2866])\n",
						"第 4144 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0824]])\n",
						"模型中偏参梯度 tensor([-0.2865])\n",
						"第 4145 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0823]])\n",
						"模型中偏参梯度 tensor([-0.2864])\n",
						"第 4146 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0823]])\n",
						"模型中偏参梯度 tensor([-0.2862])\n",
						"第 4147 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0823]])\n",
						"模型中偏参梯度 tensor([-0.2861])\n",
						"第 4148 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0822]])\n",
						"模型中偏参梯度 tensor([-0.2860])\n",
						"第 4149 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0822]])\n",
						"模型中偏参梯度 tensor([-0.2859])\n",
						"第 4150 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0822]])\n",
						"模型中偏参梯度 tensor([-0.2858])\n",
						"第 4151 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0821]])\n",
						"模型中偏参梯度 tensor([-0.2857])\n",
						"第 4152 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0821]])\n",
						"模型中偏参梯度 tensor([-0.2856])\n",
						"第 4153 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0821]])\n",
						"模型中偏参梯度 tensor([-0.2854])\n",
						"第 4154 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0820]])\n",
						"模型中偏参梯度 tensor([-0.2853])\n",
						"第 4155 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0820]])\n",
						"模型中偏参梯度 tensor([-0.2852])\n",
						"第 4156 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0819]])\n",
						"模型中偏参梯度 tensor([-0.2851])\n",
						"第 4157 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0819]])\n",
						"模型中偏参梯度 tensor([-0.2850])\n",
						"第 4158 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0819]])\n",
						"模型中偏参梯度 tensor([-0.2849])\n",
						"第 4159 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0818]])\n",
						"模型中偏参梯度 tensor([-0.2848])\n",
						"第 4160 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0818]])\n",
						"模型中偏参梯度 tensor([-0.2846])\n",
						"第 208 次epoch\n",
						"第 4161 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0817]])\n",
						"模型中偏参梯度 tensor([-0.2845])\n",
						"第 4162 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0817]])\n",
						"模型中偏参梯度 tensor([-0.2844])\n",
						"第 4163 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0817]])\n",
						"模型中偏参梯度 tensor([-0.2843])\n",
						"第 4164 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0816]])\n",
						"模型中偏参梯度 tensor([-0.2842])\n",
						"第 4165 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0816]])\n",
						"模型中偏参梯度 tensor([-0.2841])\n",
						"第 4166 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0815]])\n",
						"模型中偏参梯度 tensor([-0.2840])\n",
						"第 4167 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0815]])\n",
						"模型中偏参梯度 tensor([-0.2839])\n",
						"第 4168 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0814]])\n",
						"模型中偏参梯度 tensor([-0.2838])\n",
						"第 4169 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0814]])\n",
						"模型中偏参梯度 tensor([-0.2836])\n",
						"第 4170 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0813]])\n",
						"模型中偏参梯度 tensor([-0.2835])\n",
						"第 4171 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0813]])\n",
						"模型中偏参梯度 tensor([-0.2834])\n",
						"第 4172 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0812]])\n",
						"模型中偏参梯度 tensor([-0.2833])\n",
						"第 4173 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0812]])\n",
						"模型中偏参梯度 tensor([-0.2832])\n",
						"第 4174 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0811]])\n",
						"模型中偏参梯度 tensor([-0.2831])\n",
						"第 4175 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0811]])\n",
						"模型中偏参梯度 tensor([-0.2830])\n",
						"第 4176 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0810]])\n",
						"模型中偏参梯度 tensor([-0.2829])\n",
						"第 4177 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0810]])\n",
						"模型中偏参梯度 tensor([-0.2828])\n",
						"第 4178 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0810]])\n",
						"模型中偏参梯度 tensor([-0.2826])\n",
						"第 4179 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0810]])\n",
						"模型中偏参梯度 tensor([-0.2825])\n",
						"第 4180 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0810]])\n",
						"模型中偏参梯度 tensor([-0.2824])\n",
						"第 209 次epoch\n",
						"第 4181 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0810]])\n",
						"模型中偏参梯度 tensor([-0.2823])\n",
						"第 4182 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0809]])\n",
						"模型中偏参梯度 tensor([-0.2822])\n",
						"第 4183 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0809]])\n",
						"模型中偏参梯度 tensor([-0.2821])\n",
						"第 4184 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0809]])\n",
						"模型中偏参梯度 tensor([-0.2819])\n",
						"第 4185 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0809]])\n",
						"模型中偏参梯度 tensor([-0.2818])\n",
						"第 4186 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0809]])\n",
						"模型中偏参梯度 tensor([-0.2817])\n",
						"第 4187 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0809]])\n",
						"模型中偏参梯度 tensor([-0.2816])\n",
						"第 4188 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0808]])\n",
						"模型中偏参梯度 tensor([-0.2815])\n",
						"第 4189 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0808]])\n",
						"模型中偏参梯度 tensor([-0.2814])\n",
						"第 4190 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0808]])\n",
						"模型中偏参梯度 tensor([-0.2812])\n",
						"第 4191 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0808]])\n",
						"模型中偏参梯度 tensor([-0.2811])\n",
						"第 4192 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0807]])\n",
						"模型中偏参梯度 tensor([-0.2810])\n",
						"第 4193 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0807]])\n",
						"模型中偏参梯度 tensor([-0.2809])\n",
						"第 4194 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0807]])\n",
						"模型中偏参梯度 tensor([-0.2808])\n",
						"第 4195 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0807]])\n",
						"模型中偏参梯度 tensor([-0.2807])\n",
						"第 4196 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0806]])\n",
						"模型中偏参梯度 tensor([-0.2805])\n",
						"第 4197 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0806]])\n",
						"模型中偏参梯度 tensor([-0.2804])\n",
						"第 4198 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0806]])\n",
						"模型中偏参梯度 tensor([-0.2803])\n",
						"第 4199 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0806]])\n",
						"模型中偏参梯度 tensor([-0.2802])\n",
						"第 4200 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0805]])\n",
						"模型中偏参梯度 tensor([-0.2801])\n",
						"第 210 次epoch\n",
						"第 4201 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0805]])\n",
						"模型中偏参梯度 tensor([-0.2800])\n",
						"第 4202 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0805]])\n",
						"模型中偏参梯度 tensor([-0.2799])\n",
						"第 4203 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0804]])\n",
						"模型中偏参梯度 tensor([-0.2797])\n",
						"第 4204 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0804]])\n",
						"模型中偏参梯度 tensor([-0.2796])\n",
						"第 4205 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0804]])\n",
						"模型中偏参梯度 tensor([-0.2795])\n",
						"第 4206 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0803]])\n",
						"模型中偏参梯度 tensor([-0.2794])\n",
						"第 4207 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0803]])\n",
						"模型中偏参梯度 tensor([-0.2793])\n",
						"第 4208 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0803]])\n",
						"模型中偏参梯度 tensor([-0.2792])\n",
						"第 4209 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0803]])\n",
						"模型中偏参梯度 tensor([-0.2791])\n",
						"第 4210 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0802]])\n",
						"模型中偏参梯度 tensor([-0.2790])\n",
						"第 4211 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0802]])\n",
						"模型中偏参梯度 tensor([-0.2788])\n",
						"第 4212 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0801]])\n",
						"模型中偏参梯度 tensor([-0.2787])\n",
						"第 4213 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0801]])\n",
						"模型中偏参梯度 tensor([-0.2786])\n",
						"第 4214 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0801]])\n",
						"模型中偏参梯度 tensor([-0.2785])\n",
						"第 4215 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0800]])\n",
						"模型中偏参梯度 tensor([-0.2784])\n",
						"第 4216 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0800]])\n",
						"模型中偏参梯度 tensor([-0.2783])\n",
						"第 4217 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0800]])\n",
						"模型中偏参梯度 tensor([-0.2782])\n",
						"第 4218 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0799]])\n",
						"模型中偏参梯度 tensor([-0.2781])\n",
						"第 4219 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0799]])\n",
						"模型中偏参梯度 tensor([-0.2780])\n",
						"第 4220 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0798]])\n",
						"模型中偏参梯度 tensor([-0.2779])\n",
						"第 211 次epoch\n",
						"第 4221 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0798]])\n",
						"模型中偏参梯度 tensor([-0.2777])\n",
						"第 4222 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0798]])\n",
						"模型中偏参梯度 tensor([-0.2776])\n",
						"第 4223 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0797]])\n",
						"模型中偏参梯度 tensor([-0.2775])\n",
						"第 4224 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0797]])\n",
						"模型中偏参梯度 tensor([-0.2774])\n",
						"第 4225 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0796]])\n",
						"模型中偏参梯度 tensor([-0.2773])\n",
						"第 4226 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0796]])\n",
						"模型中偏参梯度 tensor([-0.2772])\n",
						"第 4227 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0795]])\n",
						"模型中偏参梯度 tensor([-0.2771])\n",
						"第 4228 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0795]])\n",
						"模型中偏参梯度 tensor([-0.2770])\n",
						"第 4229 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0794]])\n",
						"模型中偏参梯度 tensor([-0.2769])\n",
						"第 4230 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0794]])\n",
						"模型中偏参梯度 tensor([-0.2768])\n",
						"第 4231 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0793]])\n",
						"模型中偏参梯度 tensor([-0.2767])\n",
						"第 4232 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0793]])\n",
						"模型中偏参梯度 tensor([-0.2766])\n",
						"第 4233 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0792]])\n",
						"模型中偏参梯度 tensor([-0.2765])\n",
						"第 4234 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0792]])\n",
						"模型中偏参梯度 tensor([-0.2764])\n",
						"第 4235 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0791]])\n",
						"模型中偏参梯度 tensor([-0.2762])\n",
						"第 4236 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0791]])\n",
						"模型中偏参梯度 tensor([-0.2761])\n",
						"第 4237 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0791]])\n",
						"模型中偏参梯度 tensor([-0.2760])\n",
						"第 4238 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0791]])\n",
						"模型中偏参梯度 tensor([-0.2759])\n",
						"第 4239 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0791]])\n",
						"模型中偏参梯度 tensor([-0.2758])\n",
						"第 4240 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0791]])\n",
						"模型中偏参梯度 tensor([-0.2757])\n",
						"第 212 次epoch\n",
						"第 4241 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0791]])\n",
						"模型中偏参梯度 tensor([-0.2755])\n",
						"第 4242 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0790]])\n",
						"模型中偏参梯度 tensor([-0.2754])\n",
						"第 4243 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0790]])\n",
						"模型中偏参梯度 tensor([-0.2753])\n",
						"第 4244 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0790]])\n",
						"模型中偏参梯度 tensor([-0.2752])\n",
						"第 4245 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0790]])\n",
						"模型中偏参梯度 tensor([-0.2751])\n",
						"第 4246 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0790]])\n",
						"模型中偏参梯度 tensor([-0.2750])\n",
						"第 4247 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0790]])\n",
						"模型中偏参梯度 tensor([-0.2749])\n",
						"第 4248 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0789]])\n",
						"模型中偏参梯度 tensor([-0.2747])\n",
						"第 4249 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0789]])\n",
						"模型中偏参梯度 tensor([-0.2746])\n",
						"第 4250 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0789]])\n",
						"模型中偏参梯度 tensor([-0.2745])\n",
						"第 4251 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0789]])\n",
						"模型中偏参梯度 tensor([-0.2744])\n",
						"第 4252 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0788]])\n",
						"模型中偏参梯度 tensor([-0.2743])\n",
						"第 4253 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0788]])\n",
						"模型中偏参梯度 tensor([-0.2742])\n",
						"第 4254 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0788]])\n",
						"模型中偏参梯度 tensor([-0.2741])\n",
						"第 4255 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0788]])\n",
						"模型中偏参梯度 tensor([-0.2740])\n",
						"第 4256 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0787]])\n",
						"模型中偏参梯度 tensor([-0.2738])\n",
						"第 4257 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0787]])\n",
						"模型中偏参梯度 tensor([-0.2737])\n",
						"第 4258 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0787]])\n",
						"模型中偏参梯度 tensor([-0.2736])\n",
						"第 4259 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0787]])\n",
						"模型中偏参梯度 tensor([-0.2735])\n",
						"第 4260 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0786]])\n",
						"模型中偏参梯度 tensor([-0.2734])\n",
						"第 213 次epoch\n",
						"第 4261 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0786]])\n",
						"模型中偏参梯度 tensor([-0.2733])\n",
						"第 4262 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0786]])\n",
						"模型中偏参梯度 tensor([-0.2732])\n",
						"第 4263 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0785]])\n",
						"模型中偏参梯度 tensor([-0.2731])\n",
						"第 4264 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0785]])\n",
						"模型中偏参梯度 tensor([-0.2730])\n",
						"第 4265 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0785]])\n",
						"模型中偏参梯度 tensor([-0.2728])\n",
						"第 4266 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0785]])\n",
						"模型中偏参梯度 tensor([-0.2727])\n",
						"第 4267 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0784]])\n",
						"模型中偏参梯度 tensor([-0.2726])\n",
						"第 4268 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0784]])\n",
						"模型中偏参梯度 tensor([-0.2725])\n",
						"第 4269 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0784]])\n",
						"模型中偏参梯度 tensor([-0.2724])\n",
						"第 4270 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0783]])\n",
						"模型中偏参梯度 tensor([-0.2723])\n",
						"第 4271 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0783]])\n",
						"模型中偏参梯度 tensor([-0.2722])\n",
						"第 4272 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0783]])\n",
						"模型中偏参梯度 tensor([-0.2721])\n",
						"第 4273 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0782]])\n",
						"模型中偏参梯度 tensor([-0.2720])\n",
						"第 4274 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0782]])\n",
						"模型中偏参梯度 tensor([-0.2719])\n",
						"第 4275 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0781]])\n",
						"模型中偏参梯度 tensor([-0.2718])\n",
						"第 4276 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0781]])\n",
						"模型中偏参梯度 tensor([-0.2717])\n",
						"第 4277 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0781]])\n",
						"模型中偏参梯度 tensor([-0.2715])\n",
						"第 4278 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0780]])\n",
						"模型中偏参梯度 tensor([-0.2714])\n",
						"第 4279 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0780]])\n",
						"模型中偏参梯度 tensor([-0.2713])\n",
						"第 4280 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0779]])\n",
						"模型中偏参梯度 tensor([-0.2712])\n",
						"第 214 次epoch\n",
						"第 4281 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0779]])\n",
						"模型中偏参梯度 tensor([-0.2711])\n",
						"第 4282 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0779]])\n",
						"模型中偏参梯度 tensor([-0.2710])\n",
						"第 4283 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0778]])\n",
						"模型中偏参梯度 tensor([-0.2709])\n",
						"第 4284 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0778]])\n",
						"模型中偏参梯度 tensor([-0.2708])\n",
						"第 4285 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0777]])\n",
						"模型中偏参梯度 tensor([-0.2707])\n",
						"第 4286 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0777]])\n",
						"模型中偏参梯度 tensor([-0.2706])\n",
						"第 4287 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0777]])\n",
						"模型中偏参梯度 tensor([-0.2705])\n",
						"第 4288 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0776]])\n",
						"模型中偏参梯度 tensor([-0.2704])\n",
						"第 4289 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0776]])\n",
						"模型中偏参梯度 tensor([-0.2703])\n",
						"第 4290 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0775]])\n",
						"模型中偏参梯度 tensor([-0.2702])\n",
						"第 4291 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0775]])\n",
						"模型中偏参梯度 tensor([-0.2701])\n",
						"第 4292 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0774]])\n",
						"模型中偏参梯度 tensor([-0.2700])\n",
						"第 4293 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0774]])\n",
						"模型中偏参梯度 tensor([-0.2699])\n",
						"第 4294 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0773]])\n",
						"模型中偏参梯度 tensor([-0.2698])\n",
						"第 4295 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0773]])\n",
						"模型中偏参梯度 tensor([-0.2697])\n",
						"第 4296 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0772]])\n",
						"模型中偏参梯度 tensor([-0.2695])\n",
						"第 4297 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0772]])\n",
						"模型中偏参梯度 tensor([-0.2694])\n",
						"第 4298 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0772]])\n",
						"模型中偏参梯度 tensor([-0.2693])\n",
						"第 4299 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0772]])\n",
						"模型中偏参梯度 tensor([-0.2692])\n",
						"第 4300 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0772]])\n",
						"模型中偏参梯度 tensor([-0.2691])\n",
						"第 215 次epoch\n",
						"第 4301 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0772]])\n",
						"模型中偏参梯度 tensor([-0.2690])\n",
						"第 4302 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0771]])\n",
						"模型中偏参梯度 tensor([-0.2689])\n",
						"第 4303 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0771]])\n",
						"模型中偏参梯度 tensor([-0.2688])\n",
						"第 4304 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0771]])\n",
						"模型中偏参梯度 tensor([-0.2686])\n",
						"第 4305 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0771]])\n",
						"模型中偏参梯度 tensor([-0.2685])\n",
						"第 4306 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0771]])\n",
						"模型中偏参梯度 tensor([-0.2684])\n",
						"第 4307 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0771]])\n",
						"模型中偏参梯度 tensor([-0.2683])\n",
						"第 4308 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0770]])\n",
						"模型中偏参梯度 tensor([-0.2682])\n",
						"第 4309 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0770]])\n",
						"模型中偏参梯度 tensor([-0.2681])\n",
						"第 4310 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0770]])\n",
						"模型中偏参梯度 tensor([-0.2680])\n",
						"第 4311 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0770]])\n",
						"模型中偏参梯度 tensor([-0.2679])\n",
						"第 4312 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0770]])\n",
						"模型中偏参梯度 tensor([-0.2678])\n",
						"第 4313 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0769]])\n",
						"模型中偏参梯度 tensor([-0.2676])\n",
						"第 4314 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0769]])\n",
						"模型中偏参梯度 tensor([-0.2675])\n",
						"第 4315 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0769]])\n",
						"模型中偏参梯度 tensor([-0.2674])\n",
						"第 4316 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0769]])\n",
						"模型中偏参梯度 tensor([-0.2673])\n",
						"第 4317 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0768]])\n",
						"模型中偏参梯度 tensor([-0.2672])\n",
						"第 4318 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0768]])\n",
						"模型中偏参梯度 tensor([-0.2671])\n",
						"第 4319 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0768]])\n",
						"模型中偏参梯度 tensor([-0.2670])\n",
						"第 4320 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0768]])\n",
						"模型中偏参梯度 tensor([-0.2669])\n",
						"第 216 次epoch\n",
						"第 4321 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0767]])\n",
						"模型中偏参梯度 tensor([-0.2668])\n",
						"第 4322 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0767]])\n",
						"模型中偏参梯度 tensor([-0.2667])\n",
						"第 4323 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0767]])\n",
						"模型中偏参梯度 tensor([-0.2666])\n",
						"第 4324 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0766]])\n",
						"模型中偏参梯度 tensor([-0.2664])\n",
						"第 4325 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0766]])\n",
						"模型中偏参梯度 tensor([-0.2663])\n",
						"第 4326 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0766]])\n",
						"模型中偏参梯度 tensor([-0.2662])\n",
						"第 4327 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0766]])\n",
						"模型中偏参梯度 tensor([-0.2661])\n",
						"第 4328 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0765]])\n",
						"模型中偏参梯度 tensor([-0.2660])\n",
						"第 4329 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0765]])\n",
						"模型中偏参梯度 tensor([-0.2659])\n",
						"第 4330 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0765]])\n",
						"模型中偏参梯度 tensor([-0.2658])\n",
						"第 4331 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0764]])\n",
						"模型中偏参梯度 tensor([-0.2657])\n",
						"第 4332 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0764]])\n",
						"模型中偏参梯度 tensor([-0.2656])\n",
						"第 4333 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0764]])\n",
						"模型中偏参梯度 tensor([-0.2655])\n",
						"第 4334 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0763]])\n",
						"模型中偏参梯度 tensor([-0.2654])\n",
						"第 4335 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0763]])\n",
						"模型中偏参梯度 tensor([-0.2653])\n",
						"第 4336 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0763]])\n",
						"模型中偏参梯度 tensor([-0.2652])\n",
						"第 4337 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0762]])\n",
						"模型中偏参梯度 tensor([-0.2651])\n",
						"第 4338 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0762]])\n",
						"模型中偏参梯度 tensor([-0.2650])\n",
						"第 4339 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0761]])\n",
						"模型中偏参梯度 tensor([-0.2649])\n",
						"第 4340 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0761]])\n",
						"模型中偏参梯度 tensor([-0.2648])\n",
						"第 217 次epoch\n",
						"第 4341 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0761]])\n",
						"模型中偏参梯度 tensor([-0.2646])\n",
						"第 4342 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0760]])\n",
						"模型中偏参梯度 tensor([-0.2645])\n",
						"第 4343 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0760]])\n",
						"模型中偏参梯度 tensor([-0.2644])\n",
						"第 4344 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0759]])\n",
						"模型中偏参梯度 tensor([-0.2643])\n",
						"第 4345 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0759]])\n",
						"模型中偏参梯度 tensor([-0.2642])\n",
						"第 4346 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0759]])\n",
						"模型中偏参梯度 tensor([-0.2641])\n",
						"第 4347 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0758]])\n",
						"模型中偏参梯度 tensor([-0.2640])\n",
						"第 4348 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0758]])\n",
						"模型中偏参梯度 tensor([-0.2639])\n",
						"第 4349 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0757]])\n",
						"模型中偏参梯度 tensor([-0.2638])\n",
						"第 4350 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0757]])\n",
						"模型中偏参梯度 tensor([-0.2637])\n",
						"第 4351 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0756]])\n",
						"模型中偏参梯度 tensor([-0.2636])\n",
						"第 4352 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0756]])\n",
						"模型中偏参梯度 tensor([-0.2635])\n",
						"第 4353 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0756]])\n",
						"模型中偏参梯度 tensor([-0.2634])\n",
						"第 4354 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0755]])\n",
						"模型中偏参梯度 tensor([-0.2633])\n",
						"第 4355 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0755]])\n",
						"模型中偏参梯度 tensor([-0.2632])\n",
						"第 4356 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0754]])\n",
						"模型中偏参梯度 tensor([-0.2631])\n",
						"第 4357 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0754]])\n",
						"模型中偏参梯度 tensor([-0.2630])\n",
						"第 4358 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0753]])\n",
						"模型中偏参梯度 tensor([-0.2629])\n",
						"第 4359 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0753]])\n",
						"模型中偏参梯度 tensor([-0.2628])\n",
						"第 4360 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0753]])\n",
						"模型中偏参梯度 tensor([-0.2627])\n",
						"第 218 次epoch\n",
						"第 4361 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0753]])\n",
						"模型中偏参梯度 tensor([-0.2626])\n",
						"第 4362 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0753]])\n",
						"模型中偏参梯度 tensor([-0.2625])\n",
						"第 4363 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0753]])\n",
						"模型中偏参梯度 tensor([-0.2624])\n",
						"第 4364 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0752]])\n",
						"模型中偏参梯度 tensor([-0.2622])\n",
						"第 4365 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0752]])\n",
						"模型中偏参梯度 tensor([-0.2621])\n",
						"第 4366 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0752]])\n",
						"模型中偏参梯度 tensor([-0.2620])\n",
						"第 4367 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0752]])\n",
						"模型中偏参梯度 tensor([-0.2619])\n",
						"第 4368 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0752]])\n",
						"模型中偏参梯度 tensor([-0.2618])\n",
						"第 4369 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0752]])\n",
						"模型中偏参梯度 tensor([-0.2617])\n",
						"第 4370 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0751]])\n",
						"模型中偏参梯度 tensor([-0.2616])\n",
						"第 4371 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0751]])\n",
						"模型中偏参梯度 tensor([-0.2615])\n",
						"第 4372 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0751]])\n",
						"模型中偏参梯度 tensor([-0.2614])\n",
						"第 4373 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0751]])\n",
						"模型中偏参梯度 tensor([-0.2613])\n",
						"第 4374 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0751]])\n",
						"模型中偏参梯度 tensor([-0.2612])\n",
						"第 4375 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0750]])\n",
						"模型中偏参梯度 tensor([-0.2610])\n",
						"第 4376 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0750]])\n",
						"模型中偏参梯度 tensor([-0.2609])\n",
						"第 4377 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0750]])\n",
						"模型中偏参梯度 tensor([-0.2608])\n",
						"第 4378 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0750]])\n",
						"模型中偏参梯度 tensor([-0.2607])\n",
						"第 4379 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0750]])\n",
						"模型中偏参梯度 tensor([-0.2606])\n",
						"第 4380 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0749]])\n",
						"模型中偏参梯度 tensor([-0.2605])\n",
						"第 219 次epoch\n",
						"第 4381 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0749]])\n",
						"模型中偏参梯度 tensor([-0.2604])\n",
						"第 4382 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0749]])\n",
						"模型中偏参梯度 tensor([-0.2603])\n",
						"第 4383 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0748]])\n",
						"模型中偏参梯度 tensor([-0.2602])\n",
						"第 4384 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0748]])\n",
						"模型中偏参梯度 tensor([-0.2601])\n",
						"第 4385 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0748]])\n",
						"模型中偏参梯度 tensor([-0.2600])\n",
						"第 4386 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0748]])\n",
						"模型中偏参梯度 tensor([-0.2599])\n",
						"第 4387 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0747]])\n",
						"模型中偏参梯度 tensor([-0.2598])\n",
						"第 4388 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0747]])\n",
						"模型中偏参梯度 tensor([-0.2597])\n",
						"第 4389 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0747]])\n",
						"模型中偏参梯度 tensor([-0.2596])\n",
						"第 4390 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0747]])\n",
						"模型中偏参梯度 tensor([-0.2595])\n",
						"第 4391 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0746]])\n",
						"模型中偏参梯度 tensor([-0.2594])\n",
						"第 4392 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0746]])\n",
						"模型中偏参梯度 tensor([-0.2593])\n",
						"第 4393 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0746]])\n",
						"模型中偏参梯度 tensor([-0.2591])\n",
						"第 4394 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0745]])\n",
						"模型中偏参梯度 tensor([-0.2590])\n",
						"第 4395 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0745]])\n",
						"模型中偏参梯度 tensor([-0.2589])\n",
						"第 4396 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0745]])\n",
						"模型中偏参梯度 tensor([-0.2588])\n",
						"第 4397 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0744]])\n",
						"模型中偏参梯度 tensor([-0.2587])\n",
						"第 4398 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0744]])\n",
						"模型中偏参梯度 tensor([-0.2586])\n",
						"第 4399 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0744]])\n",
						"模型中偏参梯度 tensor([-0.2585])\n",
						"第 4400 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0743]])\n",
						"模型中偏参梯度 tensor([-0.2584])\n",
						"第 220 次epoch\n",
						"第 4401 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0743]])\n",
						"模型中偏参梯度 tensor([-0.2583])\n",
						"第 4402 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0742]])\n",
						"模型中偏参梯度 tensor([-0.2582])\n",
						"第 4403 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0742]])\n",
						"模型中偏参梯度 tensor([-0.2581])\n",
						"第 4404 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0742]])\n",
						"模型中偏参梯度 tensor([-0.2580])\n",
						"第 4405 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0741]])\n",
						"模型中偏参梯度 tensor([-0.2579])\n",
						"第 4406 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0741]])\n",
						"模型中偏参梯度 tensor([-0.2578])\n",
						"第 4407 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0741]])\n",
						"模型中偏参梯度 tensor([-0.2577])\n",
						"第 4408 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0740]])\n",
						"模型中偏参梯度 tensor([-0.2576])\n",
						"第 4409 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0740]])\n",
						"模型中偏参梯度 tensor([-0.2575])\n",
						"第 4410 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0739]])\n",
						"模型中偏参梯度 tensor([-0.2574])\n",
						"第 4411 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0739]])\n",
						"模型中偏参梯度 tensor([-0.2573])\n",
						"第 4412 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0738]])\n",
						"模型中偏参梯度 tensor([-0.2572])\n",
						"第 4413 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0738]])\n",
						"模型中偏参梯度 tensor([-0.2571])\n",
						"第 4414 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0738]])\n",
						"模型中偏参梯度 tensor([-0.2570])\n",
						"第 4415 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0737]])\n",
						"模型中偏参梯度 tensor([-0.2569])\n",
						"第 4416 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0737]])\n",
						"模型中偏参梯度 tensor([-0.2568])\n",
						"第 4417 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0736]])\n",
						"模型中偏参梯度 tensor([-0.2567])\n",
						"第 4418 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0736]])\n",
						"模型中偏参梯度 tensor([-0.2566])\n",
						"第 4419 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0735]])\n",
						"模型中偏参梯度 tensor([-0.2565])\n",
						"第 4420 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0735]])\n",
						"模型中偏参梯度 tensor([-0.2564])\n",
						"第 221 次epoch\n",
						"第 4421 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0734]])\n",
						"模型中偏参梯度 tensor([-0.2563])\n",
						"第 4422 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0734]])\n",
						"模型中偏参梯度 tensor([-0.2562])\n",
						"第 4423 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0734]])\n",
						"模型中偏参梯度 tensor([-0.2561])\n",
						"第 4424 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0734]])\n",
						"模型中偏参梯度 tensor([-0.2560])\n",
						"第 4425 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0734]])\n",
						"模型中偏参梯度 tensor([-0.2559])\n",
						"第 4426 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0733]])\n",
						"模型中偏参梯度 tensor([-0.2558])\n",
						"第 4427 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0733]])\n",
						"模型中偏参梯度 tensor([-0.2557])\n",
						"第 4428 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0733]])\n",
						"模型中偏参梯度 tensor([-0.2556])\n",
						"第 4429 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0733]])\n",
						"模型中偏参梯度 tensor([-0.2555])\n",
						"第 4430 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0733]])\n",
						"模型中偏参梯度 tensor([-0.2554])\n",
						"第 4431 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0733]])\n",
						"模型中偏参梯度 tensor([-0.2553])\n",
						"第 4432 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0733]])\n",
						"模型中偏参梯度 tensor([-0.2552])\n",
						"第 4433 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0732]])\n",
						"模型中偏参梯度 tensor([-0.2550])\n",
						"第 4434 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0732]])\n",
						"模型中偏参梯度 tensor([-0.2549])\n",
						"第 4435 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0732]])\n",
						"模型中偏参梯度 tensor([-0.2548])\n",
						"第 4436 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0732]])\n",
						"模型中偏参梯度 tensor([-0.2547])\n",
						"第 4437 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0732]])\n",
						"模型中偏参梯度 tensor([-0.2546])\n",
						"第 4438 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0732]])\n",
						"模型中偏参梯度 tensor([-0.2545])\n",
						"第 4439 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0731]])\n",
						"模型中偏参梯度 tensor([-0.2544])\n",
						"第 4440 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0731]])\n",
						"模型中偏参梯度 tensor([-0.2543])\n",
						"第 222 次epoch\n",
						"第 4441 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0731]])\n",
						"模型中偏参梯度 tensor([-0.2542])\n",
						"第 4442 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0731]])\n",
						"模型中偏参梯度 tensor([-0.2541])\n",
						"第 4443 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0730]])\n",
						"模型中偏参梯度 tensor([-0.2540])\n",
						"第 4444 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0730]])\n",
						"模型中偏参梯度 tensor([-0.2539])\n",
						"第 4445 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0730]])\n",
						"模型中偏参梯度 tensor([-0.2538])\n",
						"第 4446 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0730]])\n",
						"模型中偏参梯度 tensor([-0.2537])\n",
						"第 4447 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0729]])\n",
						"模型中偏参梯度 tensor([-0.2536])\n",
						"第 4448 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0729]])\n",
						"模型中偏参梯度 tensor([-0.2535])\n",
						"第 4449 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0729]])\n",
						"模型中偏参梯度 tensor([-0.2534])\n",
						"第 4450 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0729]])\n",
						"模型中偏参梯度 tensor([-0.2533])\n",
						"第 4451 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0728]])\n",
						"模型中偏参梯度 tensor([-0.2532])\n",
						"第 4452 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0728]])\n",
						"模型中偏参梯度 tensor([-0.2531])\n",
						"第 4453 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0728]])\n",
						"模型中偏参梯度 tensor([-0.2530])\n",
						"第 4454 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0728]])\n",
						"模型中偏参梯度 tensor([-0.2529])\n",
						"第 4455 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0727]])\n",
						"模型中偏参梯度 tensor([-0.2528])\n",
						"第 4456 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0727]])\n",
						"模型中偏参梯度 tensor([-0.2527])\n",
						"第 4457 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0727]])\n",
						"模型中偏参梯度 tensor([-0.2526])\n",
						"第 4458 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0726]])\n",
						"模型中偏参梯度 tensor([-0.2525])\n",
						"第 4459 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0726]])\n",
						"模型中偏参梯度 tensor([-0.2524])\n",
						"第 4460 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0726]])\n",
						"模型中偏参梯度 tensor([-0.2523])\n",
						"第 223 次epoch\n",
						"第 4461 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0725]])\n",
						"模型中偏参梯度 tensor([-0.2522])\n",
						"第 4462 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0725]])\n",
						"模型中偏参梯度 tensor([-0.2521])\n",
						"第 4463 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0725]])\n",
						"模型中偏参梯度 tensor([-0.2520])\n",
						"第 4464 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0724]])\n",
						"模型中偏参梯度 tensor([-0.2519])\n",
						"第 4465 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0724]])\n",
						"模型中偏参梯度 tensor([-0.2518])\n",
						"第 4466 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0724]])\n",
						"模型中偏参梯度 tensor([-0.2517])\n",
						"第 4467 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0723]])\n",
						"模型中偏参梯度 tensor([-0.2516])\n",
						"第 4468 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0723]])\n",
						"模型中偏参梯度 tensor([-0.2515])\n",
						"第 4469 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0723]])\n",
						"模型中偏参梯度 tensor([-0.2514])\n",
						"第 4470 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0722]])\n",
						"模型中偏参梯度 tensor([-0.2513])\n",
						"第 4471 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0722]])\n",
						"模型中偏参梯度 tensor([-0.2512])\n",
						"第 4472 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0721]])\n",
						"模型中偏参梯度 tensor([-0.2511])\n",
						"第 4473 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0721]])\n",
						"模型中偏参梯度 tensor([-0.2510])\n",
						"第 4474 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0721]])\n",
						"模型中偏参梯度 tensor([-0.2509])\n",
						"第 4475 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0720]])\n",
						"模型中偏参梯度 tensor([-0.2508])\n",
						"第 4476 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0720]])\n",
						"模型中偏参梯度 tensor([-0.2507])\n",
						"第 4477 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0719]])\n",
						"模型中偏参梯度 tensor([-0.2506])\n",
						"第 4478 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0719]])\n",
						"模型中偏参梯度 tensor([-0.2505])\n",
						"第 4479 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0719]])\n",
						"模型中偏参梯度 tensor([-0.2504])\n",
						"第 4480 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0718]])\n",
						"模型中偏参梯度 tensor([-0.2503])\n",
						"第 224 次epoch\n",
						"第 4481 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0718]])\n",
						"模型中偏参梯度 tensor([-0.2502])\n",
						"第 4482 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0717]])\n",
						"模型中偏参梯度 tensor([-0.2501])\n",
						"第 4483 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0717]])\n",
						"模型中偏参梯度 tensor([-0.2500])\n",
						"第 4484 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0716]])\n",
						"模型中偏参梯度 tensor([-0.2499])\n",
						"第 4485 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0716]])\n",
						"模型中偏参梯度 tensor([-0.2498])\n",
						"第 4486 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0715]])\n",
						"模型中偏参梯度 tensor([-0.2497])\n",
						"第 4487 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0715]])\n",
						"模型中偏参梯度 tensor([-0.2496])\n",
						"第 4488 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0715]])\n",
						"模型中偏参梯度 tensor([-0.2495])\n",
						"第 4489 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0715]])\n",
						"模型中偏参梯度 tensor([-0.2494])\n",
						"第 4490 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0715]])\n",
						"模型中偏参梯度 tensor([-0.2493])\n",
						"第 4491 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0714]])\n",
						"模型中偏参梯度 tensor([-0.2492])\n",
						"第 4492 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0714]])\n",
						"模型中偏参梯度 tensor([-0.2491])\n",
						"第 4493 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0714]])\n",
						"模型中偏参梯度 tensor([-0.2490])\n",
						"第 4494 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0714]])\n",
						"模型中偏参梯度 tensor([-0.2489])\n",
						"第 4495 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0714]])\n",
						"模型中偏参梯度 tensor([-0.2488])\n",
						"第 4496 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0714]])\n",
						"模型中偏参梯度 tensor([-0.2487])\n",
						"第 4497 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0714]])\n",
						"模型中偏参梯度 tensor([-0.2486])\n",
						"第 4498 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0714]])\n",
						"模型中偏参梯度 tensor([-0.2485])\n",
						"第 4499 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0713]])\n",
						"模型中偏参梯度 tensor([-0.2484])\n",
						"第 4500 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0713]])\n",
						"模型中偏参梯度 tensor([-0.2483])\n",
						"第 225 次epoch\n",
						"第 4501 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0713]])\n",
						"模型中偏参梯度 tensor([-0.2482])\n",
						"第 4502 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0713]])\n",
						"模型中偏参梯度 tensor([-0.2480])\n",
						"第 4503 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0713]])\n",
						"模型中偏参梯度 tensor([-0.2479])\n",
						"第 4504 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0712]])\n",
						"模型中偏参梯度 tensor([-0.2478])\n",
						"第 4505 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0712]])\n",
						"模型中偏参梯度 tensor([-0.2477])\n",
						"第 4506 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0712]])\n",
						"模型中偏参梯度 tensor([-0.2476])\n",
						"第 4507 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0712]])\n",
						"模型中偏参梯度 tensor([-0.2475])\n",
						"第 4508 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0712]])\n",
						"模型中偏参梯度 tensor([-0.2474])\n",
						"第 4509 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0711]])\n",
						"模型中偏参梯度 tensor([-0.2473])\n",
						"第 4510 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0711]])\n",
						"模型中偏参梯度 tensor([-0.2472])\n",
						"第 4511 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0711]])\n",
						"模型中偏参梯度 tensor([-0.2471])\n",
						"第 4512 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0711]])\n",
						"模型中偏参梯度 tensor([-0.2470])\n",
						"第 4513 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0711]])\n",
						"模型中偏参梯度 tensor([-0.2469])\n",
						"第 4514 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0710]])\n",
						"模型中偏参梯度 tensor([-0.2468])\n",
						"第 4515 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0710]])\n",
						"模型中偏参梯度 tensor([-0.2467])\n",
						"第 4516 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0710]])\n",
						"模型中偏参梯度 tensor([-0.2466])\n",
						"第 4517 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0709]])\n",
						"模型中偏参梯度 tensor([-0.2465])\n",
						"第 4518 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0709]])\n",
						"模型中偏参梯度 tensor([-0.2464])\n",
						"第 4519 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0709]])\n",
						"模型中偏参梯度 tensor([-0.2463])\n",
						"第 4520 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0709]])\n",
						"模型中偏参梯度 tensor([-0.2462])\n",
						"第 226 次epoch\n",
						"第 4521 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0708]])\n",
						"模型中偏参梯度 tensor([-0.2461])\n",
						"第 4522 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0708]])\n",
						"模型中偏参梯度 tensor([-0.2460])\n",
						"第 4523 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0708]])\n",
						"模型中偏参梯度 tensor([-0.2459])\n",
						"第 4524 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0708]])\n",
						"模型中偏参梯度 tensor([-0.2458])\n",
						"第 4525 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0707]])\n",
						"模型中偏参梯度 tensor([-0.2457])\n",
						"第 4526 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0707]])\n",
						"模型中偏参梯度 tensor([-0.2456])\n",
						"第 4527 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0707]])\n",
						"模型中偏参梯度 tensor([-0.2455])\n",
						"第 4528 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0706]])\n",
						"模型中偏参梯度 tensor([-0.2454])\n",
						"第 4529 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0706]])\n",
						"模型中偏参梯度 tensor([-0.2453])\n",
						"第 4530 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0706]])\n",
						"模型中偏参梯度 tensor([-0.2453])\n",
						"第 4531 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0705]])\n",
						"模型中偏参梯度 tensor([-0.2452])\n",
						"第 4532 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0705]])\n",
						"模型中偏参梯度 tensor([-0.2451])\n",
						"第 4533 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0705]])\n",
						"模型中偏参梯度 tensor([-0.2450])\n",
						"第 4534 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0704]])\n",
						"模型中偏参梯度 tensor([-0.2449])\n",
						"第 4535 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0704]])\n",
						"模型中偏参梯度 tensor([-0.2448])\n",
						"第 4536 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0703]])\n",
						"模型中偏参梯度 tensor([-0.2447])\n",
						"第 4537 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0703]])\n",
						"模型中偏参梯度 tensor([-0.2446])\n",
						"第 4538 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0703]])\n",
						"模型中偏参梯度 tensor([-0.2445])\n",
						"第 4539 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0702]])\n",
						"模型中偏参梯度 tensor([-0.2444])\n",
						"第 4540 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0702]])\n",
						"模型中偏参梯度 tensor([-0.2443])\n",
						"第 227 次epoch\n",
						"第 4541 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0702]])\n",
						"模型中偏参梯度 tensor([-0.2442])\n",
						"第 4542 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0701]])\n",
						"模型中偏参梯度 tensor([-0.2441])\n",
						"第 4543 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0701]])\n",
						"模型中偏参梯度 tensor([-0.2440])\n",
						"第 4544 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0700]])\n",
						"模型中偏参梯度 tensor([-0.2439])\n",
						"第 4545 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0700]])\n",
						"模型中偏参梯度 tensor([-0.2438])\n",
						"第 4546 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0700]])\n",
						"模型中偏参梯度 tensor([-0.2437])\n",
						"第 4547 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0699]])\n",
						"模型中偏参梯度 tensor([-0.2436])\n",
						"第 4548 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0699]])\n",
						"模型中偏参梯度 tensor([-0.2435])\n",
						"第 4549 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0698]])\n",
						"模型中偏参梯度 tensor([-0.2434])\n",
						"第 4550 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0698]])\n",
						"模型中偏参梯度 tensor([-0.2433])\n",
						"第 4551 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0697]])\n",
						"模型中偏参梯度 tensor([-0.2433])\n",
						"第 4552 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0697]])\n",
						"模型中偏参梯度 tensor([-0.2432])\n",
						"第 4553 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0696]])\n",
						"模型中偏参梯度 tensor([-0.2431])\n",
						"第 4554 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0696]])\n",
						"模型中偏参梯度 tensor([-0.2430])\n",
						"第 4555 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0696]])\n",
						"模型中偏参梯度 tensor([-0.2429])\n",
						"第 4556 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0696]])\n",
						"模型中偏参梯度 tensor([-0.2428])\n",
						"第 4557 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0696]])\n",
						"模型中偏参梯度 tensor([-0.2427])\n",
						"第 4558 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0696]])\n",
						"模型中偏参梯度 tensor([-0.2426])\n",
						"第 4559 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0696]])\n",
						"模型中偏参梯度 tensor([-0.2425])\n",
						"第 4560 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0695]])\n",
						"模型中偏参梯度 tensor([-0.2424])\n",
						"第 228 次epoch\n",
						"第 4561 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0695]])\n",
						"模型中偏参梯度 tensor([-0.2423])\n",
						"第 4562 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0695]])\n",
						"模型中偏参梯度 tensor([-0.2422])\n",
						"第 4563 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0695]])\n",
						"模型中偏参梯度 tensor([-0.2421])\n",
						"第 4564 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0695]])\n",
						"模型中偏参梯度 tensor([-0.2420])\n",
						"第 4565 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0695]])\n",
						"模型中偏参梯度 tensor([-0.2419])\n",
						"第 4566 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0695]])\n",
						"模型中偏参梯度 tensor([-0.2418])\n",
						"第 4567 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0694]])\n",
						"模型中偏参梯度 tensor([-0.2416])\n",
						"第 4568 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0694]])\n",
						"模型中偏参梯度 tensor([-0.2415])\n",
						"第 4569 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0694]])\n",
						"模型中偏参梯度 tensor([-0.2414])\n",
						"第 4570 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0694]])\n",
						"模型中偏参梯度 tensor([-0.2413])\n",
						"第 4571 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0694]])\n",
						"模型中偏参梯度 tensor([-0.2412])\n",
						"第 4572 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0694]])\n",
						"模型中偏参梯度 tensor([-0.2411])\n",
						"第 4573 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0693]])\n",
						"模型中偏参梯度 tensor([-0.2411])\n",
						"第 4574 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0693]])\n",
						"模型中偏参梯度 tensor([-0.2409])\n",
						"第 4575 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0693]])\n",
						"模型中偏参梯度 tensor([-0.2409])\n",
						"第 4576 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0693]])\n",
						"模型中偏参梯度 tensor([-0.2408])\n",
						"第 4577 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0693]])\n",
						"模型中偏参梯度 tensor([-0.2407])\n",
						"第 4578 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0692]])\n",
						"模型中偏参梯度 tensor([-0.2406])\n",
						"第 4579 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0692]])\n",
						"模型中偏参梯度 tensor([-0.2405])\n",
						"第 4580 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0692]])\n",
						"模型中偏参梯度 tensor([-0.2404])\n",
						"第 229 次epoch\n",
						"第 4581 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0692]])\n",
						"模型中偏参梯度 tensor([-0.2403])\n",
						"第 4582 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0691]])\n",
						"模型中偏参梯度 tensor([-0.2402])\n",
						"第 4583 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0691]])\n",
						"模型中偏参梯度 tensor([-0.2401])\n",
						"第 4584 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0691]])\n",
						"模型中偏参梯度 tensor([-0.2400])\n",
						"第 4585 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0691]])\n",
						"模型中偏参梯度 tensor([-0.2399])\n",
						"第 4586 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0690]])\n",
						"模型中偏参梯度 tensor([-0.2398])\n",
						"第 4587 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0690]])\n",
						"模型中偏参梯度 tensor([-0.2397])\n",
						"第 4588 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0690]])\n",
						"模型中偏参梯度 tensor([-0.2396])\n",
						"第 4589 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0689]])\n",
						"模型中偏参梯度 tensor([-0.2395])\n",
						"第 4590 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0689]])\n",
						"模型中偏参梯度 tensor([-0.2394])\n",
						"第 4591 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0689]])\n",
						"模型中偏参梯度 tensor([-0.2393])\n",
						"第 4592 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0689]])\n",
						"模型中偏参梯度 tensor([-0.2392])\n",
						"第 4593 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0688]])\n",
						"模型中偏参梯度 tensor([-0.2391])\n",
						"第 4594 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0688]])\n",
						"模型中偏参梯度 tensor([-0.2390])\n",
						"第 4595 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0688]])\n",
						"模型中偏参梯度 tensor([-0.2389])\n",
						"第 4596 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0687]])\n",
						"模型中偏参梯度 tensor([-0.2388])\n",
						"第 4597 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0687]])\n",
						"模型中偏参梯度 tensor([-0.2387])\n",
						"第 4598 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0687]])\n",
						"模型中偏参梯度 tensor([-0.2386])\n",
						"第 4599 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0686]])\n",
						"模型中偏参梯度 tensor([-0.2385])\n",
						"第 4600 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0686]])\n",
						"模型中偏参梯度 tensor([-0.2384])\n",
						"第 230 次epoch\n",
						"第 4601 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0686]])\n",
						"模型中偏参梯度 tensor([-0.2383])\n",
						"第 4602 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0685]])\n",
						"模型中偏参梯度 tensor([-0.2382])\n",
						"第 4603 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0685]])\n",
						"模型中偏参梯度 tensor([-0.2382])\n",
						"第 4604 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0685]])\n",
						"模型中偏参梯度 tensor([-0.2381])\n",
						"第 4605 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0684]])\n",
						"模型中偏参梯度 tensor([-0.2380])\n",
						"第 4606 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0684]])\n",
						"模型中偏参梯度 tensor([-0.2379])\n",
						"第 4607 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0684]])\n",
						"模型中偏参梯度 tensor([-0.2378])\n",
						"第 4608 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0683]])\n",
						"模型中偏参梯度 tensor([-0.2377])\n",
						"第 4609 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0683]])\n",
						"模型中偏参梯度 tensor([-0.2376])\n",
						"第 4610 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0682]])\n",
						"模型中偏参梯度 tensor([-0.2375])\n",
						"第 4611 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0682]])\n",
						"模型中偏参梯度 tensor([-0.2374])\n",
						"第 4612 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0682]])\n",
						"模型中偏参梯度 tensor([-0.2373])\n",
						"第 4613 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0681]])\n",
						"模型中偏参梯度 tensor([-0.2372])\n",
						"第 4614 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0681]])\n",
						"模型中偏参梯度 tensor([-0.2371])\n",
						"第 4615 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0680]])\n",
						"模型中偏参梯度 tensor([-0.2370])\n",
						"第 4616 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0680]])\n",
						"模型中偏参梯度 tensor([-0.2370])\n",
						"第 4617 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0680]])\n",
						"模型中偏参梯度 tensor([-0.2369])\n",
						"第 4618 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0679]])\n",
						"模型中偏参梯度 tensor([-0.2368])\n",
						"第 4619 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0679]])\n",
						"模型中偏参梯度 tensor([-0.2367])\n",
						"第 4620 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0678]])\n",
						"模型中偏参梯度 tensor([-0.2366])\n",
						"第 231 次epoch\n",
						"第 4621 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0678]])\n",
						"模型中偏参梯度 tensor([-0.2365])\n",
						"第 4622 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0677]])\n",
						"模型中偏参梯度 tensor([-0.2364])\n",
						"第 4623 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0677]])\n",
						"模型中偏参梯度 tensor([-0.2363])\n",
						"第 4624 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0677]])\n",
						"模型中偏参梯度 tensor([-0.2362])\n",
						"第 4625 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0677]])\n",
						"模型中偏参梯度 tensor([-0.2361])\n",
						"第 4626 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0677]])\n",
						"模型中偏参梯度 tensor([-0.2360])\n",
						"第 4627 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0677]])\n",
						"模型中偏参梯度 tensor([-0.2359])\n",
						"第 4628 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0677]])\n",
						"模型中偏参梯度 tensor([-0.2358])\n",
						"第 4629 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0676]])\n",
						"模型中偏参梯度 tensor([-0.2357])\n",
						"第 4630 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0676]])\n",
						"模型中偏参梯度 tensor([-0.2356])\n",
						"第 4631 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0676]])\n",
						"模型中偏参梯度 tensor([-0.2355])\n",
						"第 4632 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0676]])\n",
						"模型中偏参梯度 tensor([-0.2354])\n",
						"第 4633 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0676]])\n",
						"模型中偏参梯度 tensor([-0.2353])\n",
						"第 4634 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0676]])\n",
						"模型中偏参梯度 tensor([-0.2352])\n",
						"第 4635 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0676]])\n",
						"模型中偏参梯度 tensor([-0.2351])\n",
						"第 4636 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0675]])\n",
						"模型中偏参梯度 tensor([-0.2350])\n",
						"第 4637 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0675]])\n",
						"模型中偏参梯度 tensor([-0.2349])\n",
						"第 4638 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0675]])\n",
						"模型中偏参梯度 tensor([-0.2348])\n",
						"第 4639 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0675]])\n",
						"模型中偏参梯度 tensor([-0.2347])\n",
						"第 4640 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0675]])\n",
						"模型中偏参梯度 tensor([-0.2346])\n",
						"第 232 次epoch\n",
						"第 4641 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0675]])\n",
						"模型中偏参梯度 tensor([-0.2345])\n",
						"第 4642 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0675]])\n",
						"模型中偏参梯度 tensor([-0.2344])\n",
						"第 4643 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0674]])\n",
						"模型中偏参梯度 tensor([-0.2343])\n",
						"第 4644 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0674]])\n",
						"模型中偏参梯度 tensor([-0.2343])\n",
						"第 4645 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0674]])\n",
						"模型中偏参梯度 tensor([-0.2342])\n",
						"第 4646 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0674]])\n",
						"模型中偏参梯度 tensor([-0.2341])\n",
						"第 4647 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0673]])\n",
						"模型中偏参梯度 tensor([-0.2340])\n",
						"第 4648 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0673]])\n",
						"模型中偏参梯度 tensor([-0.2339])\n",
						"第 4649 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0673]])\n",
						"模型中偏参梯度 tensor([-0.2338])\n",
						"第 4650 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0673]])\n",
						"模型中偏参梯度 tensor([-0.2337])\n",
						"第 4651 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0673]])\n",
						"模型中偏参梯度 tensor([-0.2336])\n",
						"第 4652 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0672]])\n",
						"模型中偏参梯度 tensor([-0.2335])\n",
						"第 4653 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0672]])\n",
						"模型中偏参梯度 tensor([-0.2334])\n",
						"第 4654 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0672]])\n",
						"模型中偏参梯度 tensor([-0.2333])\n",
						"第 4655 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0672]])\n",
						"模型中偏参梯度 tensor([-0.2332])\n",
						"第 4656 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0671]])\n",
						"模型中偏参梯度 tensor([-0.2331])\n",
						"第 4657 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0671]])\n",
						"模型中偏参梯度 tensor([-0.2330])\n",
						"第 4658 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0671]])\n",
						"模型中偏参梯度 tensor([-0.2329])\n",
						"第 4659 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0671]])\n",
						"模型中偏参梯度 tensor([-0.2328])\n",
						"第 4660 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0670]])\n",
						"模型中偏参梯度 tensor([-0.2327])\n",
						"第 233 次epoch\n",
						"第 4661 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0670]])\n",
						"模型中偏参梯度 tensor([-0.2326])\n",
						"第 4662 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0670]])\n",
						"模型中偏参梯度 tensor([-0.2325])\n",
						"第 4663 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0669]])\n",
						"模型中偏参梯度 tensor([-0.2325])\n",
						"第 4664 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0669]])\n",
						"模型中偏参梯度 tensor([-0.2324])\n",
						"第 4665 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0669]])\n",
						"模型中偏参梯度 tensor([-0.2323])\n",
						"第 4666 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0668]])\n",
						"模型中偏参梯度 tensor([-0.2322])\n",
						"第 4667 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0668]])\n",
						"模型中偏参梯度 tensor([-0.2321])\n",
						"第 4668 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0668]])\n",
						"模型中偏参梯度 tensor([-0.2320])\n",
						"第 4669 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0668]])\n",
						"模型中偏参梯度 tensor([-0.2319])\n",
						"第 4670 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0667]])\n",
						"模型中偏参梯度 tensor([-0.2318])\n",
						"第 4671 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0667]])\n",
						"模型中偏参梯度 tensor([-0.2317])\n",
						"第 4672 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0667]])\n",
						"模型中偏参梯度 tensor([-0.2316])\n",
						"第 4673 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0666]])\n",
						"模型中偏参梯度 tensor([-0.2315])\n",
						"第 4674 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0666]])\n",
						"模型中偏参梯度 tensor([-0.2314])\n",
						"第 4675 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0666]])\n",
						"模型中偏参梯度 tensor([-0.2314])\n",
						"第 4676 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0665]])\n",
						"模型中偏参梯度 tensor([-0.2313])\n",
						"第 4677 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0665]])\n",
						"模型中偏参梯度 tensor([-0.2312])\n",
						"第 4678 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0664]])\n",
						"模型中偏参梯度 tensor([-0.2311])\n",
						"第 4679 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0664]])\n",
						"模型中偏参梯度 tensor([-0.2310])\n",
						"第 4680 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0664]])\n",
						"模型中偏参梯度 tensor([-0.2309])\n",
						"第 234 次epoch\n",
						"第 4681 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0663]])\n",
						"模型中偏参梯度 tensor([-0.2308])\n",
						"第 4682 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0663]])\n",
						"模型中偏参梯度 tensor([-0.2307])\n",
						"第 4683 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0663]])\n",
						"模型中偏参梯度 tensor([-0.2306])\n",
						"第 4684 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0662]])\n",
						"模型中偏参梯度 tensor([-0.2305])\n",
						"第 4685 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0662]])\n",
						"模型中偏参梯度 tensor([-0.2305])\n",
						"第 4686 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0661]])\n",
						"模型中偏参梯度 tensor([-0.2304])\n",
						"第 4687 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0661]])\n",
						"模型中偏参梯度 tensor([-0.2303])\n",
						"第 4688 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0660]])\n",
						"模型中偏参梯度 tensor([-0.2302])\n",
						"第 4689 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0660]])\n",
						"模型中偏参梯度 tensor([-0.2301])\n",
						"第 4690 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0660]])\n",
						"模型中偏参梯度 tensor([-0.2300])\n",
						"第 4691 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0659]])\n",
						"模型中偏参梯度 tensor([-0.2299])\n",
						"第 4692 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0659]])\n",
						"模型中偏参梯度 tensor([-0.2298])\n",
						"第 4693 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0658]])\n",
						"模型中偏参梯度 tensor([-0.2298])\n",
						"第 4694 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0658]])\n",
						"模型中偏参梯度 tensor([-0.2297])\n",
						"第 4695 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0658]])\n",
						"模型中偏参梯度 tensor([-0.2296])\n",
						"第 4696 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0658]])\n",
						"模型中偏参梯度 tensor([-0.2295])\n",
						"第 4697 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0658]])\n",
						"模型中偏参梯度 tensor([-0.2294])\n",
						"第 4698 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0658]])\n",
						"模型中偏参梯度 tensor([-0.2293])\n",
						"第 4699 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0657]])\n",
						"模型中偏参梯度 tensor([-0.2292])\n",
						"第 4700 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0657]])\n",
						"模型中偏参梯度 tensor([-0.2291])\n",
						"第 235 次epoch\n",
						"第 4701 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0657]])\n",
						"模型中偏参梯度 tensor([-0.2290])\n",
						"第 4702 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0657]])\n",
						"模型中偏参梯度 tensor([-0.2289])\n",
						"第 4703 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0657]])\n",
						"模型中偏参梯度 tensor([-0.2288])\n",
						"第 4704 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0657]])\n",
						"模型中偏参梯度 tensor([-0.2287])\n",
						"第 4705 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0657]])\n",
						"模型中偏参梯度 tensor([-0.2286])\n",
						"第 4706 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0657]])\n",
						"模型中偏参梯度 tensor([-0.2285])\n",
						"第 4707 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0657]])\n",
						"模型中偏参梯度 tensor([-0.2284])\n",
						"第 4708 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0656]])\n",
						"模型中偏参梯度 tensor([-0.2283])\n",
						"第 4709 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0656]])\n",
						"模型中偏参梯度 tensor([-0.2282])\n",
						"第 4710 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0656]])\n",
						"模型中偏参梯度 tensor([-0.2281])\n",
						"第 4711 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0656]])\n",
						"模型中偏参梯度 tensor([-0.2280])\n",
						"第 4712 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0656]])\n",
						"模型中偏参梯度 tensor([-0.2279])\n",
						"第 4713 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0656]])\n",
						"模型中偏参梯度 tensor([-0.2278])\n",
						"第 4714 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0655]])\n",
						"模型中偏参梯度 tensor([-0.2277])\n",
						"第 4715 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0655]])\n",
						"模型中偏参梯度 tensor([-0.2277])\n",
						"第 4716 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0655]])\n",
						"模型中偏参梯度 tensor([-0.2276])\n",
						"第 4717 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0655]])\n",
						"模型中偏参梯度 tensor([-0.2275])\n",
						"第 4718 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0655]])\n",
						"模型中偏参梯度 tensor([-0.2274])\n",
						"第 4719 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0654]])\n",
						"模型中偏参梯度 tensor([-0.2273])\n",
						"第 4720 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0654]])\n",
						"模型中偏参梯度 tensor([-0.2272])\n",
						"第 236 次epoch\n",
						"第 4721 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0654]])\n",
						"模型中偏参梯度 tensor([-0.2271])\n",
						"第 4722 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0654]])\n",
						"模型中偏参梯度 tensor([-0.2270])\n",
						"第 4723 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0654]])\n",
						"模型中偏参梯度 tensor([-0.2269])\n",
						"第 4724 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0653]])\n",
						"模型中偏参梯度 tensor([-0.2268])\n",
						"第 4725 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0653]])\n",
						"模型中偏参梯度 tensor([-0.2267])\n",
						"第 4726 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0653]])\n",
						"模型中偏参梯度 tensor([-0.2266])\n",
						"第 4727 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0653]])\n",
						"模型中偏参梯度 tensor([-0.2265])\n",
						"第 4728 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0652]])\n",
						"模型中偏参梯度 tensor([-0.2264])\n",
						"第 4729 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0652]])\n",
						"模型中偏参梯度 tensor([-0.2264])\n",
						"第 4730 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0652]])\n",
						"模型中偏参梯度 tensor([-0.2263])\n",
						"第 4731 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0652]])\n",
						"模型中偏参梯度 tensor([-0.2262])\n",
						"第 4732 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0651]])\n",
						"模型中偏参梯度 tensor([-0.2261])\n",
						"第 4733 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0651]])\n",
						"模型中偏参梯度 tensor([-0.2260])\n",
						"第 4734 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0651]])\n",
						"模型中偏参梯度 tensor([-0.2259])\n",
						"第 4735 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0651]])\n",
						"模型中偏参梯度 tensor([-0.2258])\n",
						"第 4736 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0650]])\n",
						"模型中偏参梯度 tensor([-0.2257])\n",
						"第 4737 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0650]])\n",
						"模型中偏参梯度 tensor([-0.2256])\n",
						"第 4738 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0650]])\n",
						"模型中偏参梯度 tensor([-0.2255])\n",
						"第 4739 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0649]])\n",
						"模型中偏参梯度 tensor([-0.2255])\n",
						"第 4740 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0649]])\n",
						"模型中偏参梯度 tensor([-0.2254])\n",
						"第 237 次epoch\n",
						"第 4741 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0649]])\n",
						"模型中偏参梯度 tensor([-0.2253])\n",
						"第 4742 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0648]])\n",
						"模型中偏参梯度 tensor([-0.2252])\n",
						"第 4743 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0648]])\n",
						"模型中偏参梯度 tensor([-0.2251])\n",
						"第 4744 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0648]])\n",
						"模型中偏参梯度 tensor([-0.2250])\n",
						"第 4745 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0647]])\n",
						"模型中偏参梯度 tensor([-0.2249])\n",
						"第 4746 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0647]])\n",
						"模型中偏参梯度 tensor([-0.2248])\n",
						"第 4747 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0647]])\n",
						"模型中偏参梯度 tensor([-0.2247])\n",
						"第 4748 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0646]])\n",
						"模型中偏参梯度 tensor([-0.2247])\n",
						"第 4749 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0646]])\n",
						"模型中偏参梯度 tensor([-0.2246])\n",
						"第 4750 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0646]])\n",
						"模型中偏参梯度 tensor([-0.2245])\n",
						"第 4751 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0645]])\n",
						"模型中偏参梯度 tensor([-0.2244])\n",
						"第 4752 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0645]])\n",
						"模型中偏参梯度 tensor([-0.2243])\n",
						"第 4753 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0645]])\n",
						"模型中偏参梯度 tensor([-0.2242])\n",
						"第 4754 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0644]])\n",
						"模型中偏参梯度 tensor([-0.2241])\n",
						"第 4755 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0644]])\n",
						"模型中偏参梯度 tensor([-0.2240])\n",
						"第 4756 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0643]])\n",
						"模型中偏参梯度 tensor([-0.2240])\n",
						"第 4757 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0643]])\n",
						"模型中偏参梯度 tensor([-0.2239])\n",
						"第 4758 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0643]])\n",
						"模型中偏参梯度 tensor([-0.2238])\n",
						"第 4759 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0642]])\n",
						"模型中偏参梯度 tensor([-0.2237])\n",
						"第 4760 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0642]])\n",
						"模型中偏参梯度 tensor([-0.2236])\n",
						"第 238 次epoch\n",
						"第 4761 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0641]])\n",
						"模型中偏参梯度 tensor([-0.2235])\n",
						"第 4762 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0641]])\n",
						"模型中偏参梯度 tensor([-0.2234])\n",
						"第 4763 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0641]])\n",
						"模型中偏参梯度 tensor([-0.2234])\n",
						"第 4764 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0640]])\n",
						"模型中偏参梯度 tensor([-0.2233])\n",
						"第 4765 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0640]])\n",
						"模型中偏参梯度 tensor([-0.2232])\n",
						"第 4766 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0639]])\n",
						"模型中偏参梯度 tensor([-0.2231])\n",
						"第 4767 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0639]])\n",
						"模型中偏参梯度 tensor([-0.2230])\n",
						"第 4768 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0639]])\n",
						"模型中偏参梯度 tensor([-0.2229])\n",
						"第 4769 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0639]])\n",
						"模型中偏参梯度 tensor([-0.2228])\n",
						"第 4770 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0639]])\n",
						"模型中偏参梯度 tensor([-0.2227])\n",
						"第 4771 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0639]])\n",
						"模型中偏参梯度 tensor([-0.2226])\n",
						"第 4772 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0638]])\n",
						"模型中偏参梯度 tensor([-0.2225])\n",
						"第 4773 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0638]])\n",
						"模型中偏参梯度 tensor([-0.2224])\n",
						"第 4774 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0638]])\n",
						"模型中偏参梯度 tensor([-0.2224])\n",
						"第 4775 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0638]])\n",
						"模型中偏参梯度 tensor([-0.2223])\n",
						"第 4776 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0638]])\n",
						"模型中偏参梯度 tensor([-0.2222])\n",
						"第 4777 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0638]])\n",
						"模型中偏参梯度 tensor([-0.2221])\n",
						"第 4778 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0638]])\n",
						"模型中偏参梯度 tensor([-0.2220])\n",
						"第 4779 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0638]])\n",
						"模型中偏参梯度 tensor([-0.2219])\n",
						"第 4780 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0638]])\n",
						"模型中偏参梯度 tensor([-0.2218])\n",
						"第 239 次epoch\n",
						"第 4781 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0637]])\n",
						"模型中偏参梯度 tensor([-0.2217])\n",
						"第 4782 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0637]])\n",
						"模型中偏参梯度 tensor([-0.2216])\n",
						"第 4783 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0637]])\n",
						"模型中偏参梯度 tensor([-0.2215])\n",
						"第 4784 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0637]])\n",
						"模型中偏参梯度 tensor([-0.2214])\n",
						"第 4785 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0637]])\n",
						"模型中偏参梯度 tensor([-0.2213])\n",
						"第 4786 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0637]])\n",
						"模型中偏参梯度 tensor([-0.2212])\n",
						"第 4787 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0637]])\n",
						"模型中偏参梯度 tensor([-0.2211])\n",
						"第 4788 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0636]])\n",
						"模型中偏参梯度 tensor([-0.2211])\n",
						"第 4789 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0636]])\n",
						"模型中偏参梯度 tensor([-0.2210])\n",
						"第 4790 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0636]])\n",
						"模型中偏参梯度 tensor([-0.2209])\n",
						"第 4791 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0636]])\n",
						"模型中偏参梯度 tensor([-0.2208])\n",
						"第 4792 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0636]])\n",
						"模型中偏参梯度 tensor([-0.2207])\n",
						"第 4793 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0636]])\n",
						"模型中偏参梯度 tensor([-0.2206])\n",
						"第 4794 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0635]])\n",
						"模型中偏参梯度 tensor([-0.2205])\n",
						"第 4795 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0635]])\n",
						"模型中偏参梯度 tensor([-0.2204])\n",
						"第 4796 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0635]])\n",
						"模型中偏参梯度 tensor([-0.2203])\n",
						"第 4797 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0635]])\n",
						"模型中偏参梯度 tensor([-0.2202])\n",
						"第 4798 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0634]])\n",
						"模型中偏参梯度 tensor([-0.2202])\n",
						"第 4799 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0634]])\n",
						"模型中偏参梯度 tensor([-0.2201])\n",
						"第 4800 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0634]])\n",
						"模型中偏参梯度 tensor([-0.2200])\n",
						"第 240 次epoch\n",
						"第 4801 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0634]])\n",
						"模型中偏参梯度 tensor([-0.2199])\n",
						"第 4802 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0634]])\n",
						"模型中偏参梯度 tensor([-0.2198])\n",
						"第 4803 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0633]])\n",
						"模型中偏参梯度 tensor([-0.2197])\n",
						"第 4804 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0633]])\n",
						"模型中偏参梯度 tensor([-0.2196])\n",
						"第 4805 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0633]])\n",
						"模型中偏参梯度 tensor([-0.2195])\n",
						"第 4806 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0633]])\n",
						"模型中偏参梯度 tensor([-0.2194])\n",
						"第 4807 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0632]])\n",
						"模型中偏参梯度 tensor([-0.2194])\n",
						"第 4808 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0632]])\n",
						"模型中偏参梯度 tensor([-0.2193])\n",
						"第 4809 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0632]])\n",
						"模型中偏参梯度 tensor([-0.2192])\n",
						"第 4810 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0631]])\n",
						"模型中偏参梯度 tensor([-0.2191])\n",
						"第 4811 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0631]])\n",
						"模型中偏参梯度 tensor([-0.2190])\n",
						"第 4812 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0631]])\n",
						"模型中偏参梯度 tensor([-0.2189])\n",
						"第 4813 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0631]])\n",
						"模型中偏参梯度 tensor([-0.2188])\n",
						"第 4814 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0630]])\n",
						"模型中偏参梯度 tensor([-0.2187])\n",
						"第 4815 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0630]])\n",
						"模型中偏参梯度 tensor([-0.2187])\n",
						"第 4816 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0630]])\n",
						"模型中偏参梯度 tensor([-0.2186])\n",
						"第 4817 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0629]])\n",
						"模型中偏参梯度 tensor([-0.2185])\n",
						"第 4818 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0629]])\n",
						"模型中偏参梯度 tensor([-0.2184])\n",
						"第 4819 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0629]])\n",
						"模型中偏参梯度 tensor([-0.2183])\n",
						"第 4820 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0628]])\n",
						"模型中偏参梯度 tensor([-0.2182])\n",
						"第 241 次epoch\n",
						"第 4821 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0628]])\n",
						"模型中偏参梯度 tensor([-0.2181])\n",
						"第 4822 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0628]])\n",
						"模型中偏参梯度 tensor([-0.2181])\n",
						"第 4823 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0627]])\n",
						"模型中偏参梯度 tensor([-0.2180])\n",
						"第 4824 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0627]])\n",
						"模型中偏参梯度 tensor([-0.2179])\n",
						"第 4825 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0627]])\n",
						"模型中偏参梯度 tensor([-0.2178])\n",
						"第 4826 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0626]])\n",
						"模型中偏参梯度 tensor([-0.2177])\n",
						"第 4827 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0626]])\n",
						"模型中偏参梯度 tensor([-0.2176])\n",
						"第 4828 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0626]])\n",
						"模型中偏参梯度 tensor([-0.2175])\n",
						"第 4829 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0625]])\n",
						"模型中偏参梯度 tensor([-0.2175])\n",
						"第 4830 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0625]])\n",
						"模型中偏参梯度 tensor([-0.2174])\n",
						"第 4831 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0624]])\n",
						"模型中偏参梯度 tensor([-0.2173])\n",
						"第 4832 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0624]])\n",
						"模型中偏参梯度 tensor([-0.2172])\n",
						"第 4833 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0624]])\n",
						"模型中偏参梯度 tensor([-0.2171])\n",
						"第 4834 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0623]])\n",
						"模型中偏参梯度 tensor([-0.2170])\n",
						"第 4835 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0623]])\n",
						"模型中偏参梯度 tensor([-0.2170])\n",
						"第 4836 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0623]])\n",
						"模型中偏参梯度 tensor([-0.2169])\n",
						"第 4837 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0622]])\n",
						"模型中偏参梯度 tensor([-0.2168])\n",
						"第 4838 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0622]])\n",
						"模型中偏参梯度 tensor([-0.2167])\n",
						"第 4839 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0621]])\n",
						"模型中偏参梯度 tensor([-0.2166])\n",
						"第 4840 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0621]])\n",
						"模型中偏参梯度 tensor([-0.2165])\n",
						"第 242 次epoch\n",
						"第 4841 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0620]])\n",
						"模型中偏参梯度 tensor([-0.2165])\n",
						"第 4842 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0620]])\n",
						"模型中偏参梯度 tensor([-0.2164])\n",
						"第 4843 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0620]])\n",
						"模型中偏参梯度 tensor([-0.2163])\n",
						"第 4844 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0620]])\n",
						"模型中偏参梯度 tensor([-0.2162])\n",
						"第 4845 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0619]])\n",
						"模型中偏参梯度 tensor([-0.2161])\n",
						"第 4846 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0619]])\n",
						"模型中偏参梯度 tensor([-0.2160])\n",
						"第 4847 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0619]])\n",
						"模型中偏参梯度 tensor([-0.2159])\n",
						"第 4848 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0619]])\n",
						"模型中偏参梯度 tensor([-0.2158])\n",
						"第 4849 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0619]])\n",
						"模型中偏参梯度 tensor([-0.2158])\n",
						"第 4850 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0619]])\n",
						"模型中偏参梯度 tensor([-0.2157])\n",
						"第 4851 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0619]])\n",
						"模型中偏参梯度 tensor([-0.2156])\n",
						"第 4852 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0619]])\n",
						"模型中偏参梯度 tensor([-0.2155])\n",
						"第 4853 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0619]])\n",
						"模型中偏参梯度 tensor([-0.2154])\n",
						"第 4854 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0619]])\n",
						"模型中偏参梯度 tensor([-0.2153])\n",
						"第 4855 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0619]])\n",
						"模型中偏参梯度 tensor([-0.2152])\n",
						"第 4856 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0618]])\n",
						"模型中偏参梯度 tensor([-0.2151])\n",
						"第 4857 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0618]])\n",
						"模型中偏参梯度 tensor([-0.2150])\n",
						"第 4858 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0618]])\n",
						"模型中偏参梯度 tensor([-0.2149])\n",
						"第 4859 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0618]])\n",
						"模型中偏参梯度 tensor([-0.2148])\n",
						"第 4860 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0618]])\n",
						"模型中偏参梯度 tensor([-0.2148])\n",
						"第 243 次epoch\n",
						"第 4861 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0618]])\n",
						"模型中偏参梯度 tensor([-0.2147])\n",
						"第 4862 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0618]])\n",
						"模型中偏参梯度 tensor([-0.2146])\n",
						"第 4863 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0617]])\n",
						"模型中偏参梯度 tensor([-0.2145])\n",
						"第 4864 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0617]])\n",
						"模型中偏参梯度 tensor([-0.2144])\n",
						"第 4865 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0617]])\n",
						"模型中偏参梯度 tensor([-0.2143])\n",
						"第 4866 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0617]])\n",
						"模型中偏参梯度 tensor([-0.2142])\n",
						"第 4867 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0617]])\n",
						"模型中偏参梯度 tensor([-0.2141])\n",
						"第 4868 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0617]])\n",
						"模型中偏参梯度 tensor([-0.2140])\n",
						"第 4869 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0616]])\n",
						"模型中偏参梯度 tensor([-0.2140])\n",
						"第 4870 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0616]])\n",
						"模型中偏参梯度 tensor([-0.2139])\n",
						"第 4871 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0616]])\n",
						"模型中偏参梯度 tensor([-0.2138])\n",
						"第 4872 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0616]])\n",
						"模型中偏参梯度 tensor([-0.2137])\n",
						"第 4873 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0616]])\n",
						"模型中偏参梯度 tensor([-0.2136])\n",
						"第 4874 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0615]])\n",
						"模型中偏参梯度 tensor([-0.2135])\n",
						"第 4875 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0615]])\n",
						"模型中偏参梯度 tensor([-0.2134])\n",
						"第 4876 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0615]])\n",
						"模型中偏参梯度 tensor([-0.2134])\n",
						"第 4877 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0615]])\n",
						"模型中偏参梯度 tensor([-0.2133])\n",
						"第 4878 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0615]])\n",
						"模型中偏参梯度 tensor([-0.2132])\n",
						"第 4879 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0614]])\n",
						"模型中偏参梯度 tensor([-0.2131])\n",
						"第 4880 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0614]])\n",
						"模型中偏参梯度 tensor([-0.2130])\n",
						"第 244 次epoch\n",
						"第 4881 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0614]])\n",
						"模型中偏参梯度 tensor([-0.2129])\n",
						"第 4882 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0613]])\n",
						"模型中偏参梯度 tensor([-0.2128])\n",
						"第 4883 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0613]])\n",
						"模型中偏参梯度 tensor([-0.2127])\n",
						"第 4884 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0613]])\n",
						"模型中偏参梯度 tensor([-0.2127])\n",
						"第 4885 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0613]])\n",
						"模型中偏参梯度 tensor([-0.2126])\n",
						"第 4886 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0612]])\n",
						"模型中偏参梯度 tensor([-0.2125])\n",
						"第 4887 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0612]])\n",
						"模型中偏参梯度 tensor([-0.2124])\n",
						"第 4888 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0612]])\n",
						"模型中偏参梯度 tensor([-0.2123])\n",
						"第 4889 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0612]])\n",
						"模型中偏参梯度 tensor([-0.2122])\n",
						"第 4890 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0611]])\n",
						"模型中偏参梯度 tensor([-0.2122])\n",
						"第 4891 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0611]])\n",
						"模型中偏参梯度 tensor([-0.2121])\n",
						"第 4892 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0611]])\n",
						"模型中偏参梯度 tensor([-0.2120])\n",
						"第 4893 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0610]])\n",
						"模型中偏参梯度 tensor([-0.2119])\n",
						"第 4894 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0610]])\n",
						"模型中偏参梯度 tensor([-0.2118])\n",
						"第 4895 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0610]])\n",
						"模型中偏参梯度 tensor([-0.2117])\n",
						"第 4896 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0610]])\n",
						"模型中偏参梯度 tensor([-0.2117])\n",
						"第 4897 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0609]])\n",
						"模型中偏参梯度 tensor([-0.2116])\n",
						"第 4898 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0609]])\n",
						"模型中偏参梯度 tensor([-0.2115])\n",
						"第 4899 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0609]])\n",
						"模型中偏参梯度 tensor([-0.2114])\n",
						"第 4900 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0608]])\n",
						"模型中偏参梯度 tensor([-0.2113])\n",
						"第 245 次epoch\n",
						"第 4901 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0608]])\n",
						"模型中偏参梯度 tensor([-0.2112])\n",
						"第 4902 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0608]])\n",
						"模型中偏参梯度 tensor([-0.2112])\n",
						"第 4903 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0607]])\n",
						"模型中偏参梯度 tensor([-0.2111])\n",
						"第 4904 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0607]])\n",
						"模型中偏参梯度 tensor([-0.2110])\n",
						"第 4905 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0606]])\n",
						"模型中偏参梯度 tensor([-0.2109])\n",
						"第 4906 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0606]])\n",
						"模型中偏参梯度 tensor([-0.2108])\n",
						"第 4907 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0606]])\n",
						"模型中偏参梯度 tensor([-0.2108])\n",
						"第 4908 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0605]])\n",
						"模型中偏参梯度 tensor([-0.2107])\n",
						"第 4909 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0605]])\n",
						"模型中偏参梯度 tensor([-0.2106])\n",
						"第 4910 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0605]])\n",
						"模型中偏参梯度 tensor([-0.2105])\n",
						"第 4911 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0604]])\n",
						"模型中偏参梯度 tensor([-0.2104])\n",
						"第 4912 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0604]])\n",
						"模型中偏参梯度 tensor([-0.2103])\n",
						"第 4913 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0604]])\n",
						"模型中偏参梯度 tensor([-0.2103])\n",
						"第 4914 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0603]])\n",
						"模型中偏参梯度 tensor([-0.2102])\n",
						"第 4915 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0603]])\n",
						"模型中偏参梯度 tensor([-0.2101])\n",
						"第 4916 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0602]])\n",
						"模型中偏参梯度 tensor([-0.2100])\n",
						"第 4917 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0602]])\n",
						"模型中偏参梯度 tensor([-0.2099])\n",
						"第 4918 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0601]])\n",
						"模型中偏参梯度 tensor([-0.2099])\n",
						"第 4919 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0601]])\n",
						"模型中偏参梯度 tensor([-0.2098])\n",
						"第 4920 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0601]])\n",
						"模型中偏参梯度 tensor([-0.2097])\n",
						"第 246 次epoch\n",
						"第 4921 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0601]])\n",
						"模型中偏参梯度 tensor([-0.2096])\n",
						"第 4922 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0600]])\n",
						"模型中偏参梯度 tensor([-0.2095])\n",
						"第 4923 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0600]])\n",
						"模型中偏参梯度 tensor([-0.2094])\n",
						"第 4924 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0600]])\n",
						"模型中偏参梯度 tensor([-0.2093])\n",
						"第 4925 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0600]])\n",
						"模型中偏参梯度 tensor([-0.2093])\n",
						"第 4926 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0600]])\n",
						"模型中偏参梯度 tensor([-0.2092])\n",
						"第 4927 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0600]])\n",
						"模型中偏参梯度 tensor([-0.2091])\n",
						"第 4928 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0600]])\n",
						"模型中偏参梯度 tensor([-0.2090])\n",
						"第 4929 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0600]])\n",
						"模型中偏参梯度 tensor([-0.2089])\n",
						"第 4930 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0600]])\n",
						"模型中偏参梯度 tensor([-0.2088])\n",
						"第 4931 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0600]])\n",
						"模型中偏参梯度 tensor([-0.2087])\n",
						"第 4932 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0600]])\n",
						"模型中偏参梯度 tensor([-0.2086])\n",
						"第 4933 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0600]])\n",
						"模型中偏参梯度 tensor([-0.2086])\n",
						"第 4934 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0599]])\n",
						"模型中偏参梯度 tensor([-0.2085])\n",
						"第 4935 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0599]])\n",
						"模型中偏参梯度 tensor([-0.2084])\n",
						"第 4936 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0599]])\n",
						"模型中偏参梯度 tensor([-0.2083])\n",
						"第 4937 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0599]])\n",
						"模型中偏参梯度 tensor([-0.2082])\n",
						"第 4938 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0599]])\n",
						"模型中偏参梯度 tensor([-0.2081])\n",
						"第 4939 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0599]])\n",
						"模型中偏参梯度 tensor([-0.2080])\n",
						"第 4940 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0599]])\n",
						"模型中偏参梯度 tensor([-0.2079])\n",
						"第 247 次epoch\n",
						"第 4941 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0599]])\n",
						"模型中偏参梯度 tensor([-0.2079])\n",
						"第 4942 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0598]])\n",
						"模型中偏参梯度 tensor([-0.2078])\n",
						"第 4943 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0598]])\n",
						"模型中偏参梯度 tensor([-0.2077])\n",
						"第 4944 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0598]])\n",
						"模型中偏参梯度 tensor([-0.2076])\n",
						"第 4945 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0598]])\n",
						"模型中偏参梯度 tensor([-0.2075])\n",
						"第 4946 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0598]])\n",
						"模型中偏参梯度 tensor([-0.2074])\n",
						"第 4947 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0598]])\n",
						"模型中偏参梯度 tensor([-0.2073])\n",
						"第 4948 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0597]])\n",
						"模型中偏参梯度 tensor([-0.2073])\n",
						"第 4949 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0597]])\n",
						"模型中偏参梯度 tensor([-0.2072])\n",
						"第 4950 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0597]])\n",
						"模型中偏参梯度 tensor([-0.2071])\n",
						"第 4951 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0597]])\n",
						"模型中偏参梯度 tensor([-0.2070])\n",
						"第 4952 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0597]])\n",
						"模型中偏参梯度 tensor([-0.2069])\n",
						"第 4953 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0596]])\n",
						"模型中偏参梯度 tensor([-0.2068])\n",
						"第 4954 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0596]])\n",
						"模型中偏参梯度 tensor([-0.2068])\n",
						"第 4955 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0596]])\n",
						"模型中偏参梯度 tensor([-0.2067])\n",
						"第 4956 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0596]])\n",
						"模型中偏参梯度 tensor([-0.2066])\n",
						"第 4957 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0596]])\n",
						"模型中偏参梯度 tensor([-0.2065])\n",
						"第 4958 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0595]])\n",
						"模型中偏参梯度 tensor([-0.2064])\n",
						"第 4959 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0595]])\n",
						"模型中偏参梯度 tensor([-0.2063])\n",
						"第 4960 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0595]])\n",
						"模型中偏参梯度 tensor([-0.2063])\n",
						"第 248 次epoch\n",
						"第 4961 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0595]])\n",
						"模型中偏参梯度 tensor([-0.2062])\n",
						"第 4962 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0594]])\n",
						"模型中偏参梯度 tensor([-0.2061])\n",
						"第 4963 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0594]])\n",
						"模型中偏参梯度 tensor([-0.2060])\n",
						"第 4964 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0594]])\n",
						"模型中偏参梯度 tensor([-0.2059])\n",
						"第 4965 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0594]])\n",
						"模型中偏参梯度 tensor([-0.2058])\n",
						"第 4966 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0593]])\n",
						"模型中偏参梯度 tensor([-0.2058])\n",
						"第 4967 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0593]])\n",
						"模型中偏参梯度 tensor([-0.2057])\n",
						"第 4968 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0593]])\n",
						"模型中偏参梯度 tensor([-0.2056])\n",
						"第 4969 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0593]])\n",
						"模型中偏参梯度 tensor([-0.2055])\n",
						"第 4970 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0592]])\n",
						"模型中偏参梯度 tensor([-0.2054])\n",
						"第 4971 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0592]])\n",
						"模型中偏参梯度 tensor([-0.2053])\n",
						"第 4972 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0592]])\n",
						"模型中偏参梯度 tensor([-0.2053])\n",
						"第 4973 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0591]])\n",
						"模型中偏参梯度 tensor([-0.2052])\n",
						"第 4974 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0591]])\n",
						"模型中偏参梯度 tensor([-0.2051])\n",
						"第 4975 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0591]])\n",
						"模型中偏参梯度 tensor([-0.2050])\n",
						"第 4976 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0590]])\n",
						"模型中偏参梯度 tensor([-0.2049])\n",
						"第 4977 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0590]])\n",
						"模型中偏参梯度 tensor([-0.2049])\n",
						"第 4978 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0590]])\n",
						"模型中偏参梯度 tensor([-0.2048])\n",
						"第 4979 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0589]])\n",
						"模型中偏参梯度 tensor([-0.2047])\n",
						"第 4980 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0589]])\n",
						"模型中偏参梯度 tensor([-0.2046])\n",
						"第 249 次epoch\n",
						"第 4981 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0589]])\n",
						"模型中偏参梯度 tensor([-0.2045])\n",
						"第 4982 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0588]])\n",
						"模型中偏参梯度 tensor([-0.2045])\n",
						"第 4983 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0588]])\n",
						"模型中偏参梯度 tensor([-0.2044])\n",
						"第 4984 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0588]])\n",
						"模型中偏参梯度 tensor([-0.2043])\n",
						"第 4985 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0587]])\n",
						"模型中偏参梯度 tensor([-0.2042])\n",
						"第 4986 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0587]])\n",
						"模型中偏参梯度 tensor([-0.2042])\n",
						"第 4987 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0587]])\n",
						"模型中偏参梯度 tensor([-0.2041])\n",
						"第 4988 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0586]])\n",
						"模型中偏参梯度 tensor([-0.2040])\n",
						"第 4989 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0586]])\n",
						"模型中偏参梯度 tensor([-0.2039])\n",
						"第 4990 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0586]])\n",
						"模型中偏参梯度 tensor([-0.2038])\n",
						"第 4991 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0585]])\n",
						"模型中偏参梯度 tensor([-0.2038])\n",
						"第 4992 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0585]])\n",
						"模型中偏参梯度 tensor([-0.2037])\n",
						"第 4993 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0584]])\n",
						"模型中偏参梯度 tensor([-0.2036])\n",
						"第 4994 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0584]])\n",
						"模型中偏参梯度 tensor([-0.2035])\n",
						"第 4995 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0584]])\n",
						"模型中偏参梯度 tensor([-0.2035])\n",
						"第 4996 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0583]])\n",
						"模型中偏参梯度 tensor([-0.2034])\n",
						"第 4997 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0583]])\n",
						"模型中偏参梯度 tensor([-0.2033])\n",
						"第 4998 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0582]])\n",
						"模型中偏参梯度 tensor([-0.2032])\n",
						"第 4999 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0582]])\n",
						"模型中偏参梯度 tensor([-0.2031])\n",
						"第 5000 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0582]])\n",
						"模型中偏参梯度 tensor([-0.2031])\n",
						"第 250 次epoch\n",
						"第 5001 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0582]])\n",
						"模型中偏参梯度 tensor([-0.2030])\n",
						"第 5002 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0582]])\n",
						"模型中偏参梯度 tensor([-0.2029])\n",
						"第 5003 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0581]])\n",
						"模型中偏参梯度 tensor([-0.2028])\n",
						"第 5004 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0581]])\n",
						"模型中偏参梯度 tensor([-0.2027])\n",
						"第 5005 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0581]])\n",
						"模型中偏参梯度 tensor([-0.2026])\n",
						"第 5006 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0581]])\n",
						"模型中偏参梯度 tensor([-0.2025])\n",
						"第 5007 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0581]])\n",
						"模型中偏参梯度 tensor([-0.2025])\n",
						"第 5008 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0581]])\n",
						"模型中偏参梯度 tensor([-0.2024])\n",
						"第 5009 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0581]])\n",
						"模型中偏参梯度 tensor([-0.2023])\n",
						"第 5010 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0581]])\n",
						"模型中偏参梯度 tensor([-0.2022])\n",
						"第 5011 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0581]])\n",
						"模型中偏参梯度 tensor([-0.2021])\n",
						"第 5012 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0581]])\n",
						"模型中偏参梯度 tensor([-0.2020])\n",
						"第 5013 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0581]])\n",
						"模型中偏参梯度 tensor([-0.2019])\n",
						"第 5014 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0581]])\n",
						"模型中偏参梯度 tensor([-0.2019])\n",
						"第 5015 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0581]])\n",
						"模型中偏参梯度 tensor([-0.2018])\n",
						"第 5016 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0580]])\n",
						"模型中偏参梯度 tensor([-0.2017])\n",
						"第 5017 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0580]])\n",
						"模型中偏参梯度 tensor([-0.2016])\n",
						"第 5018 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0580]])\n",
						"模型中偏参梯度 tensor([-0.2015])\n",
						"第 5019 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0580]])\n",
						"模型中偏参梯度 tensor([-0.2014])\n",
						"第 5020 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0580]])\n",
						"模型中偏参梯度 tensor([-0.2014])\n",
						"第 251 次epoch\n",
						"第 5021 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0580]])\n",
						"模型中偏参梯度 tensor([-0.2013])\n",
						"第 5022 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0580]])\n",
						"模型中偏参梯度 tensor([-0.2012])\n",
						"第 5023 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0579]])\n",
						"模型中偏参梯度 tensor([-0.2011])\n",
						"第 5024 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0579]])\n",
						"模型中偏参梯度 tensor([-0.2010])\n",
						"第 5025 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0579]])\n",
						"模型中偏参梯度 tensor([-0.2009])\n",
						"第 5026 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0579]])\n",
						"模型中偏参梯度 tensor([-0.2009])\n",
						"第 5027 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0579]])\n",
						"模型中偏参梯度 tensor([-0.2008])\n",
						"第 5028 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0579]])\n",
						"模型中偏参梯度 tensor([-0.2007])\n",
						"第 5029 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0579]])\n",
						"模型中偏参梯度 tensor([-0.2006])\n",
						"第 5030 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0578]])\n",
						"模型中偏参梯度 tensor([-0.2005])\n",
						"第 5031 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0578]])\n",
						"模型中偏参梯度 tensor([-0.2004])\n",
						"第 5032 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0578]])\n",
						"模型中偏参梯度 tensor([-0.2004])\n",
						"第 5033 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0578]])\n",
						"模型中偏参梯度 tensor([-0.2003])\n",
						"第 5034 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0578]])\n",
						"模型中偏参梯度 tensor([-0.2002])\n",
						"第 5035 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0577]])\n",
						"模型中偏参梯度 tensor([-0.2001])\n",
						"第 5036 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0577]])\n",
						"模型中偏参梯度 tensor([-0.2000])\n",
						"第 5037 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0577]])\n",
						"模型中偏参梯度 tensor([-0.2000])\n",
						"第 5038 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0577]])\n",
						"模型中偏参梯度 tensor([-0.1999])\n",
						"第 5039 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0577]])\n",
						"模型中偏参梯度 tensor([-0.1998])\n",
						"第 5040 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0576]])\n",
						"模型中偏参梯度 tensor([-0.1997])\n",
						"第 252 次epoch\n",
						"第 5041 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0576]])\n",
						"模型中偏参梯度 tensor([-0.1996])\n",
						"第 5042 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0576]])\n",
						"模型中偏参梯度 tensor([-0.1996])\n",
						"第 5043 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0576]])\n",
						"模型中偏参梯度 tensor([-0.1995])\n",
						"第 5044 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0575]])\n",
						"模型中偏参梯度 tensor([-0.1994])\n",
						"第 5045 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0575]])\n",
						"模型中偏参梯度 tensor([-0.1993])\n",
						"第 5046 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0575]])\n",
						"模型中偏参梯度 tensor([-0.1992])\n",
						"第 5047 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0575]])\n",
						"模型中偏参梯度 tensor([-0.1992])\n",
						"第 5048 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0574]])\n",
						"模型中偏参梯度 tensor([-0.1991])\n",
						"第 5049 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0574]])\n",
						"模型中偏参梯度 tensor([-0.1990])\n",
						"第 5050 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0574]])\n",
						"模型中偏参梯度 tensor([-0.1989])\n",
						"第 5051 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0574]])\n",
						"模型中偏参梯度 tensor([-0.1988])\n",
						"第 5052 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0573]])\n",
						"模型中偏参梯度 tensor([-0.1988])\n",
						"第 5053 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0573]])\n",
						"模型中偏参梯度 tensor([-0.1987])\n",
						"第 5054 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0573]])\n",
						"模型中偏参梯度 tensor([-0.1986])\n",
						"第 5055 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0572]])\n",
						"模型中偏参梯度 tensor([-0.1985])\n",
						"第 5056 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0572]])\n",
						"模型中偏参梯度 tensor([-0.1984])\n",
						"第 5057 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0572]])\n",
						"模型中偏参梯度 tensor([-0.1984])\n",
						"第 5058 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0571]])\n",
						"模型中偏参梯度 tensor([-0.1983])\n",
						"第 5059 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0571]])\n",
						"模型中偏参梯度 tensor([-0.1982])\n",
						"第 5060 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0571]])\n",
						"模型中偏参梯度 tensor([-0.1981])\n",
						"第 253 次epoch\n",
						"第 5061 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0571]])\n",
						"模型中偏参梯度 tensor([-0.1981])\n",
						"第 5062 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0570]])\n",
						"模型中偏参梯度 tensor([-0.1980])\n",
						"第 5063 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0570]])\n",
						"模型中偏参梯度 tensor([-0.1979])\n",
						"第 5064 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0570]])\n",
						"模型中偏参梯度 tensor([-0.1978])\n",
						"第 5065 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0569]])\n",
						"模型中偏参梯度 tensor([-0.1978])\n",
						"第 5066 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0569]])\n",
						"模型中偏参梯度 tensor([-0.1977])\n",
						"第 5067 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0569]])\n",
						"模型中偏参梯度 tensor([-0.1976])\n",
						"第 5068 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0568]])\n",
						"模型中偏参梯度 tensor([-0.1975])\n",
						"第 5069 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0568]])\n",
						"模型中偏参梯度 tensor([-0.1974])\n",
						"第 5070 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0567]])\n",
						"模型中偏参梯度 tensor([-0.1974])\n",
						"第 5071 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0567]])\n",
						"模型中偏参梯度 tensor([-0.1973])\n",
						"第 5072 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0567]])\n",
						"模型中偏参梯度 tensor([-0.1972])\n",
						"第 5073 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0566]])\n",
						"模型中偏参梯度 tensor([-0.1971])\n",
						"第 5074 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0566]])\n",
						"模型中偏参梯度 tensor([-0.1971])\n",
						"第 5075 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0566]])\n",
						"模型中偏参梯度 tensor([-0.1970])\n",
						"第 5076 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0565]])\n",
						"模型中偏参梯度 tensor([-0.1969])\n",
						"第 5077 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0565]])\n",
						"模型中偏参梯度 tensor([-0.1968])\n",
						"第 5078 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0565]])\n",
						"模型中偏参梯度 tensor([-0.1968])\n",
						"第 5079 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0564]])\n",
						"模型中偏参梯度 tensor([-0.1967])\n",
						"第 5080 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0564]])\n",
						"模型中偏参梯度 tensor([-0.1966])\n",
						"第 254 次epoch\n",
						"第 5081 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0563]])\n",
						"模型中偏参梯度 tensor([-0.1965])\n",
						"第 5082 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0563]])\n",
						"模型中偏参梯度 tensor([-0.1965])\n",
						"第 5083 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0562]])\n",
						"模型中偏参梯度 tensor([-0.1964])\n",
						"第 5084 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0562]])\n",
						"模型中偏参梯度 tensor([-0.1963])\n",
						"第 5085 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0562]])\n",
						"模型中偏参梯度 tensor([-0.1962])\n",
						"第 5086 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0562]])\n",
						"模型中偏参梯度 tensor([-0.1961])\n",
						"第 5087 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0562]])\n",
						"模型中偏参梯度 tensor([-0.1961])\n",
						"第 5088 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0562]])\n",
						"模型中偏参梯度 tensor([-0.1960])\n",
						"第 5089 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0562]])\n",
						"模型中偏参梯度 tensor([-0.1959])\n",
						"第 5090 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0562]])\n",
						"模型中偏参梯度 tensor([-0.1958])\n",
						"第 5091 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0562]])\n",
						"模型中偏参梯度 tensor([-0.1957])\n",
						"第 5092 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0562]])\n",
						"模型中偏参梯度 tensor([-0.1956])\n",
						"第 5093 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0562]])\n",
						"模型中偏参梯度 tensor([-0.1956])\n",
						"第 5094 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0562]])\n",
						"模型中偏参梯度 tensor([-0.1955])\n",
						"第 5095 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0562]])\n",
						"模型中偏参梯度 tensor([-0.1954])\n",
						"第 5096 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0562]])\n",
						"模型中偏参梯度 tensor([-0.1953])\n",
						"第 5097 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0562]])\n",
						"模型中偏参梯度 tensor([-0.1952])\n",
						"第 5098 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0561]])\n",
						"模型中偏参梯度 tensor([-0.1951])\n",
						"第 5099 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0561]])\n",
						"模型中偏参梯度 tensor([-0.1951])\n",
						"第 5100 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0561]])\n",
						"模型中偏参梯度 tensor([-0.1950])\n",
						"第 255 次epoch\n",
						"第 5101 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0561]])\n",
						"模型中偏参梯度 tensor([-0.1949])\n",
						"第 5102 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0561]])\n",
						"模型中偏参梯度 tensor([-0.1948])\n",
						"第 5103 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0561]])\n",
						"模型中偏参梯度 tensor([-0.1947])\n",
						"第 5104 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0561]])\n",
						"模型中偏参梯度 tensor([-0.1947])\n",
						"第 5105 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0561]])\n",
						"模型中偏参梯度 tensor([-0.1946])\n",
						"第 5106 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0561]])\n",
						"模型中偏参梯度 tensor([-0.1945])\n",
						"第 5107 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0560]])\n",
						"模型中偏参梯度 tensor([-0.1944])\n",
						"第 5108 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0560]])\n",
						"模型中偏参梯度 tensor([-0.1943])\n",
						"第 5109 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0560]])\n",
						"模型中偏参梯度 tensor([-0.1943])\n",
						"第 5110 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0560]])\n",
						"模型中偏参梯度 tensor([-0.1942])\n",
						"第 5111 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0560]])\n",
						"模型中偏参梯度 tensor([-0.1941])\n",
						"第 5112 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0560]])\n",
						"模型中偏参梯度 tensor([-0.1940])\n",
						"第 5113 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0559]])\n",
						"模型中偏参梯度 tensor([-0.1939])\n",
						"第 5114 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0559]])\n",
						"模型中偏参梯度 tensor([-0.1939])\n",
						"第 5115 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0559]])\n",
						"模型中偏参梯度 tensor([-0.1938])\n",
						"第 5116 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0559]])\n",
						"模型中偏参梯度 tensor([-0.1937])\n",
						"第 5117 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0559]])\n",
						"模型中偏参梯度 tensor([-0.1936])\n",
						"第 5118 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0559]])\n",
						"模型中偏参梯度 tensor([-0.1935])\n",
						"第 5119 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0558]])\n",
						"模型中偏参梯度 tensor([-0.1935])\n",
						"第 5120 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0558]])\n",
						"模型中偏参梯度 tensor([-0.1934])\n",
						"第 256 次epoch\n",
						"第 5121 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0558]])\n",
						"模型中偏参梯度 tensor([-0.1933])\n",
						"第 5122 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0558]])\n",
						"模型中偏参梯度 tensor([-0.1932])\n",
						"第 5123 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0558]])\n",
						"模型中偏参梯度 tensor([-0.1931])\n",
						"第 5124 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0557]])\n",
						"模型中偏参梯度 tensor([-0.1931])\n",
						"第 5125 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0557]])\n",
						"模型中偏参梯度 tensor([-0.1930])\n",
						"第 5126 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0557]])\n",
						"模型中偏参梯度 tensor([-0.1929])\n",
						"第 5127 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0557]])\n",
						"模型中偏参梯度 tensor([-0.1928])\n",
						"第 5128 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0556]])\n",
						"模型中偏参梯度 tensor([-0.1928])\n",
						"第 5129 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0556]])\n",
						"模型中偏参梯度 tensor([-0.1927])\n",
						"第 5130 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0556]])\n",
						"模型中偏参梯度 tensor([-0.1926])\n",
						"第 5131 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0556]])\n",
						"模型中偏参梯度 tensor([-0.1925])\n",
						"第 5132 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0555]])\n",
						"模型中偏参梯度 tensor([-0.1925])\n",
						"第 5133 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0555]])\n",
						"模型中偏参梯度 tensor([-0.1924])\n",
						"第 5134 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0555]])\n",
						"模型中偏参梯度 tensor([-0.1923])\n",
						"第 5135 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0555]])\n",
						"模型中偏参梯度 tensor([-0.1922])\n",
						"第 5136 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0554]])\n",
						"模型中偏参梯度 tensor([-0.1921])\n",
						"第 5137 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0554]])\n",
						"模型中偏参梯度 tensor([-0.1921])\n",
						"第 5138 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0554]])\n",
						"模型中偏参梯度 tensor([-0.1920])\n",
						"第 5139 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0554]])\n",
						"模型中偏参梯度 tensor([-0.1919])\n",
						"第 5140 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0553]])\n",
						"模型中偏参梯度 tensor([-0.1918])\n",
						"第 257 次epoch\n",
						"第 5141 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0553]])\n",
						"模型中偏参梯度 tensor([-0.1918])\n",
						"第 5142 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0553]])\n",
						"模型中偏参梯度 tensor([-0.1917])\n",
						"第 5143 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0552]])\n",
						"模型中偏参梯度 tensor([-0.1916])\n",
						"第 5144 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0552]])\n",
						"模型中偏参梯度 tensor([-0.1915])\n",
						"第 5145 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0552]])\n",
						"模型中偏参梯度 tensor([-0.1915])\n",
						"第 5146 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0551]])\n",
						"模型中偏参梯度 tensor([-0.1914])\n",
						"第 5147 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0551]])\n",
						"模型中偏参梯度 tensor([-0.1913])\n",
						"第 5148 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0551]])\n",
						"模型中偏参梯度 tensor([-0.1912])\n",
						"第 5149 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0551]])\n",
						"模型中偏参梯度 tensor([-0.1912])\n",
						"第 5150 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0550]])\n",
						"模型中偏参梯度 tensor([-0.1911])\n",
						"第 5151 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0550]])\n",
						"模型中偏参梯度 tensor([-0.1910])\n",
						"第 5152 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0550]])\n",
						"模型中偏参梯度 tensor([-0.1910])\n",
						"第 5153 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0549]])\n",
						"模型中偏参梯度 tensor([-0.1909])\n",
						"第 5154 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0549]])\n",
						"模型中偏参梯度 tensor([-0.1908])\n",
						"第 5155 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0548]])\n",
						"模型中偏参梯度 tensor([-0.1907])\n",
						"第 5156 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0548]])\n",
						"模型中偏参梯度 tensor([-0.1907])\n",
						"第 5157 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0548]])\n",
						"模型中偏参梯度 tensor([-0.1906])\n",
						"第 5158 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0547]])\n",
						"模型中偏参梯度 tensor([-0.1905])\n",
						"第 5159 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0547]])\n",
						"模型中偏参梯度 tensor([-0.1904])\n",
						"第 5160 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0547]])\n",
						"模型中偏参梯度 tensor([-0.1904])\n",
						"第 258 次epoch\n",
						"第 5161 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0546]])\n",
						"模型中偏参梯度 tensor([-0.1903])\n",
						"第 5162 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0546]])\n",
						"模型中偏参梯度 tensor([-0.1902])\n",
						"第 5163 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0546]])\n",
						"模型中偏参梯度 tensor([-0.1902])\n",
						"第 5164 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0545]])\n",
						"模型中偏参梯度 tensor([-0.1901])\n",
						"第 5165 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0545]])\n",
						"模型中偏参梯度 tensor([-0.1900])\n",
						"第 5166 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0544]])\n",
						"模型中偏参梯度 tensor([-0.1899])\n",
						"第 5167 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0544]])\n",
						"模型中偏参梯度 tensor([-0.1899])\n",
						"第 5168 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0544]])\n",
						"模型中偏参梯度 tensor([-0.1898])\n",
						"第 5169 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0543]])\n",
						"模型中偏参梯度 tensor([-0.1897])\n",
						"第 5170 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0543]])\n",
						"模型中偏参梯度 tensor([-0.1896])\n",
						"第 5171 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0543]])\n",
						"模型中偏参梯度 tensor([-0.1896])\n",
						"第 5172 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0543]])\n",
						"模型中偏参梯度 tensor([-0.1895])\n",
						"第 5173 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0543]])\n",
						"模型中偏参梯度 tensor([-0.1894])\n",
						"第 5174 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0543]])\n",
						"模型中偏参梯度 tensor([-0.1893])\n",
						"第 5175 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0543]])\n",
						"模型中偏参梯度 tensor([-0.1892])\n",
						"第 5176 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0543]])\n",
						"模型中偏参梯度 tensor([-0.1892])\n",
						"第 5177 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0543]])\n",
						"模型中偏参梯度 tensor([-0.1891])\n",
						"第 5178 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0543]])\n",
						"模型中偏参梯度 tensor([-0.1890])\n",
						"第 5179 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0543]])\n",
						"模型中偏参梯度 tensor([-0.1889])\n",
						"第 5180 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0543]])\n",
						"模型中偏参梯度 tensor([-0.1888])\n",
						"第 259 次epoch\n",
						"第 5181 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0543]])\n",
						"模型中偏参梯度 tensor([-0.1888])\n",
						"第 5182 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0543]])\n",
						"模型中偏参梯度 tensor([-0.1887])\n",
						"第 5183 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0542]])\n",
						"模型中偏参梯度 tensor([-0.1886])\n",
						"第 5184 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0542]])\n",
						"模型中偏参梯度 tensor([-0.1885])\n",
						"第 5185 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0542]])\n",
						"模型中偏参梯度 tensor([-0.1884])\n",
						"第 5186 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0542]])\n",
						"模型中偏参梯度 tensor([-0.1884])\n",
						"第 5187 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0542]])\n",
						"模型中偏参梯度 tensor([-0.1883])\n",
						"第 5188 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0542]])\n",
						"模型中偏参梯度 tensor([-0.1882])\n",
						"第 5189 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0542]])\n",
						"模型中偏参梯度 tensor([-0.1881])\n",
						"第 5190 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0542]])\n",
						"模型中偏参梯度 tensor([-0.1880])\n",
						"第 5191 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0542]])\n",
						"模型中偏参梯度 tensor([-0.1880])\n",
						"第 5192 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0541]])\n",
						"模型中偏参梯度 tensor([-0.1879])\n",
						"第 5193 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0541]])\n",
						"模型中偏参梯度 tensor([-0.1878])\n",
						"第 5194 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0541]])\n",
						"模型中偏参梯度 tensor([-0.1877])\n",
						"第 5195 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0541]])\n",
						"模型中偏参梯度 tensor([-0.1876])\n",
						"第 5196 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0541]])\n",
						"模型中偏参梯度 tensor([-0.1876])\n",
						"第 5197 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0541]])\n",
						"模型中偏参梯度 tensor([-0.1875])\n",
						"第 5198 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0541]])\n",
						"模型中偏参梯度 tensor([-0.1874])\n",
						"第 5199 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0541]])\n",
						"模型中偏参梯度 tensor([-0.1873])\n",
						"第 5200 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0540]])\n",
						"模型中偏参梯度 tensor([-0.1873])\n",
						"第 260 次epoch\n",
						"第 5201 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0540]])\n",
						"模型中偏参梯度 tensor([-0.1872])\n",
						"第 5202 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0540]])\n",
						"模型中偏参梯度 tensor([-0.1871])\n",
						"第 5203 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0540]])\n",
						"模型中偏参梯度 tensor([-0.1870])\n",
						"第 5204 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0540]])\n",
						"模型中偏参梯度 tensor([-0.1870])\n",
						"第 5205 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0539]])\n",
						"模型中偏参梯度 tensor([-0.1869])\n",
						"第 5206 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0539]])\n",
						"模型中偏参梯度 tensor([-0.1868])\n",
						"第 5207 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0539]])\n",
						"模型中偏参梯度 tensor([-0.1867])\n",
						"第 5208 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0539]])\n",
						"模型中偏参梯度 tensor([-0.1867])\n",
						"第 5209 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0539]])\n",
						"模型中偏参梯度 tensor([-0.1866])\n",
						"第 5210 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0539]])\n",
						"模型中偏参梯度 tensor([-0.1865])\n",
						"第 5211 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0538]])\n",
						"模型中偏参梯度 tensor([-0.1864])\n",
						"第 5212 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0538]])\n",
						"模型中偏参梯度 tensor([-0.1863])\n",
						"第 5213 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0538]])\n",
						"模型中偏参梯度 tensor([-0.1863])\n",
						"第 5214 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0538]])\n",
						"模型中偏参梯度 tensor([-0.1862])\n",
						"第 5215 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0537]])\n",
						"模型中偏参梯度 tensor([-0.1861])\n",
						"第 5216 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0537]])\n",
						"模型中偏参梯度 tensor([-0.1861])\n",
						"第 5217 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0537]])\n",
						"模型中偏参梯度 tensor([-0.1860])\n",
						"第 5218 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0537]])\n",
						"模型中偏参梯度 tensor([-0.1859])\n",
						"第 5219 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0537]])\n",
						"模型中偏参梯度 tensor([-0.1858])\n",
						"第 5220 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0536]])\n",
						"模型中偏参梯度 tensor([-0.1858])\n",
						"第 261 次epoch\n",
						"第 5221 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0536]])\n",
						"模型中偏参梯度 tensor([-0.1857])\n",
						"第 5222 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0536]])\n",
						"模型中偏参梯度 tensor([-0.1856])\n",
						"第 5223 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0536]])\n",
						"模型中偏参梯度 tensor([-0.1855])\n",
						"第 5224 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0535]])\n",
						"模型中偏参梯度 tensor([-0.1855])\n",
						"第 5225 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0535]])\n",
						"模型中偏参梯度 tensor([-0.1854])\n",
						"第 5226 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0535]])\n",
						"模型中偏参梯度 tensor([-0.1853])\n",
						"第 5227 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0534]])\n",
						"模型中偏参梯度 tensor([-0.1852])\n",
						"第 5228 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0534]])\n",
						"模型中偏参梯度 tensor([-0.1852])\n",
						"第 5229 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0534]])\n",
						"模型中偏参梯度 tensor([-0.1851])\n",
						"第 5230 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0534]])\n",
						"模型中偏参梯度 tensor([-0.1850])\n",
						"第 5231 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0533]])\n",
						"模型中偏参梯度 tensor([-0.1850])\n",
						"第 5232 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0533]])\n",
						"模型中偏参梯度 tensor([-0.1849])\n",
						"第 5233 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0533]])\n",
						"模型中偏参梯度 tensor([-0.1848])\n",
						"第 5234 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0532]])\n",
						"模型中偏参梯度 tensor([-0.1847])\n",
						"第 5235 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0532]])\n",
						"模型中偏参梯度 tensor([-0.1847])\n",
						"第 5236 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0532]])\n",
						"模型中偏参梯度 tensor([-0.1846])\n",
						"第 5237 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0532]])\n",
						"模型中偏参梯度 tensor([-0.1845])\n",
						"第 5238 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0531]])\n",
						"模型中偏参梯度 tensor([-0.1844])\n",
						"第 5239 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0531]])\n",
						"模型中偏参梯度 tensor([-0.1844])\n",
						"第 5240 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0531]])\n",
						"模型中偏参梯度 tensor([-0.1843])\n",
						"第 262 次epoch\n",
						"第 5241 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0530]])\n",
						"模型中偏参梯度 tensor([-0.1842])\n",
						"第 5242 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0530]])\n",
						"模型中偏参梯度 tensor([-0.1842])\n",
						"第 5243 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0529]])\n",
						"模型中偏参梯度 tensor([-0.1841])\n",
						"第 5244 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0529]])\n",
						"模型中偏参梯度 tensor([-0.1840])\n",
						"第 5245 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0529]])\n",
						"模型中偏参梯度 tensor([-0.1840])\n",
						"第 5246 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0528]])\n",
						"模型中偏参梯度 tensor([-0.1839])\n",
						"第 5247 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0528]])\n",
						"模型中偏参梯度 tensor([-0.1838])\n",
						"第 5248 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0528]])\n",
						"模型中偏参梯度 tensor([-0.1837])\n",
						"第 5249 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0527]])\n",
						"模型中偏参梯度 tensor([-0.1837])\n",
						"第 5250 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0527]])\n",
						"模型中偏参梯度 tensor([-0.1836])\n",
						"第 5251 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0527]])\n",
						"模型中偏参梯度 tensor([-0.1835])\n",
						"第 5252 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0526]])\n",
						"模型中偏参梯度 tensor([-0.1835])\n",
						"第 5253 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0526]])\n",
						"模型中偏参梯度 tensor([-0.1834])\n",
						"第 5254 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0526]])\n",
						"模型中偏参梯度 tensor([-0.1833])\n",
						"第 5255 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0525]])\n",
						"模型中偏参梯度 tensor([-0.1833])\n",
						"第 5256 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0525]])\n",
						"模型中偏参梯度 tensor([-0.1832])\n",
						"第 5257 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0524]])\n",
						"模型中偏参梯度 tensor([-0.1831])\n",
						"第 5258 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0524]])\n",
						"模型中偏参梯度 tensor([-0.1830])\n",
						"第 5259 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0524]])\n",
						"模型中偏参梯度 tensor([-0.1830])\n",
						"第 5260 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0524]])\n",
						"模型中偏参梯度 tensor([-0.1829])\n",
						"第 263 次epoch\n",
						"第 5261 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0524]])\n",
						"模型中偏参梯度 tensor([-0.1828])\n",
						"第 5262 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0524]])\n",
						"模型中偏参梯度 tensor([-0.1827])\n",
						"第 5263 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0524]])\n",
						"模型中偏参梯度 tensor([-0.1826])\n",
						"第 5264 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0524]])\n",
						"模型中偏参梯度 tensor([-0.1826])\n",
						"第 5265 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0524]])\n",
						"模型中偏参梯度 tensor([-0.1825])\n",
						"第 5266 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0524]])\n",
						"模型中偏参梯度 tensor([-0.1824])\n",
						"第 5267 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0524]])\n",
						"模型中偏参梯度 tensor([-0.1823])\n",
						"第 5268 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0524]])\n",
						"模型中偏参梯度 tensor([-0.1823])\n",
						"第 5269 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0524]])\n",
						"模型中偏参梯度 tensor([-0.1822])\n",
						"第 5270 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0524]])\n",
						"模型中偏参梯度 tensor([-0.1821])\n",
						"第 5271 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0524]])\n",
						"模型中偏参梯度 tensor([-0.1820])\n",
						"第 5272 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0524]])\n",
						"模型中偏参梯度 tensor([-0.1820])\n",
						"第 5273 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0524]])\n",
						"模型中偏参梯度 tensor([-0.1819])\n",
						"第 5274 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0524]])\n",
						"模型中偏参梯度 tensor([-0.1818])\n",
						"第 5275 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0523]])\n",
						"模型中偏参梯度 tensor([-0.1817])\n",
						"第 5276 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0523]])\n",
						"模型中偏参梯度 tensor([-0.1816])\n",
						"第 5277 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0523]])\n",
						"模型中偏参梯度 tensor([-0.1816])\n",
						"第 5278 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0523]])\n",
						"模型中偏参梯度 tensor([-0.1815])\n",
						"第 5279 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0523]])\n",
						"模型中偏参梯度 tensor([-0.1814])\n",
						"第 5280 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0523]])\n",
						"模型中偏参梯度 tensor([-0.1813])\n",
						"第 264 次epoch\n",
						"第 5281 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0523]])\n",
						"模型中偏参梯度 tensor([-0.1813])\n",
						"第 5282 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0523]])\n",
						"模型中偏参梯度 tensor([-0.1812])\n",
						"第 5283 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0522]])\n",
						"模型中偏参梯度 tensor([-0.1811])\n",
						"第 5284 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0522]])\n",
						"模型中偏参梯度 tensor([-0.1810])\n",
						"第 5285 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0522]])\n",
						"模型中偏参梯度 tensor([-0.1810])\n",
						"第 5286 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0522]])\n",
						"模型中偏参梯度 tensor([-0.1809])\n",
						"第 5287 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0522]])\n",
						"模型中偏参梯度 tensor([-0.1808])\n",
						"第 5288 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0522]])\n",
						"模型中偏参梯度 tensor([-0.1807])\n",
						"第 5289 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0522]])\n",
						"模型中偏参梯度 tensor([-0.1807])\n",
						"第 5290 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0522]])\n",
						"模型中偏参梯度 tensor([-0.1806])\n",
						"第 5291 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0521]])\n",
						"模型中偏参梯度 tensor([-0.1805])\n",
						"第 5292 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0521]])\n",
						"模型中偏参梯度 tensor([-0.1804])\n",
						"第 5293 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0521]])\n",
						"模型中偏参梯度 tensor([-0.1804])\n",
						"第 5294 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0521]])\n",
						"模型中偏参梯度 tensor([-0.1803])\n",
						"第 5295 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0521]])\n",
						"模型中偏参梯度 tensor([-0.1802])\n",
						"第 5296 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0520]])\n",
						"模型中偏参梯度 tensor([-0.1802])\n",
						"第 5297 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0520]])\n",
						"模型中偏参梯度 tensor([-0.1801])\n",
						"第 5298 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0520]])\n",
						"模型中偏参梯度 tensor([-0.1800])\n",
						"第 5299 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0520]])\n",
						"模型中偏参梯度 tensor([-0.1799])\n",
						"第 5300 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0520]])\n",
						"模型中偏参梯度 tensor([-0.1799])\n",
						"第 265 次epoch\n",
						"第 5301 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0520]])\n",
						"模型中偏参梯度 tensor([-0.1798])\n",
						"第 5302 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0519]])\n",
						"模型中偏参梯度 tensor([-0.1797])\n",
						"第 5303 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0519]])\n",
						"模型中偏参梯度 tensor([-0.1796])\n",
						"第 5304 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0519]])\n",
						"模型中偏参梯度 tensor([-0.1796])\n",
						"第 5305 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0519]])\n",
						"模型中偏参梯度 tensor([-0.1795])\n",
						"第 5306 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0519]])\n",
						"模型中偏参梯度 tensor([-0.1794])\n",
						"第 5307 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0518]])\n",
						"模型中偏参梯度 tensor([-0.1794])\n",
						"第 5308 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0518]])\n",
						"模型中偏参梯度 tensor([-0.1793])\n",
						"第 5309 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0518]])\n",
						"模型中偏参梯度 tensor([-0.1792])\n",
						"第 5310 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0518]])\n",
						"模型中偏参梯度 tensor([-0.1791])\n",
						"第 5311 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0517]])\n",
						"模型中偏参梯度 tensor([-0.1791])\n",
						"第 5312 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0517]])\n",
						"模型中偏参梯度 tensor([-0.1790])\n",
						"第 5313 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0517]])\n",
						"模型中偏参梯度 tensor([-0.1789])\n",
						"第 5314 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0517]])\n",
						"模型中偏参梯度 tensor([-0.1789])\n",
						"第 5315 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0516]])\n",
						"模型中偏参梯度 tensor([-0.1788])\n",
						"第 5316 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0516]])\n",
						"模型中偏参梯度 tensor([-0.1787])\n",
						"第 5317 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0516]])\n",
						"模型中偏参梯度 tensor([-0.1786])\n",
						"第 5318 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0516]])\n",
						"模型中偏参梯度 tensor([-0.1786])\n",
						"第 5319 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0515]])\n",
						"模型中偏参梯度 tensor([-0.1785])\n",
						"第 5320 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0515]])\n",
						"模型中偏参梯度 tensor([-0.1784])\n",
						"第 266 次epoch\n",
						"第 5321 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0515]])\n",
						"模型中偏参梯度 tensor([-0.1784])\n",
						"第 5322 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0514]])\n",
						"模型中偏参梯度 tensor([-0.1783])\n",
						"第 5323 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0514]])\n",
						"模型中偏参梯度 tensor([-0.1782])\n",
						"第 5324 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0514]])\n",
						"模型中偏参梯度 tensor([-0.1782])\n",
						"第 5325 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0514]])\n",
						"模型中偏参梯度 tensor([-0.1781])\n",
						"第 5326 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0513]])\n",
						"模型中偏参梯度 tensor([-0.1780])\n",
						"第 5327 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0513]])\n",
						"模型中偏参梯度 tensor([-0.1779])\n",
						"第 5328 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0513]])\n",
						"模型中偏参梯度 tensor([-0.1779])\n",
						"第 5329 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0513]])\n",
						"模型中偏参梯度 tensor([-0.1778])\n",
						"第 5330 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0512]])\n",
						"模型中偏参梯度 tensor([-0.1777])\n",
						"第 5331 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0512]])\n",
						"模型中偏参梯度 tensor([-0.1777])\n",
						"第 5332 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0512]])\n",
						"模型中偏参梯度 tensor([-0.1776])\n",
						"第 5333 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0511]])\n",
						"模型中偏参梯度 tensor([-0.1775])\n",
						"第 5334 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0511]])\n",
						"模型中偏参梯度 tensor([-0.1775])\n",
						"第 5335 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0510]])\n",
						"模型中偏参梯度 tensor([-0.1774])\n",
						"第 5336 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0510]])\n",
						"模型中偏参梯度 tensor([-0.1773])\n",
						"第 5337 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0510]])\n",
						"模型中偏参梯度 tensor([-0.1773])\n",
						"第 5338 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0510]])\n",
						"模型中偏参梯度 tensor([-0.1772])\n",
						"第 5339 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0509]])\n",
						"模型中偏参梯度 tensor([-0.1771])\n",
						"第 5340 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0509]])\n",
						"模型中偏参梯度 tensor([-0.1771])\n",
						"第 267 次epoch\n",
						"第 5341 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0508]])\n",
						"模型中偏参梯度 tensor([-0.1770])\n",
						"第 5342 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0508]])\n",
						"模型中偏参梯度 tensor([-0.1769])\n",
						"第 5343 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0508]])\n",
						"模型中偏参梯度 tensor([-0.1769])\n",
						"第 5344 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0507]])\n",
						"模型中偏参梯度 tensor([-0.1768])\n",
						"第 5345 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0507]])\n",
						"模型中偏参梯度 tensor([-0.1767])\n",
						"第 5346 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0507]])\n",
						"模型中偏参梯度 tensor([-0.1767])\n",
						"第 5347 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0506]])\n",
						"模型中偏参梯度 tensor([-0.1766])\n",
						"第 5348 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0506]])\n",
						"模型中偏参梯度 tensor([-0.1765])\n",
						"第 5349 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0505]])\n",
						"模型中偏参梯度 tensor([-0.1765])\n",
						"第 5350 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0505]])\n",
						"模型中偏参梯度 tensor([-0.1764])\n",
						"第 5351 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0505]])\n",
						"模型中偏参梯度 tensor([-0.1763])\n",
						"第 5352 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0505]])\n",
						"模型中偏参梯度 tensor([-0.1762])\n",
						"第 5353 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0505]])\n",
						"模型中偏参梯度 tensor([-0.1762])\n",
						"第 5354 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0505]])\n",
						"模型中偏参梯度 tensor([-0.1761])\n",
						"第 5355 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0505]])\n",
						"模型中偏参梯度 tensor([-0.1760])\n",
						"第 5356 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0505]])\n",
						"模型中偏参梯度 tensor([-0.1759])\n",
						"第 5357 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0505]])\n",
						"模型中偏参梯度 tensor([-0.1759])\n",
						"第 5358 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0505]])\n",
						"模型中偏参梯度 tensor([-0.1758])\n",
						"第 5359 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0505]])\n",
						"模型中偏参梯度 tensor([-0.1757])\n",
						"第 5360 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0505]])\n",
						"模型中偏参梯度 tensor([-0.1756])\n",
						"第 268 次epoch\n",
						"第 5361 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0505]])\n",
						"模型中偏参梯度 tensor([-0.1756])\n",
						"第 5362 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0505]])\n",
						"模型中偏参梯度 tensor([-0.1755])\n",
						"第 5363 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0505]])\n",
						"模型中偏参梯度 tensor([-0.1754])\n",
						"第 5364 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0505]])\n",
						"模型中偏参梯度 tensor([-0.1753])\n",
						"第 5365 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0504]])\n",
						"模型中偏参梯度 tensor([-0.1753])\n",
						"第 5366 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0504]])\n",
						"模型中偏参梯度 tensor([-0.1752])\n",
						"第 5367 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0504]])\n",
						"模型中偏参梯度 tensor([-0.1751])\n",
						"第 5368 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0504]])\n",
						"模型中偏参梯度 tensor([-0.1750])\n",
						"第 5369 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0504]])\n",
						"模型中偏参梯度 tensor([-0.1750])\n",
						"第 5370 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0504]])\n",
						"模型中偏参梯度 tensor([-0.1749])\n",
						"第 5371 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0504]])\n",
						"模型中偏参梯度 tensor([-0.1748])\n",
						"第 5372 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0504]])\n",
						"模型中偏参梯度 tensor([-0.1748])\n",
						"第 5373 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0504]])\n",
						"模型中偏参梯度 tensor([-0.1747])\n",
						"第 5374 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0504]])\n",
						"模型中偏参梯度 tensor([-0.1746])\n",
						"第 5375 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0504]])\n",
						"模型中偏参梯度 tensor([-0.1745])\n",
						"第 5376 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0503]])\n",
						"模型中偏参梯度 tensor([-0.1745])\n",
						"第 5377 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0503]])\n",
						"模型中偏参梯度 tensor([-0.1744])\n",
						"第 5378 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0503]])\n",
						"模型中偏参梯度 tensor([-0.1743])\n",
						"第 5379 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0503]])\n",
						"模型中偏参梯度 tensor([-0.1742])\n",
						"第 5380 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0503]])\n",
						"模型中偏参梯度 tensor([-0.1742])\n",
						"第 269 次epoch\n",
						"第 5381 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0503]])\n",
						"模型中偏参梯度 tensor([-0.1741])\n",
						"第 5382 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0503]])\n",
						"模型中偏参梯度 tensor([-0.1740])\n",
						"第 5383 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0502]])\n",
						"模型中偏参梯度 tensor([-0.1740])\n",
						"第 5384 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0502]])\n",
						"模型中偏参梯度 tensor([-0.1739])\n",
						"第 5385 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0502]])\n",
						"模型中偏参梯度 tensor([-0.1738])\n",
						"第 5386 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0502]])\n",
						"模型中偏参梯度 tensor([-0.1737])\n",
						"第 5387 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0502]])\n",
						"模型中偏参梯度 tensor([-0.1737])\n",
						"第 5388 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0502]])\n",
						"模型中偏参梯度 tensor([-0.1736])\n",
						"第 5389 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0501]])\n",
						"模型中偏参梯度 tensor([-0.1735])\n",
						"第 5390 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0501]])\n",
						"模型中偏参梯度 tensor([-0.1735])\n",
						"第 5391 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0501]])\n",
						"模型中偏参梯度 tensor([-0.1734])\n",
						"第 5392 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0501]])\n",
						"模型中偏参梯度 tensor([-0.1733])\n",
						"第 5393 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0501]])\n",
						"模型中偏参梯度 tensor([-0.1733])\n",
						"第 5394 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0501]])\n",
						"模型中偏参梯度 tensor([-0.1732])\n",
						"第 5395 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0500]])\n",
						"模型中偏参梯度 tensor([-0.1731])\n",
						"第 5396 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0500]])\n",
						"模型中偏参梯度 tensor([-0.1730])\n",
						"第 5397 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0500]])\n",
						"模型中偏参梯度 tensor([-0.1730])\n",
						"第 5398 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0500]])\n",
						"模型中偏参梯度 tensor([-0.1729])\n",
						"第 5399 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0500]])\n",
						"模型中偏参梯度 tensor([-0.1728])\n",
						"第 5400 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0499]])\n",
						"模型中偏参梯度 tensor([-0.1728])\n",
						"第 270 次epoch\n",
						"第 5401 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0499]])\n",
						"模型中偏参梯度 tensor([-0.1727])\n",
						"第 5402 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0499]])\n",
						"模型中偏参梯度 tensor([-0.1726])\n",
						"第 5403 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0499]])\n",
						"模型中偏参梯度 tensor([-0.1726])\n",
						"第 5404 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0498]])\n",
						"模型中偏参梯度 tensor([-0.1725])\n",
						"第 5405 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0498]])\n",
						"模型中偏参梯度 tensor([-0.1724])\n",
						"第 5406 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0498]])\n",
						"模型中偏参梯度 tensor([-0.1724])\n",
						"第 5407 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0498]])\n",
						"模型中偏参梯度 tensor([-0.1723])\n",
						"第 5408 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0498]])\n",
						"模型中偏参梯度 tensor([-0.1722])\n",
						"第 5409 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0497]])\n",
						"模型中偏参梯度 tensor([-0.1721])\n",
						"第 5410 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0497]])\n",
						"模型中偏参梯度 tensor([-0.1721])\n",
						"第 5411 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0497]])\n",
						"模型中偏参梯度 tensor([-0.1720])\n",
						"第 5412 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0497]])\n",
						"模型中偏参梯度 tensor([-0.1719])\n",
						"第 5413 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0496]])\n",
						"模型中偏参梯度 tensor([-0.1719])\n",
						"第 5414 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0496]])\n",
						"模型中偏参梯度 tensor([-0.1718])\n",
						"第 5415 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0496]])\n",
						"模型中偏参梯度 tensor([-0.1717])\n",
						"第 5416 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0495]])\n",
						"模型中偏参梯度 tensor([-0.1717])\n",
						"第 5417 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0495]])\n",
						"模型中偏参梯度 tensor([-0.1716])\n",
						"第 5418 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0495]])\n",
						"模型中偏参梯度 tensor([-0.1715])\n",
						"第 5419 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0495]])\n",
						"模型中偏参梯度 tensor([-0.1715])\n",
						"第 5420 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0494]])\n",
						"模型中偏参梯度 tensor([-0.1714])\n",
						"第 271 次epoch\n",
						"第 5421 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0494]])\n",
						"模型中偏参梯度 tensor([-0.1713])\n",
						"第 5422 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0494]])\n",
						"模型中偏参梯度 tensor([-0.1713])\n",
						"第 5423 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0494]])\n",
						"模型中偏参梯度 tensor([-0.1712])\n",
						"第 5424 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0493]])\n",
						"模型中偏参梯度 tensor([-0.1711])\n",
						"第 5425 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0493]])\n",
						"模型中偏参梯度 tensor([-0.1711])\n",
						"第 5426 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0493]])\n",
						"模型中偏参梯度 tensor([-0.1710])\n",
						"第 5427 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0492]])\n",
						"模型中偏参梯度 tensor([-0.1709])\n",
						"第 5428 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0492]])\n",
						"模型中偏参梯度 tensor([-0.1709])\n",
						"第 5429 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0492]])\n",
						"模型中偏参梯度 tensor([-0.1708])\n",
						"第 5430 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0491]])\n",
						"模型中偏参梯度 tensor([-0.1708])\n",
						"第 5431 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0491]])\n",
						"模型中偏参梯度 tensor([-0.1707])\n",
						"第 5432 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0491]])\n",
						"模型中偏参梯度 tensor([-0.1706])\n",
						"第 5433 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0490]])\n",
						"模型中偏参梯度 tensor([-0.1706])\n",
						"第 5434 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0490]])\n",
						"模型中偏参梯度 tensor([-0.1705])\n",
						"第 5435 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0490]])\n",
						"模型中偏参梯度 tensor([-0.1704])\n",
						"第 5436 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0489]])\n",
						"模型中偏参梯度 tensor([-0.1704])\n",
						"第 5437 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0489]])\n",
						"模型中偏参梯度 tensor([-0.1703])\n",
						"第 5438 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0489]])\n",
						"模型中偏参梯度 tensor([-0.1702])\n",
						"第 5439 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0488]])\n",
						"模型中偏参梯度 tensor([-0.1702])\n",
						"第 5440 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0488]])\n",
						"模型中偏参梯度 tensor([-0.1701])\n",
						"第 272 次epoch\n",
						"第 5441 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0488]])\n",
						"模型中偏参梯度 tensor([-0.1700])\n",
						"第 5442 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0487]])\n",
						"模型中偏参梯度 tensor([-0.1700])\n",
						"第 5443 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0487]])\n",
						"模型中偏参梯度 tensor([-0.1699])\n",
						"第 5444 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0486]])\n",
						"模型中偏参梯度 tensor([-0.1699])\n",
						"第 5445 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0486]])\n",
						"模型中偏参梯度 tensor([-0.1698])\n",
						"第 5446 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0486]])\n",
						"模型中偏参梯度 tensor([-0.1697])\n",
						"第 5447 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0486]])\n",
						"模型中偏参梯度 tensor([-0.1696])\n",
						"第 5448 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0486]])\n",
						"模型中偏参梯度 tensor([-0.1696])\n",
						"第 5449 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0486]])\n",
						"模型中偏参梯度 tensor([-0.1695])\n",
						"第 5450 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0486]])\n",
						"模型中偏参梯度 tensor([-0.1694])\n",
						"第 5451 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0486]])\n",
						"模型中偏参梯度 tensor([-0.1693])\n",
						"第 5452 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0486]])\n",
						"模型中偏参梯度 tensor([-0.1693])\n",
						"第 5453 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0486]])\n",
						"模型中偏参梯度 tensor([-0.1692])\n",
						"第 5454 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0486]])\n",
						"模型中偏参梯度 tensor([-0.1691])\n",
						"第 5455 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0486]])\n",
						"模型中偏参梯度 tensor([-0.1691])\n",
						"第 5456 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0486]])\n",
						"模型中偏参梯度 tensor([-0.1690])\n",
						"第 5457 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0486]])\n",
						"模型中偏参梯度 tensor([-0.1689])\n",
						"第 5458 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0486]])\n",
						"模型中偏参梯度 tensor([-0.1688])\n",
						"第 5459 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0486]])\n",
						"模型中偏参梯度 tensor([-0.1688])\n",
						"第 5460 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0486]])\n",
						"模型中偏参梯度 tensor([-0.1687])\n",
						"第 273 次epoch\n",
						"第 5461 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0485]])\n",
						"模型中偏参梯度 tensor([-0.1686])\n",
						"第 5462 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0485]])\n",
						"模型中偏参梯度 tensor([-0.1686])\n",
						"第 5463 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0485]])\n",
						"模型中偏参梯度 tensor([-0.1685])\n",
						"第 5464 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0485]])\n",
						"模型中偏参梯度 tensor([-0.1684])\n",
						"第 5465 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0485]])\n",
						"模型中偏参梯度 tensor([-0.1683])\n",
						"第 5466 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0485]])\n",
						"模型中偏参梯度 tensor([-0.1683])\n",
						"第 5467 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0485]])\n",
						"模型中偏参梯度 tensor([-0.1682])\n",
						"第 5468 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0485]])\n",
						"模型中偏参梯度 tensor([-0.1681])\n",
						"第 5469 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0485]])\n",
						"模型中偏参梯度 tensor([-0.1681])\n",
						"第 5470 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0485]])\n",
						"模型中偏参梯度 tensor([-0.1680])\n",
						"第 5471 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0485]])\n",
						"模型中偏参梯度 tensor([-0.1679])\n",
						"第 5472 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0484]])\n",
						"模型中偏参梯度 tensor([-0.1678])\n",
						"第 5473 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0484]])\n",
						"模型中偏参梯度 tensor([-0.1678])\n",
						"第 5474 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0484]])\n",
						"模型中偏参梯度 tensor([-0.1677])\n",
						"第 5475 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0484]])\n",
						"模型中偏参梯度 tensor([-0.1676])\n",
						"第 5476 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0484]])\n",
						"模型中偏参梯度 tensor([-0.1676])\n",
						"第 5477 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0484]])\n",
						"模型中偏参梯度 tensor([-0.1675])\n",
						"第 5478 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0484]])\n",
						"模型中偏参梯度 tensor([-0.1674])\n",
						"第 5479 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0484]])\n",
						"模型中偏参梯度 tensor([-0.1674])\n",
						"第 5480 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0484]])\n",
						"模型中偏参梯度 tensor([-0.1673])\n",
						"第 274 次epoch\n",
						"第 5481 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0483]])\n",
						"模型中偏参梯度 tensor([-0.1672])\n",
						"第 5482 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0483]])\n",
						"模型中偏参梯度 tensor([-0.1672])\n",
						"第 5483 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0483]])\n",
						"模型中偏参梯度 tensor([-0.1671])\n",
						"第 5484 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0483]])\n",
						"模型中偏参梯度 tensor([-0.1670])\n",
						"第 5485 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0483]])\n",
						"模型中偏参梯度 tensor([-0.1670])\n",
						"第 5486 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0483]])\n",
						"模型中偏参梯度 tensor([-0.1669])\n",
						"第 5487 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0482]])\n",
						"模型中偏参梯度 tensor([-0.1668])\n",
						"第 5488 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0482]])\n",
						"模型中偏参梯度 tensor([-0.1667])\n",
						"第 5489 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0482]])\n",
						"模型中偏参梯度 tensor([-0.1667])\n",
						"第 5490 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0482]])\n",
						"模型中偏参梯度 tensor([-0.1666])\n",
						"第 5491 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0482]])\n",
						"模型中偏参梯度 tensor([-0.1665])\n",
						"第 5492 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0482]])\n",
						"模型中偏参梯度 tensor([-0.1665])\n",
						"第 5493 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0481]])\n",
						"模型中偏参梯度 tensor([-0.1664])\n",
						"第 5494 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0481]])\n",
						"模型中偏参梯度 tensor([-0.1663])\n",
						"第 5495 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0481]])\n",
						"模型中偏参梯度 tensor([-0.1663])\n",
						"第 5496 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0481]])\n",
						"模型中偏参梯度 tensor([-0.1662])\n",
						"第 5497 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0481]])\n",
						"模型中偏参梯度 tensor([-0.1661])\n",
						"第 5498 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0480]])\n",
						"模型中偏参梯度 tensor([-0.1661])\n",
						"第 5499 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0480]])\n",
						"模型中偏参梯度 tensor([-0.1660])\n",
						"第 5500 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0480]])\n",
						"模型中偏参梯度 tensor([-0.1659])\n",
						"第 275 次epoch\n",
						"第 5501 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0480]])\n",
						"模型中偏参梯度 tensor([-0.1659])\n",
						"第 5502 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0480]])\n",
						"模型中偏参梯度 tensor([-0.1658])\n",
						"第 5503 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0479]])\n",
						"模型中偏参梯度 tensor([-0.1657])\n",
						"第 5504 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0479]])\n",
						"模型中偏参梯度 tensor([-0.1657])\n",
						"第 5505 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0479]])\n",
						"模型中偏参梯度 tensor([-0.1656])\n",
						"第 5506 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0479]])\n",
						"模型中偏参梯度 tensor([-0.1656])\n",
						"第 5507 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0478]])\n",
						"模型中偏参梯度 tensor([-0.1655])\n",
						"第 5508 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0478]])\n",
						"模型中偏参梯度 tensor([-0.1654])\n",
						"第 5509 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0478]])\n",
						"模型中偏参梯度 tensor([-0.1654])\n",
						"第 5510 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0478]])\n",
						"模型中偏参梯度 tensor([-0.1653])\n",
						"第 5511 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0477]])\n",
						"模型中偏参梯度 tensor([-0.1652])\n",
						"第 5512 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0477]])\n",
						"模型中偏参梯度 tensor([-0.1652])\n",
						"第 5513 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0477]])\n",
						"模型中偏参梯度 tensor([-0.1651])\n",
						"第 5514 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0477]])\n",
						"模型中偏参梯度 tensor([-0.1650])\n",
						"第 5515 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0476]])\n",
						"模型中偏参梯度 tensor([-0.1650])\n",
						"第 5516 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0476]])\n",
						"模型中偏参梯度 tensor([-0.1649])\n",
						"第 5517 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0476]])\n",
						"模型中偏参梯度 tensor([-0.1648])\n",
						"第 5518 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0476]])\n",
						"模型中偏参梯度 tensor([-0.1648])\n",
						"第 5519 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0475]])\n",
						"模型中偏参梯度 tensor([-0.1647])\n",
						"第 5520 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0475]])\n",
						"模型中偏参梯度 tensor([-0.1646])\n",
						"第 276 次epoch\n",
						"第 5521 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0475]])\n",
						"模型中偏参梯度 tensor([-0.1646])\n",
						"第 5522 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0474]])\n",
						"模型中偏参梯度 tensor([-0.1645])\n",
						"第 5523 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0474]])\n",
						"模型中偏参梯度 tensor([-0.1645])\n",
						"第 5524 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0474]])\n",
						"模型中偏参梯度 tensor([-0.1644])\n",
						"第 5525 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0473]])\n",
						"模型中偏参梯度 tensor([-0.1643])\n",
						"第 5526 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0473]])\n",
						"模型中偏参梯度 tensor([-0.1643])\n",
						"第 5527 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0473]])\n",
						"模型中偏参梯度 tensor([-0.1642])\n",
						"第 5528 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0472]])\n",
						"模型中偏参梯度 tensor([-0.1641])\n",
						"第 5529 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0472]])\n",
						"模型中偏参梯度 tensor([-0.1641])\n",
						"第 5530 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0472]])\n",
						"模型中偏参梯度 tensor([-0.1640])\n",
						"第 5531 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0472]])\n",
						"模型中偏参梯度 tensor([-0.1640])\n",
						"第 5532 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0471]])\n",
						"模型中偏参梯度 tensor([-0.1639])\n",
						"第 5533 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0471]])\n",
						"模型中偏参梯度 tensor([-0.1638])\n",
						"第 5534 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0471]])\n",
						"模型中偏参梯度 tensor([-0.1638])\n",
						"第 5535 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0470]])\n",
						"模型中偏参梯度 tensor([-0.1637])\n",
						"第 5536 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0470]])\n",
						"模型中偏参梯度 tensor([-0.1636])\n",
						"第 5537 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0470]])\n",
						"模型中偏参梯度 tensor([-0.1636])\n",
						"第 5538 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0469]])\n",
						"模型中偏参梯度 tensor([-0.1635])\n",
						"第 5539 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0469]])\n",
						"模型中偏参梯度 tensor([-0.1635])\n",
						"第 5540 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0468]])\n",
						"模型中偏参梯度 tensor([-0.1634])\n",
						"第 277 次epoch\n",
						"第 5541 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0468]])\n",
						"模型中偏参梯度 tensor([-0.1633])\n",
						"第 5542 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0468]])\n",
						"模型中偏参梯度 tensor([-0.1633])\n",
						"第 5543 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0467]])\n",
						"模型中偏参梯度 tensor([-0.1632])\n",
						"第 5544 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0467]])\n",
						"模型中偏参梯度 tensor([-0.1632])\n",
						"第 5545 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0467]])\n",
						"模型中偏参梯度 tensor([-0.1631])\n",
						"第 5546 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0467]])\n",
						"模型中偏参梯度 tensor([-0.1630])\n",
						"第 5547 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0467]])\n",
						"模型中偏参梯度 tensor([-0.1629])\n",
						"第 5548 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0467]])\n",
						"模型中偏参梯度 tensor([-0.1629])\n",
						"第 5549 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0467]])\n",
						"模型中偏参梯度 tensor([-0.1628])\n",
						"第 5550 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0467]])\n",
						"模型中偏参梯度 tensor([-0.1627])\n",
						"第 5551 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0467]])\n",
						"模型中偏参梯度 tensor([-0.1627])\n",
						"第 5552 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0467]])\n",
						"模型中偏参梯度 tensor([-0.1626])\n",
						"第 5553 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0467]])\n",
						"模型中偏参梯度 tensor([-0.1625])\n",
						"第 5554 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0467]])\n",
						"模型中偏参梯度 tensor([-0.1625])\n",
						"第 5555 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0467]])\n",
						"模型中偏参梯度 tensor([-0.1624])\n",
						"第 5556 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0467]])\n",
						"模型中偏参梯度 tensor([-0.1623])\n",
						"第 5557 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0467]])\n",
						"模型中偏参梯度 tensor([-0.1622])\n",
						"第 5558 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0467]])\n",
						"模型中偏参梯度 tensor([-0.1622])\n",
						"第 5559 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0467]])\n",
						"模型中偏参梯度 tensor([-0.1621])\n",
						"第 5560 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0467]])\n",
						"模型中偏参梯度 tensor([-0.1620])\n",
						"第 278 次epoch\n",
						"第 5561 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0467]])\n",
						"模型中偏参梯度 tensor([-0.1620])\n",
						"第 5562 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0467]])\n",
						"模型中偏参梯度 tensor([-0.1619])\n",
						"第 5563 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0466]])\n",
						"模型中偏参梯度 tensor([-0.1618])\n",
						"第 5564 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0466]])\n",
						"模型中偏参梯度 tensor([-0.1618])\n",
						"第 5565 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0466]])\n",
						"模型中偏参梯度 tensor([-0.1617])\n",
						"第 5566 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0466]])\n",
						"模型中偏参梯度 tensor([-0.1616])\n",
						"第 5567 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0466]])\n",
						"模型中偏参梯度 tensor([-0.1616])\n",
						"第 5568 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0466]])\n",
						"模型中偏参梯度 tensor([-0.1615])\n",
						"第 5569 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0466]])\n",
						"模型中偏参梯度 tensor([-0.1614])\n",
						"第 5570 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0466]])\n",
						"模型中偏参梯度 tensor([-0.1614])\n",
						"第 5571 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0466]])\n",
						"模型中偏参梯度 tensor([-0.1613])\n",
						"第 5572 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0466]])\n",
						"模型中偏参梯度 tensor([-0.1612])\n",
						"第 5573 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0466]])\n",
						"模型中偏参梯度 tensor([-0.1612])\n",
						"第 5574 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0465]])\n",
						"模型中偏参梯度 tensor([-0.1611])\n",
						"第 5575 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0465]])\n",
						"模型中偏参梯度 tensor([-0.1610])\n",
						"第 5576 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0465]])\n",
						"模型中偏参梯度 tensor([-0.1610])\n",
						"第 5577 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0465]])\n",
						"模型中偏参梯度 tensor([-0.1609])\n",
						"第 5578 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0465]])\n",
						"模型中偏参梯度 tensor([-0.1608])\n",
						"第 5579 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0465]])\n",
						"模型中偏参梯度 tensor([-0.1608])\n",
						"第 5580 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0465]])\n",
						"模型中偏参梯度 tensor([-0.1607])\n",
						"第 279 次epoch\n",
						"第 5581 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0465]])\n",
						"模型中偏参梯度 tensor([-0.1606])\n",
						"第 5582 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0465]])\n",
						"模型中偏参梯度 tensor([-0.1606])\n",
						"第 5583 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0464]])\n",
						"模型中偏参梯度 tensor([-0.1605])\n",
						"第 5584 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0464]])\n",
						"模型中偏参梯度 tensor([-0.1604])\n",
						"第 5585 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0464]])\n",
						"模型中偏参梯度 tensor([-0.1604])\n",
						"第 5586 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0464]])\n",
						"模型中偏参梯度 tensor([-0.1603])\n",
						"第 5587 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0464]])\n",
						"模型中偏参梯度 tensor([-0.1602])\n",
						"第 5588 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0464]])\n",
						"模型中偏参梯度 tensor([-0.1602])\n",
						"第 5589 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0463]])\n",
						"模型中偏参梯度 tensor([-0.1601])\n",
						"第 5590 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0463]])\n",
						"模型中偏参梯度 tensor([-0.1600])\n",
						"第 5591 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0463]])\n",
						"模型中偏参梯度 tensor([-0.1600])\n",
						"第 5592 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0463]])\n",
						"模型中偏参梯度 tensor([-0.1599])\n",
						"第 5593 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0463]])\n",
						"模型中偏参梯度 tensor([-0.1598])\n",
						"第 5594 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0463]])\n",
						"模型中偏参梯度 tensor([-0.1598])\n",
						"第 5595 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0463]])\n",
						"模型中偏参梯度 tensor([-0.1597])\n",
						"第 5596 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0462]])\n",
						"模型中偏参梯度 tensor([-0.1596])\n",
						"第 5597 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0462]])\n",
						"模型中偏参梯度 tensor([-0.1596])\n",
						"第 5598 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0462]])\n",
						"模型中偏参梯度 tensor([-0.1595])\n",
						"第 5599 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0462]])\n",
						"模型中偏参梯度 tensor([-0.1595])\n",
						"第 5600 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0461]])\n",
						"模型中偏参梯度 tensor([-0.1594])\n",
						"第 280 次epoch\n",
						"第 5601 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0461]])\n",
						"模型中偏参梯度 tensor([-0.1593])\n",
						"第 5602 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0461]])\n",
						"模型中偏参梯度 tensor([-0.1593])\n",
						"第 5603 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0461]])\n",
						"模型中偏参梯度 tensor([-0.1592])\n",
						"第 5604 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0461]])\n",
						"模型中偏参梯度 tensor([-0.1591])\n",
						"第 5605 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0460]])\n",
						"模型中偏参梯度 tensor([-0.1591])\n",
						"第 5606 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0460]])\n",
						"模型中偏参梯度 tensor([-0.1590])\n",
						"第 5607 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0460]])\n",
						"模型中偏参梯度 tensor([-0.1589])\n",
						"第 5608 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0460]])\n",
						"模型中偏参梯度 tensor([-0.1589])\n",
						"第 5609 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0460]])\n",
						"模型中偏参梯度 tensor([-0.1588])\n",
						"第 5610 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0459]])\n",
						"模型中偏参梯度 tensor([-0.1588])\n",
						"第 5611 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0459]])\n",
						"模型中偏参梯度 tensor([-0.1587])\n",
						"第 5612 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0459]])\n",
						"模型中偏参梯度 tensor([-0.1586])\n",
						"第 5613 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0459]])\n",
						"模型中偏参梯度 tensor([-0.1586])\n",
						"第 5614 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0458]])\n",
						"模型中偏参梯度 tensor([-0.1585])\n",
						"第 5615 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0458]])\n",
						"模型中偏参梯度 tensor([-0.1585])\n",
						"第 5616 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0458]])\n",
						"模型中偏参梯度 tensor([-0.1584])\n",
						"第 5617 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0458]])\n",
						"模型中偏参梯度 tensor([-0.1583])\n",
						"第 5618 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0457]])\n",
						"模型中偏参梯度 tensor([-0.1583])\n",
						"第 5619 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0457]])\n",
						"模型中偏参梯度 tensor([-0.1582])\n",
						"第 5620 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0457]])\n",
						"模型中偏参梯度 tensor([-0.1581])\n",
						"第 281 次epoch\n",
						"第 5621 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0456]])\n",
						"模型中偏参梯度 tensor([-0.1581])\n",
						"第 5622 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0456]])\n",
						"模型中偏参梯度 tensor([-0.1580])\n",
						"第 5623 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0456]])\n",
						"模型中偏参梯度 tensor([-0.1580])\n",
						"第 5624 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0456]])\n",
						"模型中偏参梯度 tensor([-0.1579])\n",
						"第 5625 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0455]])\n",
						"模型中偏参梯度 tensor([-0.1578])\n",
						"第 5626 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0455]])\n",
						"模型中偏参梯度 tensor([-0.1578])\n",
						"第 5627 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0455]])\n",
						"模型中偏参梯度 tensor([-0.1577])\n",
						"第 5628 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0454]])\n",
						"模型中偏参梯度 tensor([-0.1577])\n",
						"第 5629 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0454]])\n",
						"模型中偏参梯度 tensor([-0.1576])\n",
						"第 5630 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0454]])\n",
						"模型中偏参梯度 tensor([-0.1575])\n",
						"第 5631 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0454]])\n",
						"模型中偏参梯度 tensor([-0.1575])\n",
						"第 5632 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0453]])\n",
						"模型中偏参梯度 tensor([-0.1574])\n",
						"第 5633 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0453]])\n",
						"模型中偏参梯度 tensor([-0.1574])\n",
						"第 5634 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0453]])\n",
						"模型中偏参梯度 tensor([-0.1573])\n",
						"第 5635 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0452]])\n",
						"模型中偏参梯度 tensor([-0.1572])\n",
						"第 5636 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0452]])\n",
						"模型中偏参梯度 tensor([-0.1572])\n",
						"第 5637 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0452]])\n",
						"模型中偏参梯度 tensor([-0.1571])\n",
						"第 5638 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0451]])\n",
						"模型中偏参梯度 tensor([-0.1571])\n",
						"第 5639 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0451]])\n",
						"模型中偏参梯度 tensor([-0.1570])\n",
						"第 5640 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0451]])\n",
						"模型中偏参梯度 tensor([-0.1569])\n",
						"第 282 次epoch\n",
						"第 5641 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0450]])\n",
						"模型中偏参梯度 tensor([-0.1569])\n",
						"第 5642 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0450]])\n",
						"模型中偏参梯度 tensor([-0.1568])\n",
						"第 5643 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0450]])\n",
						"模型中偏参梯度 tensor([-0.1568])\n",
						"第 5644 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0449]])\n",
						"模型中偏参梯度 tensor([-0.1567])\n",
						"第 5645 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0449]])\n",
						"模型中偏参梯度 tensor([-0.1566])\n",
						"第 5646 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0449]])\n",
						"模型中偏参梯度 tensor([-0.1566])\n",
						"第 5647 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0448]])\n",
						"模型中偏参梯度 tensor([-0.1565])\n",
						"第 5648 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0448]])\n",
						"模型中偏参梯度 tensor([-0.1565])\n",
						"第 5649 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0448]])\n",
						"模型中偏参梯度 tensor([-0.1564])\n",
						"第 5650 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0448]])\n",
						"模型中偏参梯度 tensor([-0.1563])\n",
						"第 5651 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0448]])\n",
						"模型中偏参梯度 tensor([-0.1563])\n",
						"第 5652 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0448]])\n",
						"模型中偏参梯度 tensor([-0.1562])\n",
						"第 5653 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0448]])\n",
						"模型中偏参梯度 tensor([-0.1561])\n",
						"第 5654 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0448]])\n",
						"模型中偏参梯度 tensor([-0.1561])\n",
						"第 5655 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0448]])\n",
						"模型中偏参梯度 tensor([-0.1560])\n",
						"第 5656 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0448]])\n",
						"模型中偏参梯度 tensor([-0.1559])\n",
						"第 5657 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0448]])\n",
						"模型中偏参梯度 tensor([-0.1559])\n",
						"第 5658 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0448]])\n",
						"模型中偏参梯度 tensor([-0.1558])\n",
						"第 5659 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0448]])\n",
						"模型中偏参梯度 tensor([-0.1557])\n",
						"第 5660 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0448]])\n",
						"模型中偏参梯度 tensor([-0.1557])\n",
						"第 283 次epoch\n",
						"第 5661 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0448]])\n",
						"模型中偏参梯度 tensor([-0.1556])\n",
						"第 5662 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0448]])\n",
						"模型中偏参梯度 tensor([-0.1555])\n",
						"第 5663 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0448]])\n",
						"模型中偏参梯度 tensor([-0.1555])\n",
						"第 5664 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0448]])\n",
						"模型中偏参梯度 tensor([-0.1554])\n",
						"第 5665 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0448]])\n",
						"模型中偏参梯度 tensor([-0.1553])\n",
						"第 5666 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0448]])\n",
						"模型中偏参梯度 tensor([-0.1553])\n",
						"第 5667 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0447]])\n",
						"模型中偏参梯度 tensor([-0.1552])\n",
						"第 5668 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0447]])\n",
						"模型中偏参梯度 tensor([-0.1551])\n",
						"第 5669 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0447]])\n",
						"模型中偏参梯度 tensor([-0.1551])\n",
						"第 5670 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0447]])\n",
						"模型中偏参梯度 tensor([-0.1550])\n",
						"第 5671 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0447]])\n",
						"模型中偏参梯度 tensor([-0.1549])\n",
						"第 5672 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0447]])\n",
						"模型中偏参梯度 tensor([-0.1549])\n",
						"第 5673 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0447]])\n",
						"模型中偏参梯度 tensor([-0.1548])\n",
						"第 5674 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0447]])\n",
						"模型中偏参梯度 tensor([-0.1547])\n",
						"第 5675 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0447]])\n",
						"模型中偏参梯度 tensor([-0.1547])\n",
						"第 5676 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0447]])\n",
						"模型中偏参梯度 tensor([-0.1546])\n",
						"第 5677 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0447]])\n",
						"模型中偏参梯度 tensor([-0.1545])\n",
						"第 5678 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0447]])\n",
						"模型中偏参梯度 tensor([-0.1545])\n",
						"第 5679 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0446]])\n",
						"模型中偏参梯度 tensor([-0.1544])\n",
						"第 5680 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0446]])\n",
						"模型中偏参梯度 tensor([-0.1544])\n",
						"第 284 次epoch\n",
						"第 5681 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0446]])\n",
						"模型中偏参梯度 tensor([-0.1543])\n",
						"第 5682 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0446]])\n",
						"模型中偏参梯度 tensor([-0.1542])\n",
						"第 5683 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0446]])\n",
						"模型中偏参梯度 tensor([-0.1542])\n",
						"第 5684 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0446]])\n",
						"模型中偏参梯度 tensor([-0.1541])\n",
						"第 5685 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0446]])\n",
						"模型中偏参梯度 tensor([-0.1540])\n",
						"第 5686 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0446]])\n",
						"模型中偏参梯度 tensor([-0.1540])\n",
						"第 5687 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0446]])\n",
						"模型中偏参梯度 tensor([-0.1539])\n",
						"第 5688 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0446]])\n",
						"模型中偏参梯度 tensor([-0.1538])\n",
						"第 5689 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0445]])\n",
						"模型中偏参梯度 tensor([-0.1538])\n",
						"第 5690 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0445]])\n",
						"模型中偏参梯度 tensor([-0.1537])\n",
						"第 5691 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0445]])\n",
						"模型中偏参梯度 tensor([-0.1537])\n",
						"第 5692 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0445]])\n",
						"模型中偏参梯度 tensor([-0.1536])\n",
						"第 5693 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0445]])\n",
						"模型中偏参梯度 tensor([-0.1535])\n",
						"第 5694 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0445]])\n",
						"模型中偏参梯度 tensor([-0.1535])\n",
						"第 5695 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0444]])\n",
						"模型中偏参梯度 tensor([-0.1534])\n",
						"第 5696 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0444]])\n",
						"模型中偏参梯度 tensor([-0.1533])\n",
						"第 5697 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0444]])\n",
						"模型中偏参梯度 tensor([-0.1533])\n",
						"第 5698 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0444]])\n",
						"模型中偏参梯度 tensor([-0.1532])\n",
						"第 5699 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0444]])\n",
						"模型中偏参梯度 tensor([-0.1532])\n",
						"第 5700 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0444]])\n",
						"模型中偏参梯度 tensor([-0.1531])\n",
						"第 285 次epoch\n",
						"第 5701 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0444]])\n",
						"模型中偏参梯度 tensor([-0.1530])\n",
						"第 5702 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0443]])\n",
						"模型中偏参梯度 tensor([-0.1530])\n",
						"第 5703 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0443]])\n",
						"模型中偏参梯度 tensor([-0.1529])\n",
						"第 5704 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0443]])\n",
						"模型中偏参梯度 tensor([-0.1529])\n",
						"第 5705 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0443]])\n",
						"模型中偏参梯度 tensor([-0.1528])\n",
						"第 5706 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0443]])\n",
						"模型中偏参梯度 tensor([-0.1527])\n",
						"第 5707 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0442]])\n",
						"模型中偏参梯度 tensor([-0.1527])\n",
						"第 5708 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0442]])\n",
						"模型中偏参梯度 tensor([-0.1526])\n",
						"第 5709 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0442]])\n",
						"模型中偏参梯度 tensor([-0.1525])\n",
						"第 5710 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0442]])\n",
						"模型中偏参梯度 tensor([-0.1525])\n",
						"第 5711 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0442]])\n",
						"模型中偏参梯度 tensor([-0.1524])\n",
						"第 5712 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0441]])\n",
						"模型中偏参梯度 tensor([-0.1524])\n",
						"第 5713 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0441]])\n",
						"模型中偏参梯度 tensor([-0.1523])\n",
						"第 5714 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0441]])\n",
						"模型中偏参梯度 tensor([-0.1522])\n",
						"第 5715 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0441]])\n",
						"模型中偏参梯度 tensor([-0.1522])\n",
						"第 5716 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0441]])\n",
						"模型中偏参梯度 tensor([-0.1521])\n",
						"第 5717 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0440]])\n",
						"模型中偏参梯度 tensor([-0.1521])\n",
						"第 5718 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0440]])\n",
						"模型中偏参梯度 tensor([-0.1520])\n",
						"第 5719 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0440]])\n",
						"模型中偏参梯度 tensor([-0.1519])\n",
						"第 5720 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0440]])\n",
						"模型中偏参梯度 tensor([-0.1519])\n",
						"第 286 次epoch\n",
						"第 5721 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0439]])\n",
						"模型中偏参梯度 tensor([-0.1518])\n",
						"第 5722 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0439]])\n",
						"模型中偏参梯度 tensor([-0.1518])\n",
						"第 5723 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0439]])\n",
						"模型中偏参梯度 tensor([-0.1517])\n",
						"第 5724 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0438]])\n",
						"模型中偏参梯度 tensor([-0.1517])\n",
						"第 5725 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0438]])\n",
						"模型中偏参梯度 tensor([-0.1516])\n",
						"第 5726 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0438]])\n",
						"模型中偏参梯度 tensor([-0.1515])\n",
						"第 5727 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0438]])\n",
						"模型中偏参梯度 tensor([-0.1515])\n",
						"第 5728 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0438]])\n",
						"模型中偏参梯度 tensor([-0.1514])\n",
						"第 5729 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0437]])\n",
						"模型中偏参梯度 tensor([-0.1514])\n",
						"第 5730 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0437]])\n",
						"模型中偏参梯度 tensor([-0.1513])\n",
						"第 5731 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0437]])\n",
						"模型中偏参梯度 tensor([-0.1512])\n",
						"第 5732 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0436]])\n",
						"模型中偏参梯度 tensor([-0.1512])\n",
						"第 5733 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0436]])\n",
						"模型中偏参梯度 tensor([-0.1511])\n",
						"第 5734 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0436]])\n",
						"模型中偏参梯度 tensor([-0.1511])\n",
						"第 5735 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0436]])\n",
						"模型中偏参梯度 tensor([-0.1510])\n",
						"第 5736 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0435]])\n",
						"模型中偏参梯度 tensor([-0.1510])\n",
						"第 5737 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0435]])\n",
						"模型中偏参梯度 tensor([-0.1509])\n",
						"第 5738 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0435]])\n",
						"模型中偏参梯度 tensor([-0.1508])\n",
						"第 5739 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0434]])\n",
						"模型中偏参梯度 tensor([-0.1508])\n",
						"第 5740 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0434]])\n",
						"模型中偏参梯度 tensor([-0.1507])\n",
						"第 287 次epoch\n",
						"第 5741 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0434]])\n",
						"模型中偏参梯度 tensor([-0.1507])\n",
						"第 5742 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0433]])\n",
						"模型中偏参梯度 tensor([-0.1506])\n",
						"第 5743 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0433]])\n",
						"模型中偏参梯度 tensor([-0.1506])\n",
						"第 5744 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0433]])\n",
						"模型中偏参梯度 tensor([-0.1505])\n",
						"第 5745 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0432]])\n",
						"模型中偏参梯度 tensor([-0.1504])\n",
						"第 5746 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0432]])\n",
						"模型中偏参梯度 tensor([-0.1504])\n",
						"第 5747 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0432]])\n",
						"模型中偏参梯度 tensor([-0.1503])\n",
						"第 5748 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0432]])\n",
						"模型中偏参梯度 tensor([-0.1503])\n",
						"第 5749 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0431]])\n",
						"模型中偏参梯度 tensor([-0.1502])\n",
						"第 5750 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0431]])\n",
						"模型中偏参梯度 tensor([-0.1502])\n",
						"第 5751 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0431]])\n",
						"模型中偏参梯度 tensor([-0.1501])\n",
						"第 5752 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0430]])\n",
						"模型中偏参梯度 tensor([-0.1500])\n",
						"第 5753 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0430]])\n",
						"模型中偏参梯度 tensor([-0.1500])\n",
						"第 5754 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0429]])\n",
						"模型中偏参梯度 tensor([-0.1499])\n",
						"第 5755 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0429]])\n",
						"模型中偏参梯度 tensor([-0.1499])\n",
						"第 5756 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0429]])\n",
						"模型中偏参梯度 tensor([-0.1498])\n",
						"第 5757 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0429]])\n",
						"模型中偏参梯度 tensor([-0.1498])\n",
						"第 5758 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0429]])\n",
						"模型中偏参梯度 tensor([-0.1497])\n",
						"第 5759 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0429]])\n",
						"模型中偏参梯度 tensor([-0.1496])\n",
						"第 5760 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0429]])\n",
						"模型中偏参梯度 tensor([-0.1496])\n",
						"第 288 次epoch\n",
						"第 5761 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0429]])\n",
						"模型中偏参梯度 tensor([-0.1495])\n",
						"第 5762 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0429]])\n",
						"模型中偏参梯度 tensor([-0.1494])\n",
						"第 5763 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0429]])\n",
						"模型中偏参梯度 tensor([-0.1494])\n",
						"第 5764 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0429]])\n",
						"模型中偏参梯度 tensor([-0.1493])\n",
						"第 5765 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0429]])\n",
						"模型中偏参梯度 tensor([-0.1492])\n",
						"第 5766 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0429]])\n",
						"模型中偏参梯度 tensor([-0.1492])\n",
						"第 5767 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0429]])\n",
						"模型中偏参梯度 tensor([-0.1491])\n",
						"第 5768 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0429]])\n",
						"模型中偏参梯度 tensor([-0.1490])\n",
						"第 5769 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0429]])\n",
						"模型中偏参梯度 tensor([-0.1490])\n",
						"第 5770 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0429]])\n",
						"模型中偏参梯度 tensor([-0.1489])\n",
						"第 5771 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0429]])\n",
						"模型中偏参梯度 tensor([-0.1489])\n",
						"第 5772 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0429]])\n",
						"模型中偏参梯度 tensor([-0.1488])\n",
						"第 5773 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0429]])\n",
						"模型中偏参梯度 tensor([-0.1487])\n",
						"第 5774 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0429]])\n",
						"模型中偏参梯度 tensor([-0.1487])\n",
						"第 5775 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0428]])\n",
						"模型中偏参梯度 tensor([-0.1486])\n",
						"第 5776 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0428]])\n",
						"模型中偏参梯度 tensor([-0.1485])\n",
						"第 5777 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0428]])\n",
						"模型中偏参梯度 tensor([-0.1485])\n",
						"第 5778 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0428]])\n",
						"模型中偏参梯度 tensor([-0.1484])\n",
						"第 5779 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0428]])\n",
						"模型中偏参梯度 tensor([-0.1483])\n",
						"第 5780 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0428]])\n",
						"模型中偏参梯度 tensor([-0.1483])\n",
						"第 289 次epoch\n",
						"第 5781 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0428]])\n",
						"模型中偏参梯度 tensor([-0.1482])\n",
						"第 5782 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0428]])\n",
						"模型中偏参梯度 tensor([-0.1482])\n",
						"第 5783 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0428]])\n",
						"模型中偏参梯度 tensor([-0.1481])\n",
						"第 5784 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0428]])\n",
						"模型中偏参梯度 tensor([-0.1480])\n",
						"第 5785 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0428]])\n",
						"模型中偏参梯度 tensor([-0.1480])\n",
						"第 5786 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0428]])\n",
						"模型中偏参梯度 tensor([-0.1479])\n",
						"第 5787 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0428]])\n",
						"模型中偏参梯度 tensor([-0.1479])\n",
						"第 5788 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0428]])\n",
						"模型中偏参梯度 tensor([-0.1478])\n",
						"第 5789 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0428]])\n",
						"模型中偏参梯度 tensor([-0.1477])\n",
						"第 5790 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0427]])\n",
						"模型中偏参梯度 tensor([-0.1477])\n",
						"第 5791 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0427]])\n",
						"模型中偏参梯度 tensor([-0.1476])\n",
						"第 5792 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0427]])\n",
						"模型中偏参梯度 tensor([-0.1475])\n",
						"第 5793 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0427]])\n",
						"模型中偏参梯度 tensor([-0.1475])\n",
						"第 5794 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0427]])\n",
						"模型中偏参梯度 tensor([-0.1474])\n",
						"第 5795 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0427]])\n",
						"模型中偏参梯度 tensor([-0.1474])\n",
						"第 5796 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0427]])\n",
						"模型中偏参梯度 tensor([-0.1473])\n",
						"第 5797 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0427]])\n",
						"模型中偏参梯度 tensor([-0.1472])\n",
						"第 5798 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0427]])\n",
						"模型中偏参梯度 tensor([-0.1472])\n",
						"第 5799 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0426]])\n",
						"模型中偏参梯度 tensor([-0.1471])\n",
						"第 5800 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0426]])\n",
						"模型中偏参梯度 tensor([-0.1471])\n",
						"第 290 次epoch\n",
						"第 5801 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0426]])\n",
						"模型中偏参梯度 tensor([-0.1470])\n",
						"第 5802 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0426]])\n",
						"模型中偏参梯度 tensor([-0.1469])\n",
						"第 5803 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0426]])\n",
						"模型中偏参梯度 tensor([-0.1469])\n",
						"第 5804 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0426]])\n",
						"模型中偏参梯度 tensor([-0.1468])\n",
						"第 5805 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0426]])\n",
						"模型中偏参梯度 tensor([-0.1468])\n",
						"第 5806 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0425]])\n",
						"模型中偏参梯度 tensor([-0.1467])\n",
						"第 5807 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0425]])\n",
						"模型中偏参梯度 tensor([-0.1466])\n",
						"第 5808 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0425]])\n",
						"模型中偏参梯度 tensor([-0.1466])\n",
						"第 5809 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0425]])\n",
						"模型中偏参梯度 tensor([-0.1465])\n",
						"第 5810 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0425]])\n",
						"模型中偏参梯度 tensor([-0.1465])\n",
						"第 5811 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0425]])\n",
						"模型中偏参梯度 tensor([-0.1464])\n",
						"第 5812 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0425]])\n",
						"模型中偏参梯度 tensor([-0.1463])\n",
						"第 5813 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0424]])\n",
						"模型中偏参梯度 tensor([-0.1463])\n",
						"第 5814 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0424]])\n",
						"模型中偏参梯度 tensor([-0.1462])\n",
						"第 5815 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0424]])\n",
						"模型中偏参梯度 tensor([-0.1462])\n",
						"第 5816 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0424]])\n",
						"模型中偏参梯度 tensor([-0.1461])\n",
						"第 5817 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0424]])\n",
						"模型中偏参梯度 tensor([-0.1461])\n",
						"第 5818 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0423]])\n",
						"模型中偏参梯度 tensor([-0.1460])\n",
						"第 5819 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0423]])\n",
						"模型中偏参梯度 tensor([-0.1459])\n",
						"第 5820 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0423]])\n",
						"模型中偏参梯度 tensor([-0.1459])\n",
						"第 291 次epoch\n",
						"第 5821 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0423]])\n",
						"模型中偏参梯度 tensor([-0.1458])\n",
						"第 5822 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0423]])\n",
						"模型中偏参梯度 tensor([-0.1458])\n",
						"第 5823 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0422]])\n",
						"模型中偏参梯度 tensor([-0.1457])\n",
						"第 5824 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0422]])\n",
						"模型中偏参梯度 tensor([-0.1456])\n",
						"第 5825 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0422]])\n",
						"模型中偏参梯度 tensor([-0.1456])\n",
						"第 5826 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0422]])\n",
						"模型中偏参梯度 tensor([-0.1455])\n",
						"第 5827 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0422]])\n",
						"模型中偏参梯度 tensor([-0.1455])\n",
						"第 5828 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0421]])\n",
						"模型中偏参梯度 tensor([-0.1454])\n",
						"第 5829 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0421]])\n",
						"模型中偏参梯度 tensor([-0.1454])\n",
						"第 5830 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0421]])\n",
						"模型中偏参梯度 tensor([-0.1453])\n",
						"第 5831 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0421]])\n",
						"模型中偏参梯度 tensor([-0.1452])\n",
						"第 5832 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0420]])\n",
						"模型中偏参梯度 tensor([-0.1452])\n",
						"第 5833 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0420]])\n",
						"模型中偏参梯度 tensor([-0.1451])\n",
						"第 5834 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0420]])\n",
						"模型中偏参梯度 tensor([-0.1451])\n",
						"第 5835 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0420]])\n",
						"模型中偏参梯度 tensor([-0.1450])\n",
						"第 5836 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0419]])\n",
						"模型中偏参梯度 tensor([-0.1450])\n",
						"第 5837 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0419]])\n",
						"模型中偏参梯度 tensor([-0.1449])\n",
						"第 5838 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0419]])\n",
						"模型中偏参梯度 tensor([-0.1449])\n",
						"第 5839 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0419]])\n",
						"模型中偏参梯度 tensor([-0.1448])\n",
						"第 5840 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0418]])\n",
						"模型中偏参梯度 tensor([-0.1447])\n",
						"第 292 次epoch\n",
						"第 5841 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0418]])\n",
						"模型中偏参梯度 tensor([-0.1447])\n",
						"第 5842 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0418]])\n",
						"模型中偏参梯度 tensor([-0.1446])\n",
						"第 5843 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0418]])\n",
						"模型中偏参梯度 tensor([-0.1446])\n",
						"第 5844 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0417]])\n",
						"模型中偏参梯度 tensor([-0.1445])\n",
						"第 5845 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0417]])\n",
						"模型中偏参梯度 tensor([-0.1445])\n",
						"第 5846 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0417]])\n",
						"模型中偏参梯度 tensor([-0.1444])\n",
						"第 5847 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0416]])\n",
						"模型中偏参梯度 tensor([-0.1444])\n",
						"第 5848 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0416]])\n",
						"模型中偏参梯度 tensor([-0.1443])\n",
						"第 5849 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0416]])\n",
						"模型中偏参梯度 tensor([-0.1442])\n",
						"第 5850 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0416]])\n",
						"模型中偏参梯度 tensor([-0.1442])\n",
						"第 5851 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0415]])\n",
						"模型中偏参梯度 tensor([-0.1441])\n",
						"第 5852 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0415]])\n",
						"模型中偏参梯度 tensor([-0.1441])\n",
						"第 5853 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0415]])\n",
						"模型中偏参梯度 tensor([-0.1440])\n",
						"第 5854 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0414]])\n",
						"模型中偏参梯度 tensor([-0.1440])\n",
						"第 5855 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0414]])\n",
						"模型中偏参梯度 tensor([-0.1439])\n",
						"第 5856 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0414]])\n",
						"模型中偏参梯度 tensor([-0.1439])\n",
						"第 5857 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0413]])\n",
						"模型中偏参梯度 tensor([-0.1438])\n",
						"第 5858 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0413]])\n",
						"模型中偏参梯度 tensor([-0.1438])\n",
						"第 5859 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0413]])\n",
						"模型中偏参梯度 tensor([-0.1437])\n",
						"第 5860 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0413]])\n",
						"模型中偏参梯度 tensor([-0.1437])\n",
						"第 293 次epoch\n",
						"第 5861 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0412]])\n",
						"模型中偏参梯度 tensor([-0.1436])\n",
						"第 5862 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0412]])\n",
						"模型中偏参梯度 tensor([-0.1435])\n",
						"第 5863 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0412]])\n",
						"模型中偏参梯度 tensor([-0.1435])\n",
						"第 5864 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0411]])\n",
						"模型中偏参梯度 tensor([-0.1434])\n",
						"第 5865 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0411]])\n",
						"模型中偏参梯度 tensor([-0.1434])\n",
						"第 5866 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0411]])\n",
						"模型中偏参梯度 tensor([-0.1433])\n",
						"第 5867 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0410]])\n",
						"模型中偏参梯度 tensor([-0.1433])\n",
						"第 5868 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0410]])\n",
						"模型中偏参梯度 tensor([-0.1432])\n",
						"第 5869 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0410]])\n",
						"模型中偏参梯度 tensor([-0.1432])\n",
						"第 5870 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0410]])\n",
						"模型中偏参梯度 tensor([-0.1431])\n",
						"第 5871 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0410]])\n",
						"模型中偏参梯度 tensor([-0.1430])\n",
						"第 5872 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0410]])\n",
						"模型中偏参梯度 tensor([-0.1430])\n",
						"第 5873 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0410]])\n",
						"模型中偏参梯度 tensor([-0.1429])\n",
						"第 5874 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0410]])\n",
						"模型中偏参梯度 tensor([-0.1429])\n",
						"第 5875 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0410]])\n",
						"模型中偏参梯度 tensor([-0.1428])\n",
						"第 5876 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0410]])\n",
						"模型中偏参梯度 tensor([-0.1427])\n",
						"第 5877 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0410]])\n",
						"模型中偏参梯度 tensor([-0.1427])\n",
						"第 5878 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0410]])\n",
						"模型中偏参梯度 tensor([-0.1426])\n",
						"第 5879 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0410]])\n",
						"模型中偏参梯度 tensor([-0.1425])\n",
						"第 5880 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0410]])\n",
						"模型中偏参梯度 tensor([-0.1425])\n",
						"第 294 次epoch\n",
						"第 5881 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0410]])\n",
						"模型中偏参梯度 tensor([-0.1424])\n",
						"第 5882 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0410]])\n",
						"模型中偏参梯度 tensor([-0.1424])\n",
						"第 5883 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0410]])\n",
						"模型中偏参梯度 tensor([-0.1423])\n",
						"第 5884 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0410]])\n",
						"模型中偏参梯度 tensor([-0.1422])\n",
						"第 5885 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0410]])\n",
						"模型中偏参梯度 tensor([-0.1422])\n",
						"第 5886 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0410]])\n",
						"模型中偏参梯度 tensor([-0.1421])\n",
						"第 5887 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0409]])\n",
						"模型中偏参梯度 tensor([-0.1421])\n",
						"第 5888 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0409]])\n",
						"模型中偏参梯度 tensor([-0.1420])\n",
						"第 5889 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0409]])\n",
						"模型中偏参梯度 tensor([-0.1419])\n",
						"第 5890 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0409]])\n",
						"模型中偏参梯度 tensor([-0.1419])\n",
						"第 5891 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0409]])\n",
						"模型中偏参梯度 tensor([-0.1418])\n",
						"第 5892 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0409]])\n",
						"模型中偏参梯度 tensor([-0.1418])\n",
						"第 5893 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0409]])\n",
						"模型中偏参梯度 tensor([-0.1417])\n",
						"第 5894 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0409]])\n",
						"模型中偏参梯度 tensor([-0.1416])\n",
						"第 5895 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0409]])\n",
						"模型中偏参梯度 tensor([-0.1416])\n",
						"第 5896 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0409]])\n",
						"模型中偏参梯度 tensor([-0.1415])\n",
						"第 5897 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0409]])\n",
						"模型中偏参梯度 tensor([-0.1415])\n",
						"第 5898 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0409]])\n",
						"模型中偏参梯度 tensor([-0.1414])\n",
						"第 5899 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0409]])\n",
						"模型中偏参梯度 tensor([-0.1413])\n",
						"第 5900 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0409]])\n",
						"模型中偏参梯度 tensor([-0.1413])\n",
						"第 295 次epoch\n",
						"第 5901 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0409]])\n",
						"模型中偏参梯度 tensor([-0.1412])\n",
						"第 5902 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0409]])\n",
						"模型中偏参梯度 tensor([-0.1412])\n",
						"第 5903 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0409]])\n",
						"模型中偏参梯度 tensor([-0.1411])\n",
						"第 5904 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0408]])\n",
						"模型中偏参梯度 tensor([-0.1410])\n",
						"第 5905 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0408]])\n",
						"模型中偏参梯度 tensor([-0.1410])\n",
						"第 5906 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0408]])\n",
						"模型中偏参梯度 tensor([-0.1409])\n",
						"第 5907 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0408]])\n",
						"模型中偏参梯度 tensor([-0.1409])\n",
						"第 5908 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0408]])\n",
						"模型中偏参梯度 tensor([-0.1408])\n",
						"第 5909 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0408]])\n",
						"模型中偏参梯度 tensor([-0.1407])\n",
						"第 5910 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0408]])\n",
						"模型中偏参梯度 tensor([-0.1407])\n",
						"第 5911 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0408]])\n",
						"模型中偏参梯度 tensor([-0.1406])\n",
						"第 5912 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0408]])\n",
						"模型中偏参梯度 tensor([-0.1406])\n",
						"第 5913 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0408]])\n",
						"模型中偏参梯度 tensor([-0.1405])\n",
						"第 5914 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0407]])\n",
						"模型中偏参梯度 tensor([-0.1405])\n",
						"第 5915 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0407]])\n",
						"模型中偏参梯度 tensor([-0.1404])\n",
						"第 5916 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0407]])\n",
						"模型中偏参梯度 tensor([-0.1403])\n",
						"第 5917 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0407]])\n",
						"模型中偏参梯度 tensor([-0.1403])\n",
						"第 5918 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0407]])\n",
						"模型中偏参梯度 tensor([-0.1402])\n",
						"第 5919 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0407]])\n",
						"模型中偏参梯度 tensor([-0.1402])\n",
						"第 5920 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0407]])\n",
						"模型中偏参梯度 tensor([-0.1401])\n",
						"第 296 次epoch\n",
						"第 5921 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0407]])\n",
						"模型中偏参梯度 tensor([-0.1401])\n",
						"第 5922 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0406]])\n",
						"模型中偏参梯度 tensor([-0.1400])\n",
						"第 5923 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0406]])\n",
						"模型中偏参梯度 tensor([-0.1399])\n",
						"第 5924 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0406]])\n",
						"模型中偏参梯度 tensor([-0.1399])\n",
						"第 5925 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0406]])\n",
						"模型中偏参梯度 tensor([-0.1398])\n",
						"第 5926 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0406]])\n",
						"模型中偏参梯度 tensor([-0.1398])\n",
						"第 5927 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0406]])\n",
						"模型中偏参梯度 tensor([-0.1397])\n",
						"第 5928 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0406]])\n",
						"模型中偏参梯度 tensor([-0.1397])\n",
						"第 5929 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0405]])\n",
						"模型中偏参梯度 tensor([-0.1396])\n",
						"第 5930 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0405]])\n",
						"模型中偏参梯度 tensor([-0.1395])\n",
						"第 5931 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0405]])\n",
						"模型中偏参梯度 tensor([-0.1395])\n",
						"第 5932 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0405]])\n",
						"模型中偏参梯度 tensor([-0.1394])\n",
						"第 5933 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0405]])\n",
						"模型中偏参梯度 tensor([-0.1394])\n",
						"第 5934 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0404]])\n",
						"模型中偏参梯度 tensor([-0.1393])\n",
						"第 5935 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0404]])\n",
						"模型中偏参梯度 tensor([-0.1393])\n",
						"第 5936 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0404]])\n",
						"模型中偏参梯度 tensor([-0.1392])\n",
						"第 5937 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0404]])\n",
						"模型中偏参梯度 tensor([-0.1392])\n",
						"第 5938 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0404]])\n",
						"模型中偏参梯度 tensor([-0.1391])\n",
						"第 5939 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0403]])\n",
						"模型中偏参梯度 tensor([-0.1391])\n",
						"第 5940 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0403]])\n",
						"模型中偏参梯度 tensor([-0.1390])\n",
						"第 297 次epoch\n",
						"第 5941 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0403]])\n",
						"模型中偏参梯度 tensor([-0.1389])\n",
						"第 5942 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0403]])\n",
						"模型中偏参梯度 tensor([-0.1389])\n",
						"第 5943 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0403]])\n",
						"模型中偏参梯度 tensor([-0.1388])\n",
						"第 5944 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0403]])\n",
						"模型中偏参梯度 tensor([-0.1388])\n",
						"第 5945 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0402]])\n",
						"模型中偏参梯度 tensor([-0.1387])\n",
						"第 5946 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0402]])\n",
						"模型中偏参梯度 tensor([-0.1387])\n",
						"第 5947 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0402]])\n",
						"模型中偏参梯度 tensor([-0.1386])\n",
						"第 5948 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0402]])\n",
						"模型中偏参梯度 tensor([-0.1386])\n",
						"第 5949 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0401]])\n",
						"模型中偏参梯度 tensor([-0.1385])\n",
						"第 5950 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0401]])\n",
						"模型中偏参梯度 tensor([-0.1385])\n",
						"第 5951 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0401]])\n",
						"模型中偏参梯度 tensor([-0.1384])\n",
						"第 5952 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0401]])\n",
						"模型中偏参梯度 tensor([-0.1383])\n",
						"第 5953 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0400]])\n",
						"模型中偏参梯度 tensor([-0.1383])\n",
						"第 5954 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0400]])\n",
						"模型中偏参梯度 tensor([-0.1382])\n",
						"第 5955 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0400]])\n",
						"模型中偏参梯度 tensor([-0.1382])\n",
						"第 5956 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0400]])\n",
						"模型中偏参梯度 tensor([-0.1381])\n",
						"第 5957 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0399]])\n",
						"模型中偏参梯度 tensor([-0.1381])\n",
						"第 5958 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0399]])\n",
						"模型中偏参梯度 tensor([-0.1380])\n",
						"第 5959 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0399]])\n",
						"模型中偏参梯度 tensor([-0.1380])\n",
						"第 5960 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0399]])\n",
						"模型中偏参梯度 tensor([-0.1379])\n",
						"第 298 次epoch\n",
						"第 5961 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0398]])\n",
						"模型中偏参梯度 tensor([-0.1379])\n",
						"第 5962 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0398]])\n",
						"模型中偏参梯度 tensor([-0.1378])\n",
						"第 5963 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0398]])\n",
						"模型中偏参梯度 tensor([-0.1378])\n",
						"第 5964 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0398]])\n",
						"模型中偏参梯度 tensor([-0.1377])\n",
						"第 5965 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0397]])\n",
						"模型中偏参梯度 tensor([-0.1377])\n",
						"第 5966 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0397]])\n",
						"模型中偏参梯度 tensor([-0.1376])\n",
						"第 5967 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0397]])\n",
						"模型中偏参梯度 tensor([-0.1376])\n",
						"第 5968 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0396]])\n",
						"模型中偏参梯度 tensor([-0.1375])\n",
						"第 5969 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0396]])\n",
						"模型中偏参梯度 tensor([-0.1375])\n",
						"第 5970 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0396]])\n",
						"模型中偏参梯度 tensor([-0.1374])\n",
						"第 5971 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0396]])\n",
						"模型中偏参梯度 tensor([-0.1374])\n",
						"第 5972 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0395]])\n",
						"模型中偏参梯度 tensor([-0.1373])\n",
						"第 5973 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0395]])\n",
						"模型中偏参梯度 tensor([-0.1372])\n",
						"第 5974 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0395]])\n",
						"模型中偏参梯度 tensor([-0.1372])\n",
						"第 5975 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0394]])\n",
						"模型中偏参梯度 tensor([-0.1371])\n",
						"第 5976 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0394]])\n",
						"模型中偏参梯度 tensor([-0.1371])\n",
						"第 5977 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0394]])\n",
						"模型中偏参梯度 tensor([-0.1370])\n",
						"第 5978 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0393]])\n",
						"模型中偏参梯度 tensor([-0.1370])\n",
						"第 5979 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0393]])\n",
						"模型中偏参梯度 tensor([-0.1369])\n",
						"第 5980 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0393]])\n",
						"模型中偏参梯度 tensor([-0.1369])\n",
						"第 299 次epoch\n",
						"第 5981 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0393]])\n",
						"模型中偏参梯度 tensor([-0.1368])\n",
						"第 5982 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0392]])\n",
						"模型中偏参梯度 tensor([-0.1368])\n",
						"第 5983 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0392]])\n",
						"模型中偏参梯度 tensor([-0.1367])\n",
						"第 5984 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0391]])\n",
						"模型中偏参梯度 tensor([-0.1367])\n",
						"第 5985 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0391]])\n",
						"模型中偏参梯度 tensor([-0.1366])\n",
						"第 5986 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0391]])\n",
						"模型中偏参梯度 tensor([-0.1366])\n",
						"第 5987 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0391]])\n",
						"模型中偏参梯度 tensor([-0.1365])\n",
						"第 5988 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0391]])\n",
						"模型中偏参梯度 tensor([-0.1365])\n",
						"第 5989 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0391]])\n",
						"模型中偏参梯度 tensor([-0.1364])\n",
						"第 5990 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0391]])\n",
						"模型中偏参梯度 tensor([-0.1364])\n",
						"第 5991 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0391]])\n",
						"模型中偏参梯度 tensor([-0.1363])\n",
						"第 5992 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0391]])\n",
						"模型中偏参梯度 tensor([-0.1362])\n",
						"第 5993 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0391]])\n",
						"模型中偏参梯度 tensor([-0.1362])\n",
						"第 5994 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0391]])\n",
						"模型中偏参梯度 tensor([-0.1361])\n",
						"第 5995 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0391]])\n",
						"模型中偏参梯度 tensor([-0.1361])\n",
						"第 5996 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0391]])\n",
						"模型中偏参梯度 tensor([-0.1360])\n",
						"第 5997 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0391]])\n",
						"模型中偏参梯度 tensor([-0.1359])\n",
						"第 5998 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0391]])\n",
						"模型中偏参梯度 tensor([-0.1359])\n",
						"第 5999 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0391]])\n",
						"模型中偏参梯度 tensor([-0.1358])\n",
						"第 6000 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0391]])\n",
						"模型中偏参梯度 tensor([-0.1358])\n",
						"第 300 次epoch\n",
						"第 6001 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0391]])\n",
						"模型中偏参梯度 tensor([-0.1357])\n",
						"第 6002 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0391]])\n",
						"模型中偏参梯度 tensor([-0.1356])\n",
						"第 6003 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0391]])\n",
						"模型中偏参梯度 tensor([-0.1356])\n",
						"第 6004 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0391]])\n",
						"模型中偏参梯度 tensor([-0.1355])\n",
						"第 6005 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0391]])\n",
						"模型中偏参梯度 tensor([-0.1355])\n",
						"第 6006 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0391]])\n",
						"模型中偏参梯度 tensor([-0.1354])\n",
						"第 6007 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0391]])\n",
						"模型中偏参梯度 tensor([-0.1354])\n",
						"第 6008 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0390]])\n",
						"模型中偏参梯度 tensor([-0.1353])\n",
						"第 6009 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0391]])\n",
						"模型中偏参梯度 tensor([-0.1352])\n",
						"第 6010 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0390]])\n",
						"模型中偏参梯度 tensor([-0.1352])\n",
						"第 6011 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0390]])\n",
						"模型中偏参梯度 tensor([-0.1351])\n",
						"第 6012 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0390]])\n",
						"模型中偏参梯度 tensor([-0.1351])\n",
						"第 6013 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0390]])\n",
						"模型中偏参梯度 tensor([-0.1350])\n",
						"第 6014 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0390]])\n",
						"模型中偏参梯度 tensor([-0.1349])\n",
						"第 6015 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0390]])\n",
						"模型中偏参梯度 tensor([-0.1349])\n",
						"第 6016 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0390]])\n",
						"模型中偏参梯度 tensor([-0.1348])\n",
						"第 6017 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0390]])\n",
						"模型中偏参梯度 tensor([-0.1348])\n",
						"第 6018 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0390]])\n",
						"模型中偏参梯度 tensor([-0.1347])\n",
						"第 6019 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0390]])\n",
						"模型中偏参梯度 tensor([-0.1347])\n",
						"第 6020 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0390]])\n",
						"模型中偏参梯度 tensor([-0.1346])\n",
						"第 301 次epoch\n",
						"第 6021 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0390]])\n",
						"模型中偏参梯度 tensor([-0.1346])\n",
						"第 6022 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0390]])\n",
						"模型中偏参梯度 tensor([-0.1345])\n",
						"第 6023 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0390]])\n",
						"模型中偏参梯度 tensor([-0.1344])\n",
						"第 6024 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0390]])\n",
						"模型中偏参梯度 tensor([-0.1344])\n",
						"第 6025 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0390]])\n",
						"模型中偏参梯度 tensor([-0.1343])\n",
						"第 6026 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0389]])\n",
						"模型中偏参梯度 tensor([-0.1343])\n",
						"第 6027 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0389]])\n",
						"模型中偏参梯度 tensor([-0.1342])\n",
						"第 6028 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0389]])\n",
						"模型中偏参梯度 tensor([-0.1342])\n",
						"第 6029 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0389]])\n",
						"模型中偏参梯度 tensor([-0.1341])\n",
						"第 6030 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0389]])\n",
						"模型中偏参梯度 tensor([-0.1340])\n",
						"第 6031 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0389]])\n",
						"模型中偏参梯度 tensor([-0.1340])\n",
						"第 6032 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0389]])\n",
						"模型中偏参梯度 tensor([-0.1339])\n",
						"第 6033 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0389]])\n",
						"模型中偏参梯度 tensor([-0.1339])\n",
						"第 6034 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0389]])\n",
						"模型中偏参梯度 tensor([-0.1338])\n",
						"第 6035 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0389]])\n",
						"模型中偏参梯度 tensor([-0.1338])\n",
						"第 6036 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0388]])\n",
						"模型中偏参梯度 tensor([-0.1337])\n",
						"第 6037 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0388]])\n",
						"模型中偏参梯度 tensor([-0.1337])\n",
						"第 6038 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0388]])\n",
						"模型中偏参梯度 tensor([-0.1336])\n",
						"第 6039 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0388]])\n",
						"模型中偏参梯度 tensor([-0.1336])\n",
						"第 6040 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0388]])\n",
						"模型中偏参梯度 tensor([-0.1335])\n",
						"第 302 次epoch\n",
						"第 6041 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0388]])\n",
						"模型中偏参梯度 tensor([-0.1334])\n",
						"第 6042 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0388]])\n",
						"模型中偏参梯度 tensor([-0.1334])\n",
						"第 6043 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0388]])\n",
						"模型中偏参梯度 tensor([-0.1333])\n",
						"第 6044 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0387]])\n",
						"模型中偏参梯度 tensor([-0.1333])\n",
						"第 6045 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0387]])\n",
						"模型中偏参梯度 tensor([-0.1332])\n",
						"第 6046 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0387]])\n",
						"模型中偏参梯度 tensor([-0.1332])\n",
						"第 6047 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0387]])\n",
						"模型中偏参梯度 tensor([-0.1331])\n",
						"第 6048 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0387]])\n",
						"模型中偏参梯度 tensor([-0.1331])\n",
						"第 6049 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0387]])\n",
						"模型中偏参梯度 tensor([-0.1330])\n",
						"第 6050 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0387]])\n",
						"模型中偏参梯度 tensor([-0.1330])\n",
						"第 6051 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0386]])\n",
						"模型中偏参梯度 tensor([-0.1329])\n",
						"第 6052 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0386]])\n",
						"模型中偏参梯度 tensor([-0.1329])\n",
						"第 6053 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0386]])\n",
						"模型中偏参梯度 tensor([-0.1328])\n",
						"第 6054 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0386]])\n",
						"模型中偏参梯度 tensor([-0.1327])\n",
						"第 6055 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0386]])\n",
						"模型中偏参梯度 tensor([-0.1327])\n",
						"第 6056 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0385]])\n",
						"模型中偏参梯度 tensor([-0.1326])\n",
						"第 6057 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0385]])\n",
						"模型中偏参梯度 tensor([-0.1326])\n",
						"第 6058 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0385]])\n",
						"模型中偏参梯度 tensor([-0.1325])\n",
						"第 6059 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0385]])\n",
						"模型中偏参梯度 tensor([-0.1325])\n",
						"第 6060 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0385]])\n",
						"模型中偏参梯度 tensor([-0.1324])\n",
						"第 303 次epoch\n",
						"第 6061 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0385]])\n",
						"模型中偏参梯度 tensor([-0.1324])\n",
						"第 6062 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0384]])\n",
						"模型中偏参梯度 tensor([-0.1323])\n",
						"第 6063 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0384]])\n",
						"模型中偏参梯度 tensor([-0.1323])\n",
						"第 6064 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0384]])\n",
						"模型中偏参梯度 tensor([-0.1322])\n",
						"第 6065 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0384]])\n",
						"模型中偏参梯度 tensor([-0.1322])\n",
						"第 6066 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0384]])\n",
						"模型中偏参梯度 tensor([-0.1321])\n",
						"第 6067 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0384]])\n",
						"模型中偏参梯度 tensor([-0.1321])\n",
						"第 6068 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0383]])\n",
						"模型中偏参梯度 tensor([-0.1320])\n",
						"第 6069 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0383]])\n",
						"模型中偏参梯度 tensor([-0.1320])\n",
						"第 6070 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0383]])\n",
						"模型中偏参梯度 tensor([-0.1319])\n",
						"第 6071 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0383]])\n",
						"模型中偏参梯度 tensor([-0.1319])\n",
						"第 6072 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0382]])\n",
						"模型中偏参梯度 tensor([-0.1318])\n",
						"第 6073 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0382]])\n",
						"模型中偏参梯度 tensor([-0.1318])\n",
						"第 6074 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0382]])\n",
						"模型中偏参梯度 tensor([-0.1317])\n",
						"第 6075 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0382]])\n",
						"模型中偏参梯度 tensor([-0.1317])\n",
						"第 6076 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0381]])\n",
						"模型中偏参梯度 tensor([-0.1316])\n",
						"第 6077 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0381]])\n",
						"模型中偏参梯度 tensor([-0.1316])\n",
						"第 6078 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0381]])\n",
						"模型中偏参梯度 tensor([-0.1315])\n",
						"第 6079 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0381]])\n",
						"模型中偏参梯度 tensor([-0.1315])\n",
						"第 6080 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0380]])\n",
						"模型中偏参梯度 tensor([-0.1314])\n",
						"第 304 次epoch\n",
						"第 6081 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0380]])\n",
						"模型中偏参梯度 tensor([-0.1314])\n",
						"第 6082 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0380]])\n",
						"模型中偏参梯度 tensor([-0.1313])\n",
						"第 6083 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0380]])\n",
						"模型中偏参梯度 tensor([-0.1313])\n",
						"第 6084 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0379]])\n",
						"模型中偏参梯度 tensor([-0.1312])\n",
						"第 6085 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0379]])\n",
						"模型中偏参梯度 tensor([-0.1312])\n",
						"第 6086 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0379]])\n",
						"模型中偏参梯度 tensor([-0.1311])\n",
						"第 6087 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0379]])\n",
						"模型中偏参梯度 tensor([-0.1311])\n",
						"第 6088 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0378]])\n",
						"模型中偏参梯度 tensor([-0.1310])\n",
						"第 6089 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0378]])\n",
						"模型中偏参梯度 tensor([-0.1310])\n",
						"第 6090 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0378]])\n",
						"模型中偏参梯度 tensor([-0.1309])\n",
						"第 6091 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0378]])\n",
						"模型中偏参梯度 tensor([-0.1309])\n",
						"第 6092 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0377]])\n",
						"模型中偏参梯度 tensor([-0.1308])\n",
						"第 6093 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0377]])\n",
						"模型中偏参梯度 tensor([-0.1308])\n",
						"第 6094 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0377]])\n",
						"模型中偏参梯度 tensor([-0.1307])\n",
						"第 6095 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0376]])\n",
						"模型中偏参梯度 tensor([-0.1307])\n",
						"第 6096 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0376]])\n",
						"模型中偏参梯度 tensor([-0.1306])\n",
						"第 6097 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0376]])\n",
						"模型中偏参梯度 tensor([-0.1306])\n",
						"第 6098 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0375]])\n",
						"模型中偏参梯度 tensor([-0.1305])\n",
						"第 6099 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0375]])\n",
						"模型中偏参梯度 tensor([-0.1305])\n",
						"第 6100 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0375]])\n",
						"模型中偏参梯度 tensor([-0.1304])\n",
						"第 305 次epoch\n",
						"第 6101 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0375]])\n",
						"模型中偏参梯度 tensor([-0.1304])\n",
						"第 6102 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0374]])\n",
						"模型中偏参梯度 tensor([-0.1303])\n",
						"第 6103 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0374]])\n",
						"模型中偏参梯度 tensor([-0.1303])\n",
						"第 6104 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0374]])\n",
						"模型中偏参梯度 tensor([-0.1302])\n",
						"第 6105 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0373]])\n",
						"模型中偏参梯度 tensor([-0.1302])\n",
						"第 6106 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0373]])\n",
						"模型中偏参梯度 tensor([-0.1301])\n",
						"第 6107 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0373]])\n",
						"模型中偏参梯度 tensor([-0.1301])\n",
						"第 6108 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0372]])\n",
						"模型中偏参梯度 tensor([-0.1300])\n",
						"第 6109 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0372]])\n",
						"模型中偏参梯度 tensor([-0.1300])\n",
						"第 6110 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0372]])\n",
						"模型中偏参梯度 tensor([-0.1299])\n",
						"第 6111 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0372]])\n",
						"模型中偏参梯度 tensor([-0.1299])\n",
						"第 6112 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0372]])\n",
						"模型中偏参梯度 tensor([-0.1298])\n",
						"第 6113 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0372]])\n",
						"模型中偏参梯度 tensor([-0.1298])\n",
						"第 6114 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0372]])\n",
						"模型中偏参梯度 tensor([-0.1297])\n",
						"第 6115 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0372]])\n",
						"模型中偏参梯度 tensor([-0.1297])\n",
						"第 6116 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0372]])\n",
						"模型中偏参梯度 tensor([-0.1296])\n",
						"第 6117 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0372]])\n",
						"模型中偏参梯度 tensor([-0.1296])\n",
						"第 6118 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0372]])\n",
						"模型中偏参梯度 tensor([-0.1295])\n",
						"第 6119 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0372]])\n",
						"模型中偏参梯度 tensor([-0.1294])\n",
						"第 6120 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0372]])\n",
						"模型中偏参梯度 tensor([-0.1294])\n",
						"第 306 次epoch\n",
						"第 6121 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0372]])\n",
						"模型中偏参梯度 tensor([-0.1293])\n",
						"第 6122 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0372]])\n",
						"模型中偏参梯度 tensor([-0.1293])\n",
						"第 6123 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0372]])\n",
						"模型中偏参梯度 tensor([-0.1292])\n",
						"第 6124 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0372]])\n",
						"模型中偏参梯度 tensor([-0.1292])\n",
						"第 6125 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0372]])\n",
						"模型中偏参梯度 tensor([-0.1291])\n",
						"第 6126 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0372]])\n",
						"模型中偏参梯度 tensor([-0.1290])\n",
						"第 6127 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0372]])\n",
						"模型中偏参梯度 tensor([-0.1290])\n",
						"第 6128 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0372]])\n",
						"模型中偏参梯度 tensor([-0.1289])\n",
						"第 6129 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0372]])\n",
						"模型中偏参梯度 tensor([-0.1289])\n",
						"第 6130 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0372]])\n",
						"模型中偏参梯度 tensor([-0.1288])\n",
						"第 6131 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0372]])\n",
						"模型中偏参梯度 tensor([-0.1288])\n",
						"第 6132 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0372]])\n",
						"模型中偏参梯度 tensor([-0.1287])\n",
						"第 6133 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0372]])\n",
						"模型中偏参梯度 tensor([-0.1287])\n",
						"第 6134 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0372]])\n",
						"模型中偏参梯度 tensor([-0.1286])\n",
						"第 6135 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0372]])\n",
						"模型中偏参梯度 tensor([-0.1285])\n",
						"第 6136 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0372]])\n",
						"模型中偏参梯度 tensor([-0.1285])\n",
						"第 6137 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0372]])\n",
						"模型中偏参梯度 tensor([-0.1284])\n",
						"第 6138 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0372]])\n",
						"模型中偏参梯度 tensor([-0.1284])\n",
						"第 6139 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0372]])\n",
						"模型中偏参梯度 tensor([-0.1283])\n",
						"第 6140 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0372]])\n",
						"模型中偏参梯度 tensor([-0.1283])\n",
						"第 307 次epoch\n",
						"第 6141 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0371]])\n",
						"模型中偏参梯度 tensor([-0.1282])\n",
						"第 6142 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0371]])\n",
						"模型中偏参梯度 tensor([-0.1282])\n",
						"第 6143 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0371]])\n",
						"模型中偏参梯度 tensor([-0.1281])\n",
						"第 6144 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0371]])\n",
						"模型中偏参梯度 tensor([-0.1281])\n",
						"第 6145 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0371]])\n",
						"模型中偏参梯度 tensor([-0.1280])\n",
						"第 6146 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0371]])\n",
						"模型中偏参梯度 tensor([-0.1279])\n",
						"第 6147 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0371]])\n",
						"模型中偏参梯度 tensor([-0.1279])\n",
						"第 6148 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0371]])\n",
						"模型中偏参梯度 tensor([-0.1278])\n",
						"第 6149 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0371]])\n",
						"模型中偏参梯度 tensor([-0.1278])\n",
						"第 6150 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0371]])\n",
						"模型中偏参梯度 tensor([-0.1277])\n",
						"第 6151 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0371]])\n",
						"模型中偏参梯度 tensor([-0.1277])\n",
						"第 6152 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0371]])\n",
						"模型中偏参梯度 tensor([-0.1276])\n",
						"第 6153 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0371]])\n",
						"模型中偏参梯度 tensor([-0.1276])\n",
						"第 6154 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0371]])\n",
						"模型中偏参梯度 tensor([-0.1275])\n",
						"第 6155 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0371]])\n",
						"模型中偏参梯度 tensor([-0.1275])\n",
						"第 6156 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0370]])\n",
						"模型中偏参梯度 tensor([-0.1274])\n",
						"第 6157 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0370]])\n",
						"模型中偏参梯度 tensor([-0.1274])\n",
						"第 6158 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0370]])\n",
						"模型中偏参梯度 tensor([-0.1273])\n",
						"第 6159 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0370]])\n",
						"模型中偏参梯度 tensor([-0.1273])\n",
						"第 6160 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0370]])\n",
						"模型中偏参梯度 tensor([-0.1272])\n",
						"第 308 次epoch\n",
						"第 6161 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0370]])\n",
						"模型中偏参梯度 tensor([-0.1271])\n",
						"第 6162 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0370]])\n",
						"模型中偏参梯度 tensor([-0.1271])\n",
						"第 6163 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0370]])\n",
						"模型中偏参梯度 tensor([-0.1270])\n",
						"第 6164 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0370]])\n",
						"模型中偏参梯度 tensor([-0.1270])\n",
						"第 6165 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0369]])\n",
						"模型中偏参梯度 tensor([-0.1269])\n",
						"第 6166 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0369]])\n",
						"模型中偏参梯度 tensor([-0.1269])\n",
						"第 6167 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0369]])\n",
						"模型中偏参梯度 tensor([-0.1268])\n",
						"第 6168 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0369]])\n",
						"模型中偏参梯度 tensor([-0.1268])\n",
						"第 6169 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0369]])\n",
						"模型中偏参梯度 tensor([-0.1267])\n",
						"第 6170 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0369]])\n",
						"模型中偏参梯度 tensor([-0.1267])\n",
						"第 6171 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0369]])\n",
						"模型中偏参梯度 tensor([-0.1266])\n",
						"第 6172 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0368]])\n",
						"模型中偏参梯度 tensor([-0.1266])\n",
						"第 6173 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0368]])\n",
						"模型中偏参梯度 tensor([-0.1265])\n",
						"第 6174 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0368]])\n",
						"模型中偏参梯度 tensor([-0.1265])\n",
						"第 6175 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0368]])\n",
						"模型中偏参梯度 tensor([-0.1264])\n",
						"第 6176 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0368]])\n",
						"模型中偏参梯度 tensor([-0.1264])\n",
						"第 6177 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0368]])\n",
						"模型中偏参梯度 tensor([-0.1263])\n",
						"第 6178 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0368]])\n",
						"模型中偏参梯度 tensor([-0.1263])\n",
						"第 6179 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0368]])\n",
						"模型中偏参梯度 tensor([-0.1262])\n",
						"第 6180 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0367]])\n",
						"模型中偏参梯度 tensor([-0.1262])\n",
						"第 309 次epoch\n",
						"第 6181 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0367]])\n",
						"模型中偏参梯度 tensor([-0.1261])\n",
						"第 6182 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0367]])\n",
						"模型中偏参梯度 tensor([-0.1261])\n",
						"第 6183 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0367]])\n",
						"模型中偏参梯度 tensor([-0.1260])\n",
						"第 6184 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0367]])\n",
						"模型中偏参梯度 tensor([-0.1260])\n",
						"第 6185 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0366]])\n",
						"模型中偏参梯度 tensor([-0.1259])\n",
						"第 6186 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0366]])\n",
						"模型中偏参梯度 tensor([-0.1259])\n",
						"第 6187 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0366]])\n",
						"模型中偏参梯度 tensor([-0.1258])\n",
						"第 6188 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0366]])\n",
						"模型中偏参梯度 tensor([-0.1258])\n",
						"第 6189 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0366]])\n",
						"模型中偏参梯度 tensor([-0.1257])\n",
						"第 6190 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0366]])\n",
						"模型中偏参梯度 tensor([-0.1257])\n",
						"第 6191 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0365]])\n",
						"模型中偏参梯度 tensor([-0.1256])\n",
						"第 6192 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0365]])\n",
						"模型中偏参梯度 tensor([-0.1256])\n",
						"第 6193 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0365]])\n",
						"模型中偏参梯度 tensor([-0.1255])\n",
						"第 6194 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0365]])\n",
						"模型中偏参梯度 tensor([-0.1255])\n",
						"第 6195 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0365]])\n",
						"模型中偏参梯度 tensor([-0.1254])\n",
						"第 6196 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0364]])\n",
						"模型中偏参梯度 tensor([-0.1254])\n",
						"第 6197 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0364]])\n",
						"模型中偏参梯度 tensor([-0.1253])\n",
						"第 6198 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0364]])\n",
						"模型中偏参梯度 tensor([-0.1253])\n",
						"第 6199 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0364]])\n",
						"模型中偏参梯度 tensor([-0.1252])\n",
						"第 6200 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0364]])\n",
						"模型中偏参梯度 tensor([-0.1252])\n",
						"第 310 次epoch\n",
						"第 6201 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0363]])\n",
						"模型中偏参梯度 tensor([-0.1251])\n",
						"第 6202 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0363]])\n",
						"模型中偏参梯度 tensor([-0.1251])\n",
						"第 6203 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0363]])\n",
						"模型中偏参梯度 tensor([-0.1250])\n",
						"第 6204 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0363]])\n",
						"模型中偏参梯度 tensor([-0.1250])\n",
						"第 6205 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0362]])\n",
						"模型中偏参梯度 tensor([-0.1249])\n",
						"第 6206 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0362]])\n",
						"模型中偏参梯度 tensor([-0.1249])\n",
						"第 6207 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0362]])\n",
						"模型中偏参梯度 tensor([-0.1249])\n",
						"第 6208 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0362]])\n",
						"模型中偏参梯度 tensor([-0.1248])\n",
						"第 6209 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0362]])\n",
						"模型中偏参梯度 tensor([-0.1248])\n",
						"第 6210 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0361]])\n",
						"模型中偏参梯度 tensor([-0.1247])\n",
						"第 6211 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0361]])\n",
						"模型中偏参梯度 tensor([-0.1247])\n",
						"第 6212 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0361]])\n",
						"模型中偏参梯度 tensor([-0.1246])\n",
						"第 6213 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0361]])\n",
						"模型中偏参梯度 tensor([-0.1246])\n",
						"第 6214 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0360]])\n",
						"模型中偏参梯度 tensor([-0.1245])\n",
						"第 6215 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0360]])\n",
						"模型中偏参梯度 tensor([-0.1245])\n",
						"第 6216 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0360]])\n",
						"模型中偏参梯度 tensor([-0.1244])\n",
						"第 6217 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0360]])\n",
						"模型中偏参梯度 tensor([-0.1244])\n",
						"第 6218 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0359]])\n",
						"模型中偏参梯度 tensor([-0.1243])\n",
						"第 6219 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0359]])\n",
						"模型中偏参梯度 tensor([-0.1243])\n",
						"第 6220 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0359]])\n",
						"模型中偏参梯度 tensor([-0.1242])\n",
						"第 311 次epoch\n",
						"第 6221 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0358]])\n",
						"模型中偏参梯度 tensor([-0.1242])\n",
						"第 6222 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0358]])\n",
						"模型中偏参梯度 tensor([-0.1241])\n",
						"第 6223 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0358]])\n",
						"模型中偏参梯度 tensor([-0.1241])\n",
						"第 6224 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0358]])\n",
						"模型中偏参梯度 tensor([-0.1241])\n",
						"第 6225 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0357]])\n",
						"模型中偏参梯度 tensor([-0.1240])\n",
						"第 6226 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0357]])\n",
						"模型中偏参梯度 tensor([-0.1240])\n",
						"第 6227 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0357]])\n",
						"模型中偏参梯度 tensor([-0.1239])\n",
						"第 6228 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0356]])\n",
						"模型中偏参梯度 tensor([-0.1239])\n",
						"第 6229 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0356]])\n",
						"模型中偏参梯度 tensor([-0.1238])\n",
						"第 6230 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0356]])\n",
						"模型中偏参梯度 tensor([-0.1238])\n",
						"第 6231 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0356]])\n",
						"模型中偏参梯度 tensor([-0.1237])\n",
						"第 6232 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0355]])\n",
						"模型中偏参梯度 tensor([-0.1237])\n",
						"第 6233 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0355]])\n",
						"模型中偏参梯度 tensor([-0.1236])\n",
						"第 6234 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0355]])\n",
						"模型中偏参梯度 tensor([-0.1236])\n",
						"第 6235 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0355]])\n",
						"模型中偏参梯度 tensor([-0.1235])\n",
						"第 6236 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0354]])\n",
						"模型中偏参梯度 tensor([-0.1235])\n",
						"第 6237 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0354]])\n",
						"模型中偏参梯度 tensor([-0.1235])\n",
						"第 6238 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0354]])\n",
						"模型中偏参梯度 tensor([-0.1234])\n",
						"第 6239 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0353]])\n",
						"模型中偏参梯度 tensor([-0.1234])\n",
						"第 6240 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0353]])\n",
						"模型中偏参梯度 tensor([-0.1233])\n",
						"第 312 次epoch\n",
						"第 6241 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0353]])\n",
						"模型中偏参梯度 tensor([-0.1233])\n",
						"第 6242 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0353]])\n",
						"模型中偏参梯度 tensor([-0.1232])\n",
						"第 6243 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0353]])\n",
						"模型中偏参梯度 tensor([-0.1232])\n",
						"第 6244 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0353]])\n",
						"模型中偏参梯度 tensor([-0.1231])\n",
						"第 6245 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0353]])\n",
						"模型中偏参梯度 tensor([-0.1231])\n",
						"第 6246 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0353]])\n",
						"模型中偏参梯度 tensor([-0.1230])\n",
						"第 6247 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0353]])\n",
						"模型中偏参梯度 tensor([-0.1230])\n",
						"第 6248 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0353]])\n",
						"模型中偏参梯度 tensor([-0.1229])\n",
						"第 6249 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0353]])\n",
						"模型中偏参梯度 tensor([-0.1229])\n",
						"第 6250 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0353]])\n",
						"模型中偏参梯度 tensor([-0.1228])\n",
						"第 6251 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0353]])\n",
						"模型中偏参梯度 tensor([-0.1227])\n",
						"第 6252 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0353]])\n",
						"模型中偏参梯度 tensor([-0.1227])\n",
						"第 6253 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0353]])\n",
						"模型中偏参梯度 tensor([-0.1226])\n",
						"第 6254 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0353]])\n",
						"模型中偏参梯度 tensor([-0.1226])\n",
						"第 6255 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0353]])\n",
						"模型中偏参梯度 tensor([-0.1225])\n",
						"第 6256 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0353]])\n",
						"模型中偏参梯度 tensor([-0.1225])\n",
						"第 6257 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0353]])\n",
						"模型中偏参梯度 tensor([-0.1224])\n",
						"第 6258 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0353]])\n",
						"模型中偏参梯度 tensor([-0.1224])\n",
						"第 6259 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0353]])\n",
						"模型中偏参梯度 tensor([-0.1223])\n",
						"第 6260 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0353]])\n",
						"模型中偏参梯度 tensor([-0.1223])\n",
						"第 313 次epoch\n",
						"第 6261 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0353]])\n",
						"模型中偏参梯度 tensor([-0.1222])\n",
						"第 6262 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0353]])\n",
						"模型中偏参梯度 tensor([-0.1222])\n",
						"第 6263 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0353]])\n",
						"模型中偏参梯度 tensor([-0.1221])\n",
						"第 6264 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0353]])\n",
						"模型中偏参梯度 tensor([-0.1221])\n",
						"第 6265 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0353]])\n",
						"模型中偏参梯度 tensor([-0.1220])\n",
						"第 6266 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0353]])\n",
						"模型中偏参梯度 tensor([-0.1219])\n",
						"第 6267 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0353]])\n",
						"模型中偏参梯度 tensor([-0.1219])\n",
						"第 6268 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0353]])\n",
						"模型中偏参梯度 tensor([-0.1218])\n",
						"第 6269 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0353]])\n",
						"模型中偏参梯度 tensor([-0.1218])\n",
						"第 6270 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0353]])\n",
						"模型中偏参梯度 tensor([-0.1217])\n",
						"第 6271 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0353]])\n",
						"模型中偏参梯度 tensor([-0.1217])\n",
						"第 6272 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0352]])\n",
						"模型中偏参梯度 tensor([-0.1216])\n",
						"第 6273 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0353]])\n",
						"模型中偏参梯度 tensor([-0.1216])\n",
						"第 6274 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0353]])\n",
						"模型中偏参梯度 tensor([-0.1215])\n",
						"第 6275 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0352]])\n",
						"模型中偏参梯度 tensor([-0.1215])\n",
						"第 6276 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0352]])\n",
						"模型中偏参梯度 tensor([-0.1214])\n",
						"第 6277 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0352]])\n",
						"模型中偏参梯度 tensor([-0.1214])\n",
						"第 6278 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0352]])\n",
						"模型中偏参梯度 tensor([-0.1213])\n",
						"第 6279 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0352]])\n",
						"模型中偏参梯度 tensor([-0.1213])\n",
						"第 6280 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0352]])\n",
						"模型中偏参梯度 tensor([-0.1212])\n",
						"第 314 次epoch\n",
						"第 6281 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0352]])\n",
						"模型中偏参梯度 tensor([-0.1212])\n",
						"第 6282 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0352]])\n",
						"模型中偏参梯度 tensor([-0.1211])\n",
						"第 6283 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0352]])\n",
						"模型中偏参梯度 tensor([-0.1211])\n",
						"第 6284 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0352]])\n",
						"模型中偏参梯度 tensor([-0.1210])\n",
						"第 6285 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0352]])\n",
						"模型中偏参梯度 tensor([-0.1210])\n",
						"第 6286 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0352]])\n",
						"模型中偏参梯度 tensor([-0.1209])\n",
						"第 6287 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0352]])\n",
						"模型中偏参梯度 tensor([-0.1209])\n",
						"第 6288 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0352]])\n",
						"模型中偏参梯度 tensor([-0.1208])\n",
						"第 6289 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0352]])\n",
						"模型中偏参梯度 tensor([-0.1208])\n",
						"第 6290 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0351]])\n",
						"模型中偏参梯度 tensor([-0.1207])\n",
						"第 6291 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0351]])\n",
						"模型中偏参梯度 tensor([-0.1207])\n",
						"第 6292 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0351]])\n",
						"模型中偏参梯度 tensor([-0.1206])\n",
						"第 6293 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0351]])\n",
						"模型中偏参梯度 tensor([-0.1206])\n",
						"第 6294 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0351]])\n",
						"模型中偏参梯度 tensor([-0.1205])\n",
						"第 6295 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0351]])\n",
						"模型中偏参梯度 tensor([-0.1205])\n",
						"第 6296 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0351]])\n",
						"模型中偏参梯度 tensor([-0.1204])\n",
						"第 6297 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0351]])\n",
						"模型中偏参梯度 tensor([-0.1204])\n",
						"第 6298 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0351]])\n",
						"模型中偏参梯度 tensor([-0.1203])\n",
						"第 6299 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0351]])\n",
						"模型中偏参梯度 tensor([-0.1203])\n",
						"第 6300 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0350]])\n",
						"模型中偏参梯度 tensor([-0.1202])\n",
						"第 315 次epoch\n",
						"第 6301 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0350]])\n",
						"模型中偏参梯度 tensor([-0.1202])\n",
						"第 6302 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0350]])\n",
						"模型中偏参梯度 tensor([-0.1201])\n",
						"第 6303 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0350]])\n",
						"模型中偏参梯度 tensor([-0.1201])\n",
						"第 6304 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0350]])\n",
						"模型中偏参梯度 tensor([-0.1200])\n",
						"第 6305 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0350]])\n",
						"模型中偏参梯度 tensor([-0.1200])\n",
						"第 6306 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0350]])\n",
						"模型中偏参梯度 tensor([-0.1199])\n",
						"第 6307 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0350]])\n",
						"模型中偏参梯度 tensor([-0.1199])\n",
						"第 6308 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0349]])\n",
						"模型中偏参梯度 tensor([-0.1198])\n",
						"第 6309 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0349]])\n",
						"模型中偏参梯度 tensor([-0.1198])\n",
						"第 6310 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0349]])\n",
						"模型中偏参梯度 tensor([-0.1197])\n",
						"第 6311 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0349]])\n",
						"模型中偏参梯度 tensor([-0.1197])\n",
						"第 6312 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0349]])\n",
						"模型中偏参梯度 tensor([-0.1196])\n",
						"第 6313 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0349]])\n",
						"模型中偏参梯度 tensor([-0.1196])\n",
						"第 6314 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0349]])\n",
						"模型中偏参梯度 tensor([-0.1195])\n",
						"第 6315 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0348]])\n",
						"模型中偏参梯度 tensor([-0.1195])\n",
						"第 6316 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0348]])\n",
						"模型中偏参梯度 tensor([-0.1194])\n",
						"第 6317 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0348]])\n",
						"模型中偏参梯度 tensor([-0.1194])\n",
						"第 6318 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0348]])\n",
						"模型中偏参梯度 tensor([-0.1194])\n",
						"第 6319 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0348]])\n",
						"模型中偏参梯度 tensor([-0.1193])\n",
						"第 6320 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0348]])\n",
						"模型中偏参梯度 tensor([-0.1193])\n",
						"第 316 次epoch\n",
						"第 6321 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0347]])\n",
						"模型中偏参梯度 tensor([-0.1192])\n",
						"第 6322 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0347]])\n",
						"模型中偏参梯度 tensor([-0.1192])\n",
						"第 6323 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0347]])\n",
						"模型中偏参梯度 tensor([-0.1191])\n",
						"第 6324 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0347]])\n",
						"模型中偏参梯度 tensor([-0.1191])\n",
						"第 6325 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0347]])\n",
						"模型中偏参梯度 tensor([-0.1190])\n",
						"第 6326 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0347]])\n",
						"模型中偏参梯度 tensor([-0.1190])\n",
						"第 6327 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0346]])\n",
						"模型中偏参梯度 tensor([-0.1189])\n",
						"第 6328 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0346]])\n",
						"模型中偏参梯度 tensor([-0.1189])\n",
						"第 6329 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0346]])\n",
						"模型中偏参梯度 tensor([-0.1188])\n",
						"第 6330 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0346]])\n",
						"模型中偏参梯度 tensor([-0.1188])\n",
						"第 6331 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0346]])\n",
						"模型中偏参梯度 tensor([-0.1187])\n",
						"第 6332 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0345]])\n",
						"模型中偏参梯度 tensor([-0.1187])\n",
						"第 6333 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0345]])\n",
						"模型中偏参梯度 tensor([-0.1187])\n",
						"第 6334 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0345]])\n",
						"模型中偏参梯度 tensor([-0.1186])\n",
						"第 6335 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0345]])\n",
						"模型中偏参梯度 tensor([-0.1186])\n",
						"第 6336 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0344]])\n",
						"模型中偏参梯度 tensor([-0.1185])\n",
						"第 6337 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0344]])\n",
						"模型中偏参梯度 tensor([-0.1185])\n",
						"第 6338 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0344]])\n",
						"模型中偏参梯度 tensor([-0.1184])\n",
						"第 6339 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0344]])\n",
						"模型中偏参梯度 tensor([-0.1184])\n",
						"第 6340 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0344]])\n",
						"模型中偏参梯度 tensor([-0.1183])\n",
						"第 317 次epoch\n",
						"第 6341 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0343]])\n",
						"模型中偏参梯度 tensor([-0.1183])\n",
						"第 6342 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0343]])\n",
						"模型中偏参梯度 tensor([-0.1182])\n",
						"第 6343 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0343]])\n",
						"模型中偏参梯度 tensor([-0.1182])\n",
						"第 6344 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0343]])\n",
						"模型中偏参梯度 tensor([-0.1182])\n",
						"第 6345 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0343]])\n",
						"模型中偏参梯度 tensor([-0.1181])\n",
						"第 6346 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0342]])\n",
						"模型中偏参梯度 tensor([-0.1181])\n",
						"第 6347 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0342]])\n",
						"模型中偏参梯度 tensor([-0.1180])\n",
						"第 6348 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0342]])\n",
						"模型中偏参梯度 tensor([-0.1180])\n",
						"第 6349 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0342]])\n",
						"模型中偏参梯度 tensor([-0.1179])\n",
						"第 6350 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0341]])\n",
						"模型中偏参梯度 tensor([-0.1179])\n",
						"第 6351 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0341]])\n",
						"模型中偏参梯度 tensor([-0.1178])\n",
						"第 6352 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0341]])\n",
						"模型中偏参梯度 tensor([-0.1178])\n",
						"第 6353 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0341]])\n",
						"模型中偏参梯度 tensor([-0.1177])\n",
						"第 6354 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0341]])\n",
						"模型中偏参梯度 tensor([-0.1177])\n",
						"第 6355 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0340]])\n",
						"模型中偏参梯度 tensor([-0.1177])\n",
						"第 6356 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0340]])\n",
						"模型中偏参梯度 tensor([-0.1176])\n",
						"第 6357 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0340]])\n",
						"模型中偏参梯度 tensor([-0.1176])\n",
						"第 6358 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0339]])\n",
						"模型中偏参梯度 tensor([-0.1175])\n",
						"第 6359 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0339]])\n",
						"模型中偏参梯度 tensor([-0.1175])\n",
						"第 6360 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0339]])\n",
						"模型中偏参梯度 tensor([-0.1174])\n",
						"第 318 次epoch\n",
						"第 6361 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0339]])\n",
						"模型中偏参梯度 tensor([-0.1174])\n",
						"第 6362 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0338]])\n",
						"模型中偏参梯度 tensor([-0.1174])\n",
						"第 6363 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0338]])\n",
						"模型中偏参梯度 tensor([-0.1173])\n",
						"第 6364 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0338]])\n",
						"模型中偏参梯度 tensor([-0.1173])\n",
						"第 6365 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0337]])\n",
						"模型中偏参梯度 tensor([-0.1172])\n",
						"第 6366 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0337]])\n",
						"模型中偏参梯度 tensor([-0.1172])\n",
						"第 6367 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0337]])\n",
						"模型中偏参梯度 tensor([-0.1171])\n",
						"第 6368 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0337]])\n",
						"模型中偏参梯度 tensor([-0.1171])\n",
						"第 6369 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0336]])\n",
						"模型中偏参梯度 tensor([-0.1171])\n",
						"第 6370 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0336]])\n",
						"模型中偏参梯度 tensor([-0.1170])\n",
						"第 6371 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0336]])\n",
						"模型中偏参梯度 tensor([-0.1170])\n",
						"第 6372 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0336]])\n",
						"模型中偏参梯度 tensor([-0.1169])\n",
						"第 6373 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0335]])\n",
						"模型中偏参梯度 tensor([-0.1169])\n",
						"第 6374 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0335]])\n",
						"模型中偏参梯度 tensor([-0.1168])\n",
						"第 6375 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0335]])\n",
						"模型中偏参梯度 tensor([-0.1168])\n",
						"第 6376 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0334]])\n",
						"模型中偏参梯度 tensor([-0.1168])\n",
						"第 6377 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0334]])\n",
						"模型中偏参梯度 tensor([-0.1167])\n",
						"第 6378 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0334]])\n",
						"模型中偏参梯度 tensor([-0.1167])\n",
						"第 6379 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0334]])\n",
						"模型中偏参梯度 tensor([-0.1166])\n",
						"第 6380 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0334]])\n",
						"模型中偏参梯度 tensor([-0.1166])\n",
						"第 319 次epoch\n",
						"第 6381 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0333]])\n",
						"模型中偏参梯度 tensor([-0.1165])\n",
						"第 6382 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0334]])\n",
						"模型中偏参梯度 tensor([-0.1165])\n",
						"第 6383 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0334]])\n",
						"模型中偏参梯度 tensor([-0.1164])\n",
						"第 6384 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0334]])\n",
						"模型中偏参梯度 tensor([-0.1164])\n",
						"第 6385 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0334]])\n",
						"模型中偏参梯度 tensor([-0.1163])\n",
						"第 6386 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0334]])\n",
						"模型中偏参梯度 tensor([-0.1163])\n",
						"第 6387 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0334]])\n",
						"模型中偏参梯度 tensor([-0.1162])\n",
						"第 6388 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0334]])\n",
						"模型中偏参梯度 tensor([-0.1162])\n",
						"第 6389 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0334]])\n",
						"模型中偏参梯度 tensor([-0.1161])\n",
						"第 6390 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0333]])\n",
						"模型中偏参梯度 tensor([-0.1161])\n",
						"第 6391 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0334]])\n",
						"模型中偏参梯度 tensor([-0.1160])\n",
						"第 6392 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0334]])\n",
						"模型中偏参梯度 tensor([-0.1160])\n",
						"第 6393 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0334]])\n",
						"模型中偏参梯度 tensor([-0.1159])\n",
						"第 6394 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0334]])\n",
						"模型中偏参梯度 tensor([-0.1159])\n",
						"第 6395 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0334]])\n",
						"模型中偏参梯度 tensor([-0.1158])\n",
						"第 6396 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0334]])\n",
						"模型中偏参梯度 tensor([-0.1158])\n",
						"第 6397 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0334]])\n",
						"模型中偏参梯度 tensor([-0.1157])\n",
						"第 6398 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0334]])\n",
						"模型中偏参梯度 tensor([-0.1157])\n",
						"第 6399 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0334]])\n",
						"模型中偏参梯度 tensor([-0.1156])\n",
						"第 6400 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0334]])\n",
						"模型中偏参梯度 tensor([-0.1156])\n",
						"第 320 次epoch\n",
						"第 6401 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0334]])\n",
						"模型中偏参梯度 tensor([-0.1155])\n",
						"第 6402 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0334]])\n",
						"模型中偏参梯度 tensor([-0.1155])\n",
						"第 6403 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0334]])\n",
						"模型中偏参梯度 tensor([-0.1154])\n",
						"第 6404 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0334]])\n",
						"模型中偏参梯度 tensor([-0.1154])\n",
						"第 6405 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0334]])\n",
						"模型中偏参梯度 tensor([-0.1153])\n",
						"第 6406 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0334]])\n",
						"模型中偏参梯度 tensor([-0.1153])\n",
						"第 6407 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0334]])\n",
						"模型中偏参梯度 tensor([-0.1152])\n",
						"第 6408 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0334]])\n",
						"模型中偏参梯度 tensor([-0.1152])\n",
						"第 6409 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0334]])\n",
						"模型中偏参梯度 tensor([-0.1151])\n",
						"第 6410 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0334]])\n",
						"模型中偏参梯度 tensor([-0.1151])\n",
						"第 6411 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0334]])\n",
						"模型中偏参梯度 tensor([-0.1150])\n",
						"第 6412 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0334]])\n",
						"模型中偏参梯度 tensor([-0.1150])\n",
						"第 6413 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0334]])\n",
						"模型中偏参梯度 tensor([-0.1149])\n",
						"第 6414 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0334]])\n",
						"模型中偏参梯度 tensor([-0.1149])\n",
						"第 6415 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0333]])\n",
						"模型中偏参梯度 tensor([-0.1148])\n",
						"第 6416 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0333]])\n",
						"模型中偏参梯度 tensor([-0.1148])\n",
						"第 6417 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0333]])\n",
						"模型中偏参梯度 tensor([-0.1147])\n",
						"第 6418 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0333]])\n",
						"模型中偏参梯度 tensor([-0.1147])\n",
						"第 6419 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0333]])\n",
						"模型中偏参梯度 tensor([-0.1146])\n",
						"第 6420 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0333]])\n",
						"模型中偏参梯度 tensor([-0.1146])\n",
						"第 321 次epoch\n",
						"第 6421 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0333]])\n",
						"模型中偏参梯度 tensor([-0.1145])\n",
						"第 6422 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0333]])\n",
						"模型中偏参梯度 tensor([-0.1145])\n",
						"第 6423 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0333]])\n",
						"模型中偏参梯度 tensor([-0.1144])\n",
						"第 6424 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0333]])\n",
						"模型中偏参梯度 tensor([-0.1144])\n",
						"第 6425 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0333]])\n",
						"模型中偏参梯度 tensor([-0.1143])\n",
						"第 6426 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0333]])\n",
						"模型中偏参梯度 tensor([-0.1143])\n",
						"第 6427 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0333]])\n",
						"模型中偏参梯度 tensor([-0.1142])\n",
						"第 6428 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0333]])\n",
						"模型中偏参梯度 tensor([-0.1142])\n",
						"第 6429 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0333]])\n",
						"模型中偏参梯度 tensor([-0.1141])\n",
						"第 6430 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0333]])\n",
						"模型中偏参梯度 tensor([-0.1141])\n",
						"第 6431 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0333]])\n",
						"模型中偏参梯度 tensor([-0.1140])\n",
						"第 6432 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0333]])\n",
						"模型中偏参梯度 tensor([-0.1140])\n",
						"第 6433 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0332]])\n",
						"模型中偏参梯度 tensor([-0.1140])\n",
						"第 6434 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0332]])\n",
						"模型中偏参梯度 tensor([-0.1139])\n",
						"第 6435 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0332]])\n",
						"模型中偏参梯度 tensor([-0.1139])\n",
						"第 6436 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0332]])\n",
						"模型中偏参梯度 tensor([-0.1138])\n",
						"第 6437 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0332]])\n",
						"模型中偏参梯度 tensor([-0.1138])\n",
						"第 6438 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0332]])\n",
						"模型中偏参梯度 tensor([-0.1137])\n",
						"第 6439 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0332]])\n",
						"模型中偏参梯度 tensor([-0.1137])\n",
						"第 6440 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0332]])\n",
						"模型中偏参梯度 tensor([-0.1136])\n",
						"第 322 次epoch\n",
						"第 6441 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0332]])\n",
						"模型中偏参梯度 tensor([-0.1136])\n",
						"第 6442 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0331]])\n",
						"模型中偏参梯度 tensor([-0.1135])\n",
						"第 6443 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0331]])\n",
						"模型中偏参梯度 tensor([-0.1135])\n",
						"第 6444 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0331]])\n",
						"模型中偏参梯度 tensor([-0.1134])\n",
						"第 6445 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0331]])\n",
						"模型中偏参梯度 tensor([-0.1134])\n",
						"第 6446 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0331]])\n",
						"模型中偏参梯度 tensor([-0.1134])\n",
						"第 6447 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0331]])\n",
						"模型中偏参梯度 tensor([-0.1133])\n",
						"第 6448 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0331]])\n",
						"模型中偏参梯度 tensor([-0.1133])\n",
						"第 6449 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0331]])\n",
						"模型中偏参梯度 tensor([-0.1132])\n",
						"第 6450 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0331]])\n",
						"模型中偏参梯度 tensor([-0.1132])\n",
						"第 6451 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0330]])\n",
						"模型中偏参梯度 tensor([-0.1131])\n",
						"第 6452 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0330]])\n",
						"模型中偏参梯度 tensor([-0.1131])\n",
						"第 6453 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0330]])\n",
						"模型中偏参梯度 tensor([-0.1130])\n",
						"第 6454 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0330]])\n",
						"模型中偏参梯度 tensor([-0.1130])\n",
						"第 6455 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0330]])\n",
						"模型中偏参梯度 tensor([-0.1129])\n",
						"第 6456 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0330]])\n",
						"模型中偏参梯度 tensor([-0.1129])\n",
						"第 6457 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0330]])\n",
						"模型中偏参梯度 tensor([-0.1128])\n",
						"第 6458 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0329]])\n",
						"模型中偏参梯度 tensor([-0.1128])\n",
						"第 6459 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0329]])\n",
						"模型中偏参梯度 tensor([-0.1128])\n",
						"第 6460 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0329]])\n",
						"模型中偏参梯度 tensor([-0.1127])\n",
						"第 323 次epoch\n",
						"第 6461 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0329]])\n",
						"模型中偏参梯度 tensor([-0.1127])\n",
						"第 6462 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0329]])\n",
						"模型中偏参梯度 tensor([-0.1126])\n",
						"第 6463 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0329]])\n",
						"模型中偏参梯度 tensor([-0.1126])\n",
						"第 6464 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0328]])\n",
						"模型中偏参梯度 tensor([-0.1125])\n",
						"第 6465 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0328]])\n",
						"模型中偏参梯度 tensor([-0.1125])\n",
						"第 6466 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0328]])\n",
						"模型中偏参梯度 tensor([-0.1125])\n",
						"第 6467 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0328]])\n",
						"模型中偏参梯度 tensor([-0.1124])\n",
						"第 6468 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0328]])\n",
						"模型中偏参梯度 tensor([-0.1124])\n",
						"第 6469 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0328]])\n",
						"模型中偏参梯度 tensor([-0.1123])\n",
						"第 6470 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0327]])\n",
						"模型中偏参梯度 tensor([-0.1123])\n",
						"第 6471 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0327]])\n",
						"模型中偏参梯度 tensor([-0.1122])\n",
						"第 6472 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0327]])\n",
						"模型中偏参梯度 tensor([-0.1122])\n",
						"第 6473 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0327]])\n",
						"模型中偏参梯度 tensor([-0.1121])\n",
						"第 6474 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0327]])\n",
						"模型中偏参梯度 tensor([-0.1121])\n",
						"第 6475 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0327]])\n",
						"模型中偏参梯度 tensor([-0.1121])\n",
						"第 6476 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0326]])\n",
						"模型中偏参梯度 tensor([-0.1120])\n",
						"第 6477 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0326]])\n",
						"模型中偏参梯度 tensor([-0.1120])\n",
						"第 6478 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0326]])\n",
						"模型中偏参梯度 tensor([-0.1119])\n",
						"第 6479 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0326]])\n",
						"模型中偏参梯度 tensor([-0.1119])\n",
						"第 6480 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0326]])\n",
						"模型中偏参梯度 tensor([-0.1118])\n",
						"第 324 次epoch\n",
						"第 6481 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0325]])\n",
						"模型中偏参梯度 tensor([-0.1118])\n",
						"第 6482 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0325]])\n",
						"模型中偏参梯度 tensor([-0.1118])\n",
						"第 6483 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0325]])\n",
						"模型中偏参梯度 tensor([-0.1117])\n",
						"第 6484 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0325]])\n",
						"模型中偏参梯度 tensor([-0.1117])\n",
						"第 6485 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0324]])\n",
						"模型中偏参梯度 tensor([-0.1116])\n",
						"第 6486 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0324]])\n",
						"模型中偏参梯度 tensor([-0.1116])\n",
						"第 6487 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0324]])\n",
						"模型中偏参梯度 tensor([-0.1115])\n",
						"第 6488 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0324]])\n",
						"模型中偏参梯度 tensor([-0.1115])\n",
						"第 6489 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0324]])\n",
						"模型中偏参梯度 tensor([-0.1115])\n",
						"第 6490 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0323]])\n",
						"模型中偏参梯度 tensor([-0.1114])\n",
						"第 6491 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0323]])\n",
						"模型中偏参梯度 tensor([-0.1114])\n",
						"第 6492 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0323]])\n",
						"模型中偏参梯度 tensor([-0.1113])\n",
						"第 6493 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0323]])\n",
						"模型中偏参梯度 tensor([-0.1113])\n",
						"第 6494 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0322]])\n",
						"模型中偏参梯度 tensor([-0.1112])\n",
						"第 6495 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0322]])\n",
						"模型中偏参梯度 tensor([-0.1112])\n",
						"第 6496 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0322]])\n",
						"模型中偏参梯度 tensor([-0.1112])\n",
						"第 6497 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0322]])\n",
						"模型中偏参梯度 tensor([-0.1111])\n",
						"第 6498 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0322]])\n",
						"模型中偏参梯度 tensor([-0.1111])\n",
						"第 6499 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0321]])\n",
						"模型中偏参梯度 tensor([-0.1110])\n",
						"第 6500 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0321]])\n",
						"模型中偏参梯度 tensor([-0.1110])\n",
						"第 325 次epoch\n",
						"第 6501 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0321]])\n",
						"模型中偏参梯度 tensor([-0.1110])\n",
						"第 6502 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0321]])\n",
						"模型中偏参梯度 tensor([-0.1109])\n",
						"第 6503 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0320]])\n",
						"模型中偏参梯度 tensor([-0.1109])\n",
						"第 6504 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0320]])\n",
						"模型中偏参梯度 tensor([-0.1108])\n",
						"第 6505 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0320]])\n",
						"模型中偏参梯度 tensor([-0.1108])\n",
						"第 6506 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0319]])\n",
						"模型中偏参梯度 tensor([-0.1108])\n",
						"第 6507 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0319]])\n",
						"模型中偏参梯度 tensor([-0.1107])\n",
						"第 6508 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0319]])\n",
						"模型中偏参梯度 tensor([-0.1107])\n",
						"第 6509 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0319]])\n",
						"模型中偏参梯度 tensor([-0.1106])\n",
						"第 6510 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0318]])\n",
						"模型中偏参梯度 tensor([-0.1106])\n",
						"第 6511 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0318]])\n",
						"模型中偏参梯度 tensor([-0.1106])\n",
						"第 6512 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0318]])\n",
						"模型中偏参梯度 tensor([-0.1105])\n",
						"第 6513 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0318]])\n",
						"模型中偏参梯度 tensor([-0.1105])\n",
						"第 6514 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0317]])\n",
						"模型中偏参梯度 tensor([-0.1104])\n",
						"第 6515 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0317]])\n",
						"模型中偏参梯度 tensor([-0.1104])\n",
						"第 6516 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0317]])\n",
						"模型中偏参梯度 tensor([-0.1103])\n",
						"第 6517 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0316]])\n",
						"模型中偏参梯度 tensor([-0.1103])\n",
						"第 6518 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0316]])\n",
						"模型中偏参梯度 tensor([-0.1103])\n",
						"第 6519 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0316]])\n",
						"模型中偏参梯度 tensor([-0.1102])\n",
						"第 6520 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0316]])\n",
						"模型中偏参梯度 tensor([-0.1102])\n",
						"第 326 次epoch\n",
						"第 6521 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0315]])\n",
						"模型中偏参梯度 tensor([-0.1101])\n",
						"第 6522 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0315]])\n",
						"模型中偏参梯度 tensor([-0.1101])\n",
						"第 6523 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0315]])\n",
						"模型中偏参梯度 tensor([-0.1101])\n",
						"第 6524 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0314]])\n",
						"模型中偏参梯度 tensor([-0.1100])\n",
						"第 6525 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0315]])\n",
						"模型中偏参梯度 tensor([-0.1100])\n",
						"第 6526 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0315]])\n",
						"模型中偏参梯度 tensor([-0.1099])\n",
						"第 6527 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0315]])\n",
						"模型中偏参梯度 tensor([-0.1099])\n",
						"第 6528 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0315]])\n",
						"模型中偏参梯度 tensor([-0.1098])\n",
						"第 6529 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0315]])\n",
						"模型中偏参梯度 tensor([-0.1098])\n",
						"第 6530 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0315]])\n",
						"模型中偏参梯度 tensor([-0.1097])\n",
						"第 6531 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0314]])\n",
						"模型中偏参梯度 tensor([-0.1097])\n",
						"第 6532 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0314]])\n",
						"模型中偏参梯度 tensor([-0.1096])\n",
						"第 6533 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0315]])\n",
						"模型中偏参梯度 tensor([-0.1096])\n",
						"第 6534 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0315]])\n",
						"模型中偏参梯度 tensor([-0.1095])\n",
						"第 6535 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0315]])\n",
						"模型中偏参梯度 tensor([-0.1095])\n",
						"第 6536 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0315]])\n",
						"模型中偏参梯度 tensor([-0.1094])\n",
						"第 6537 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0314]])\n",
						"模型中偏参梯度 tensor([-0.1094])\n",
						"第 6538 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0314]])\n",
						"模型中偏参梯度 tensor([-0.1094])\n",
						"第 6539 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0314]])\n",
						"模型中偏参梯度 tensor([-0.1093])\n",
						"第 6540 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0315]])\n",
						"模型中偏参梯度 tensor([-0.1093])\n",
						"第 327 次epoch\n",
						"第 6541 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0315]])\n",
						"模型中偏参梯度 tensor([-0.1092])\n",
						"第 6542 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0315]])\n",
						"模型中偏参梯度 tensor([-0.1092])\n",
						"第 6543 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0315]])\n",
						"模型中偏参梯度 tensor([-0.1091])\n",
						"第 6544 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0315]])\n",
						"模型中偏参梯度 tensor([-0.1091])\n",
						"第 6545 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0315]])\n",
						"模型中偏参梯度 tensor([-0.1090])\n",
						"第 6546 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0315]])\n",
						"模型中偏参梯度 tensor([-0.1090])\n",
						"第 6547 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0315]])\n",
						"模型中偏参梯度 tensor([-0.1089])\n",
						"第 6548 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0315]])\n",
						"模型中偏参梯度 tensor([-0.1089])\n",
						"第 6549 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0315]])\n",
						"模型中偏参梯度 tensor([-0.1088])\n",
						"第 6550 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0315]])\n",
						"模型中偏参梯度 tensor([-0.1088])\n",
						"第 6551 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0315]])\n",
						"模型中偏参梯度 tensor([-0.1087])\n",
						"第 6552 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0315]])\n",
						"模型中偏参梯度 tensor([-0.1087])\n",
						"第 6553 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0315]])\n",
						"模型中偏参梯度 tensor([-0.1086])\n",
						"第 6554 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0315]])\n",
						"模型中偏参梯度 tensor([-0.1086])\n",
						"第 6555 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0315]])\n",
						"模型中偏参梯度 tensor([-0.1086])\n",
						"第 6556 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0315]])\n",
						"模型中偏参梯度 tensor([-0.1085])\n",
						"第 6557 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0315]])\n",
						"模型中偏参梯度 tensor([-0.1085])\n",
						"第 6558 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0315]])\n",
						"模型中偏参梯度 tensor([-0.1084])\n",
						"第 6559 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0315]])\n",
						"模型中偏参梯度 tensor([-0.1084])\n",
						"第 6560 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0315]])\n",
						"模型中偏参梯度 tensor([-0.1083])\n",
						"第 328 次epoch\n",
						"第 6561 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0315]])\n",
						"模型中偏参梯度 tensor([-0.1083])\n",
						"第 6562 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0315]])\n",
						"模型中偏参梯度 tensor([-0.1082])\n",
						"第 6563 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0315]])\n",
						"模型中偏参梯度 tensor([-0.1082])\n",
						"第 6564 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0315]])\n",
						"模型中偏参梯度 tensor([-0.1081])\n",
						"第 6565 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0315]])\n",
						"模型中偏参梯度 tensor([-0.1081])\n",
						"第 6566 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0314]])\n",
						"模型中偏参梯度 tensor([-0.1080])\n",
						"第 6567 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0314]])\n",
						"模型中偏参梯度 tensor([-0.1080])\n",
						"第 6568 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0314]])\n",
						"模型中偏参梯度 tensor([-0.1079])\n",
						"第 6569 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0314]])\n",
						"模型中偏参梯度 tensor([-0.1079])\n",
						"第 6570 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0314]])\n",
						"模型中偏参梯度 tensor([-0.1079])\n",
						"第 6571 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0314]])\n",
						"模型中偏参梯度 tensor([-0.1078])\n",
						"第 6572 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0314]])\n",
						"模型中偏参梯度 tensor([-0.1078])\n",
						"第 6573 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0314]])\n",
						"模型中偏参梯度 tensor([-0.1077])\n",
						"第 6574 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0314]])\n",
						"模型中偏参梯度 tensor([-0.1077])\n",
						"第 6575 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0314]])\n",
						"模型中偏参梯度 tensor([-0.1076])\n",
						"第 6576 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0314]])\n",
						"模型中偏参梯度 tensor([-0.1076])\n",
						"第 6577 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0314]])\n",
						"模型中偏参梯度 tensor([-0.1075])\n",
						"第 6578 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0314]])\n",
						"模型中偏参梯度 tensor([-0.1075])\n",
						"第 6579 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0314]])\n",
						"模型中偏参梯度 tensor([-0.1074])\n",
						"第 6580 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0314]])\n",
						"模型中偏参梯度 tensor([-0.1074])\n",
						"第 329 次epoch\n",
						"第 6581 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0314]])\n",
						"模型中偏参梯度 tensor([-0.1074])\n",
						"第 6582 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0314]])\n",
						"模型中偏参梯度 tensor([-0.1073])\n",
						"第 6583 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0314]])\n",
						"模型中偏参梯度 tensor([-0.1073])\n",
						"第 6584 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0313]])\n",
						"模型中偏参梯度 tensor([-0.1072])\n",
						"第 6585 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0313]])\n",
						"模型中偏参梯度 tensor([-0.1072])\n",
						"第 6586 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0313]])\n",
						"模型中偏参梯度 tensor([-0.1071])\n",
						"第 6587 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0313]])\n",
						"模型中偏参梯度 tensor([-0.1071])\n",
						"第 6588 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0313]])\n",
						"模型中偏参梯度 tensor([-0.1070])\n",
						"第 6589 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0313]])\n",
						"模型中偏参梯度 tensor([-0.1070])\n",
						"第 6590 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0313]])\n",
						"模型中偏参梯度 tensor([-0.1070])\n",
						"第 6591 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0313]])\n",
						"模型中偏参梯度 tensor([-0.1069])\n",
						"第 6592 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0313]])\n",
						"模型中偏参梯度 tensor([-0.1069])\n",
						"第 6593 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0313]])\n",
						"模型中偏参梯度 tensor([-0.1068])\n",
						"第 6594 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0312]])\n",
						"模型中偏参梯度 tensor([-0.1068])\n",
						"第 6595 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0312]])\n",
						"模型中偏参梯度 tensor([-0.1067])\n",
						"第 6596 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0312]])\n",
						"模型中偏参梯度 tensor([-0.1067])\n",
						"第 6597 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0312]])\n",
						"模型中偏参梯度 tensor([-0.1067])\n",
						"第 6598 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0312]])\n",
						"模型中偏参梯度 tensor([-0.1066])\n",
						"第 6599 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0312]])\n",
						"模型中偏参梯度 tensor([-0.1066])\n",
						"第 6600 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0312]])\n",
						"模型中偏参梯度 tensor([-0.1065])\n",
						"第 330 次epoch\n",
						"第 6601 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0312]])\n",
						"模型中偏参梯度 tensor([-0.1065])\n",
						"第 6602 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0312]])\n",
						"模型中偏参梯度 tensor([-0.1064])\n",
						"第 6603 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0311]])\n",
						"模型中偏参梯度 tensor([-0.1064])\n",
						"第 6604 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0311]])\n",
						"模型中偏参梯度 tensor([-0.1064])\n",
						"第 6605 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0311]])\n",
						"模型中偏参梯度 tensor([-0.1063])\n",
						"第 6606 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0311]])\n",
						"模型中偏参梯度 tensor([-0.1063])\n",
						"第 6607 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0311]])\n",
						"模型中偏参梯度 tensor([-0.1062])\n",
						"第 6608 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0311]])\n",
						"模型中偏参梯度 tensor([-0.1062])\n",
						"第 6609 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0311]])\n",
						"模型中偏参梯度 tensor([-0.1061])\n",
						"第 6610 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0310]])\n",
						"模型中偏参梯度 tensor([-0.1061])\n",
						"第 6611 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0310]])\n",
						"模型中偏参梯度 tensor([-0.1061])\n",
						"第 6612 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0310]])\n",
						"模型中偏参梯度 tensor([-0.1060])\n",
						"第 6613 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0310]])\n",
						"模型中偏参梯度 tensor([-0.1060])\n",
						"第 6614 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0310]])\n",
						"模型中偏参梯度 tensor([-0.1059])\n",
						"第 6615 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0310]])\n",
						"模型中偏参梯度 tensor([-0.1059])\n",
						"第 6616 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0310]])\n",
						"模型中偏参梯度 tensor([-0.1059])\n",
						"第 6617 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0309]])\n",
						"模型中偏参梯度 tensor([-0.1058])\n",
						"第 6618 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0309]])\n",
						"模型中偏参梯度 tensor([-0.1058])\n",
						"第 6619 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0309]])\n",
						"模型中偏参梯度 tensor([-0.1057])\n",
						"第 6620 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0309]])\n",
						"模型中偏参梯度 tensor([-0.1057])\n",
						"第 331 次epoch\n",
						"第 6621 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0309]])\n",
						"模型中偏参梯度 tensor([-0.1056])\n",
						"第 6622 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0309]])\n",
						"模型中偏参梯度 tensor([-0.1056])\n",
						"第 6623 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0308]])\n",
						"模型中偏参梯度 tensor([-0.1056])\n",
						"第 6624 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0308]])\n",
						"模型中偏参梯度 tensor([-0.1055])\n",
						"第 6625 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0308]])\n",
						"模型中偏参梯度 tensor([-0.1055])\n",
						"第 6626 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0308]])\n",
						"模型中偏参梯度 tensor([-0.1054])\n",
						"第 6627 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0308]])\n",
						"模型中偏参梯度 tensor([-0.1054])\n",
						"第 6628 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0308]])\n",
						"模型中偏参梯度 tensor([-0.1054])\n",
						"第 6629 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0307]])\n",
						"模型中偏参梯度 tensor([-0.1053])\n",
						"第 6630 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0307]])\n",
						"模型中偏参梯度 tensor([-0.1053])\n",
						"第 6631 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0307]])\n",
						"模型中偏参梯度 tensor([-0.1052])\n",
						"第 6632 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0307]])\n",
						"模型中偏参梯度 tensor([-0.1052])\n",
						"第 6633 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0307]])\n",
						"模型中偏参梯度 tensor([-0.1052])\n",
						"第 6634 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0306]])\n",
						"模型中偏参梯度 tensor([-0.1051])\n",
						"第 6635 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0306]])\n",
						"模型中偏参梯度 tensor([-0.1051])\n",
						"第 6636 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0306]])\n",
						"模型中偏参梯度 tensor([-0.1050])\n",
						"第 6637 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0306]])\n",
						"模型中偏参梯度 tensor([-0.1050])\n",
						"第 6638 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0306]])\n",
						"模型中偏参梯度 tensor([-0.1050])\n",
						"第 6639 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0305]])\n",
						"模型中偏参梯度 tensor([-0.1049])\n",
						"第 6640 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0305]])\n",
						"模型中偏参梯度 tensor([-0.1049])\n",
						"第 332 次epoch\n",
						"第 6641 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0305]])\n",
						"模型中偏参梯度 tensor([-0.1048])\n",
						"第 6642 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0305]])\n",
						"模型中偏参梯度 tensor([-0.1048])\n",
						"第 6643 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0304]])\n",
						"模型中偏参梯度 tensor([-0.1048])\n",
						"第 6644 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0304]])\n",
						"模型中偏参梯度 tensor([-0.1047])\n",
						"第 6645 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0304]])\n",
						"模型中偏参梯度 tensor([-0.1047])\n",
						"第 6646 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0304]])\n",
						"模型中偏参梯度 tensor([-0.1046])\n",
						"第 6647 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0304]])\n",
						"模型中偏参梯度 tensor([-0.1046])\n",
						"第 6648 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0303]])\n",
						"模型中偏参梯度 tensor([-0.1046])\n",
						"第 6649 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0303]])\n",
						"模型中偏参梯度 tensor([-0.1045])\n",
						"第 6650 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0303]])\n",
						"模型中偏参梯度 tensor([-0.1045])\n",
						"第 6651 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0303]])\n",
						"模型中偏参梯度 tensor([-0.1044])\n",
						"第 6652 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0303]])\n",
						"模型中偏参梯度 tensor([-0.1044])\n",
						"第 6653 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0302]])\n",
						"模型中偏参梯度 tensor([-0.1044])\n",
						"第 6654 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0302]])\n",
						"模型中偏参梯度 tensor([-0.1043])\n",
						"第 6655 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0302]])\n",
						"模型中偏参梯度 tensor([-0.1043])\n",
						"第 6656 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0302]])\n",
						"模型中偏参梯度 tensor([-0.1042])\n",
						"第 6657 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0301]])\n",
						"模型中偏参梯度 tensor([-0.1042])\n",
						"第 6658 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0301]])\n",
						"模型中偏参梯度 tensor([-0.1042])\n",
						"第 6659 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0301]])\n",
						"模型中偏参梯度 tensor([-0.1041])\n",
						"第 6660 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0300]])\n",
						"模型中偏参梯度 tensor([-0.1041])\n",
						"第 333 次epoch\n",
						"第 6661 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0300]])\n",
						"模型中偏参梯度 tensor([-0.1041])\n",
						"第 6662 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0300]])\n",
						"模型中偏参梯度 tensor([-0.1040])\n",
						"第 6663 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0300]])\n",
						"模型中偏参梯度 tensor([-0.1040])\n",
						"第 6664 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0299]])\n",
						"模型中偏参梯度 tensor([-0.1039])\n",
						"第 6665 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0299]])\n",
						"模型中偏参梯度 tensor([-0.1039])\n",
						"第 6666 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0299]])\n",
						"模型中偏参梯度 tensor([-0.1039])\n",
						"第 6667 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0299]])\n",
						"模型中偏参梯度 tensor([-0.1038])\n",
						"第 6668 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0298]])\n",
						"模型中偏参梯度 tensor([-0.1038])\n",
						"第 6669 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0298]])\n",
						"模型中偏参梯度 tensor([-0.1038])\n",
						"第 6670 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0298]])\n",
						"模型中偏参梯度 tensor([-0.1037])\n",
						"第 6671 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0298]])\n",
						"模型中偏参梯度 tensor([-0.1037])\n",
						"第 6672 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0297]])\n",
						"模型中偏参梯度 tensor([-0.1036])\n",
						"第 6673 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0297]])\n",
						"模型中偏参梯度 tensor([-0.1036])\n",
						"第 6674 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0297]])\n",
						"模型中偏参梯度 tensor([-0.1036])\n",
						"第 6675 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0296]])\n",
						"模型中偏参梯度 tensor([-0.1035])\n",
						"第 6676 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0296]])\n",
						"模型中偏参梯度 tensor([-0.1035])\n",
						"第 6677 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0296]])\n",
						"模型中偏参梯度 tensor([-0.1035])\n",
						"第 6678 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0296]])\n",
						"模型中偏参梯度 tensor([-0.1034])\n",
						"第 6679 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0295]])\n",
						"模型中偏参梯度 tensor([-0.1034])\n",
						"第 6680 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0295]])\n",
						"模型中偏参梯度 tensor([-0.1033])\n",
						"第 334 次epoch\n",
						"第 6681 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0295]])\n",
						"模型中偏参梯度 tensor([-0.1033])\n",
						"第 6682 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0296]])\n",
						"模型中偏参梯度 tensor([-0.1032])\n",
						"第 6683 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0296]])\n",
						"模型中偏参梯度 tensor([-0.1032])\n",
						"第 6684 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0296]])\n",
						"模型中偏参梯度 tensor([-0.1032])\n",
						"第 6685 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0295]])\n",
						"模型中偏参梯度 tensor([-0.1031])\n",
						"第 6686 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0295]])\n",
						"模型中偏参梯度 tensor([-0.1031])\n",
						"第 6687 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0295]])\n",
						"模型中偏参梯度 tensor([-0.1030])\n",
						"第 6688 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0295]])\n",
						"模型中偏参梯度 tensor([-0.1030])\n",
						"第 6689 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0296]])\n",
						"模型中偏参梯度 tensor([-0.1029])\n",
						"第 6690 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0296]])\n",
						"模型中偏参梯度 tensor([-0.1029])\n",
						"第 6691 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0295]])\n",
						"模型中偏参梯度 tensor([-0.1028])\n",
						"第 6692 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0295]])\n",
						"模型中偏参梯度 tensor([-0.1028])\n",
						"第 6693 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0295]])\n",
						"模型中偏参梯度 tensor([-0.1028])\n",
						"第 6694 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0295]])\n",
						"模型中偏参梯度 tensor([-0.1027])\n",
						"第 6695 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0296]])\n",
						"模型中偏参梯度 tensor([-0.1027])\n",
						"第 6696 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0296]])\n",
						"模型中偏参梯度 tensor([-0.1026])\n",
						"第 6697 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0296]])\n",
						"模型中偏参梯度 tensor([-0.1026])\n",
						"第 6698 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0295]])\n",
						"模型中偏参梯度 tensor([-0.1025])\n",
						"第 6699 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0295]])\n",
						"模型中偏参梯度 tensor([-0.1025])\n",
						"第 6700 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0295]])\n",
						"模型中偏参梯度 tensor([-0.1024])\n",
						"第 335 次epoch\n",
						"第 6701 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0295]])\n",
						"模型中偏参梯度 tensor([-0.1024])\n",
						"第 6702 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0295]])\n",
						"模型中偏参梯度 tensor([-0.1024])\n",
						"第 6703 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0295]])\n",
						"模型中偏参梯度 tensor([-0.1023])\n",
						"第 6704 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0295]])\n",
						"模型中偏参梯度 tensor([-0.1023])\n",
						"第 6705 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0295]])\n",
						"模型中偏参梯度 tensor([-0.1022])\n",
						"第 6706 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0295]])\n",
						"模型中偏参梯度 tensor([-0.1022])\n",
						"第 6707 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0295]])\n",
						"模型中偏参梯度 tensor([-0.1021])\n",
						"第 6708 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0296]])\n",
						"模型中偏参梯度 tensor([-0.1021])\n",
						"第 6709 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0295]])\n",
						"模型中偏参梯度 tensor([-0.1020])\n",
						"第 6710 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0296]])\n",
						"模型中偏参梯度 tensor([-0.1020])\n",
						"第 6711 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0295]])\n",
						"模型中偏参梯度 tensor([-0.1020])\n",
						"第 6712 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0296]])\n",
						"模型中偏参梯度 tensor([-0.1019])\n",
						"第 6713 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0296]])\n",
						"模型中偏参梯度 tensor([-0.1019])\n",
						"第 6714 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0296]])\n",
						"模型中偏参梯度 tensor([-0.1018])\n",
						"第 6715 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0296]])\n",
						"模型中偏参梯度 tensor([-0.1018])\n",
						"第 6716 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0296]])\n",
						"模型中偏参梯度 tensor([-0.1017])\n",
						"第 6717 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0296]])\n",
						"模型中偏参梯度 tensor([-0.1017])\n",
						"第 6718 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0296]])\n",
						"模型中偏参梯度 tensor([-0.1016])\n",
						"第 6719 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0296]])\n",
						"模型中偏参梯度 tensor([-0.1016])\n",
						"第 6720 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0296]])\n",
						"模型中偏参梯度 tensor([-0.1016])\n",
						"第 336 次epoch\n",
						"第 6721 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0295]])\n",
						"模型中偏参梯度 tensor([-0.1015])\n",
						"第 6722 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0295]])\n",
						"模型中偏参梯度 tensor([-0.1015])\n",
						"第 6723 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0295]])\n",
						"模型中偏参梯度 tensor([-0.1014])\n",
						"第 6724 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0295]])\n",
						"模型中偏参梯度 tensor([-0.1014])\n",
						"第 6725 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0295]])\n",
						"模型中偏参梯度 tensor([-0.1013])\n",
						"第 6726 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0295]])\n",
						"模型中偏参梯度 tensor([-0.1013])\n",
						"第 6727 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0295]])\n",
						"模型中偏参梯度 tensor([-0.1013])\n",
						"第 6728 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0295]])\n",
						"模型中偏参梯度 tensor([-0.1012])\n",
						"第 6729 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0295]])\n",
						"模型中偏参梯度 tensor([-0.1012])\n",
						"第 6730 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0295]])\n",
						"模型中偏参梯度 tensor([-0.1011])\n",
						"第 6731 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0295]])\n",
						"模型中偏参梯度 tensor([-0.1011])\n",
						"第 6732 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0295]])\n",
						"模型中偏参梯度 tensor([-0.1010])\n",
						"第 6733 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0295]])\n",
						"模型中偏参梯度 tensor([-0.1010])\n",
						"第 6734 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0295]])\n",
						"模型中偏参梯度 tensor([-0.1010])\n",
						"第 6735 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0295]])\n",
						"模型中偏参梯度 tensor([-0.1009])\n",
						"第 6736 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0295]])\n",
						"模型中偏参梯度 tensor([-0.1009])\n",
						"第 6737 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0295]])\n",
						"模型中偏参梯度 tensor([-0.1008])\n",
						"第 6738 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0295]])\n",
						"模型中偏参梯度 tensor([-0.1008])\n",
						"第 6739 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0295]])\n",
						"模型中偏参梯度 tensor([-0.1007])\n",
						"第 6740 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0295]])\n",
						"模型中偏参梯度 tensor([-0.1007])\n",
						"第 337 次epoch\n",
						"第 6741 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0295]])\n",
						"模型中偏参梯度 tensor([-0.1007])\n",
						"第 6742 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0295]])\n",
						"模型中偏参梯度 tensor([-0.1006])\n",
						"第 6743 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0294]])\n",
						"模型中偏参梯度 tensor([-0.1006])\n",
						"第 6744 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0294]])\n",
						"模型中偏参梯度 tensor([-0.1005])\n",
						"第 6745 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0294]])\n",
						"模型中偏参梯度 tensor([-0.1005])\n",
						"第 6746 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0294]])\n",
						"模型中偏参梯度 tensor([-0.1004])\n",
						"第 6747 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0294]])\n",
						"模型中偏参梯度 tensor([-0.1004])\n",
						"第 6748 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0294]])\n",
						"模型中偏参梯度 tensor([-0.1004])\n",
						"第 6749 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0294]])\n",
						"模型中偏参梯度 tensor([-0.1003])\n",
						"第 6750 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0294]])\n",
						"模型中偏参梯度 tensor([-0.1003])\n",
						"第 6751 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0294]])\n",
						"模型中偏参梯度 tensor([-0.1002])\n",
						"第 6752 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0294]])\n",
						"模型中偏参梯度 tensor([-0.1002])\n",
						"第 6753 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0294]])\n",
						"模型中偏参梯度 tensor([-0.1002])\n",
						"第 6754 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0293]])\n",
						"模型中偏参梯度 tensor([-0.1001])\n",
						"第 6755 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0293]])\n",
						"模型中偏参梯度 tensor([-0.1001])\n",
						"第 6756 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0293]])\n",
						"模型中偏参梯度 tensor([-0.1000])\n",
						"第 6757 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0293]])\n",
						"模型中偏参梯度 tensor([-0.1000])\n",
						"第 6758 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0293]])\n",
						"模型中偏参梯度 tensor([-0.1000])\n",
						"第 6759 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0293]])\n",
						"模型中偏参梯度 tensor([-0.0999])\n",
						"第 6760 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0293]])\n",
						"模型中偏参梯度 tensor([-0.0999])\n",
						"第 338 次epoch\n",
						"第 6761 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0293]])\n",
						"模型中偏参梯度 tensor([-0.0998])\n",
						"第 6762 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0293]])\n",
						"模型中偏参梯度 tensor([-0.0998])\n",
						"第 6763 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0293]])\n",
						"模型中偏参梯度 tensor([-0.0998])\n",
						"第 6764 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0292]])\n",
						"模型中偏参梯度 tensor([-0.0997])\n",
						"第 6765 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0292]])\n",
						"模型中偏参梯度 tensor([-0.0997])\n",
						"第 6766 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0292]])\n",
						"模型中偏参梯度 tensor([-0.0996])\n",
						"第 6767 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0292]])\n",
						"模型中偏参梯度 tensor([-0.0996])\n",
						"第 6768 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0292]])\n",
						"模型中偏参梯度 tensor([-0.0996])\n",
						"第 6769 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0292]])\n",
						"模型中偏参梯度 tensor([-0.0995])\n",
						"第 6770 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0292]])\n",
						"模型中偏参梯度 tensor([-0.0995])\n",
						"第 6771 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0291]])\n",
						"模型中偏参梯度 tensor([-0.0994])\n",
						"第 6772 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0291]])\n",
						"模型中偏参梯度 tensor([-0.0994])\n",
						"第 6773 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0291]])\n",
						"模型中偏参梯度 tensor([-0.0994])\n",
						"第 6774 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0291]])\n",
						"模型中偏参梯度 tensor([-0.0993])\n",
						"第 6775 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0291]])\n",
						"模型中偏参梯度 tensor([-0.0993])\n",
						"第 6776 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0291]])\n",
						"模型中偏参梯度 tensor([-0.0992])\n",
						"第 6777 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0291]])\n",
						"模型中偏参梯度 tensor([-0.0992])\n",
						"第 6778 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0290]])\n",
						"模型中偏参梯度 tensor([-0.0992])\n",
						"第 6779 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0290]])\n",
						"模型中偏参梯度 tensor([-0.0991])\n",
						"第 6780 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0290]])\n",
						"模型中偏参梯度 tensor([-0.0991])\n",
						"第 339 次epoch\n",
						"第 6781 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0290]])\n",
						"模型中偏参梯度 tensor([-0.0991])\n",
						"第 6782 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0290]])\n",
						"模型中偏参梯度 tensor([-0.0990])\n",
						"第 6783 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0290]])\n",
						"模型中偏参梯度 tensor([-0.0990])\n",
						"第 6784 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0289]])\n",
						"模型中偏参梯度 tensor([-0.0989])\n",
						"第 6785 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0289]])\n",
						"模型中偏参梯度 tensor([-0.0989])\n",
						"第 6786 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0289]])\n",
						"模型中偏参梯度 tensor([-0.0989])\n",
						"第 6787 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0289]])\n",
						"模型中偏参梯度 tensor([-0.0988])\n",
						"第 6788 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0289]])\n",
						"模型中偏参梯度 tensor([-0.0988])\n",
						"第 6789 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0289]])\n",
						"模型中偏参梯度 tensor([-0.0987])\n",
						"第 6790 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0289]])\n",
						"模型中偏参梯度 tensor([-0.0987])\n",
						"第 6791 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0288]])\n",
						"模型中偏参梯度 tensor([-0.0987])\n",
						"第 6792 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0288]])\n",
						"模型中偏参梯度 tensor([-0.0986])\n",
						"第 6793 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0288]])\n",
						"模型中偏参梯度 tensor([-0.0986])\n",
						"第 6794 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0288]])\n",
						"模型中偏参梯度 tensor([-0.0986])\n",
						"第 6795 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0288]])\n",
						"模型中偏参梯度 tensor([-0.0985])\n",
						"第 6796 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0287]])\n",
						"模型中偏参梯度 tensor([-0.0985])\n",
						"第 6797 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0287]])\n",
						"模型中偏参梯度 tensor([-0.0984])\n",
						"第 6798 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0287]])\n",
						"模型中偏参梯度 tensor([-0.0984])\n",
						"第 6799 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0287]])\n",
						"模型中偏参梯度 tensor([-0.0984])\n",
						"第 6800 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0287]])\n",
						"模型中偏参梯度 tensor([-0.0983])\n",
						"第 340 次epoch\n",
						"第 6801 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0286]])\n",
						"模型中偏参梯度 tensor([-0.0983])\n",
						"第 6802 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0286]])\n",
						"模型中偏参梯度 tensor([-0.0983])\n",
						"第 6803 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0286]])\n",
						"模型中偏参梯度 tensor([-0.0982])\n",
						"第 6804 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0286]])\n",
						"模型中偏参梯度 tensor([-0.0982])\n",
						"第 6805 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0286]])\n",
						"模型中偏参梯度 tensor([-0.0981])\n",
						"第 6806 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0285]])\n",
						"模型中偏参梯度 tensor([-0.0981])\n",
						"第 6807 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0285]])\n",
						"模型中偏参梯度 tensor([-0.0981])\n",
						"第 6808 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0285]])\n",
						"模型中偏参梯度 tensor([-0.0980])\n",
						"第 6809 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0285]])\n",
						"模型中偏参梯度 tensor([-0.0980])\n",
						"第 6810 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0285]])\n",
						"模型中偏参梯度 tensor([-0.0980])\n",
						"第 6811 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0284]])\n",
						"模型中偏参梯度 tensor([-0.0979])\n",
						"第 6812 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0284]])\n",
						"模型中偏参梯度 tensor([-0.0979])\n",
						"第 6813 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0284]])\n",
						"模型中偏参梯度 tensor([-0.0979])\n",
						"第 6814 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0284]])\n",
						"模型中偏参梯度 tensor([-0.0978])\n",
						"第 6815 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0283]])\n",
						"模型中偏参梯度 tensor([-0.0978])\n",
						"第 6816 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0283]])\n",
						"模型中偏参梯度 tensor([-0.0977])\n",
						"第 6817 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0283]])\n",
						"模型中偏参梯度 tensor([-0.0977])\n",
						"第 6818 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0283]])\n",
						"模型中偏参梯度 tensor([-0.0977])\n",
						"第 6819 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0283]])\n",
						"模型中偏参梯度 tensor([-0.0976])\n",
						"第 6820 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0282]])\n",
						"模型中偏参梯度 tensor([-0.0976])\n",
						"第 341 次epoch\n",
						"第 6821 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0282]])\n",
						"模型中偏参梯度 tensor([-0.0976])\n",
						"第 6822 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0282]])\n",
						"模型中偏参梯度 tensor([-0.0975])\n",
						"第 6823 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0281]])\n",
						"模型中偏参梯度 tensor([-0.0975])\n",
						"第 6824 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0281]])\n",
						"模型中偏参梯度 tensor([-0.0975])\n",
						"第 6825 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0281]])\n",
						"模型中偏参梯度 tensor([-0.0974])\n",
						"第 6826 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0281]])\n",
						"模型中偏参梯度 tensor([-0.0974])\n",
						"第 6827 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0280]])\n",
						"模型中偏参梯度 tensor([-0.0974])\n",
						"第 6828 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0280]])\n",
						"模型中偏参梯度 tensor([-0.0973])\n",
						"第 6829 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0280]])\n",
						"模型中偏参梯度 tensor([-0.0973])\n",
						"第 6830 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0280]])\n",
						"模型中偏参梯度 tensor([-0.0972])\n",
						"第 6831 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0279]])\n",
						"模型中偏参梯度 tensor([-0.0972])\n",
						"第 6832 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0279]])\n",
						"模型中偏参梯度 tensor([-0.0972])\n",
						"第 6833 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0279]])\n",
						"模型中偏参梯度 tensor([-0.0971])\n",
						"第 6834 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0279]])\n",
						"模型中偏参梯度 tensor([-0.0971])\n",
						"第 6835 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0278]])\n",
						"模型中偏参梯度 tensor([-0.0971])\n",
						"第 6836 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0278]])\n",
						"模型中偏参梯度 tensor([-0.0970])\n",
						"第 6837 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0278]])\n",
						"模型中偏参梯度 tensor([-0.0970])\n",
						"第 6838 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0278]])\n",
						"模型中偏参梯度 tensor([-0.0970])\n",
						"第 6839 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0277]])\n",
						"模型中偏参梯度 tensor([-0.0969])\n",
						"第 6840 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0277]])\n",
						"模型中偏参梯度 tensor([-0.0969])\n",
						"第 342 次epoch\n",
						"第 6841 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0277]])\n",
						"模型中偏参梯度 tensor([-0.0969])\n",
						"第 6842 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0277]])\n",
						"模型中偏参梯度 tensor([-0.0968])\n",
						"第 6843 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0277]])\n",
						"模型中偏参梯度 tensor([-0.0968])\n",
						"第 6844 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0276]])\n",
						"模型中偏参梯度 tensor([-0.0968])\n",
						"第 6845 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0276]])\n",
						"模型中偏参梯度 tensor([-0.0967])\n",
						"第 6846 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0277]])\n",
						"模型中偏参梯度 tensor([-0.0967])\n",
						"第 6847 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0277]])\n",
						"模型中偏参梯度 tensor([-0.0966])\n",
						"第 6848 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0277]])\n",
						"模型中偏参梯度 tensor([-0.0966])\n",
						"第 6849 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0276]])\n",
						"模型中偏参梯度 tensor([-0.0965])\n",
						"第 6850 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0276]])\n",
						"模型中偏参梯度 tensor([-0.0965])\n",
						"第 6851 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0276]])\n",
						"模型中偏参梯度 tensor([-0.0965])\n",
						"第 6852 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0277]])\n",
						"模型中偏参梯度 tensor([-0.0964])\n",
						"第 6853 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0277]])\n",
						"模型中偏参梯度 tensor([-0.0964])\n",
						"第 6854 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0276]])\n",
						"模型中偏参梯度 tensor([-0.0963])\n",
						"第 6855 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0276]])\n",
						"模型中偏参梯度 tensor([-0.0963])\n",
						"第 6856 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0276]])\n",
						"模型中偏参梯度 tensor([-0.0962])\n",
						"第 6857 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0277]])\n",
						"模型中偏参梯度 tensor([-0.0962])\n",
						"第 6858 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0277]])\n",
						"模型中偏参梯度 tensor([-0.0962])\n",
						"第 6859 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0277]])\n",
						"模型中偏参梯度 tensor([-0.0961])\n",
						"第 6860 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0276]])\n",
						"模型中偏参梯度 tensor([-0.0961])\n",
						"第 343 次epoch\n",
						"第 6861 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0276]])\n",
						"模型中偏参梯度 tensor([-0.0960])\n",
						"第 6862 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0276]])\n",
						"模型中偏参梯度 tensor([-0.0960])\n",
						"第 6863 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0277]])\n",
						"模型中偏参梯度 tensor([-0.0960])\n",
						"第 6864 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0277]])\n",
						"模型中偏参梯度 tensor([-0.0959])\n",
						"第 6865 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0276]])\n",
						"模型中偏参梯度 tensor([-0.0959])\n",
						"第 6866 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0276]])\n",
						"模型中偏参梯度 tensor([-0.0958])\n",
						"第 6867 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0276]])\n",
						"模型中偏参梯度 tensor([-0.0958])\n",
						"第 6868 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0276]])\n",
						"模型中偏参梯度 tensor([-0.0957])\n",
						"第 6869 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0276]])\n",
						"模型中偏参梯度 tensor([-0.0957])\n",
						"第 6870 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0276]])\n",
						"模型中偏参梯度 tensor([-0.0957])\n",
						"第 6871 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0276]])\n",
						"模型中偏参梯度 tensor([-0.0956])\n",
						"第 6872 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0276]])\n",
						"模型中偏参梯度 tensor([-0.0956])\n",
						"第 6873 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0276]])\n",
						"模型中偏参梯度 tensor([-0.0955])\n",
						"第 6874 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0276]])\n",
						"模型中偏参梯度 tensor([-0.0955])\n",
						"第 6875 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0276]])\n",
						"模型中偏参梯度 tensor([-0.0955])\n",
						"第 6876 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0276]])\n",
						"模型中偏参梯度 tensor([-0.0954])\n",
						"第 6877 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0277]])\n",
						"模型中偏参梯度 tensor([-0.0954])\n",
						"第 6878 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0277]])\n",
						"模型中偏参梯度 tensor([-0.0953])\n",
						"第 6879 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0277]])\n",
						"模型中偏参梯度 tensor([-0.0953])\n",
						"第 6880 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0277]])\n",
						"模型中偏参梯度 tensor([-0.0952])\n",
						"第 344 次epoch\n",
						"第 6881 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0277]])\n",
						"模型中偏参梯度 tensor([-0.0952])\n",
						"第 6882 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0277]])\n",
						"模型中偏参梯度 tensor([-0.0952])\n",
						"第 6883 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0276]])\n",
						"模型中偏参梯度 tensor([-0.0951])\n",
						"第 6884 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0276]])\n",
						"模型中偏参梯度 tensor([-0.0951])\n",
						"第 6885 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0276]])\n",
						"模型中偏参梯度 tensor([-0.0950])\n",
						"第 6886 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0276]])\n",
						"模型中偏参梯度 tensor([-0.0950])\n",
						"第 6887 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0276]])\n",
						"模型中偏参梯度 tensor([-0.0950])\n",
						"第 6888 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0276]])\n",
						"模型中偏参梯度 tensor([-0.0949])\n",
						"第 6889 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0276]])\n",
						"模型中偏参梯度 tensor([-0.0949])\n",
						"第 6890 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0276]])\n",
						"模型中偏参梯度 tensor([-0.0948])\n",
						"第 6891 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0276]])\n",
						"模型中偏参梯度 tensor([-0.0948])\n",
						"第 6892 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0276]])\n",
						"模型中偏参梯度 tensor([-0.0948])\n",
						"第 6893 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0276]])\n",
						"模型中偏参梯度 tensor([-0.0947])\n",
						"第 6894 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0276]])\n",
						"模型中偏参梯度 tensor([-0.0947])\n",
						"第 6895 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0276]])\n",
						"模型中偏参梯度 tensor([-0.0946])\n",
						"第 6896 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0276]])\n",
						"模型中偏参梯度 tensor([-0.0946])\n",
						"第 6897 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0276]])\n",
						"模型中偏参梯度 tensor([-0.0946])\n",
						"第 6898 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0276]])\n",
						"模型中偏参梯度 tensor([-0.0945])\n",
						"第 6899 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0276]])\n",
						"模型中偏参梯度 tensor([-0.0945])\n",
						"第 6900 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0276]])\n",
						"模型中偏参梯度 tensor([-0.0944])\n",
						"第 345 次epoch\n",
						"第 6901 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0276]])\n",
						"模型中偏参梯度 tensor([-0.0944])\n",
						"第 6902 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0276]])\n",
						"模型中偏参梯度 tensor([-0.0944])\n",
						"第 6903 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0276]])\n",
						"模型中偏参梯度 tensor([-0.0943])\n",
						"第 6904 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0276]])\n",
						"模型中偏参梯度 tensor([-0.0943])\n",
						"第 6905 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0276]])\n",
						"模型中偏参梯度 tensor([-0.0942])\n",
						"第 6906 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0276]])\n",
						"模型中偏参梯度 tensor([-0.0942])\n",
						"第 6907 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0276]])\n",
						"模型中偏参梯度 tensor([-0.0942])\n",
						"第 6908 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0276]])\n",
						"模型中偏参梯度 tensor([-0.0941])\n",
						"第 6909 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0276]])\n",
						"模型中偏参梯度 tensor([-0.0941])\n",
						"第 6910 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0275]])\n",
						"模型中偏参梯度 tensor([-0.0940])\n",
						"第 6911 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0275]])\n",
						"模型中偏参梯度 tensor([-0.0940])\n",
						"第 6912 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0275]])\n",
						"模型中偏参梯度 tensor([-0.0940])\n",
						"第 6913 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0275]])\n",
						"模型中偏参梯度 tensor([-0.0939])\n",
						"第 6914 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0275]])\n",
						"模型中偏参梯度 tensor([-0.0939])\n",
						"第 6915 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0275]])\n",
						"模型中偏参梯度 tensor([-0.0938])\n",
						"第 6916 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0275]])\n",
						"模型中偏参梯度 tensor([-0.0938])\n",
						"第 6917 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0275]])\n",
						"模型中偏参梯度 tensor([-0.0938])\n",
						"第 6918 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0275]])\n",
						"模型中偏参梯度 tensor([-0.0937])\n",
						"第 6919 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0275]])\n",
						"模型中偏参梯度 tensor([-0.0937])\n",
						"第 6920 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0275]])\n",
						"模型中偏参梯度 tensor([-0.0937])\n",
						"第 346 次epoch\n",
						"第 6921 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0275]])\n",
						"模型中偏参梯度 tensor([-0.0936])\n",
						"第 6922 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0275]])\n",
						"模型中偏参梯度 tensor([-0.0936])\n",
						"第 6923 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0274]])\n",
						"模型中偏参梯度 tensor([-0.0935])\n",
						"第 6924 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0274]])\n",
						"模型中偏参梯度 tensor([-0.0935])\n",
						"第 6925 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0274]])\n",
						"模型中偏参梯度 tensor([-0.0935])\n",
						"第 6926 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0274]])\n",
						"模型中偏参梯度 tensor([-0.0934])\n",
						"第 6927 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0274]])\n",
						"模型中偏参梯度 tensor([-0.0934])\n",
						"第 6928 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0274]])\n",
						"模型中偏参梯度 tensor([-0.0933])\n",
						"第 6929 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0274]])\n",
						"模型中偏参梯度 tensor([-0.0933])\n",
						"第 6930 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0274]])\n",
						"模型中偏参梯度 tensor([-0.0933])\n",
						"第 6931 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0274]])\n",
						"模型中偏参梯度 tensor([-0.0932])\n",
						"第 6932 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0274]])\n",
						"模型中偏参梯度 tensor([-0.0932])\n",
						"第 6933 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0274]])\n",
						"模型中偏参梯度 tensor([-0.0932])\n",
						"第 6934 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0273]])\n",
						"模型中偏参梯度 tensor([-0.0931])\n",
						"第 6935 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0273]])\n",
						"模型中偏参梯度 tensor([-0.0931])\n",
						"第 6936 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0273]])\n",
						"模型中偏参梯度 tensor([-0.0930])\n",
						"第 6937 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0273]])\n",
						"模型中偏参梯度 tensor([-0.0930])\n",
						"第 6938 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0273]])\n",
						"模型中偏参梯度 tensor([-0.0930])\n",
						"第 6939 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0273]])\n",
						"模型中偏参梯度 tensor([-0.0929])\n",
						"第 6940 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0273]])\n",
						"模型中偏参梯度 tensor([-0.0929])\n",
						"第 347 次epoch\n",
						"第 6941 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0273]])\n",
						"模型中偏参梯度 tensor([-0.0929])\n",
						"第 6942 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0272]])\n",
						"模型中偏参梯度 tensor([-0.0928])\n",
						"第 6943 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0272]])\n",
						"模型中偏参梯度 tensor([-0.0928])\n",
						"第 6944 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0272]])\n",
						"模型中偏参梯度 tensor([-0.0927])\n",
						"第 6945 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0272]])\n",
						"模型中偏参梯度 tensor([-0.0927])\n",
						"第 6946 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0272]])\n",
						"模型中偏参梯度 tensor([-0.0927])\n",
						"第 6947 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0272]])\n",
						"模型中偏参梯度 tensor([-0.0926])\n",
						"第 6948 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0272]])\n",
						"模型中偏参梯度 tensor([-0.0926])\n",
						"第 6949 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0271]])\n",
						"模型中偏参梯度 tensor([-0.0926])\n",
						"第 6950 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0271]])\n",
						"模型中偏参梯度 tensor([-0.0925])\n",
						"第 6951 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0271]])\n",
						"模型中偏参梯度 tensor([-0.0925])\n",
						"第 6952 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0271]])\n",
						"模型中偏参梯度 tensor([-0.0925])\n",
						"第 6953 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0271]])\n",
						"模型中偏参梯度 tensor([-0.0924])\n",
						"第 6954 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0271]])\n",
						"模型中偏参梯度 tensor([-0.0924])\n",
						"第 6955 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0271]])\n",
						"模型中偏参梯度 tensor([-0.0924])\n",
						"第 6956 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0270]])\n",
						"模型中偏参梯度 tensor([-0.0923])\n",
						"第 6957 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0270]])\n",
						"模型中偏参梯度 tensor([-0.0923])\n",
						"第 6958 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0270]])\n",
						"模型中偏参梯度 tensor([-0.0922])\n",
						"第 6959 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0270]])\n",
						"模型中偏参梯度 tensor([-0.0922])\n",
						"第 6960 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0270]])\n",
						"模型中偏参梯度 tensor([-0.0922])\n",
						"第 348 次epoch\n",
						"第 6961 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0270]])\n",
						"模型中偏参梯度 tensor([-0.0921])\n",
						"第 6962 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0270]])\n",
						"模型中偏参梯度 tensor([-0.0921])\n",
						"第 6963 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0269]])\n",
						"模型中偏参梯度 tensor([-0.0921])\n",
						"第 6964 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0269]])\n",
						"模型中偏参梯度 tensor([-0.0920])\n",
						"第 6965 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0269]])\n",
						"模型中偏参梯度 tensor([-0.0920])\n",
						"第 6966 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0269]])\n",
						"模型中偏参梯度 tensor([-0.0920])\n",
						"第 6967 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0269]])\n",
						"模型中偏参梯度 tensor([-0.0919])\n",
						"第 6968 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0269]])\n",
						"模型中偏参梯度 tensor([-0.0919])\n",
						"第 6969 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0268]])\n",
						"模型中偏参梯度 tensor([-0.0919])\n",
						"第 6970 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0268]])\n",
						"模型中偏参梯度 tensor([-0.0918])\n",
						"第 6971 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0268]])\n",
						"模型中偏参梯度 tensor([-0.0918])\n",
						"第 6972 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0268]])\n",
						"模型中偏参梯度 tensor([-0.0918])\n",
						"第 6973 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0268]])\n",
						"模型中偏参梯度 tensor([-0.0917])\n",
						"第 6974 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0267]])\n",
						"模型中偏参梯度 tensor([-0.0917])\n",
						"第 6975 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0267]])\n",
						"模型中偏参梯度 tensor([-0.0916])\n",
						"第 6976 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0267]])\n",
						"模型中偏参梯度 tensor([-0.0916])\n",
						"第 6977 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0267]])\n",
						"模型中偏参梯度 tensor([-0.0916])\n",
						"第 6978 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0266]])\n",
						"模型中偏参梯度 tensor([-0.0915])\n",
						"第 6979 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0266]])\n",
						"模型中偏参梯度 tensor([-0.0915])\n",
						"第 6980 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0266]])\n",
						"模型中偏参梯度 tensor([-0.0915])\n",
						"第 349 次epoch\n",
						"第 6981 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0266]])\n",
						"模型中偏参梯度 tensor([-0.0914])\n",
						"第 6982 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0266]])\n",
						"模型中偏参梯度 tensor([-0.0914])\n",
						"第 6983 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0266]])\n",
						"模型中偏参梯度 tensor([-0.0914])\n",
						"第 6984 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0265]])\n",
						"模型中偏参梯度 tensor([-0.0913])\n",
						"第 6985 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0265]])\n",
						"模型中偏参梯度 tensor([-0.0913])\n",
						"第 6986 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0265]])\n",
						"模型中偏参梯度 tensor([-0.0913])\n",
						"第 6987 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0265]])\n",
						"模型中偏参梯度 tensor([-0.0912])\n",
						"第 6988 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0265]])\n",
						"模型中偏参梯度 tensor([-0.0912])\n",
						"第 6989 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0264]])\n",
						"模型中偏参梯度 tensor([-0.0912])\n",
						"第 6990 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0264]])\n",
						"模型中偏参梯度 tensor([-0.0911])\n",
						"第 6991 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0264]])\n",
						"模型中偏参梯度 tensor([-0.0911])\n",
						"第 6992 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0264]])\n",
						"模型中偏参梯度 tensor([-0.0911])\n",
						"第 6993 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0264]])\n",
						"模型中偏参梯度 tensor([-0.0910])\n",
						"第 6994 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0263]])\n",
						"模型中偏参梯度 tensor([-0.0910])\n",
						"第 6995 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0263]])\n",
						"模型中偏参梯度 tensor([-0.0910])\n",
						"第 6996 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0263]])\n",
						"模型中偏参梯度 tensor([-0.0909])\n",
						"第 6997 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0263]])\n",
						"模型中偏参梯度 tensor([-0.0909])\n",
						"第 6998 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0262]])\n",
						"模型中偏参梯度 tensor([-0.0909])\n",
						"第 6999 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0262]])\n",
						"模型中偏参梯度 tensor([-0.0908])\n",
						"第 7000 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0262]])\n",
						"模型中偏参梯度 tensor([-0.0908])\n",
						"第 350 次epoch\n",
						"第 7001 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0261]])\n",
						"模型中偏参梯度 tensor([-0.0908])\n",
						"第 7002 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0261]])\n",
						"模型中偏参梯度 tensor([-0.0907])\n",
						"第 7003 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0261]])\n",
						"模型中偏参梯度 tensor([-0.0907])\n",
						"第 7004 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0261]])\n",
						"模型中偏参梯度 tensor([-0.0907])\n",
						"第 7005 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0261]])\n",
						"模型中偏参梯度 tensor([-0.0906])\n",
						"第 7006 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0260]])\n",
						"模型中偏参梯度 tensor([-0.0906])\n",
						"第 7007 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0260]])\n",
						"模型中偏参梯度 tensor([-0.0906])\n",
						"第 7008 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0260]])\n",
						"模型中偏参梯度 tensor([-0.0906])\n",
						"第 7009 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0260]])\n",
						"模型中偏参梯度 tensor([-0.0905])\n",
						"第 7010 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0259]])\n",
						"模型中偏参梯度 tensor([-0.0905])\n",
						"第 7011 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0259]])\n",
						"模型中偏参梯度 tensor([-0.0905])\n",
						"第 7012 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0259]])\n",
						"模型中偏参梯度 tensor([-0.0904])\n",
						"第 7013 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0259]])\n",
						"模型中偏参梯度 tensor([-0.0904])\n",
						"第 7014 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0258]])\n",
						"模型中偏参梯度 tensor([-0.0904])\n",
						"第 7015 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0258]])\n",
						"模型中偏参梯度 tensor([-0.0903])\n",
						"第 7016 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0258]])\n",
						"模型中偏参梯度 tensor([-0.0903])\n",
						"第 7017 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0257]])\n",
						"模型中偏参梯度 tensor([-0.0903])\n",
						"第 7018 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0258]])\n",
						"模型中偏参梯度 tensor([-0.0902])\n",
						"第 7019 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0257]])\n",
						"模型中偏参梯度 tensor([-0.0902])\n",
						"第 7020 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0257]])\n",
						"模型中偏参梯度 tensor([-0.0901])\n",
						"第 351 次epoch\n",
						"第 7021 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0257]])\n",
						"模型中偏参梯度 tensor([-0.0901])\n",
						"第 7022 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0257]])\n",
						"模型中偏参梯度 tensor([-0.0901])\n",
						"第 7023 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0257]])\n",
						"模型中偏参梯度 tensor([-0.0900])\n",
						"第 7024 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0257]])\n",
						"模型中偏参梯度 tensor([-0.0900])\n",
						"第 7025 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0258]])\n",
						"模型中偏参梯度 tensor([-0.0899])\n",
						"第 7026 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0257]])\n",
						"模型中偏参梯度 tensor([-0.0899])\n",
						"第 7027 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0257]])\n",
						"模型中偏参梯度 tensor([-0.0899])\n",
						"第 7028 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0257]])\n",
						"模型中偏参梯度 tensor([-0.0898])\n",
						"第 7029 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0257]])\n",
						"模型中偏参梯度 tensor([-0.0898])\n",
						"第 7030 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0258]])\n",
						"模型中偏参梯度 tensor([-0.0898])\n",
						"第 7031 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0257]])\n",
						"模型中偏参梯度 tensor([-0.0897])\n",
						"第 7032 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0257]])\n",
						"模型中偏参梯度 tensor([-0.0897])\n",
						"第 7033 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0257]])\n",
						"模型中偏参梯度 tensor([-0.0896])\n",
						"第 7034 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0257]])\n",
						"模型中偏参梯度 tensor([-0.0896])\n",
						"第 7035 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0257]])\n",
						"模型中偏参梯度 tensor([-0.0896])\n",
						"第 7036 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0257]])\n",
						"模型中偏参梯度 tensor([-0.0895])\n",
						"第 7037 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0257]])\n",
						"模型中偏参梯度 tensor([-0.0895])\n",
						"第 7038 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0257]])\n",
						"模型中偏参梯度 tensor([-0.0894])\n",
						"第 7039 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0257]])\n",
						"模型中偏参梯度 tensor([-0.0894])\n",
						"第 7040 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0258]])\n",
						"模型中偏参梯度 tensor([-0.0894])\n",
						"第 352 次epoch\n",
						"第 7041 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0257]])\n",
						"模型中偏参梯度 tensor([-0.0893])\n",
						"第 7042 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0257]])\n",
						"模型中偏参梯度 tensor([-0.0893])\n",
						"第 7043 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0257]])\n",
						"模型中偏参梯度 tensor([-0.0892])\n",
						"第 7044 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0257]])\n",
						"模型中偏参梯度 tensor([-0.0892])\n",
						"第 7045 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0258]])\n",
						"模型中偏参梯度 tensor([-0.0892])\n",
						"第 7046 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0257]])\n",
						"模型中偏参梯度 tensor([-0.0891])\n",
						"第 7047 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0257]])\n",
						"模型中偏参梯度 tensor([-0.0891])\n",
						"第 7048 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0257]])\n",
						"模型中偏参梯度 tensor([-0.0891])\n",
						"第 7049 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0257]])\n",
						"模型中偏参梯度 tensor([-0.0890])\n",
						"第 7050 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0257]])\n",
						"模型中偏参梯度 tensor([-0.0890])\n",
						"第 7051 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0257]])\n",
						"模型中偏参梯度 tensor([-0.0889])\n",
						"第 7052 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0257]])\n",
						"模型中偏参梯度 tensor([-0.0889])\n",
						"第 7053 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0257]])\n",
						"模型中偏参梯度 tensor([-0.0889])\n",
						"第 7054 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0257]])\n",
						"模型中偏参梯度 tensor([-0.0888])\n",
						"第 7055 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0257]])\n",
						"模型中偏参梯度 tensor([-0.0888])\n",
						"第 7056 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0257]])\n",
						"模型中偏参梯度 tensor([-0.0887])\n",
						"第 7057 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0257]])\n",
						"模型中偏参梯度 tensor([-0.0887])\n",
						"第 7058 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0257]])\n",
						"模型中偏参梯度 tensor([-0.0887])\n",
						"第 7059 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0257]])\n",
						"模型中偏参梯度 tensor([-0.0886])\n",
						"第 7060 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0257]])\n",
						"模型中偏参梯度 tensor([-0.0886])\n",
						"第 353 次epoch\n",
						"第 7061 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0258]])\n",
						"模型中偏参梯度 tensor([-0.0886])\n",
						"第 7062 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0257]])\n",
						"模型中偏参梯度 tensor([-0.0885])\n",
						"第 7063 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0257]])\n",
						"模型中偏参梯度 tensor([-0.0885])\n",
						"第 7064 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0257]])\n",
						"模型中偏参梯度 tensor([-0.0884])\n",
						"第 7065 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0257]])\n",
						"模型中偏参梯度 tensor([-0.0884])\n",
						"第 7066 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0257]])\n",
						"模型中偏参梯度 tensor([-0.0884])\n",
						"第 7067 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0257]])\n",
						"模型中偏参梯度 tensor([-0.0883])\n",
						"第 7068 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0257]])\n",
						"模型中偏参梯度 tensor([-0.0883])\n",
						"第 7069 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0257]])\n",
						"模型中偏参梯度 tensor([-0.0882])\n",
						"第 7070 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0257]])\n",
						"模型中偏参梯度 tensor([-0.0882])\n",
						"第 7071 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0257]])\n",
						"模型中偏参梯度 tensor([-0.0882])\n",
						"第 7072 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0257]])\n",
						"模型中偏参梯度 tensor([-0.0881])\n",
						"第 7073 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0257]])\n",
						"模型中偏参梯度 tensor([-0.0881])\n",
						"第 7074 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0257]])\n",
						"模型中偏参梯度 tensor([-0.0881])\n",
						"第 7075 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0257]])\n",
						"模型中偏参梯度 tensor([-0.0880])\n",
						"第 7076 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0257]])\n",
						"模型中偏参梯度 tensor([-0.0880])\n",
						"第 7077 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0257]])\n",
						"模型中偏参梯度 tensor([-0.0879])\n",
						"第 7078 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0257]])\n",
						"模型中偏参梯度 tensor([-0.0879])\n",
						"第 7079 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0257]])\n",
						"模型中偏参梯度 tensor([-0.0879])\n",
						"第 7080 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0257]])\n",
						"模型中偏参梯度 tensor([-0.0878])\n",
						"第 354 次epoch\n",
						"第 7081 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0257]])\n",
						"模型中偏参梯度 tensor([-0.0878])\n",
						"第 7082 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0257]])\n",
						"模型中偏参梯度 tensor([-0.0878])\n",
						"第 7083 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0257]])\n",
						"模型中偏参梯度 tensor([-0.0877])\n",
						"第 7084 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0257]])\n",
						"模型中偏参梯度 tensor([-0.0877])\n",
						"第 7085 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0257]])\n",
						"模型中偏参梯度 tensor([-0.0877])\n",
						"第 7086 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0257]])\n",
						"模型中偏参梯度 tensor([-0.0876])\n",
						"第 7087 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0257]])\n",
						"模型中偏参梯度 tensor([-0.0876])\n",
						"第 7088 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0257]])\n",
						"模型中偏参梯度 tensor([-0.0875])\n",
						"第 7089 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0257]])\n",
						"模型中偏参梯度 tensor([-0.0875])\n",
						"第 7090 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0257]])\n",
						"模型中偏参梯度 tensor([-0.0875])\n",
						"第 7091 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0257]])\n",
						"模型中偏参梯度 tensor([-0.0874])\n",
						"第 7092 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0257]])\n",
						"模型中偏参梯度 tensor([-0.0874])\n",
						"第 7093 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0257]])\n",
						"模型中偏参梯度 tensor([-0.0874])\n",
						"第 7094 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0257]])\n",
						"模型中偏参梯度 tensor([-0.0873])\n",
						"第 7095 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0257]])\n",
						"模型中偏参梯度 tensor([-0.0873])\n",
						"第 7096 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0256]])\n",
						"模型中偏参梯度 tensor([-0.0872])\n",
						"第 7097 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0256]])\n",
						"模型中偏参梯度 tensor([-0.0872])\n",
						"第 7098 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0256]])\n",
						"模型中偏参梯度 tensor([-0.0872])\n",
						"第 7099 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0256]])\n",
						"模型中偏参梯度 tensor([-0.0871])\n",
						"第 7100 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0256]])\n",
						"模型中偏参梯度 tensor([-0.0871])\n",
						"第 355 次epoch\n",
						"第 7101 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0256]])\n",
						"模型中偏参梯度 tensor([-0.0871])\n",
						"第 7102 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0256]])\n",
						"模型中偏参梯度 tensor([-0.0870])\n",
						"第 7103 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0256]])\n",
						"模型中偏参梯度 tensor([-0.0870])\n",
						"第 7104 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0256]])\n",
						"模型中偏参梯度 tensor([-0.0870])\n",
						"第 7105 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0256]])\n",
						"模型中偏参梯度 tensor([-0.0869])\n",
						"第 7106 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0256]])\n",
						"模型中偏参梯度 tensor([-0.0869])\n",
						"第 7107 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0256]])\n",
						"模型中偏参梯度 tensor([-0.0869])\n",
						"第 7108 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0255]])\n",
						"模型中偏参梯度 tensor([-0.0868])\n",
						"第 7109 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0255]])\n",
						"模型中偏参梯度 tensor([-0.0868])\n",
						"第 7110 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0255]])\n",
						"模型中偏参梯度 tensor([-0.0867])\n",
						"第 7111 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0255]])\n",
						"模型中偏参梯度 tensor([-0.0867])\n",
						"第 7112 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0255]])\n",
						"模型中偏参梯度 tensor([-0.0867])\n",
						"第 7113 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0255]])\n",
						"模型中偏参梯度 tensor([-0.0866])\n",
						"第 7114 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0255]])\n",
						"模型中偏参梯度 tensor([-0.0866])\n",
						"第 7115 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0255]])\n",
						"模型中偏参梯度 tensor([-0.0866])\n",
						"第 7116 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0255]])\n",
						"模型中偏参梯度 tensor([-0.0865])\n",
						"第 7117 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0255]])\n",
						"模型中偏参梯度 tensor([-0.0865])\n",
						"第 7118 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0255]])\n",
						"模型中偏参梯度 tensor([-0.0865])\n",
						"第 7119 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0254]])\n",
						"模型中偏参梯度 tensor([-0.0864])\n",
						"第 7120 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0254]])\n",
						"模型中偏参梯度 tensor([-0.0864])\n",
						"第 356 次epoch\n",
						"第 7121 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0254]])\n",
						"模型中偏参梯度 tensor([-0.0864])\n",
						"第 7122 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0254]])\n",
						"模型中偏参梯度 tensor([-0.0863])\n",
						"第 7123 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0254]])\n",
						"模型中偏参梯度 tensor([-0.0863])\n",
						"第 7124 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0254]])\n",
						"模型中偏参梯度 tensor([-0.0863])\n",
						"第 7125 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0254]])\n",
						"模型中偏参梯度 tensor([-0.0862])\n",
						"第 7126 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0254]])\n",
						"模型中偏参梯度 tensor([-0.0862])\n",
						"第 7127 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0253]])\n",
						"模型中偏参梯度 tensor([-0.0862])\n",
						"第 7128 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0253]])\n",
						"模型中偏参梯度 tensor([-0.0861])\n",
						"第 7129 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0253]])\n",
						"模型中偏参梯度 tensor([-0.0861])\n",
						"第 7130 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0253]])\n",
						"模型中偏参梯度 tensor([-0.0861])\n",
						"第 7131 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0253]])\n",
						"模型中偏参梯度 tensor([-0.0860])\n",
						"第 7132 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0253]])\n",
						"模型中偏参梯度 tensor([-0.0860])\n",
						"第 7133 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0253]])\n",
						"模型中偏参梯度 tensor([-0.0860])\n",
						"第 7134 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0253]])\n",
						"模型中偏参梯度 tensor([-0.0859])\n",
						"第 7135 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0252]])\n",
						"模型中偏参梯度 tensor([-0.0859])\n",
						"第 7136 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0252]])\n",
						"模型中偏参梯度 tensor([-0.0859])\n",
						"第 7137 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0252]])\n",
						"模型中偏参梯度 tensor([-0.0858])\n",
						"第 7138 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0252]])\n",
						"模型中偏参梯度 tensor([-0.0858])\n",
						"第 7139 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0252]])\n",
						"模型中偏参梯度 tensor([-0.0858])\n",
						"第 7140 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0252]])\n",
						"模型中偏参梯度 tensor([-0.0857])\n",
						"第 357 次epoch\n",
						"第 7141 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0252]])\n",
						"模型中偏参梯度 tensor([-0.0857])\n",
						"第 7142 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0251]])\n",
						"模型中偏参梯度 tensor([-0.0857])\n",
						"第 7143 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0251]])\n",
						"模型中偏参梯度 tensor([-0.0856])\n",
						"第 7144 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0251]])\n",
						"模型中偏参梯度 tensor([-0.0856])\n",
						"第 7145 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0251]])\n",
						"模型中偏参梯度 tensor([-0.0856])\n",
						"第 7146 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0251]])\n",
						"模型中偏参梯度 tensor([-0.0855])\n",
						"第 7147 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0251]])\n",
						"模型中偏参梯度 tensor([-0.0855])\n",
						"第 7148 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0251]])\n",
						"模型中偏参梯度 tensor([-0.0855])\n",
						"第 7149 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0251]])\n",
						"模型中偏参梯度 tensor([-0.0854])\n",
						"第 7150 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0250]])\n",
						"模型中偏参梯度 tensor([-0.0854])\n",
						"第 7151 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0250]])\n",
						"模型中偏参梯度 tensor([-0.0854])\n",
						"第 7152 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0250]])\n",
						"模型中偏参梯度 tensor([-0.0853])\n",
						"第 7153 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0250]])\n",
						"模型中偏参梯度 tensor([-0.0853])\n",
						"第 7154 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0250]])\n",
						"模型中偏参梯度 tensor([-0.0853])\n",
						"第 7155 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0249]])\n",
						"模型中偏参梯度 tensor([-0.0852])\n",
						"第 7156 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0249]])\n",
						"模型中偏参梯度 tensor([-0.0852])\n",
						"第 7157 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0249]])\n",
						"模型中偏参梯度 tensor([-0.0852])\n",
						"第 7158 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0249]])\n",
						"模型中偏参梯度 tensor([-0.0851])\n",
						"第 7159 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0249]])\n",
						"模型中偏参梯度 tensor([-0.0851])\n",
						"第 7160 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0249]])\n",
						"模型中偏参梯度 tensor([-0.0851])\n",
						"第 358 次epoch\n",
						"第 7161 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0248]])\n",
						"模型中偏参梯度 tensor([-0.0850])\n",
						"第 7162 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0248]])\n",
						"模型中偏参梯度 tensor([-0.0850])\n",
						"第 7163 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0248]])\n",
						"模型中偏参梯度 tensor([-0.0850])\n",
						"第 7164 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0248]])\n",
						"模型中偏参梯度 tensor([-0.0849])\n",
						"第 7165 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0248]])\n",
						"模型中偏参梯度 tensor([-0.0849])\n",
						"第 7166 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0247]])\n",
						"模型中偏参梯度 tensor([-0.0849])\n",
						"第 7167 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0247]])\n",
						"模型中偏参梯度 tensor([-0.0848])\n",
						"第 7168 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0247]])\n",
						"模型中偏参梯度 tensor([-0.0848])\n",
						"第 7169 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0247]])\n",
						"模型中偏参梯度 tensor([-0.0848])\n",
						"第 7170 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0247]])\n",
						"模型中偏参梯度 tensor([-0.0848])\n",
						"第 7171 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0246]])\n",
						"模型中偏参梯度 tensor([-0.0847])\n",
						"第 7172 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0246]])\n",
						"模型中偏参梯度 tensor([-0.0847])\n",
						"第 7173 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0246]])\n",
						"模型中偏参梯度 tensor([-0.0847])\n",
						"第 7174 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0246]])\n",
						"模型中偏参梯度 tensor([-0.0846])\n",
						"第 7175 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0246]])\n",
						"模型中偏参梯度 tensor([-0.0846])\n",
						"第 7176 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0245]])\n",
						"模型中偏参梯度 tensor([-0.0846])\n",
						"第 7177 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0245]])\n",
						"模型中偏参梯度 tensor([-0.0845])\n",
						"第 7178 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0245]])\n",
						"模型中偏参梯度 tensor([-0.0845])\n",
						"第 7179 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0245]])\n",
						"模型中偏参梯度 tensor([-0.0845])\n",
						"第 7180 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0245]])\n",
						"模型中偏参梯度 tensor([-0.0844])\n",
						"第 359 次epoch\n",
						"第 7181 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0244]])\n",
						"模型中偏参梯度 tensor([-0.0844])\n",
						"第 7182 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0244]])\n",
						"模型中偏参梯度 tensor([-0.0844])\n",
						"第 7183 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0244]])\n",
						"模型中偏参梯度 tensor([-0.0843])\n",
						"第 7184 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0244]])\n",
						"模型中偏参梯度 tensor([-0.0843])\n",
						"第 7185 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0244]])\n",
						"模型中偏参梯度 tensor([-0.0843])\n",
						"第 7186 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0243]])\n",
						"模型中偏参梯度 tensor([-0.0843])\n",
						"第 7187 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0243]])\n",
						"模型中偏参梯度 tensor([-0.0842])\n",
						"第 7188 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0243]])\n",
						"模型中偏参梯度 tensor([-0.0842])\n",
						"第 7189 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0243]])\n",
						"模型中偏参梯度 tensor([-0.0842])\n",
						"第 7190 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0242]])\n",
						"模型中偏参梯度 tensor([-0.0841])\n",
						"第 7191 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0242]])\n",
						"模型中偏参梯度 tensor([-0.0841])\n",
						"第 7192 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0242]])\n",
						"模型中偏参梯度 tensor([-0.0841])\n",
						"第 7193 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0242]])\n",
						"模型中偏参梯度 tensor([-0.0840])\n",
						"第 7194 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0241]])\n",
						"模型中偏参梯度 tensor([-0.0840])\n",
						"第 7195 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0241]])\n",
						"模型中偏参梯度 tensor([-0.0840])\n",
						"第 7196 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0241]])\n",
						"模型中偏参梯度 tensor([-0.0840])\n",
						"第 7197 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0241]])\n",
						"模型中偏参梯度 tensor([-0.0839])\n",
						"第 7198 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0240]])\n",
						"模型中偏参梯度 tensor([-0.0839])\n",
						"第 7199 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0240]])\n",
						"模型中偏参梯度 tensor([-0.0839])\n",
						"第 7200 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0240]])\n",
						"模型中偏参梯度 tensor([-0.0838])\n",
						"第 360 次epoch\n",
						"第 7201 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0240]])\n",
						"模型中偏参梯度 tensor([-0.0838])\n",
						"第 7202 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0239]])\n",
						"模型中偏参梯度 tensor([-0.0838])\n",
						"第 7203 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0239]])\n",
						"模型中偏参梯度 tensor([-0.0838])\n",
						"第 7204 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0239]])\n",
						"模型中偏参梯度 tensor([-0.0837])\n",
						"第 7205 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0239]])\n",
						"模型中偏参梯度 tensor([-0.0837])\n",
						"第 7206 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0238]])\n",
						"模型中偏参梯度 tensor([-0.0837])\n",
						"第 7207 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0238]])\n",
						"模型中偏参梯度 tensor([-0.0836])\n",
						"第 7208 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0238]])\n",
						"模型中偏参梯度 tensor([-0.0836])\n",
						"第 7209 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0238]])\n",
						"模型中偏参梯度 tensor([-0.0836])\n",
						"第 7210 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0238]])\n",
						"模型中偏参梯度 tensor([-0.0835])\n",
						"第 7211 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0238]])\n",
						"模型中偏参梯度 tensor([-0.0835])\n",
						"第 7212 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0238]])\n",
						"模型中偏参梯度 tensor([-0.0834])\n",
						"第 7213 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0238]])\n",
						"模型中偏参梯度 tensor([-0.0834])\n",
						"第 7214 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0238]])\n",
						"模型中偏参梯度 tensor([-0.0834])\n",
						"第 7215 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0238]])\n",
						"模型中偏参梯度 tensor([-0.0833])\n",
						"第 7216 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0238]])\n",
						"模型中偏参梯度 tensor([-0.0833])\n",
						"第 7217 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0238]])\n",
						"模型中偏参梯度 tensor([-0.0833])\n",
						"第 7218 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0238]])\n",
						"模型中偏参梯度 tensor([-0.0832])\n",
						"第 7219 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0238]])\n",
						"模型中偏参梯度 tensor([-0.0832])\n",
						"第 7220 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0238]])\n",
						"模型中偏参梯度 tensor([-0.0832])\n",
						"第 361 次epoch\n",
						"第 7221 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0238]])\n",
						"模型中偏参梯度 tensor([-0.0831])\n",
						"第 7222 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0238]])\n",
						"模型中偏参梯度 tensor([-0.0831])\n",
						"第 7223 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0238]])\n",
						"模型中偏参梯度 tensor([-0.0831])\n",
						"第 7224 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0238]])\n",
						"模型中偏参梯度 tensor([-0.0830])\n",
						"第 7225 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0238]])\n",
						"模型中偏参梯度 tensor([-0.0830])\n",
						"第 7226 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0238]])\n",
						"模型中偏参梯度 tensor([-0.0829])\n",
						"第 7227 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0238]])\n",
						"模型中偏参梯度 tensor([-0.0829])\n",
						"第 7228 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0238]])\n",
						"模型中偏参梯度 tensor([-0.0829])\n",
						"第 7229 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0238]])\n",
						"模型中偏参梯度 tensor([-0.0828])\n",
						"第 7230 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0238]])\n",
						"模型中偏参梯度 tensor([-0.0828])\n",
						"第 7231 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0238]])\n",
						"模型中偏参梯度 tensor([-0.0828])\n",
						"第 7232 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0238]])\n",
						"模型中偏参梯度 tensor([-0.0827])\n",
						"第 7233 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0238]])\n",
						"模型中偏参梯度 tensor([-0.0827])\n",
						"第 7234 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0238]])\n",
						"模型中偏参梯度 tensor([-0.0827])\n",
						"第 7235 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0238]])\n",
						"模型中偏参梯度 tensor([-0.0826])\n",
						"第 7236 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0238]])\n",
						"模型中偏参梯度 tensor([-0.0826])\n",
						"第 7237 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0238]])\n",
						"模型中偏参梯度 tensor([-0.0825])\n",
						"第 7238 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0238]])\n",
						"模型中偏参梯度 tensor([-0.0825])\n",
						"第 7239 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0238]])\n",
						"模型中偏参梯度 tensor([-0.0825])\n",
						"第 7240 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0238]])\n",
						"模型中偏参梯度 tensor([-0.0824])\n",
						"第 362 次epoch\n",
						"第 7241 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0238]])\n",
						"模型中偏参梯度 tensor([-0.0824])\n",
						"第 7242 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0238]])\n",
						"模型中偏参梯度 tensor([-0.0824])\n",
						"第 7243 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0238]])\n",
						"模型中偏参梯度 tensor([-0.0823])\n",
						"第 7244 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0238]])\n",
						"模型中偏参梯度 tensor([-0.0823])\n",
						"第 7245 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0238]])\n",
						"模型中偏参梯度 tensor([-0.0823])\n",
						"第 7246 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0238]])\n",
						"模型中偏参梯度 tensor([-0.0822])\n",
						"第 7247 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0238]])\n",
						"模型中偏参梯度 tensor([-0.0822])\n",
						"第 7248 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0238]])\n",
						"模型中偏参梯度 tensor([-0.0822])\n",
						"第 7249 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0238]])\n",
						"模型中偏参梯度 tensor([-0.0821])\n",
						"第 7250 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0238]])\n",
						"模型中偏参梯度 tensor([-0.0821])\n",
						"第 7251 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0238]])\n",
						"模型中偏参梯度 tensor([-0.0820])\n",
						"第 7252 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0238]])\n",
						"模型中偏参梯度 tensor([-0.0820])\n",
						"第 7253 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0238]])\n",
						"模型中偏参梯度 tensor([-0.0820])\n",
						"第 7254 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0238]])\n",
						"模型中偏参梯度 tensor([-0.0819])\n",
						"第 7255 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0238]])\n",
						"模型中偏参梯度 tensor([-0.0819])\n",
						"第 7256 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0238]])\n",
						"模型中偏参梯度 tensor([-0.0819])\n",
						"第 7257 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0238]])\n",
						"模型中偏参梯度 tensor([-0.0818])\n",
						"第 7258 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0238]])\n",
						"模型中偏参梯度 tensor([-0.0818])\n",
						"第 7259 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0238]])\n",
						"模型中偏参梯度 tensor([-0.0818])\n",
						"第 7260 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0238]])\n",
						"模型中偏参梯度 tensor([-0.0817])\n",
						"第 363 次epoch\n",
						"第 7261 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0238]])\n",
						"模型中偏参梯度 tensor([-0.0817])\n",
						"第 7262 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0238]])\n",
						"模型中偏参梯度 tensor([-0.0817])\n",
						"第 7263 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0238]])\n",
						"模型中偏参梯度 tensor([-0.0816])\n",
						"第 7264 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0238]])\n",
						"模型中偏参梯度 tensor([-0.0816])\n",
						"第 7265 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0238]])\n",
						"模型中偏参梯度 tensor([-0.0815])\n",
						"第 7266 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0238]])\n",
						"模型中偏参梯度 tensor([-0.0815])\n",
						"第 7267 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0238]])\n",
						"模型中偏参梯度 tensor([-0.0815])\n",
						"第 7268 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0238]])\n",
						"模型中偏参梯度 tensor([-0.0814])\n",
						"第 7269 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0238]])\n",
						"模型中偏参梯度 tensor([-0.0814])\n",
						"第 7270 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0238]])\n",
						"模型中偏参梯度 tensor([-0.0814])\n",
						"第 7271 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0238]])\n",
						"模型中偏参梯度 tensor([-0.0813])\n",
						"第 7272 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0238]])\n",
						"模型中偏参梯度 tensor([-0.0813])\n",
						"第 7273 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0238]])\n",
						"模型中偏参梯度 tensor([-0.0813])\n",
						"第 7274 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0238]])\n",
						"模型中偏参梯度 tensor([-0.0812])\n",
						"第 7275 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0238]])\n",
						"模型中偏参梯度 tensor([-0.0812])\n",
						"第 7276 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0238]])\n",
						"模型中偏参梯度 tensor([-0.0812])\n",
						"第 7277 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0238]])\n",
						"模型中偏参梯度 tensor([-0.0811])\n",
						"第 7278 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0238]])\n",
						"模型中偏参梯度 tensor([-0.0811])\n",
						"第 7279 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0238]])\n",
						"模型中偏参梯度 tensor([-0.0811])\n",
						"第 7280 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0238]])\n",
						"模型中偏参梯度 tensor([-0.0810])\n",
						"第 364 次epoch\n",
						"第 7281 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0238]])\n",
						"模型中偏参梯度 tensor([-0.0810])\n",
						"第 7282 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0238]])\n",
						"模型中偏参梯度 tensor([-0.0810])\n",
						"第 7283 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0238]])\n",
						"模型中偏参梯度 tensor([-0.0809])\n",
						"第 7284 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0238]])\n",
						"模型中偏参梯度 tensor([-0.0809])\n",
						"第 7285 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0238]])\n",
						"模型中偏参梯度 tensor([-0.0809])\n",
						"第 7286 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0238]])\n",
						"模型中偏参梯度 tensor([-0.0808])\n",
						"第 7287 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0238]])\n",
						"模型中偏参梯度 tensor([-0.0808])\n",
						"第 7288 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0238]])\n",
						"模型中偏参梯度 tensor([-0.0808])\n",
						"第 7289 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0238]])\n",
						"模型中偏参梯度 tensor([-0.0807])\n",
						"第 7290 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0238]])\n",
						"模型中偏参梯度 tensor([-0.0807])\n",
						"第 7291 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0238]])\n",
						"模型中偏参梯度 tensor([-0.0806])\n",
						"第 7292 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0238]])\n",
						"模型中偏参梯度 tensor([-0.0806])\n",
						"第 7293 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0238]])\n",
						"模型中偏参梯度 tensor([-0.0806])\n",
						"第 7294 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0238]])\n",
						"模型中偏参梯度 tensor([-0.0805])\n",
						"第 7295 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0238]])\n",
						"模型中偏参梯度 tensor([-0.0805])\n",
						"第 7296 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0237]])\n",
						"模型中偏参梯度 tensor([-0.0805])\n",
						"第 7297 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0237]])\n",
						"模型中偏参梯度 tensor([-0.0804])\n",
						"第 7298 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0237]])\n",
						"模型中偏参梯度 tensor([-0.0804])\n",
						"第 7299 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0237]])\n",
						"模型中偏参梯度 tensor([-0.0804])\n",
						"第 7300 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0237]])\n",
						"模型中偏参梯度 tensor([-0.0804])\n",
						"第 365 次epoch\n",
						"第 7301 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0237]])\n",
						"模型中偏参梯度 tensor([-0.0803])\n",
						"第 7302 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0237]])\n",
						"模型中偏参梯度 tensor([-0.0803])\n",
						"第 7303 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0237]])\n",
						"模型中偏参梯度 tensor([-0.0803])\n",
						"第 7304 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0237]])\n",
						"模型中偏参梯度 tensor([-0.0802])\n",
						"第 7305 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0237]])\n",
						"模型中偏参梯度 tensor([-0.0802])\n",
						"第 7306 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0237]])\n",
						"模型中偏参梯度 tensor([-0.0802])\n",
						"第 7307 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0237]])\n",
						"模型中偏参梯度 tensor([-0.0801])\n",
						"第 7308 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0236]])\n",
						"模型中偏参梯度 tensor([-0.0801])\n",
						"第 7309 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0236]])\n",
						"模型中偏参梯度 tensor([-0.0801])\n",
						"第 7310 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0236]])\n",
						"模型中偏参梯度 tensor([-0.0800])\n",
						"第 7311 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0236]])\n",
						"模型中偏参梯度 tensor([-0.0800])\n",
						"第 7312 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0236]])\n",
						"模型中偏参梯度 tensor([-0.0800])\n",
						"第 7313 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0236]])\n",
						"模型中偏参梯度 tensor([-0.0799])\n",
						"第 7314 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0236]])\n",
						"模型中偏参梯度 tensor([-0.0799])\n",
						"第 7315 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0236]])\n",
						"模型中偏参梯度 tensor([-0.0799])\n",
						"第 7316 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0236]])\n",
						"模型中偏参梯度 tensor([-0.0798])\n",
						"第 7317 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0236]])\n",
						"模型中偏参梯度 tensor([-0.0798])\n",
						"第 7318 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0236]])\n",
						"模型中偏参梯度 tensor([-0.0798])\n",
						"第 7319 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0236]])\n",
						"模型中偏参梯度 tensor([-0.0797])\n",
						"第 7320 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0236]])\n",
						"模型中偏参梯度 tensor([-0.0797])\n",
						"第 366 次epoch\n",
						"第 7321 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0236]])\n",
						"模型中偏参梯度 tensor([-0.0797])\n",
						"第 7322 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0235]])\n",
						"模型中偏参梯度 tensor([-0.0796])\n",
						"第 7323 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0235]])\n",
						"模型中偏参梯度 tensor([-0.0796])\n",
						"第 7324 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0235]])\n",
						"模型中偏参梯度 tensor([-0.0796])\n",
						"第 7325 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0235]])\n",
						"模型中偏参梯度 tensor([-0.0795])\n",
						"第 7326 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0235]])\n",
						"模型中偏参梯度 tensor([-0.0795])\n",
						"第 7327 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0235]])\n",
						"模型中偏参梯度 tensor([-0.0795])\n",
						"第 7328 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0235]])\n",
						"模型中偏参梯度 tensor([-0.0794])\n",
						"第 7329 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0235]])\n",
						"模型中偏参梯度 tensor([-0.0794])\n",
						"第 7330 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0234]])\n",
						"模型中偏参梯度 tensor([-0.0794])\n",
						"第 7331 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0234]])\n",
						"模型中偏参梯度 tensor([-0.0794])\n",
						"第 7332 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0234]])\n",
						"模型中偏参梯度 tensor([-0.0793])\n",
						"第 7333 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0234]])\n",
						"模型中偏参梯度 tensor([-0.0793])\n",
						"第 7334 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0234]])\n",
						"模型中偏参梯度 tensor([-0.0793])\n",
						"第 7335 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0234]])\n",
						"模型中偏参梯度 tensor([-0.0792])\n",
						"第 7336 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0234]])\n",
						"模型中偏参梯度 tensor([-0.0792])\n",
						"第 7337 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0234]])\n",
						"模型中偏参梯度 tensor([-0.0792])\n",
						"第 7338 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0233]])\n",
						"模型中偏参梯度 tensor([-0.0791])\n",
						"第 7339 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0233]])\n",
						"模型中偏参梯度 tensor([-0.0791])\n",
						"第 7340 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0233]])\n",
						"模型中偏参梯度 tensor([-0.0791])\n",
						"第 367 次epoch\n",
						"第 7341 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0233]])\n",
						"模型中偏参梯度 tensor([-0.0790])\n",
						"第 7342 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0233]])\n",
						"模型中偏参梯度 tensor([-0.0790])\n",
						"第 7343 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0233]])\n",
						"模型中偏参梯度 tensor([-0.0790])\n",
						"第 7344 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0233]])\n",
						"模型中偏参梯度 tensor([-0.0790])\n",
						"第 7345 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0232]])\n",
						"模型中偏参梯度 tensor([-0.0789])\n",
						"第 7346 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0232]])\n",
						"模型中偏参梯度 tensor([-0.0789])\n",
						"第 7347 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0232]])\n",
						"模型中偏参梯度 tensor([-0.0789])\n",
						"第 7348 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0232]])\n",
						"模型中偏参梯度 tensor([-0.0788])\n",
						"第 7349 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0232]])\n",
						"模型中偏参梯度 tensor([-0.0788])\n",
						"第 7350 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0232]])\n",
						"模型中偏参梯度 tensor([-0.0788])\n",
						"第 7351 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0232]])\n",
						"模型中偏参梯度 tensor([-0.0787])\n",
						"第 7352 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0232]])\n",
						"模型中偏参梯度 tensor([-0.0787])\n",
						"第 7353 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0231]])\n",
						"模型中偏参梯度 tensor([-0.0787])\n",
						"第 7354 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0231]])\n",
						"模型中偏参梯度 tensor([-0.0786])\n",
						"第 7355 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0231]])\n",
						"模型中偏参梯度 tensor([-0.0786])\n",
						"第 7356 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0231]])\n",
						"模型中偏参梯度 tensor([-0.0786])\n",
						"第 7357 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0231]])\n",
						"模型中偏参梯度 tensor([-0.0786])\n",
						"第 7358 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0230]])\n",
						"模型中偏参梯度 tensor([-0.0785])\n",
						"第 7359 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0230]])\n",
						"模型中偏参梯度 tensor([-0.0785])\n",
						"第 7360 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0230]])\n",
						"模型中偏参梯度 tensor([-0.0785])\n",
						"第 368 次epoch\n",
						"第 7361 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0230]])\n",
						"模型中偏参梯度 tensor([-0.0784])\n",
						"第 7362 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0230]])\n",
						"模型中偏参梯度 tensor([-0.0784])\n",
						"第 7363 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0230]])\n",
						"模型中偏参梯度 tensor([-0.0784])\n",
						"第 7364 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0229]])\n",
						"模型中偏参梯度 tensor([-0.0784])\n",
						"第 7365 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0229]])\n",
						"模型中偏参梯度 tensor([-0.0783])\n",
						"第 7366 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0229]])\n",
						"模型中偏参梯度 tensor([-0.0783])\n",
						"第 7367 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0229]])\n",
						"模型中偏参梯度 tensor([-0.0783])\n",
						"第 7368 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0229]])\n",
						"模型中偏参梯度 tensor([-0.0782])\n",
						"第 7369 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0228]])\n",
						"模型中偏参梯度 tensor([-0.0782])\n",
						"第 7370 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0228]])\n",
						"模型中偏参梯度 tensor([-0.0782])\n",
						"第 7371 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0228]])\n",
						"模型中偏参梯度 tensor([-0.0782])\n",
						"第 7372 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0228]])\n",
						"模型中偏参梯度 tensor([-0.0781])\n",
						"第 7373 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0228]])\n",
						"模型中偏参梯度 tensor([-0.0781])\n",
						"第 7374 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0228]])\n",
						"模型中偏参梯度 tensor([-0.0781])\n",
						"第 7375 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0227]])\n",
						"模型中偏参梯度 tensor([-0.0780])\n",
						"第 7376 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0227]])\n",
						"模型中偏参梯度 tensor([-0.0780])\n",
						"第 7377 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0227]])\n",
						"模型中偏参梯度 tensor([-0.0780])\n",
						"第 7378 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0227]])\n",
						"模型中偏参梯度 tensor([-0.0780])\n",
						"第 7379 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0227]])\n",
						"模型中偏参梯度 tensor([-0.0779])\n",
						"第 7380 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0226]])\n",
						"模型中偏参梯度 tensor([-0.0779])\n",
						"第 369 次epoch\n",
						"第 7381 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0226]])\n",
						"模型中偏参梯度 tensor([-0.0779])\n",
						"第 7382 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0226]])\n",
						"模型中偏参梯度 tensor([-0.0778])\n",
						"第 7383 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0226]])\n",
						"模型中偏参梯度 tensor([-0.0778])\n",
						"第 7384 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0226]])\n",
						"模型中偏参梯度 tensor([-0.0778])\n",
						"第 7385 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0225]])\n",
						"模型中偏参梯度 tensor([-0.0778])\n",
						"第 7386 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0225]])\n",
						"模型中偏参梯度 tensor([-0.0777])\n",
						"第 7387 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0225]])\n",
						"模型中偏参梯度 tensor([-0.0777])\n",
						"第 7388 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0225]])\n",
						"模型中偏参梯度 tensor([-0.0777])\n",
						"第 7389 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0225]])\n",
						"模型中偏参梯度 tensor([-0.0776])\n",
						"第 7390 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0224]])\n",
						"模型中偏参梯度 tensor([-0.0776])\n",
						"第 7391 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0224]])\n",
						"模型中偏参梯度 tensor([-0.0776])\n",
						"第 7392 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0224]])\n",
						"模型中偏参梯度 tensor([-0.0776])\n",
						"第 7393 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0224]])\n",
						"模型中偏参梯度 tensor([-0.0775])\n",
						"第 7394 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0223]])\n",
						"模型中偏参梯度 tensor([-0.0775])\n",
						"第 7395 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0223]])\n",
						"模型中偏参梯度 tensor([-0.0775])\n",
						"第 7396 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0223]])\n",
						"模型中偏参梯度 tensor([-0.0775])\n",
						"第 7397 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0223]])\n",
						"模型中偏参梯度 tensor([-0.0774])\n",
						"第 7398 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0222]])\n",
						"模型中偏参梯度 tensor([-0.0774])\n",
						"第 7399 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0222]])\n",
						"模型中偏参梯度 tensor([-0.0774])\n",
						"第 7400 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0222]])\n",
						"模型中偏参梯度 tensor([-0.0773])\n",
						"第 370 次epoch\n",
						"第 7401 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0222]])\n",
						"模型中偏参梯度 tensor([-0.0773])\n",
						"第 7402 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0222]])\n",
						"模型中偏参梯度 tensor([-0.0773])\n",
						"第 7403 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0221]])\n",
						"模型中偏参梯度 tensor([-0.0773])\n",
						"第 7404 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0221]])\n",
						"模型中偏参梯度 tensor([-0.0772])\n",
						"第 7405 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0221]])\n",
						"模型中偏参梯度 tensor([-0.0772])\n",
						"第 7406 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0221]])\n",
						"模型中偏参梯度 tensor([-0.0772])\n",
						"第 7407 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0220]])\n",
						"模型中偏参梯度 tensor([-0.0772])\n",
						"第 7408 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0220]])\n",
						"模型中偏参梯度 tensor([-0.0771])\n",
						"第 7409 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0220]])\n",
						"模型中偏参梯度 tensor([-0.0771])\n",
						"第 7410 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0220]])\n",
						"模型中偏参梯度 tensor([-0.0771])\n",
						"第 7411 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0219]])\n",
						"模型中偏参梯度 tensor([-0.0771])\n",
						"第 7412 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0219]])\n",
						"模型中偏参梯度 tensor([-0.0770])\n",
						"第 7413 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0219]])\n",
						"模型中偏参梯度 tensor([-0.0770])\n",
						"第 7414 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0219]])\n",
						"模型中偏参梯度 tensor([-0.0770])\n",
						"第 7415 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0219]])\n",
						"模型中偏参梯度 tensor([-0.0769])\n",
						"第 7416 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0219]])\n",
						"模型中偏参梯度 tensor([-0.0769])\n",
						"第 7417 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0219]])\n",
						"模型中偏参梯度 tensor([-0.0769])\n",
						"第 7418 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0219]])\n",
						"模型中偏参梯度 tensor([-0.0768])\n",
						"第 7419 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0219]])\n",
						"模型中偏参梯度 tensor([-0.0768])\n",
						"第 7420 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0219]])\n",
						"模型中偏参梯度 tensor([-0.0768])\n",
						"第 371 次epoch\n",
						"第 7421 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0219]])\n",
						"模型中偏参梯度 tensor([-0.0767])\n",
						"第 7422 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0219]])\n",
						"模型中偏参梯度 tensor([-0.0767])\n",
						"第 7423 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0219]])\n",
						"模型中偏参梯度 tensor([-0.0767])\n",
						"第 7424 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0219]])\n",
						"模型中偏参梯度 tensor([-0.0766])\n",
						"第 7425 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0219]])\n",
						"模型中偏参梯度 tensor([-0.0766])\n",
						"第 7426 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0219]])\n",
						"模型中偏参梯度 tensor([-0.0766])\n",
						"第 7427 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0219]])\n",
						"模型中偏参梯度 tensor([-0.0765])\n",
						"第 7428 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0219]])\n",
						"模型中偏参梯度 tensor([-0.0765])\n",
						"第 7429 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0219]])\n",
						"模型中偏参梯度 tensor([-0.0765])\n",
						"第 7430 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0219]])\n",
						"模型中偏参梯度 tensor([-0.0764])\n",
						"第 7431 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0219]])\n",
						"模型中偏参梯度 tensor([-0.0764])\n",
						"第 7432 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0219]])\n",
						"模型中偏参梯度 tensor([-0.0764])\n",
						"第 7433 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0219]])\n",
						"模型中偏参梯度 tensor([-0.0763])\n",
						"第 7434 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0219]])\n",
						"模型中偏参梯度 tensor([-0.0763])\n",
						"第 7435 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0219]])\n",
						"模型中偏参梯度 tensor([-0.0763])\n",
						"第 7436 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0219]])\n",
						"模型中偏参梯度 tensor([-0.0762])\n",
						"第 7437 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0219]])\n",
						"模型中偏参梯度 tensor([-0.0762])\n",
						"第 7438 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0219]])\n",
						"模型中偏参梯度 tensor([-0.0762])\n",
						"第 7439 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0219]])\n",
						"模型中偏参梯度 tensor([-0.0761])\n",
						"第 7440 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0219]])\n",
						"模型中偏参梯度 tensor([-0.0761])\n",
						"第 372 次epoch\n",
						"第 7441 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0219]])\n",
						"模型中偏参梯度 tensor([-0.0761])\n",
						"第 7442 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0219]])\n",
						"模型中偏参梯度 tensor([-0.0760])\n",
						"第 7443 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0219]])\n",
						"模型中偏参梯度 tensor([-0.0760])\n",
						"第 7444 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0219]])\n",
						"模型中偏参梯度 tensor([-0.0760])\n",
						"第 7445 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0219]])\n",
						"模型中偏参梯度 tensor([-0.0759])\n",
						"第 7446 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0219]])\n",
						"模型中偏参梯度 tensor([-0.0759])\n",
						"第 7447 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0219]])\n",
						"模型中偏参梯度 tensor([-0.0759])\n",
						"第 7448 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0219]])\n",
						"模型中偏参梯度 tensor([-0.0758])\n",
						"第 7449 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0219]])\n",
						"模型中偏参梯度 tensor([-0.0758])\n",
						"第 7450 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0219]])\n",
						"模型中偏参梯度 tensor([-0.0758])\n",
						"第 7451 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0219]])\n",
						"模型中偏参梯度 tensor([-0.0757])\n",
						"第 7452 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0219]])\n",
						"模型中偏参梯度 tensor([-0.0757])\n",
						"第 7453 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0219]])\n",
						"模型中偏参梯度 tensor([-0.0757])\n",
						"第 7454 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0219]])\n",
						"模型中偏参梯度 tensor([-0.0756])\n",
						"第 7455 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0219]])\n",
						"模型中偏参梯度 tensor([-0.0756])\n",
						"第 7456 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0219]])\n",
						"模型中偏参梯度 tensor([-0.0756])\n",
						"第 7457 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0219]])\n",
						"模型中偏参梯度 tensor([-0.0755])\n",
						"第 7458 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0219]])\n",
						"模型中偏参梯度 tensor([-0.0755])\n",
						"第 7459 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0219]])\n",
						"模型中偏参梯度 tensor([-0.0755])\n",
						"第 7460 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0219]])\n",
						"模型中偏参梯度 tensor([-0.0754])\n",
						"第 373 次epoch\n",
						"第 7461 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0219]])\n",
						"模型中偏参梯度 tensor([-0.0754])\n",
						"第 7462 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0219]])\n",
						"模型中偏参梯度 tensor([-0.0754])\n",
						"第 7463 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0219]])\n",
						"模型中偏参梯度 tensor([-0.0753])\n",
						"第 7464 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0219]])\n",
						"模型中偏参梯度 tensor([-0.0753])\n",
						"第 7465 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0219]])\n",
						"模型中偏参梯度 tensor([-0.0753])\n",
						"第 7466 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0219]])\n",
						"模型中偏参梯度 tensor([-0.0752])\n",
						"第 7467 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0219]])\n",
						"模型中偏参梯度 tensor([-0.0752])\n",
						"第 7468 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0219]])\n",
						"模型中偏参梯度 tensor([-0.0752])\n",
						"第 7469 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0219]])\n",
						"模型中偏参梯度 tensor([-0.0751])\n",
						"第 7470 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0219]])\n",
						"模型中偏参梯度 tensor([-0.0751])\n",
						"第 7471 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0219]])\n",
						"模型中偏参梯度 tensor([-0.0751])\n",
						"第 7472 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0219]])\n",
						"模型中偏参梯度 tensor([-0.0750])\n",
						"第 7473 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0219]])\n",
						"模型中偏参梯度 tensor([-0.0750])\n",
						"第 7474 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0219]])\n",
						"模型中偏参梯度 tensor([-0.0750])\n",
						"第 7475 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0219]])\n",
						"模型中偏参梯度 tensor([-0.0749])\n",
						"第 7476 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0219]])\n",
						"模型中偏参梯度 tensor([-0.0749])\n",
						"第 7477 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0219]])\n",
						"模型中偏参梯度 tensor([-0.0749])\n",
						"第 7478 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0219]])\n",
						"模型中偏参梯度 tensor([-0.0748])\n",
						"第 7479 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0219]])\n",
						"模型中偏参梯度 tensor([-0.0748])\n",
						"第 7480 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0219]])\n",
						"模型中偏参梯度 tensor([-0.0748])\n",
						"第 374 次epoch\n",
						"第 7481 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0219]])\n",
						"模型中偏参梯度 tensor([-0.0747])\n",
						"第 7482 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0219]])\n",
						"模型中偏参梯度 tensor([-0.0747])\n",
						"第 7483 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0219]])\n",
						"模型中偏参梯度 tensor([-0.0747])\n",
						"第 7484 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0219]])\n",
						"模型中偏参梯度 tensor([-0.0747])\n",
						"第 7485 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0219]])\n",
						"模型中偏参梯度 tensor([-0.0746])\n",
						"第 7486 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0219]])\n",
						"模型中偏参梯度 tensor([-0.0746])\n",
						"第 7487 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0219]])\n",
						"模型中偏参梯度 tensor([-0.0746])\n",
						"第 7488 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0219]])\n",
						"模型中偏参梯度 tensor([-0.0745])\n",
						"第 7489 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0219]])\n",
						"模型中偏参梯度 tensor([-0.0745])\n",
						"第 7490 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0219]])\n",
						"模型中偏参梯度 tensor([-0.0745])\n",
						"第 7491 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0219]])\n",
						"模型中偏参梯度 tensor([-0.0744])\n",
						"第 7492 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0219]])\n",
						"模型中偏参梯度 tensor([-0.0744])\n",
						"第 7493 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0219]])\n",
						"模型中偏参梯度 tensor([-0.0744])\n",
						"第 7494 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0219]])\n",
						"模型中偏参梯度 tensor([-0.0743])\n",
						"第 7495 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0219]])\n",
						"模型中偏参梯度 tensor([-0.0743])\n",
						"第 7496 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0219]])\n",
						"模型中偏参梯度 tensor([-0.0743])\n",
						"第 7497 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0219]])\n",
						"模型中偏参梯度 tensor([-0.0742])\n",
						"第 7498 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0219]])\n",
						"模型中偏参梯度 tensor([-0.0742])\n",
						"第 7499 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0219]])\n",
						"模型中偏参梯度 tensor([-0.0742])\n",
						"第 7500 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0219]])\n",
						"模型中偏参梯度 tensor([-0.0741])\n",
						"第 375 次epoch\n",
						"第 7501 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0219]])\n",
						"模型中偏参梯度 tensor([-0.0741])\n",
						"第 7502 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0219]])\n",
						"模型中偏参梯度 tensor([-0.0741])\n",
						"第 7503 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0219]])\n",
						"模型中偏参梯度 tensor([-0.0740])\n",
						"第 7504 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0219]])\n",
						"模型中偏参梯度 tensor([-0.0740])\n",
						"第 7505 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0219]])\n",
						"模型中偏参梯度 tensor([-0.0740])\n",
						"第 7506 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0219]])\n",
						"模型中偏参梯度 tensor([-0.0740])\n",
						"第 7507 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0219]])\n",
						"模型中偏参梯度 tensor([-0.0739])\n",
						"第 7508 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0219]])\n",
						"模型中偏参梯度 tensor([-0.0739])\n",
						"第 7509 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0219]])\n",
						"模型中偏参梯度 tensor([-0.0739])\n",
						"第 7510 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0219]])\n",
						"模型中偏参梯度 tensor([-0.0738])\n",
						"第 7511 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0218]])\n",
						"模型中偏参梯度 tensor([-0.0738])\n",
						"第 7512 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0218]])\n",
						"模型中偏参梯度 tensor([-0.0738])\n",
						"第 7513 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0218]])\n",
						"模型中偏参梯度 tensor([-0.0737])\n",
						"第 7514 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0218]])\n",
						"模型中偏参梯度 tensor([-0.0737])\n",
						"第 7515 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0218]])\n",
						"模型中偏参梯度 tensor([-0.0737])\n",
						"第 7516 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0218]])\n",
						"模型中偏参梯度 tensor([-0.0737])\n",
						"第 7517 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0218]])\n",
						"模型中偏参梯度 tensor([-0.0736])\n",
						"第 7518 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0218]])\n",
						"模型中偏参梯度 tensor([-0.0736])\n",
						"第 7519 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0218]])\n",
						"模型中偏参梯度 tensor([-0.0736])\n",
						"第 7520 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0218]])\n",
						"模型中偏参梯度 tensor([-0.0735])\n",
						"第 376 次epoch\n",
						"第 7521 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0218]])\n",
						"模型中偏参梯度 tensor([-0.0735])\n",
						"第 7522 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0218]])\n",
						"模型中偏参梯度 tensor([-0.0735])\n",
						"第 7523 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0218]])\n",
						"模型中偏参梯度 tensor([-0.0734])\n",
						"第 7524 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0218]])\n",
						"模型中偏参梯度 tensor([-0.0734])\n",
						"第 7525 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0217]])\n",
						"模型中偏参梯度 tensor([-0.0734])\n",
						"第 7526 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0217]])\n",
						"模型中偏参梯度 tensor([-0.0734])\n",
						"第 7527 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0217]])\n",
						"模型中偏参梯度 tensor([-0.0733])\n",
						"第 7528 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0217]])\n",
						"模型中偏参梯度 tensor([-0.0733])\n",
						"第 7529 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0217]])\n",
						"模型中偏参梯度 tensor([-0.0733])\n",
						"第 7530 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0217]])\n",
						"模型中偏参梯度 tensor([-0.0732])\n",
						"第 7531 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0217]])\n",
						"模型中偏参梯度 tensor([-0.0732])\n",
						"第 7532 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0217]])\n",
						"模型中偏参梯度 tensor([-0.0732])\n",
						"第 7533 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0217]])\n",
						"模型中偏参梯度 tensor([-0.0731])\n",
						"第 7534 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0217]])\n",
						"模型中偏参梯度 tensor([-0.0731])\n",
						"第 7535 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0217]])\n",
						"模型中偏参梯度 tensor([-0.0731])\n",
						"第 7536 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0217]])\n",
						"模型中偏参梯度 tensor([-0.0731])\n",
						"第 7537 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0217]])\n",
						"模型中偏参梯度 tensor([-0.0730])\n",
						"第 7538 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0217]])\n",
						"模型中偏参梯度 tensor([-0.0730])\n",
						"第 7539 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0216]])\n",
						"模型中偏参梯度 tensor([-0.0730])\n",
						"第 7540 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0216]])\n",
						"模型中偏参梯度 tensor([-0.0729])\n",
						"第 377 次epoch\n",
						"第 7541 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0216]])\n",
						"模型中偏参梯度 tensor([-0.0729])\n",
						"第 7542 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0216]])\n",
						"模型中偏参梯度 tensor([-0.0729])\n",
						"第 7543 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0216]])\n",
						"模型中偏参梯度 tensor([-0.0728])\n",
						"第 7544 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0216]])\n",
						"模型中偏参梯度 tensor([-0.0728])\n",
						"第 7545 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0216]])\n",
						"模型中偏参梯度 tensor([-0.0728])\n",
						"第 7546 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0216]])\n",
						"模型中偏参梯度 tensor([-0.0728])\n",
						"第 7547 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0216]])\n",
						"模型中偏参梯度 tensor([-0.0727])\n",
						"第 7548 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0215]])\n",
						"模型中偏参梯度 tensor([-0.0727])\n",
						"第 7549 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0215]])\n",
						"模型中偏参梯度 tensor([-0.0727])\n",
						"第 7550 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0215]])\n",
						"模型中偏参梯度 tensor([-0.0727])\n",
						"第 7551 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0215]])\n",
						"模型中偏参梯度 tensor([-0.0726])\n",
						"第 7552 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0215]])\n",
						"模型中偏参梯度 tensor([-0.0726])\n",
						"第 7553 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0215]])\n",
						"模型中偏参梯度 tensor([-0.0726])\n",
						"第 7554 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0215]])\n",
						"模型中偏参梯度 tensor([-0.0725])\n",
						"第 7555 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0215]])\n",
						"模型中偏参梯度 tensor([-0.0725])\n",
						"第 7556 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0214]])\n",
						"模型中偏参梯度 tensor([-0.0725])\n",
						"第 7557 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0214]])\n",
						"模型中偏参梯度 tensor([-0.0725])\n",
						"第 7558 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0214]])\n",
						"模型中偏参梯度 tensor([-0.0724])\n",
						"第 7559 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0214]])\n",
						"模型中偏参梯度 tensor([-0.0724])\n",
						"第 7560 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0214]])\n",
						"模型中偏参梯度 tensor([-0.0724])\n",
						"第 378 次epoch\n",
						"第 7561 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0214]])\n",
						"模型中偏参梯度 tensor([-0.0723])\n",
						"第 7562 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0214]])\n",
						"模型中偏参梯度 tensor([-0.0723])\n",
						"第 7563 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0213]])\n",
						"模型中偏参梯度 tensor([-0.0723])\n",
						"第 7564 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0213]])\n",
						"模型中偏参梯度 tensor([-0.0723])\n",
						"第 7565 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0213]])\n",
						"模型中偏参梯度 tensor([-0.0722])\n",
						"第 7566 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0213]])\n",
						"模型中偏参梯度 tensor([-0.0722])\n",
						"第 7567 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0213]])\n",
						"模型中偏参梯度 tensor([-0.0722])\n",
						"第 7568 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0213]])\n",
						"模型中偏参梯度 tensor([-0.0721])\n",
						"第 7569 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0213]])\n",
						"模型中偏参梯度 tensor([-0.0721])\n",
						"第 7570 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0213]])\n",
						"模型中偏参梯度 tensor([-0.0721])\n",
						"第 7571 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0213]])\n",
						"模型中偏参梯度 tensor([-0.0721])\n",
						"第 7572 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0212]])\n",
						"模型中偏参梯度 tensor([-0.0720])\n",
						"第 7573 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0212]])\n",
						"模型中偏参梯度 tensor([-0.0720])\n",
						"第 7574 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0212]])\n",
						"模型中偏参梯度 tensor([-0.0720])\n",
						"第 7575 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0212]])\n",
						"模型中偏参梯度 tensor([-0.0720])\n",
						"第 7576 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0212]])\n",
						"模型中偏参梯度 tensor([-0.0719])\n",
						"第 7577 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0212]])\n",
						"模型中偏参梯度 tensor([-0.0719])\n",
						"第 7578 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0211]])\n",
						"模型中偏参梯度 tensor([-0.0719])\n",
						"第 7579 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0211]])\n",
						"模型中偏参梯度 tensor([-0.0718])\n",
						"第 7580 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0211]])\n",
						"模型中偏参梯度 tensor([-0.0718])\n",
						"第 379 次epoch\n",
						"第 7581 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0211]])\n",
						"模型中偏参梯度 tensor([-0.0718])\n",
						"第 7582 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0211]])\n",
						"模型中偏参梯度 tensor([-0.0718])\n",
						"第 7583 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0210]])\n",
						"模型中偏参梯度 tensor([-0.0717])\n",
						"第 7584 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0210]])\n",
						"模型中偏参梯度 tensor([-0.0717])\n",
						"第 7585 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0210]])\n",
						"模型中偏参梯度 tensor([-0.0717])\n",
						"第 7586 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0210]])\n",
						"模型中偏参梯度 tensor([-0.0717])\n",
						"第 7587 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0210]])\n",
						"模型中偏参梯度 tensor([-0.0716])\n",
						"第 7588 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0210]])\n",
						"模型中偏参梯度 tensor([-0.0716])\n",
						"第 7589 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0209]])\n",
						"模型中偏参梯度 tensor([-0.0716])\n",
						"第 7590 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0209]])\n",
						"模型中偏参梯度 tensor([-0.0716])\n",
						"第 7591 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0209]])\n",
						"模型中偏参梯度 tensor([-0.0715])\n",
						"第 7592 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0209]])\n",
						"模型中偏参梯度 tensor([-0.0715])\n",
						"第 7593 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0209]])\n",
						"模型中偏参梯度 tensor([-0.0715])\n",
						"第 7594 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0209]])\n",
						"模型中偏参梯度 tensor([-0.0715])\n",
						"第 7595 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0208]])\n",
						"模型中偏参梯度 tensor([-0.0714])\n",
						"第 7596 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0208]])\n",
						"模型中偏参梯度 tensor([-0.0714])\n",
						"第 7597 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0208]])\n",
						"模型中偏参梯度 tensor([-0.0714])\n",
						"第 7598 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0208]])\n",
						"模型中偏参梯度 tensor([-0.0714])\n",
						"第 7599 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0208]])\n",
						"模型中偏参梯度 tensor([-0.0713])\n",
						"第 7600 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0207]])\n",
						"模型中偏参梯度 tensor([-0.0713])\n",
						"第 380 次epoch\n",
						"第 7601 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0207]])\n",
						"模型中偏参梯度 tensor([-0.0713])\n",
						"第 7602 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0207]])\n",
						"模型中偏参梯度 tensor([-0.0712])\n",
						"第 7603 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0207]])\n",
						"模型中偏参梯度 tensor([-0.0712])\n",
						"第 7604 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0207]])\n",
						"模型中偏参梯度 tensor([-0.0712])\n",
						"第 7605 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0207]])\n",
						"模型中偏参梯度 tensor([-0.0712])\n",
						"第 7606 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0206]])\n",
						"模型中偏参梯度 tensor([-0.0711])\n",
						"第 7607 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0206]])\n",
						"模型中偏参梯度 tensor([-0.0711])\n",
						"第 7608 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0206]])\n",
						"模型中偏参梯度 tensor([-0.0711])\n",
						"第 7609 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0206]])\n",
						"模型中偏参梯度 tensor([-0.0711])\n",
						"第 7610 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0206]])\n",
						"模型中偏参梯度 tensor([-0.0710])\n",
						"第 7611 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0205]])\n",
						"模型中偏参梯度 tensor([-0.0710])\n",
						"第 7612 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0205]])\n",
						"模型中偏参梯度 tensor([-0.0710])\n",
						"第 7613 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0205]])\n",
						"模型中偏参梯度 tensor([-0.0710])\n",
						"第 7614 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0205]])\n",
						"模型中偏参梯度 tensor([-0.0709])\n",
						"第 7615 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0205]])\n",
						"模型中偏参梯度 tensor([-0.0709])\n",
						"第 7616 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0204]])\n",
						"模型中偏参梯度 tensor([-0.0709])\n",
						"第 7617 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0204]])\n",
						"模型中偏参梯度 tensor([-0.0709])\n",
						"第 7618 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0204]])\n",
						"模型中偏参梯度 tensor([-0.0708])\n",
						"第 7619 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0204]])\n",
						"模型中偏参梯度 tensor([-0.0708])\n",
						"第 7620 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0203]])\n",
						"模型中偏参梯度 tensor([-0.0708])\n",
						"第 381 次epoch\n",
						"第 7621 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0203]])\n",
						"模型中偏参梯度 tensor([-0.0708])\n",
						"第 7622 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0203]])\n",
						"模型中偏参梯度 tensor([-0.0708])\n",
						"第 7623 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0203]])\n",
						"模型中偏参梯度 tensor([-0.0707])\n",
						"第 7624 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0202]])\n",
						"模型中偏参梯度 tensor([-0.0707])\n",
						"第 7625 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0202]])\n",
						"模型中偏参梯度 tensor([-0.0707])\n",
						"第 7626 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0202]])\n",
						"模型中偏参梯度 tensor([-0.0707])\n",
						"第 7627 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0202]])\n",
						"模型中偏参梯度 tensor([-0.0706])\n",
						"第 7628 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0201]])\n",
						"模型中偏参梯度 tensor([-0.0706])\n",
						"第 7629 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0201]])\n",
						"模型中偏参梯度 tensor([-0.0706])\n",
						"第 7630 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0201]])\n",
						"模型中偏参梯度 tensor([-0.0706])\n",
						"第 7631 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0201]])\n",
						"模型中偏参梯度 tensor([-0.0705])\n",
						"第 7632 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0201]])\n",
						"模型中偏参梯度 tensor([-0.0705])\n",
						"第 7633 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0705])\n",
						"第 7634 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0705])\n",
						"第 7635 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0704])\n",
						"第 7636 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0704])\n",
						"第 7637 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0704])\n",
						"第 7638 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0703])\n",
						"第 7639 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0703])\n",
						"第 7640 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0703])\n",
						"第 382 次epoch\n",
						"第 7641 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0703])\n",
						"第 7642 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0702])\n",
						"第 7643 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0702])\n",
						"第 7644 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0702])\n",
						"第 7645 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0701])\n",
						"第 7646 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0701])\n",
						"第 7647 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0701])\n",
						"第 7648 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0700])\n",
						"第 7649 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0700])\n",
						"第 7650 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0700])\n",
						"第 7651 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0699])\n",
						"第 7652 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0699])\n",
						"第 7653 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0699])\n",
						"第 7654 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0698])\n",
						"第 7655 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0698])\n",
						"第 7656 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0698])\n",
						"第 7657 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0698])\n",
						"第 7658 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0697])\n",
						"第 7659 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0697])\n",
						"第 7660 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0697])\n",
						"第 383 次epoch\n",
						"第 7661 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0696])\n",
						"第 7662 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0696])\n",
						"第 7663 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0696])\n",
						"第 7664 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0695])\n",
						"第 7665 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0695])\n",
						"第 7666 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0695])\n",
						"第 7667 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0695])\n",
						"第 7668 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0694])\n",
						"第 7669 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0694])\n",
						"第 7670 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0694])\n",
						"第 7671 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0693])\n",
						"第 7672 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0693])\n",
						"第 7673 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0693])\n",
						"第 7674 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0692])\n",
						"第 7675 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0692])\n",
						"第 7676 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0692])\n",
						"第 7677 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0692])\n",
						"第 7678 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0691])\n",
						"第 7679 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0691])\n",
						"第 7680 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0691])\n",
						"第 384 次epoch\n",
						"第 7681 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0690])\n",
						"第 7682 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0690])\n",
						"第 7683 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0690])\n",
						"第 7684 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0689])\n",
						"第 7685 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0689])\n",
						"第 7686 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0689])\n",
						"第 7687 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0689])\n",
						"第 7688 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0688])\n",
						"第 7689 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0688])\n",
						"第 7690 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0688])\n",
						"第 7691 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0687])\n",
						"第 7692 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0687])\n",
						"第 7693 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0687])\n",
						"第 7694 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0686])\n",
						"第 7695 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0686])\n",
						"第 7696 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0686])\n",
						"第 7697 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0686])\n",
						"第 7698 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0685])\n",
						"第 7699 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0685])\n",
						"第 7700 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0685])\n",
						"第 385 次epoch\n",
						"第 7701 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0684])\n",
						"第 7702 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0684])\n",
						"第 7703 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0684])\n",
						"第 7704 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0684])\n",
						"第 7705 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0683])\n",
						"第 7706 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0683])\n",
						"第 7707 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0683])\n",
						"第 7708 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0682])\n",
						"第 7709 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0682])\n",
						"第 7710 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0682])\n",
						"第 7711 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0681])\n",
						"第 7712 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0681])\n",
						"第 7713 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0681])\n",
						"第 7714 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0681])\n",
						"第 7715 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0680])\n",
						"第 7716 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0680])\n",
						"第 7717 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0680])\n",
						"第 7718 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0679])\n",
						"第 7719 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0679])\n",
						"第 7720 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0679])\n",
						"第 386 次epoch\n",
						"第 7721 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0678])\n",
						"第 7722 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0678])\n",
						"第 7723 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0678])\n",
						"第 7724 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0678])\n",
						"第 7725 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0677])\n",
						"第 7726 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0677])\n",
						"第 7727 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0677])\n",
						"第 7728 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0676])\n",
						"第 7729 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0676])\n",
						"第 7730 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0676])\n",
						"第 7731 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0676])\n",
						"第 7732 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0675])\n",
						"第 7733 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0675])\n",
						"第 7734 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0675])\n",
						"第 7735 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0674])\n",
						"第 7736 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0674])\n",
						"第 7737 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0674])\n",
						"第 7738 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0674])\n",
						"第 7739 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0673])\n",
						"第 7740 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0673])\n",
						"第 387 次epoch\n",
						"第 7741 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0673])\n",
						"第 7742 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0672])\n",
						"第 7743 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0672])\n",
						"第 7744 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0672])\n",
						"第 7745 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0672])\n",
						"第 7746 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0200]])\n",
						"模型中偏参梯度 tensor([-0.0671])\n",
						"第 7747 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0199]])\n",
						"模型中偏参梯度 tensor([-0.0671])\n",
						"第 7748 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0199]])\n",
						"模型中偏参梯度 tensor([-0.0671])\n",
						"第 7749 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0199]])\n",
						"模型中偏参梯度 tensor([-0.0670])\n",
						"第 7750 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0199]])\n",
						"模型中偏参梯度 tensor([-0.0670])\n",
						"第 7751 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0199]])\n",
						"模型中偏参梯度 tensor([-0.0670])\n",
						"第 7752 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0199]])\n",
						"模型中偏参梯度 tensor([-0.0670])\n",
						"第 7753 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0199]])\n",
						"模型中偏参梯度 tensor([-0.0669])\n",
						"第 7754 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0199]])\n",
						"模型中偏参梯度 tensor([-0.0669])\n",
						"第 7755 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0199]])\n",
						"模型中偏参梯度 tensor([-0.0669])\n",
						"第 7756 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0199]])\n",
						"模型中偏参梯度 tensor([-0.0669])\n",
						"第 7757 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0199]])\n",
						"模型中偏参梯度 tensor([-0.0668])\n",
						"第 7758 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0199]])\n",
						"模型中偏参梯度 tensor([-0.0668])\n",
						"第 7759 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0199]])\n",
						"模型中偏参梯度 tensor([-0.0668])\n",
						"第 7760 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0199]])\n",
						"模型中偏参梯度 tensor([-0.0667])\n",
						"第 388 次epoch\n",
						"第 7761 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0199]])\n",
						"模型中偏参梯度 tensor([-0.0667])\n",
						"第 7762 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0198]])\n",
						"模型中偏参梯度 tensor([-0.0667])\n",
						"第 7763 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0198]])\n",
						"模型中偏参梯度 tensor([-0.0667])\n",
						"第 7764 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0198]])\n",
						"模型中偏参梯度 tensor([-0.0666])\n",
						"第 7765 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0198]])\n",
						"模型中偏参梯度 tensor([-0.0666])\n",
						"第 7766 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0198]])\n",
						"模型中偏参梯度 tensor([-0.0666])\n",
						"第 7767 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0198]])\n",
						"模型中偏参梯度 tensor([-0.0666])\n",
						"第 7768 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0198]])\n",
						"模型中偏参梯度 tensor([-0.0665])\n",
						"第 7769 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0198]])\n",
						"模型中偏参梯度 tensor([-0.0665])\n",
						"第 7770 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0198]])\n",
						"模型中偏参梯度 tensor([-0.0665])\n",
						"第 7771 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0198]])\n",
						"模型中偏参梯度 tensor([-0.0664])\n",
						"第 7772 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0198]])\n",
						"模型中偏参梯度 tensor([-0.0664])\n",
						"第 7773 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0198]])\n",
						"模型中偏参梯度 tensor([-0.0664])\n",
						"第 7774 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0198]])\n",
						"模型中偏参梯度 tensor([-0.0664])\n",
						"第 7775 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0198]])\n",
						"模型中偏参梯度 tensor([-0.0663])\n",
						"第 7776 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0198]])\n",
						"模型中偏参梯度 tensor([-0.0663])\n",
						"第 7777 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0197]])\n",
						"模型中偏参梯度 tensor([-0.0663])\n",
						"第 7778 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0197]])\n",
						"模型中偏参梯度 tensor([-0.0663])\n",
						"第 7779 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0197]])\n",
						"模型中偏参梯度 tensor([-0.0662])\n",
						"第 7780 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0197]])\n",
						"模型中偏参梯度 tensor([-0.0662])\n",
						"第 389 次epoch\n",
						"第 7781 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0197]])\n",
						"模型中偏参梯度 tensor([-0.0662])\n",
						"第 7782 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0197]])\n",
						"模型中偏参梯度 tensor([-0.0662])\n",
						"第 7783 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0197]])\n",
						"模型中偏参梯度 tensor([-0.0661])\n",
						"第 7784 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0197]])\n",
						"模型中偏参梯度 tensor([-0.0661])\n",
						"第 7785 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0197]])\n",
						"模型中偏参梯度 tensor([-0.0661])\n",
						"第 7786 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0197]])\n",
						"模型中偏参梯度 tensor([-0.0661])\n",
						"第 7787 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0196]])\n",
						"模型中偏参梯度 tensor([-0.0660])\n",
						"第 7788 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0196]])\n",
						"模型中偏参梯度 tensor([-0.0660])\n",
						"第 7789 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0196]])\n",
						"模型中偏参梯度 tensor([-0.0660])\n",
						"第 7790 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0196]])\n",
						"模型中偏参梯度 tensor([-0.0660])\n",
						"第 7791 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0196]])\n",
						"模型中偏参梯度 tensor([-0.0659])\n",
						"第 7792 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0196]])\n",
						"模型中偏参梯度 tensor([-0.0659])\n",
						"第 7793 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0196]])\n",
						"模型中偏参梯度 tensor([-0.0659])\n",
						"第 7794 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0196]])\n",
						"模型中偏参梯度 tensor([-0.0659])\n",
						"第 7795 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0195]])\n",
						"模型中偏参梯度 tensor([-0.0658])\n",
						"第 7796 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0195]])\n",
						"模型中偏参梯度 tensor([-0.0658])\n",
						"第 7797 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0195]])\n",
						"模型中偏参梯度 tensor([-0.0658])\n",
						"第 7798 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0195]])\n",
						"模型中偏参梯度 tensor([-0.0658])\n",
						"第 7799 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0195]])\n",
						"模型中偏参梯度 tensor([-0.0657])\n",
						"第 7800 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0195]])\n",
						"模型中偏参梯度 tensor([-0.0657])\n",
						"第 390 次epoch\n",
						"第 7801 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0195]])\n",
						"模型中偏参梯度 tensor([-0.0657])\n",
						"第 7802 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0195]])\n",
						"模型中偏参梯度 tensor([-0.0657])\n",
						"第 7803 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0195]])\n",
						"模型中偏参梯度 tensor([-0.0656])\n",
						"第 7804 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0194]])\n",
						"模型中偏参梯度 tensor([-0.0656])\n",
						"第 7805 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0194]])\n",
						"模型中偏参梯度 tensor([-0.0656])\n",
						"第 7806 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0194]])\n",
						"模型中偏参梯度 tensor([-0.0656])\n",
						"第 7807 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0194]])\n",
						"模型中偏参梯度 tensor([-0.0655])\n",
						"第 7808 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0194]])\n",
						"模型中偏参梯度 tensor([-0.0655])\n",
						"第 7809 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0194]])\n",
						"模型中偏参梯度 tensor([-0.0655])\n",
						"第 7810 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0194]])\n",
						"模型中偏参梯度 tensor([-0.0654])\n",
						"第 7811 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0194]])\n",
						"模型中偏参梯度 tensor([-0.0654])\n",
						"第 7812 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0193]])\n",
						"模型中偏参梯度 tensor([-0.0654])\n",
						"第 7813 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0193]])\n",
						"模型中偏参梯度 tensor([-0.0654])\n",
						"第 7814 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0193]])\n",
						"模型中偏参梯度 tensor([-0.0653])\n",
						"第 7815 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0193]])\n",
						"模型中偏参梯度 tensor([-0.0653])\n",
						"第 7816 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0193]])\n",
						"模型中偏参梯度 tensor([-0.0653])\n",
						"第 7817 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0193]])\n",
						"模型中偏参梯度 tensor([-0.0653])\n",
						"第 7818 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0193]])\n",
						"模型中偏参梯度 tensor([-0.0653])\n",
						"第 7819 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0192]])\n",
						"模型中偏参梯度 tensor([-0.0652])\n",
						"第 7820 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0192]])\n",
						"模型中偏参梯度 tensor([-0.0652])\n",
						"第 391 次epoch\n",
						"第 7821 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0192]])\n",
						"模型中偏参梯度 tensor([-0.0652])\n",
						"第 7822 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0192]])\n",
						"模型中偏参梯度 tensor([-0.0652])\n",
						"第 7823 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0192]])\n",
						"模型中偏参梯度 tensor([-0.0651])\n",
						"第 7824 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0192]])\n",
						"模型中偏参梯度 tensor([-0.0651])\n",
						"第 7825 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0191]])\n",
						"模型中偏参梯度 tensor([-0.0651])\n",
						"第 7826 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0191]])\n",
						"模型中偏参梯度 tensor([-0.0651])\n",
						"第 7827 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0191]])\n",
						"模型中偏参梯度 tensor([-0.0650])\n",
						"第 7828 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0191]])\n",
						"模型中偏参梯度 tensor([-0.0650])\n",
						"第 7829 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0191]])\n",
						"模型中偏参梯度 tensor([-0.0650])\n",
						"第 7830 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0190]])\n",
						"模型中偏参梯度 tensor([-0.0650])\n",
						"第 7831 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0190]])\n",
						"模型中偏参梯度 tensor([-0.0649])\n",
						"第 7832 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0190]])\n",
						"模型中偏参梯度 tensor([-0.0649])\n",
						"第 7833 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0190]])\n",
						"模型中偏参梯度 tensor([-0.0649])\n",
						"第 7834 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0190]])\n",
						"模型中偏参梯度 tensor([-0.0649])\n",
						"第 7835 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0190]])\n",
						"模型中偏参梯度 tensor([-0.0649])\n",
						"第 7836 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0189]])\n",
						"模型中偏参梯度 tensor([-0.0648])\n",
						"第 7837 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0189]])\n",
						"模型中偏参梯度 tensor([-0.0648])\n",
						"第 7838 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0189]])\n",
						"模型中偏参梯度 tensor([-0.0648])\n",
						"第 7839 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0189]])\n",
						"模型中偏参梯度 tensor([-0.0648])\n",
						"第 7840 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0189]])\n",
						"模型中偏参梯度 tensor([-0.0647])\n",
						"第 392 次epoch\n",
						"第 7841 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0189]])\n",
						"模型中偏参梯度 tensor([-0.0647])\n",
						"第 7842 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0188]])\n",
						"模型中偏参梯度 tensor([-0.0647])\n",
						"第 7843 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0188]])\n",
						"模型中偏参梯度 tensor([-0.0647])\n",
						"第 7844 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0188]])\n",
						"模型中偏参梯度 tensor([-0.0646])\n",
						"第 7845 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0188]])\n",
						"模型中偏参梯度 tensor([-0.0646])\n",
						"第 7846 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0188]])\n",
						"模型中偏参梯度 tensor([-0.0646])\n",
						"第 7847 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0188]])\n",
						"模型中偏参梯度 tensor([-0.0646])\n",
						"第 7848 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0187]])\n",
						"模型中偏参梯度 tensor([-0.0646])\n",
						"第 7849 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0187]])\n",
						"模型中偏参梯度 tensor([-0.0645])\n",
						"第 7850 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0187]])\n",
						"模型中偏参梯度 tensor([-0.0645])\n",
						"第 7851 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0187]])\n",
						"模型中偏参梯度 tensor([-0.0645])\n",
						"第 7852 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0187]])\n",
						"模型中偏参梯度 tensor([-0.0645])\n",
						"第 7853 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0187]])\n",
						"模型中偏参梯度 tensor([-0.0644])\n",
						"第 7854 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0186]])\n",
						"模型中偏参梯度 tensor([-0.0644])\n",
						"第 7855 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0186]])\n",
						"模型中偏参梯度 tensor([-0.0644])\n",
						"第 7856 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0186]])\n",
						"模型中偏参梯度 tensor([-0.0644])\n",
						"第 7857 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0186]])\n",
						"模型中偏参梯度 tensor([-0.0643])\n",
						"第 7858 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0186]])\n",
						"模型中偏参梯度 tensor([-0.0643])\n",
						"第 7859 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0185]])\n",
						"模型中偏参梯度 tensor([-0.0643])\n",
						"第 7860 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0185]])\n",
						"模型中偏参梯度 tensor([-0.0643])\n",
						"第 393 次epoch\n",
						"第 7861 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0185]])\n",
						"模型中偏参梯度 tensor([-0.0643])\n",
						"第 7862 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0185]])\n",
						"模型中偏参梯度 tensor([-0.0642])\n",
						"第 7863 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0184]])\n",
						"模型中偏参梯度 tensor([-0.0642])\n",
						"第 7864 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0184]])\n",
						"模型中偏参梯度 tensor([-0.0642])\n",
						"第 7865 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0184]])\n",
						"模型中偏参梯度 tensor([-0.0642])\n",
						"第 7866 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0184]])\n",
						"模型中偏参梯度 tensor([-0.0641])\n",
						"第 7867 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0184]])\n",
						"模型中偏参梯度 tensor([-0.0641])\n",
						"第 7868 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0183]])\n",
						"模型中偏参梯度 tensor([-0.0641])\n",
						"第 7869 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0183]])\n",
						"模型中偏参梯度 tensor([-0.0641])\n",
						"第 7870 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0183]])\n",
						"模型中偏参梯度 tensor([-0.0641])\n",
						"第 7871 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0183]])\n",
						"模型中偏参梯度 tensor([-0.0640])\n",
						"第 7872 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0182]])\n",
						"模型中偏参梯度 tensor([-0.0640])\n",
						"第 7873 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0182]])\n",
						"模型中偏参梯度 tensor([-0.0640])\n",
						"第 7874 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0182]])\n",
						"模型中偏参梯度 tensor([-0.0640])\n",
						"第 7875 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0182]])\n",
						"模型中偏参梯度 tensor([-0.0640])\n",
						"第 7876 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0639])\n",
						"第 7877 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0639])\n",
						"第 7878 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0639])\n",
						"第 7879 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0639])\n",
						"第 7880 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0638])\n",
						"第 394 次epoch\n",
						"第 7881 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0638])\n",
						"第 7882 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0638])\n",
						"第 7883 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0638])\n",
						"第 7884 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0637])\n",
						"第 7885 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0637])\n",
						"第 7886 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0637])\n",
						"第 7887 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0636])\n",
						"第 7888 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0636])\n",
						"第 7889 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0636])\n",
						"第 7890 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0636])\n",
						"第 7891 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0635])\n",
						"第 7892 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0635])\n",
						"第 7893 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0635])\n",
						"第 7894 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0634])\n",
						"第 7895 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0634])\n",
						"第 7896 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0634])\n",
						"第 7897 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0634])\n",
						"第 7898 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0633])\n",
						"第 7899 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0633])\n",
						"第 7900 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0633])\n",
						"第 395 次epoch\n",
						"第 7901 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0633])\n",
						"第 7902 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0632])\n",
						"第 7903 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0632])\n",
						"第 7904 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0632])\n",
						"第 7905 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0632])\n",
						"第 7906 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0631])\n",
						"第 7907 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0631])\n",
						"第 7908 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0631])\n",
						"第 7909 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0630])\n",
						"第 7910 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0630])\n",
						"第 7911 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0630])\n",
						"第 7912 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0629])\n",
						"第 7913 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0629])\n",
						"第 7914 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0629])\n",
						"第 7915 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0629])\n",
						"第 7916 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0628])\n",
						"第 7917 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0628])\n",
						"第 7918 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0628])\n",
						"第 7919 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0628])\n",
						"第 7920 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0627])\n",
						"第 396 次epoch\n",
						"第 7921 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0627])\n",
						"第 7922 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0627])\n",
						"第 7923 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0626])\n",
						"第 7924 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0626])\n",
						"第 7925 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0626])\n",
						"第 7926 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0626])\n",
						"第 7927 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0625])\n",
						"第 7928 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0625])\n",
						"第 7929 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0625])\n",
						"第 7930 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0625])\n",
						"第 7931 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0624])\n",
						"第 7932 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0624])\n",
						"第 7933 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0624])\n",
						"第 7934 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0624])\n",
						"第 7935 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0623])\n",
						"第 7936 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0623])\n",
						"第 7937 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0623])\n",
						"第 7938 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0622])\n",
						"第 7939 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0622])\n",
						"第 7940 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0622])\n",
						"第 397 次epoch\n",
						"第 7941 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0622])\n",
						"第 7942 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0621])\n",
						"第 7943 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0621])\n",
						"第 7944 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0621])\n",
						"第 7945 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0621])\n",
						"第 7946 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0620])\n",
						"第 7947 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0620])\n",
						"第 7948 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0620])\n",
						"第 7949 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0620])\n",
						"第 7950 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0619])\n",
						"第 7951 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0619])\n",
						"第 7952 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0619])\n",
						"第 7953 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0618])\n",
						"第 7954 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0618])\n",
						"第 7955 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0618])\n",
						"第 7956 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0618])\n",
						"第 7957 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0617])\n",
						"第 7958 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0617])\n",
						"第 7959 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0617])\n",
						"第 7960 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0617])\n",
						"第 398 次epoch\n",
						"第 7961 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0616])\n",
						"第 7962 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0616])\n",
						"第 7963 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0616])\n",
						"第 7964 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0616])\n",
						"第 7965 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0615])\n",
						"第 7966 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0615])\n",
						"第 7967 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0615])\n",
						"第 7968 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0614])\n",
						"第 7969 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0614])\n",
						"第 7970 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0614])\n",
						"第 7971 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0614])\n",
						"第 7972 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0613])\n",
						"第 7973 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0613])\n",
						"第 7974 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0613])\n",
						"第 7975 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0613])\n",
						"第 7976 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0612])\n",
						"第 7977 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0612])\n",
						"第 7978 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0612])\n",
						"第 7979 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0611])\n",
						"第 7980 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0611])\n",
						"第 399 次epoch\n",
						"第 7981 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0611])\n",
						"第 7982 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0611])\n",
						"第 7983 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0610])\n",
						"第 7984 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0610])\n",
						"第 7985 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0610])\n",
						"第 7986 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0610])\n",
						"第 7987 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0609])\n",
						"第 7988 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0609])\n",
						"第 7989 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0609])\n",
						"第 7990 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0609])\n",
						"第 7991 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0608])\n",
						"第 7992 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0608])\n",
						"第 7993 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0608])\n",
						"第 7994 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0608])\n",
						"第 7995 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0607])\n",
						"第 7996 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0607])\n",
						"第 7997 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0607])\n",
						"第 7998 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0606])\n",
						"第 7999 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0606])\n",
						"第 8000 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0606])\n",
						"第 400 次epoch\n",
						"第 8001 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0606])\n",
						"第 8002 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0605])\n",
						"第 8003 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0605])\n",
						"第 8004 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0605])\n",
						"第 8005 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0605])\n",
						"第 8006 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0181]])\n",
						"模型中偏参梯度 tensor([-0.0604])\n",
						"第 8007 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0180]])\n",
						"模型中偏参梯度 tensor([-0.0604])\n",
						"第 8008 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0180]])\n",
						"模型中偏参梯度 tensor([-0.0604])\n",
						"第 8009 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0180]])\n",
						"模型中偏参梯度 tensor([-0.0604])\n",
						"第 8010 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0180]])\n",
						"模型中偏参梯度 tensor([-0.0603])\n",
						"第 8011 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0180]])\n",
						"模型中偏参梯度 tensor([-0.0603])\n",
						"第 8012 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0180]])\n",
						"模型中偏参梯度 tensor([-0.0603])\n",
						"第 8013 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0180]])\n",
						"模型中偏参梯度 tensor([-0.0603])\n",
						"第 8014 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0180]])\n",
						"模型中偏参梯度 tensor([-0.0603])\n",
						"第 8015 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0180]])\n",
						"模型中偏参梯度 tensor([-0.0602])\n",
						"第 8016 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0180]])\n",
						"模型中偏参梯度 tensor([-0.0602])\n",
						"第 8017 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0180]])\n",
						"模型中偏参梯度 tensor([-0.0602])\n",
						"第 8018 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0180]])\n",
						"模型中偏参梯度 tensor([-0.0602])\n",
						"第 8019 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0180]])\n",
						"模型中偏参梯度 tensor([-0.0601])\n",
						"第 8020 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0180]])\n",
						"模型中偏参梯度 tensor([-0.0601])\n",
						"第 401 次epoch\n",
						"第 8021 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0180]])\n",
						"模型中偏参梯度 tensor([-0.0601])\n",
						"第 8022 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0180]])\n",
						"模型中偏参梯度 tensor([-0.0601])\n",
						"第 8023 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0180]])\n",
						"模型中偏参梯度 tensor([-0.0600])\n",
						"第 8024 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0179]])\n",
						"模型中偏参梯度 tensor([-0.0600])\n",
						"第 8025 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0179]])\n",
						"模型中偏参梯度 tensor([-0.0600])\n",
						"第 8026 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0179]])\n",
						"模型中偏参梯度 tensor([-0.0600])\n",
						"第 8027 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0179]])\n",
						"模型中偏参梯度 tensor([-0.0599])\n",
						"第 8028 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0179]])\n",
						"模型中偏参梯度 tensor([-0.0599])\n",
						"第 8029 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0179]])\n",
						"模型中偏参梯度 tensor([-0.0599])\n",
						"第 8030 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0179]])\n",
						"模型中偏参梯度 tensor([-0.0599])\n",
						"第 8031 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0179]])\n",
						"模型中偏参梯度 tensor([-0.0598])\n",
						"第 8032 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0179]])\n",
						"模型中偏参梯度 tensor([-0.0598])\n",
						"第 8033 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0179]])\n",
						"模型中偏参梯度 tensor([-0.0598])\n",
						"第 8034 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0179]])\n",
						"模型中偏参梯度 tensor([-0.0598])\n",
						"第 8035 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0179]])\n",
						"模型中偏参梯度 tensor([-0.0597])\n",
						"第 8036 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0179]])\n",
						"模型中偏参梯度 tensor([-0.0597])\n",
						"第 8037 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0179]])\n",
						"模型中偏参梯度 tensor([-0.0597])\n",
						"第 8038 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0179]])\n",
						"模型中偏参梯度 tensor([-0.0597])\n",
						"第 8039 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0179]])\n",
						"模型中偏参梯度 tensor([-0.0596])\n",
						"第 8040 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0179]])\n",
						"模型中偏参梯度 tensor([-0.0596])\n",
						"第 402 次epoch\n",
						"第 8041 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0178]])\n",
						"模型中偏参梯度 tensor([-0.0596])\n",
						"第 8042 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0178]])\n",
						"模型中偏参梯度 tensor([-0.0596])\n",
						"第 8043 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0178]])\n",
						"模型中偏参梯度 tensor([-0.0595])\n",
						"第 8044 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0178]])\n",
						"模型中偏参梯度 tensor([-0.0595])\n",
						"第 8045 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0178]])\n",
						"模型中偏参梯度 tensor([-0.0595])\n",
						"第 8046 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0178]])\n",
						"模型中偏参梯度 tensor([-0.0595])\n",
						"第 8047 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0178]])\n",
						"模型中偏参梯度 tensor([-0.0595])\n",
						"第 8048 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0178]])\n",
						"模型中偏参梯度 tensor([-0.0594])\n",
						"第 8049 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0178]])\n",
						"模型中偏参梯度 tensor([-0.0594])\n",
						"第 8050 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0177]])\n",
						"模型中偏参梯度 tensor([-0.0594])\n",
						"第 8051 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0177]])\n",
						"模型中偏参梯度 tensor([-0.0594])\n",
						"第 8052 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0177]])\n",
						"模型中偏参梯度 tensor([-0.0593])\n",
						"第 8053 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0177]])\n",
						"模型中偏参梯度 tensor([-0.0593])\n",
						"第 8054 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0177]])\n",
						"模型中偏参梯度 tensor([-0.0593])\n",
						"第 8055 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0177]])\n",
						"模型中偏参梯度 tensor([-0.0593])\n",
						"第 8056 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0177]])\n",
						"模型中偏参梯度 tensor([-0.0593])\n",
						"第 8057 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0177]])\n",
						"模型中偏参梯度 tensor([-0.0592])\n",
						"第 8058 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0177]])\n",
						"模型中偏参梯度 tensor([-0.0592])\n",
						"第 8059 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0177]])\n",
						"模型中偏参梯度 tensor([-0.0592])\n",
						"第 8060 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0176]])\n",
						"模型中偏参梯度 tensor([-0.0592])\n",
						"第 403 次epoch\n",
						"第 8061 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0176]])\n",
						"模型中偏参梯度 tensor([-0.0591])\n",
						"第 8062 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0176]])\n",
						"模型中偏参梯度 tensor([-0.0591])\n",
						"第 8063 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0176]])\n",
						"模型中偏参梯度 tensor([-0.0591])\n",
						"第 8064 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0176]])\n",
						"模型中偏参梯度 tensor([-0.0591])\n",
						"第 8065 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0176]])\n",
						"模型中偏参梯度 tensor([-0.0590])\n",
						"第 8066 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0176]])\n",
						"模型中偏参梯度 tensor([-0.0590])\n",
						"第 8067 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0176]])\n",
						"模型中偏参梯度 tensor([-0.0590])\n",
						"第 8068 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0175]])\n",
						"模型中偏参梯度 tensor([-0.0590])\n",
						"第 8069 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0175]])\n",
						"模型中偏参梯度 tensor([-0.0590])\n",
						"第 8070 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0175]])\n",
						"模型中偏参梯度 tensor([-0.0589])\n",
						"第 8071 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0175]])\n",
						"模型中偏参梯度 tensor([-0.0589])\n",
						"第 8072 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0175]])\n",
						"模型中偏参梯度 tensor([-0.0589])\n",
						"第 8073 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0175]])\n",
						"模型中偏参梯度 tensor([-0.0589])\n",
						"第 8074 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0175]])\n",
						"模型中偏参梯度 tensor([-0.0588])\n",
						"第 8075 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0175]])\n",
						"模型中偏参梯度 tensor([-0.0588])\n",
						"第 8076 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0175]])\n",
						"模型中偏参梯度 tensor([-0.0588])\n",
						"第 8077 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0174]])\n",
						"模型中偏参梯度 tensor([-0.0588])\n",
						"第 8078 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0174]])\n",
						"模型中偏参梯度 tensor([-0.0588])\n",
						"第 8079 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0174]])\n",
						"模型中偏参梯度 tensor([-0.0587])\n",
						"第 8080 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0174]])\n",
						"模型中偏参梯度 tensor([-0.0587])\n",
						"第 404 次epoch\n",
						"第 8081 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0174]])\n",
						"模型中偏参梯度 tensor([-0.0587])\n",
						"第 8082 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0174]])\n",
						"模型中偏参梯度 tensor([-0.0587])\n",
						"第 8083 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0174]])\n",
						"模型中偏参梯度 tensor([-0.0586])\n",
						"第 8084 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0174]])\n",
						"模型中偏参梯度 tensor([-0.0586])\n",
						"第 8085 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0173]])\n",
						"模型中偏参梯度 tensor([-0.0586])\n",
						"第 8086 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0173]])\n",
						"模型中偏参梯度 tensor([-0.0586])\n",
						"第 8087 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0173]])\n",
						"模型中偏参梯度 tensor([-0.0586])\n",
						"第 8088 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0173]])\n",
						"模型中偏参梯度 tensor([-0.0585])\n",
						"第 8089 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0173]])\n",
						"模型中偏参梯度 tensor([-0.0585])\n",
						"第 8090 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0173]])\n",
						"模型中偏参梯度 tensor([-0.0585])\n",
						"第 8091 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0172]])\n",
						"模型中偏参梯度 tensor([-0.0585])\n",
						"第 8092 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0172]])\n",
						"模型中偏参梯度 tensor([-0.0585])\n",
						"第 8093 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0172]])\n",
						"模型中偏参梯度 tensor([-0.0584])\n",
						"第 8094 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0172]])\n",
						"模型中偏参梯度 tensor([-0.0584])\n",
						"第 8095 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0172]])\n",
						"模型中偏参梯度 tensor([-0.0584])\n",
						"第 8096 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0172]])\n",
						"模型中偏参梯度 tensor([-0.0584])\n",
						"第 8097 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0171]])\n",
						"模型中偏参梯度 tensor([-0.0584])\n",
						"第 8098 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0171]])\n",
						"模型中偏参梯度 tensor([-0.0583])\n",
						"第 8099 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0171]])\n",
						"模型中偏参梯度 tensor([-0.0583])\n",
						"第 8100 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0171]])\n",
						"模型中偏参梯度 tensor([-0.0583])\n",
						"第 405 次epoch\n",
						"第 8101 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0171]])\n",
						"模型中偏参梯度 tensor([-0.0583])\n",
						"第 8102 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0171]])\n",
						"模型中偏参梯度 tensor([-0.0583])\n",
						"第 8103 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0170]])\n",
						"模型中偏参梯度 tensor([-0.0582])\n",
						"第 8104 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0170]])\n",
						"模型中偏参梯度 tensor([-0.0582])\n",
						"第 8105 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0170]])\n",
						"模型中偏参梯度 tensor([-0.0582])\n",
						"第 8106 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0170]])\n",
						"模型中偏参梯度 tensor([-0.0582])\n",
						"第 8107 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0170]])\n",
						"模型中偏参梯度 tensor([-0.0581])\n",
						"第 8108 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0170]])\n",
						"模型中偏参梯度 tensor([-0.0581])\n",
						"第 8109 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0169]])\n",
						"模型中偏参梯度 tensor([-0.0581])\n",
						"第 8110 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0169]])\n",
						"模型中偏参梯度 tensor([-0.0581])\n",
						"第 8111 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0169]])\n",
						"模型中偏参梯度 tensor([-0.0581])\n",
						"第 8112 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0169]])\n",
						"模型中偏参梯度 tensor([-0.0580])\n",
						"第 8113 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0169]])\n",
						"模型中偏参梯度 tensor([-0.0580])\n",
						"第 8114 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0169]])\n",
						"模型中偏参梯度 tensor([-0.0580])\n",
						"第 8115 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0169]])\n",
						"模型中偏参梯度 tensor([-0.0580])\n",
						"第 8116 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0168]])\n",
						"模型中偏参梯度 tensor([-0.0580])\n",
						"第 8117 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0168]])\n",
						"模型中偏参梯度 tensor([-0.0579])\n",
						"第 8118 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0168]])\n",
						"模型中偏参梯度 tensor([-0.0579])\n",
						"第 8119 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0168]])\n",
						"模型中偏参梯度 tensor([-0.0579])\n",
						"第 8120 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0168]])\n",
						"模型中偏参梯度 tensor([-0.0579])\n",
						"第 406 次epoch\n",
						"第 8121 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0167]])\n",
						"模型中偏参梯度 tensor([-0.0579])\n",
						"第 8122 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0167]])\n",
						"模型中偏参梯度 tensor([-0.0578])\n",
						"第 8123 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0167]])\n",
						"模型中偏参梯度 tensor([-0.0578])\n",
						"第 8124 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0167]])\n",
						"模型中偏参梯度 tensor([-0.0578])\n",
						"第 8125 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0167]])\n",
						"模型中偏参梯度 tensor([-0.0578])\n",
						"第 8126 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0167]])\n",
						"模型中偏参梯度 tensor([-0.0578])\n",
						"第 8127 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0166]])\n",
						"模型中偏参梯度 tensor([-0.0577])\n",
						"第 8128 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0166]])\n",
						"模型中偏参梯度 tensor([-0.0577])\n",
						"第 8129 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0166]])\n",
						"模型中偏参梯度 tensor([-0.0577])\n",
						"第 8130 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0166]])\n",
						"模型中偏参梯度 tensor([-0.0577])\n",
						"第 8131 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0166]])\n",
						"模型中偏参梯度 tensor([-0.0577])\n",
						"第 8132 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0166]])\n",
						"模型中偏参梯度 tensor([-0.0576])\n",
						"第 8133 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0165]])\n",
						"模型中偏参梯度 tensor([-0.0576])\n",
						"第 8134 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0165]])\n",
						"模型中偏参梯度 tensor([-0.0576])\n",
						"第 8135 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0165]])\n",
						"模型中偏参梯度 tensor([-0.0576])\n",
						"第 8136 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0165]])\n",
						"模型中偏参梯度 tensor([-0.0576])\n",
						"第 8137 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0164]])\n",
						"模型中偏参梯度 tensor([-0.0575])\n",
						"第 8138 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0164]])\n",
						"模型中偏参梯度 tensor([-0.0575])\n",
						"第 8139 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0164]])\n",
						"模型中偏参梯度 tensor([-0.0575])\n",
						"第 8140 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0164]])\n",
						"模型中偏参梯度 tensor([-0.0575])\n",
						"第 407 次epoch\n",
						"第 8141 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0164]])\n",
						"模型中偏参梯度 tensor([-0.0575])\n",
						"第 8142 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0163]])\n",
						"模型中偏参梯度 tensor([-0.0574])\n",
						"第 8143 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0163]])\n",
						"模型中偏参梯度 tensor([-0.0574])\n",
						"第 8144 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0163]])\n",
						"模型中偏参梯度 tensor([-0.0574])\n",
						"第 8145 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0163]])\n",
						"模型中偏参梯度 tensor([-0.0574])\n",
						"第 8146 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0574])\n",
						"第 8147 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0574])\n",
						"第 8148 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0573])\n",
						"第 8149 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0573])\n",
						"第 8150 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0573])\n",
						"第 8151 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0573])\n",
						"第 8152 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0572])\n",
						"第 8153 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0572])\n",
						"第 8154 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0572])\n",
						"第 8155 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0572])\n",
						"第 8156 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0571])\n",
						"第 8157 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0571])\n",
						"第 8158 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0571])\n",
						"第 8159 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0571])\n",
						"第 8160 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0570])\n",
						"第 408 次epoch\n",
						"第 8161 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0570])\n",
						"第 8162 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0570])\n",
						"第 8163 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0570])\n",
						"第 8164 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0569])\n",
						"第 8165 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0569])\n",
						"第 8166 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0569])\n",
						"第 8167 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0569])\n",
						"第 8168 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0568])\n",
						"第 8169 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0568])\n",
						"第 8170 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0568])\n",
						"第 8171 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0568])\n",
						"第 8172 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0567])\n",
						"第 8173 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0567])\n",
						"第 8174 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0567])\n",
						"第 8175 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0567])\n",
						"第 8176 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0566])\n",
						"第 8177 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0566])\n",
						"第 8178 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0566])\n",
						"第 8179 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0566])\n",
						"第 8180 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0565])\n",
						"第 409 次epoch\n",
						"第 8181 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0565])\n",
						"第 8182 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0565])\n",
						"第 8183 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0565])\n",
						"第 8184 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0564])\n",
						"第 8185 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0564])\n",
						"第 8186 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0564])\n",
						"第 8187 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0564])\n",
						"第 8188 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0564])\n",
						"第 8189 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0563])\n",
						"第 8190 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0563])\n",
						"第 8191 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0563])\n",
						"第 8192 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0563])\n",
						"第 8193 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0562])\n",
						"第 8194 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0562])\n",
						"第 8195 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0562])\n",
						"第 8196 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0562])\n",
						"第 8197 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0561])\n",
						"第 8198 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0561])\n",
						"第 8199 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0561])\n",
						"第 8200 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0561])\n",
						"第 410 次epoch\n",
						"第 8201 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0560])\n",
						"第 8202 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0560])\n",
						"第 8203 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0560])\n",
						"第 8204 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0560])\n",
						"第 8205 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0559])\n",
						"第 8206 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0559])\n",
						"第 8207 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0559])\n",
						"第 8208 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0559])\n",
						"第 8209 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0558])\n",
						"第 8210 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0558])\n",
						"第 8211 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0558])\n",
						"第 8212 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0558])\n",
						"第 8213 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0557])\n",
						"第 8214 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0557])\n",
						"第 8215 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0557])\n",
						"第 8216 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0557])\n",
						"第 8217 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0556])\n",
						"第 8218 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0556])\n",
						"第 8219 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0556])\n",
						"第 8220 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0556])\n",
						"第 411 次epoch\n",
						"第 8221 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0555])\n",
						"第 8222 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0555])\n",
						"第 8223 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0555])\n",
						"第 8224 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0555])\n",
						"第 8225 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0554])\n",
						"第 8226 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0554])\n",
						"第 8227 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0554])\n",
						"第 8228 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0554])\n",
						"第 8229 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0554])\n",
						"第 8230 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0553])\n",
						"第 8231 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0553])\n",
						"第 8232 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0553])\n",
						"第 8233 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0553])\n",
						"第 8234 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0552])\n",
						"第 8235 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0552])\n",
						"第 8236 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0552])\n",
						"第 8237 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0552])\n",
						"第 8238 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0551])\n",
						"第 8239 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0551])\n",
						"第 8240 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0551])\n",
						"第 412 次epoch\n",
						"第 8241 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0551])\n",
						"第 8242 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0550])\n",
						"第 8243 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0550])\n",
						"第 8244 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0550])\n",
						"第 8245 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0550])\n",
						"第 8246 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0549])\n",
						"第 8247 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0549])\n",
						"第 8248 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0549])\n",
						"第 8249 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0549])\n",
						"第 8250 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0549])\n",
						"第 8251 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0548])\n",
						"第 8252 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0548])\n",
						"第 8253 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0548])\n",
						"第 8254 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0548])\n",
						"第 8255 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0547])\n",
						"第 8256 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0547])\n",
						"第 8257 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0547])\n",
						"第 8258 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0547])\n",
						"第 8259 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0546])\n",
						"第 8260 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0546])\n",
						"第 413 次epoch\n",
						"第 8261 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0546])\n",
						"第 8262 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0546])\n",
						"第 8263 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0545])\n",
						"第 8264 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0545])\n",
						"第 8265 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0545])\n",
						"第 8266 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0545])\n",
						"第 8267 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0544])\n",
						"第 8268 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0544])\n",
						"第 8269 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0544])\n",
						"第 8270 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0544])\n",
						"第 8271 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0544])\n",
						"第 8272 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0543])\n",
						"第 8273 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0543])\n",
						"第 8274 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0543])\n",
						"第 8275 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0543])\n",
						"第 8276 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0542])\n",
						"第 8277 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0542])\n",
						"第 8278 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0542])\n",
						"第 8279 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0542])\n",
						"第 8280 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0541])\n",
						"第 414 次epoch\n",
						"第 8281 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0541])\n",
						"第 8282 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0541])\n",
						"第 8283 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0541])\n",
						"第 8284 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0540])\n",
						"第 8285 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0540])\n",
						"第 8286 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0540])\n",
						"第 8287 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0540])\n",
						"第 8288 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0540])\n",
						"第 8289 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0539])\n",
						"第 8290 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0539])\n",
						"第 8291 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0539])\n",
						"第 8292 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0539])\n",
						"第 8293 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0538])\n",
						"第 8294 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0538])\n",
						"第 8295 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0538])\n",
						"第 8296 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0538])\n",
						"第 8297 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0538])\n",
						"第 8298 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0537])\n",
						"第 8299 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0162]])\n",
						"模型中偏参梯度 tensor([-0.0537])\n",
						"第 8300 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0161]])\n",
						"模型中偏参梯度 tensor([-0.0537])\n",
						"第 415 次epoch\n",
						"第 8301 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0161]])\n",
						"模型中偏参梯度 tensor([-0.0537])\n",
						"第 8302 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0161]])\n",
						"模型中偏参梯度 tensor([-0.0536])\n",
						"第 8303 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0161]])\n",
						"模型中偏参梯度 tensor([-0.0536])\n",
						"第 8304 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0161]])\n",
						"模型中偏参梯度 tensor([-0.0536])\n",
						"第 8305 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0161]])\n",
						"模型中偏参梯度 tensor([-0.0536])\n",
						"第 8306 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0161]])\n",
						"模型中偏参梯度 tensor([-0.0536])\n",
						"第 8307 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0161]])\n",
						"模型中偏参梯度 tensor([-0.0535])\n",
						"第 8308 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0161]])\n",
						"模型中偏参梯度 tensor([-0.0535])\n",
						"第 8309 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0161]])\n",
						"模型中偏参梯度 tensor([-0.0535])\n",
						"第 8310 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0161]])\n",
						"模型中偏参梯度 tensor([-0.0535])\n",
						"第 8311 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0161]])\n",
						"模型中偏参梯度 tensor([-0.0534])\n",
						"第 8312 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0161]])\n",
						"模型中偏参梯度 tensor([-0.0534])\n",
						"第 8313 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0161]])\n",
						"模型中偏参梯度 tensor([-0.0534])\n",
						"第 8314 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0161]])\n",
						"模型中偏参梯度 tensor([-0.0534])\n",
						"第 8315 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0161]])\n",
						"模型中偏参梯度 tensor([-0.0534])\n",
						"第 8316 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0161]])\n",
						"模型中偏参梯度 tensor([-0.0533])\n",
						"第 8317 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0161]])\n",
						"模型中偏参梯度 tensor([-0.0533])\n",
						"第 8318 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0161]])\n",
						"模型中偏参梯度 tensor([-0.0533])\n",
						"第 8319 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0160]])\n",
						"模型中偏参梯度 tensor([-0.0533])\n",
						"第 8320 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0160]])\n",
						"模型中偏参梯度 tensor([-0.0533])\n",
						"第 416 次epoch\n",
						"第 8321 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0160]])\n",
						"模型中偏参梯度 tensor([-0.0532])\n",
						"第 8322 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0160]])\n",
						"模型中偏参梯度 tensor([-0.0532])\n",
						"第 8323 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0160]])\n",
						"模型中偏参梯度 tensor([-0.0532])\n",
						"第 8324 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0160]])\n",
						"模型中偏参梯度 tensor([-0.0532])\n",
						"第 8325 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0160]])\n",
						"模型中偏参梯度 tensor([-0.0531])\n",
						"第 8326 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0160]])\n",
						"模型中偏参梯度 tensor([-0.0531])\n",
						"第 8327 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0160]])\n",
						"模型中偏参梯度 tensor([-0.0531])\n",
						"第 8328 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0160]])\n",
						"模型中偏参梯度 tensor([-0.0531])\n",
						"第 8329 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0160]])\n",
						"模型中偏参梯度 tensor([-0.0531])\n",
						"第 8330 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0160]])\n",
						"模型中偏参梯度 tensor([-0.0530])\n",
						"第 8331 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0160]])\n",
						"模型中偏参梯度 tensor([-0.0530])\n",
						"第 8332 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0160]])\n",
						"模型中偏参梯度 tensor([-0.0530])\n",
						"第 8333 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0160]])\n",
						"模型中偏参梯度 tensor([-0.0530])\n",
						"第 8334 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0160]])\n",
						"模型中偏参梯度 tensor([-0.0529])\n",
						"第 8335 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0160]])\n",
						"模型中偏参梯度 tensor([-0.0529])\n",
						"第 8336 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0160]])\n",
						"模型中偏参梯度 tensor([-0.0529])\n",
						"第 8337 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0159]])\n",
						"模型中偏参梯度 tensor([-0.0529])\n",
						"第 8338 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0159]])\n",
						"模型中偏参梯度 tensor([-0.0529])\n",
						"第 8339 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0159]])\n",
						"模型中偏参梯度 tensor([-0.0528])\n",
						"第 8340 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0159]])\n",
						"模型中偏参梯度 tensor([-0.0528])\n",
						"第 417 次epoch\n",
						"第 8341 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0159]])\n",
						"模型中偏参梯度 tensor([-0.0528])\n",
						"第 8342 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0159]])\n",
						"模型中偏参梯度 tensor([-0.0528])\n",
						"第 8343 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0159]])\n",
						"模型中偏参梯度 tensor([-0.0528])\n",
						"第 8344 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0159]])\n",
						"模型中偏参梯度 tensor([-0.0527])\n",
						"第 8345 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0159]])\n",
						"模型中偏参梯度 tensor([-0.0527])\n",
						"第 8346 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0159]])\n",
						"模型中偏参梯度 tensor([-0.0527])\n",
						"第 8347 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0158]])\n",
						"模型中偏参梯度 tensor([-0.0527])\n",
						"第 8348 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0158]])\n",
						"模型中偏参梯度 tensor([-0.0527])\n",
						"第 8349 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0158]])\n",
						"模型中偏参梯度 tensor([-0.0526])\n",
						"第 8350 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0158]])\n",
						"模型中偏参梯度 tensor([-0.0526])\n",
						"第 8351 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0158]])\n",
						"模型中偏参梯度 tensor([-0.0526])\n",
						"第 8352 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0158]])\n",
						"模型中偏参梯度 tensor([-0.0526])\n",
						"第 8353 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0158]])\n",
						"模型中偏参梯度 tensor([-0.0526])\n",
						"第 8354 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0158]])\n",
						"模型中偏参梯度 tensor([-0.0525])\n",
						"第 8355 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0158]])\n",
						"模型中偏参梯度 tensor([-0.0525])\n",
						"第 8356 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0158]])\n",
						"模型中偏参梯度 tensor([-0.0525])\n",
						"第 8357 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0157]])\n",
						"模型中偏参梯度 tensor([-0.0525])\n",
						"第 8358 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0157]])\n",
						"模型中偏参梯度 tensor([-0.0525])\n",
						"第 8359 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0157]])\n",
						"模型中偏参梯度 tensor([-0.0524])\n",
						"第 8360 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0157]])\n",
						"模型中偏参梯度 tensor([-0.0524])\n",
						"第 418 次epoch\n",
						"第 8361 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0157]])\n",
						"模型中偏参梯度 tensor([-0.0524])\n",
						"第 8362 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0157]])\n",
						"模型中偏参梯度 tensor([-0.0524])\n",
						"第 8363 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0157]])\n",
						"模型中偏参梯度 tensor([-0.0524])\n",
						"第 8364 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0157]])\n",
						"模型中偏参梯度 tensor([-0.0523])\n",
						"第 8365 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0156]])\n",
						"模型中偏参梯度 tensor([-0.0523])\n",
						"第 8366 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0156]])\n",
						"模型中偏参梯度 tensor([-0.0523])\n",
						"第 8367 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0156]])\n",
						"模型中偏参梯度 tensor([-0.0523])\n",
						"第 8368 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0156]])\n",
						"模型中偏参梯度 tensor([-0.0523])\n",
						"第 8369 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0156]])\n",
						"模型中偏参梯度 tensor([-0.0522])\n",
						"第 8370 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0156]])\n",
						"模型中偏参梯度 tensor([-0.0522])\n",
						"第 8371 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0156]])\n",
						"模型中偏参梯度 tensor([-0.0522])\n",
						"第 8372 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0156]])\n",
						"模型中偏参梯度 tensor([-0.0522])\n",
						"第 8373 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0156]])\n",
						"模型中偏参梯度 tensor([-0.0522])\n",
						"第 8374 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0156]])\n",
						"模型中偏参梯度 tensor([-0.0522])\n",
						"第 8375 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0155]])\n",
						"模型中偏参梯度 tensor([-0.0521])\n",
						"第 8376 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0155]])\n",
						"模型中偏参梯度 tensor([-0.0521])\n",
						"第 8377 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0155]])\n",
						"模型中偏参梯度 tensor([-0.0521])\n",
						"第 8378 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0155]])\n",
						"模型中偏参梯度 tensor([-0.0521])\n",
						"第 8379 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0155]])\n",
						"模型中偏参梯度 tensor([-0.0521])\n",
						"第 8380 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0155]])\n",
						"模型中偏参梯度 tensor([-0.0520])\n",
						"第 419 次epoch\n",
						"第 8381 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0155]])\n",
						"模型中偏参梯度 tensor([-0.0520])\n",
						"第 8382 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0155]])\n",
						"模型中偏参梯度 tensor([-0.0520])\n",
						"第 8383 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0155]])\n",
						"模型中偏参梯度 tensor([-0.0520])\n",
						"第 8384 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0154]])\n",
						"模型中偏参梯度 tensor([-0.0520])\n",
						"第 8385 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0154]])\n",
						"模型中偏参梯度 tensor([-0.0519])\n",
						"第 8386 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0154]])\n",
						"模型中偏参梯度 tensor([-0.0519])\n",
						"第 8387 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0154]])\n",
						"模型中偏参梯度 tensor([-0.0519])\n",
						"第 8388 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0154]])\n",
						"模型中偏参梯度 tensor([-0.0519])\n",
						"第 8389 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0154]])\n",
						"模型中偏参梯度 tensor([-0.0519])\n",
						"第 8390 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0153]])\n",
						"模型中偏参梯度 tensor([-0.0518])\n",
						"第 8391 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0153]])\n",
						"模型中偏参梯度 tensor([-0.0518])\n",
						"第 8392 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0153]])\n",
						"模型中偏参梯度 tensor([-0.0518])\n",
						"第 8393 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0153]])\n",
						"模型中偏参梯度 tensor([-0.0518])\n",
						"第 8394 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0153]])\n",
						"模型中偏参梯度 tensor([-0.0518])\n",
						"第 8395 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0153]])\n",
						"模型中偏参梯度 tensor([-0.0518])\n",
						"第 8396 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0153]])\n",
						"模型中偏参梯度 tensor([-0.0517])\n",
						"第 8397 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0152]])\n",
						"模型中偏参梯度 tensor([-0.0517])\n",
						"第 8398 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0152]])\n",
						"模型中偏参梯度 tensor([-0.0517])\n",
						"第 8399 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0152]])\n",
						"模型中偏参梯度 tensor([-0.0517])\n",
						"第 8400 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0152]])\n",
						"模型中偏参梯度 tensor([-0.0517])\n",
						"第 420 次epoch\n",
						"第 8401 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0152]])\n",
						"模型中偏参梯度 tensor([-0.0516])\n",
						"第 8402 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0152]])\n",
						"模型中偏参梯度 tensor([-0.0516])\n",
						"第 8403 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0151]])\n",
						"模型中偏参梯度 tensor([-0.0516])\n",
						"第 8404 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0151]])\n",
						"模型中偏参梯度 tensor([-0.0516])\n",
						"第 8405 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0151]])\n",
						"模型中偏参梯度 tensor([-0.0516])\n",
						"第 8406 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0151]])\n",
						"模型中偏参梯度 tensor([-0.0516])\n",
						"第 8407 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0151]])\n",
						"模型中偏参梯度 tensor([-0.0515])\n",
						"第 8408 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0151]])\n",
						"模型中偏参梯度 tensor([-0.0515])\n",
						"第 8409 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0151]])\n",
						"模型中偏参梯度 tensor([-0.0515])\n",
						"第 8410 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0150]])\n",
						"模型中偏参梯度 tensor([-0.0515])\n",
						"第 8411 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0150]])\n",
						"模型中偏参梯度 tensor([-0.0515])\n",
						"第 8412 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0150]])\n",
						"模型中偏参梯度 tensor([-0.0515])\n",
						"第 8413 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0150]])\n",
						"模型中偏参梯度 tensor([-0.0514])\n",
						"第 8414 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0150]])\n",
						"模型中偏参梯度 tensor([-0.0514])\n",
						"第 8415 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0150]])\n",
						"模型中偏参梯度 tensor([-0.0514])\n",
						"第 8416 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0149]])\n",
						"模型中偏参梯度 tensor([-0.0514])\n",
						"第 8417 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0149]])\n",
						"模型中偏参梯度 tensor([-0.0514])\n",
						"第 8418 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0149]])\n",
						"模型中偏参梯度 tensor([-0.0513])\n",
						"第 8419 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0149]])\n",
						"模型中偏参梯度 tensor([-0.0513])\n",
						"第 8420 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0149]])\n",
						"模型中偏参梯度 tensor([-0.0513])\n",
						"第 421 次epoch\n",
						"第 8421 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0149]])\n",
						"模型中偏参梯度 tensor([-0.0513])\n",
						"第 8422 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0148]])\n",
						"模型中偏参梯度 tensor([-0.0513])\n",
						"第 8423 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0148]])\n",
						"模型中偏参梯度 tensor([-0.0513])\n",
						"第 8424 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0148]])\n",
						"模型中偏参梯度 tensor([-0.0512])\n",
						"第 8425 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0148]])\n",
						"模型中偏参梯度 tensor([-0.0512])\n",
						"第 8426 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0148]])\n",
						"模型中偏参梯度 tensor([-0.0512])\n",
						"第 8427 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0148]])\n",
						"模型中偏参梯度 tensor([-0.0512])\n",
						"第 8428 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0147]])\n",
						"模型中偏参梯度 tensor([-0.0512])\n",
						"第 8429 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0147]])\n",
						"模型中偏参梯度 tensor([-0.0511])\n",
						"第 8430 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0147]])\n",
						"模型中偏参梯度 tensor([-0.0511])\n",
						"第 8431 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0147]])\n",
						"模型中偏参梯度 tensor([-0.0511])\n",
						"第 8432 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0147]])\n",
						"模型中偏参梯度 tensor([-0.0511])\n",
						"第 8433 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0147]])\n",
						"模型中偏参梯度 tensor([-0.0511])\n",
						"第 8434 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0147]])\n",
						"模型中偏参梯度 tensor([-0.0511])\n",
						"第 8435 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0146]])\n",
						"模型中偏参梯度 tensor([-0.0510])\n",
						"第 8436 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0146]])\n",
						"模型中偏参梯度 tensor([-0.0510])\n",
						"第 8437 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0146]])\n",
						"模型中偏参梯度 tensor([-0.0510])\n",
						"第 8438 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0146]])\n",
						"模型中偏参梯度 tensor([-0.0510])\n",
						"第 8439 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0146]])\n",
						"模型中偏参梯度 tensor([-0.0510])\n",
						"第 8440 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0145]])\n",
						"模型中偏参梯度 tensor([-0.0510])\n",
						"第 422 次epoch\n",
						"第 8441 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0145]])\n",
						"模型中偏参梯度 tensor([-0.0509])\n",
						"第 8442 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0145]])\n",
						"模型中偏参梯度 tensor([-0.0509])\n",
						"第 8443 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0145]])\n",
						"模型中偏参梯度 tensor([-0.0509])\n",
						"第 8444 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0145]])\n",
						"模型中偏参梯度 tensor([-0.0509])\n",
						"第 8445 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0144]])\n",
						"模型中偏参梯度 tensor([-0.0509])\n",
						"第 8446 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0144]])\n",
						"模型中偏参梯度 tensor([-0.0509])\n",
						"第 8447 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0144]])\n",
						"模型中偏参梯度 tensor([-0.0508])\n",
						"第 8448 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0144]])\n",
						"模型中偏参梯度 tensor([-0.0508])\n",
						"第 8449 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0508])\n",
						"第 8450 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0508])\n",
						"第 8451 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0508])\n",
						"第 8452 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0508])\n",
						"第 8453 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0507])\n",
						"第 8454 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0507])\n",
						"第 8455 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0507])\n",
						"第 8456 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0507])\n",
						"第 8457 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0507])\n",
						"第 8458 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0506])\n",
						"第 8459 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0506])\n",
						"第 8460 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0506])\n",
						"第 423 次epoch\n",
						"第 8461 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0506])\n",
						"第 8462 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0505])\n",
						"第 8463 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0505])\n",
						"第 8464 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0505])\n",
						"第 8465 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0505])\n",
						"第 8466 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0505])\n",
						"第 8467 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0504])\n",
						"第 8468 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0504])\n",
						"第 8469 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0504])\n",
						"第 8470 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0504])\n",
						"第 8471 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0503])\n",
						"第 8472 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0503])\n",
						"第 8473 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0503])\n",
						"第 8474 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0503])\n",
						"第 8475 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0502])\n",
						"第 8476 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0502])\n",
						"第 8477 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0502])\n",
						"第 8478 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0502])\n",
						"第 8479 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0502])\n",
						"第 8480 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0501])\n",
						"第 424 次epoch\n",
						"第 8481 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0501])\n",
						"第 8482 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0501])\n",
						"第 8483 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0501])\n",
						"第 8484 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0501])\n",
						"第 8485 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0500])\n",
						"第 8486 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0500])\n",
						"第 8487 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0500])\n",
						"第 8488 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0500])\n",
						"第 8489 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0499])\n",
						"第 8490 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0499])\n",
						"第 8491 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0499])\n",
						"第 8492 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0499])\n",
						"第 8493 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0499])\n",
						"第 8494 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0498])\n",
						"第 8495 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0498])\n",
						"第 8496 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0498])\n",
						"第 8497 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0498])\n",
						"第 8498 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0498])\n",
						"第 8499 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0497])\n",
						"第 8500 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0497])\n",
						"第 425 次epoch\n",
						"第 8501 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0497])\n",
						"第 8502 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0497])\n",
						"第 8503 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0496])\n",
						"第 8504 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0496])\n",
						"第 8505 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0496])\n",
						"第 8506 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0496])\n",
						"第 8507 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0496])\n",
						"第 8508 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0495])\n",
						"第 8509 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0495])\n",
						"第 8510 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0495])\n",
						"第 8511 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0495])\n",
						"第 8512 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0495])\n",
						"第 8513 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0494])\n",
						"第 8514 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0494])\n",
						"第 8515 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0494])\n",
						"第 8516 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0494])\n",
						"第 8517 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0493])\n",
						"第 8518 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0493])\n",
						"第 8519 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0493])\n",
						"第 8520 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0493])\n",
						"第 426 次epoch\n",
						"第 8521 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0493])\n",
						"第 8522 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0492])\n",
						"第 8523 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0492])\n",
						"第 8524 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0492])\n",
						"第 8525 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0492])\n",
						"第 8526 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0491])\n",
						"第 8527 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0491])\n",
						"第 8528 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0491])\n",
						"第 8529 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0491])\n",
						"第 8530 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0491])\n",
						"第 8531 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0490])\n",
						"第 8532 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0490])\n",
						"第 8533 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0490])\n",
						"第 8534 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0490])\n",
						"第 8535 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0490])\n",
						"第 8536 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0489])\n",
						"第 8537 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0489])\n",
						"第 8538 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0489])\n",
						"第 8539 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0489])\n",
						"第 8540 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0489])\n",
						"第 427 次epoch\n",
						"第 8541 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0488])\n",
						"第 8542 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0488])\n",
						"第 8543 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0488])\n",
						"第 8544 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0488])\n",
						"第 8545 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0488])\n",
						"第 8546 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0487])\n",
						"第 8547 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0487])\n",
						"第 8548 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0487])\n",
						"第 8549 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0487])\n",
						"第 8550 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0487])\n",
						"第 8551 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0486])\n",
						"第 8552 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0486])\n",
						"第 8553 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0486])\n",
						"第 8554 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0486])\n",
						"第 8555 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0485])\n",
						"第 8556 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0485])\n",
						"第 8557 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0485])\n",
						"第 8558 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0485])\n",
						"第 8559 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0485])\n",
						"第 8560 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0484])\n",
						"第 428 次epoch\n",
						"第 8561 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0484])\n",
						"第 8562 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0484])\n",
						"第 8563 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0484])\n",
						"第 8564 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0484])\n",
						"第 8565 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0483])\n",
						"第 8566 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0483])\n",
						"第 8567 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0483])\n",
						"第 8568 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0483])\n",
						"第 8569 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0482])\n",
						"第 8570 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0482])\n",
						"第 8571 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0482])\n",
						"第 8572 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0482])\n",
						"第 8573 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0482])\n",
						"第 8574 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0481])\n",
						"第 8575 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0481])\n",
						"第 8576 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0481])\n",
						"第 8577 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0481])\n",
						"第 8578 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0481])\n",
						"第 8579 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0480])\n",
						"第 8580 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0480])\n",
						"第 429 次epoch\n",
						"第 8581 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0480])\n",
						"第 8582 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0480])\n",
						"第 8583 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0480])\n",
						"第 8584 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0479])\n",
						"第 8585 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0479])\n",
						"第 8586 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0479])\n",
						"第 8587 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0479])\n",
						"第 8588 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0479])\n",
						"第 8589 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0478])\n",
						"第 8590 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0478])\n",
						"第 8591 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0478])\n",
						"第 8592 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0478])\n",
						"第 8593 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0477])\n",
						"第 8594 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0477])\n",
						"第 8595 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0477])\n",
						"第 8596 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0477])\n",
						"第 8597 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0477])\n",
						"第 8598 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0476])\n",
						"第 8599 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0476])\n",
						"第 8600 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0476])\n",
						"第 430 次epoch\n",
						"第 8601 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0476])\n",
						"第 8602 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0476])\n",
						"第 8603 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0475])\n",
						"第 8604 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0475])\n",
						"第 8605 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0475])\n",
						"第 8606 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0475])\n",
						"第 8607 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0475])\n",
						"第 8608 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0474])\n",
						"第 8609 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0474])\n",
						"第 8610 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0474])\n",
						"第 8611 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0474])\n",
						"第 8612 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0474])\n",
						"第 8613 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0473])\n",
						"第 8614 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0473])\n",
						"第 8615 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0473])\n",
						"第 8616 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0473])\n",
						"第 8617 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0472])\n",
						"第 8618 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0472])\n",
						"第 8619 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0472])\n",
						"第 8620 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0472])\n",
						"第 431 次epoch\n",
						"第 8621 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0472])\n",
						"第 8622 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0471])\n",
						"第 8623 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0471])\n",
						"第 8624 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0471])\n",
						"第 8625 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0471])\n",
						"第 8626 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0471])\n",
						"第 8627 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0471])\n",
						"第 8628 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0143]])\n",
						"模型中偏参梯度 tensor([-0.0470])\n",
						"第 8629 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0142]])\n",
						"模型中偏参梯度 tensor([-0.0470])\n",
						"第 8630 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0142]])\n",
						"模型中偏参梯度 tensor([-0.0470])\n",
						"第 8631 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0142]])\n",
						"模型中偏参梯度 tensor([-0.0470])\n",
						"第 8632 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0142]])\n",
						"模型中偏参梯度 tensor([-0.0470])\n",
						"第 8633 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0142]])\n",
						"模型中偏参梯度 tensor([-0.0469])\n",
						"第 8634 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0142]])\n",
						"模型中偏参梯度 tensor([-0.0469])\n",
						"第 8635 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0142]])\n",
						"模型中偏参梯度 tensor([-0.0469])\n",
						"第 8636 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0142]])\n",
						"模型中偏参梯度 tensor([-0.0469])\n",
						"第 8637 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0142]])\n",
						"模型中偏参梯度 tensor([-0.0469])\n",
						"第 8638 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0142]])\n",
						"模型中偏参梯度 tensor([-0.0468])\n",
						"第 8639 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0142]])\n",
						"模型中偏参梯度 tensor([-0.0468])\n",
						"第 8640 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0142]])\n",
						"模型中偏参梯度 tensor([-0.0468])\n",
						"第 432 次epoch\n",
						"第 8641 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0142]])\n",
						"模型中偏参梯度 tensor([-0.0468])\n",
						"第 8642 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0142]])\n",
						"模型中偏参梯度 tensor([-0.0468])\n",
						"第 8643 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0142]])\n",
						"模型中偏参梯度 tensor([-0.0467])\n",
						"第 8644 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0142]])\n",
						"模型中偏参梯度 tensor([-0.0467])\n",
						"第 8645 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0142]])\n",
						"模型中偏参梯度 tensor([-0.0467])\n",
						"第 8646 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0142]])\n",
						"模型中偏参梯度 tensor([-0.0467])\n",
						"第 8647 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0142]])\n",
						"模型中偏参梯度 tensor([-0.0467])\n",
						"第 8648 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0142]])\n",
						"模型中偏参梯度 tensor([-0.0467])\n",
						"第 8649 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0142]])\n",
						"模型中偏参梯度 tensor([-0.0466])\n",
						"第 8650 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0142]])\n",
						"模型中偏参梯度 tensor([-0.0466])\n",
						"第 8651 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0142]])\n",
						"模型中偏参梯度 tensor([-0.0466])\n",
						"第 8652 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0141]])\n",
						"模型中偏参梯度 tensor([-0.0466])\n",
						"第 8653 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0141]])\n",
						"模型中偏参梯度 tensor([-0.0466])\n",
						"第 8654 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0141]])\n",
						"模型中偏参梯度 tensor([-0.0465])\n",
						"第 8655 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0141]])\n",
						"模型中偏参梯度 tensor([-0.0465])\n",
						"第 8656 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0141]])\n",
						"模型中偏参梯度 tensor([-0.0465])\n",
						"第 8657 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0141]])\n",
						"模型中偏参梯度 tensor([-0.0465])\n",
						"第 8658 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0141]])\n",
						"模型中偏参梯度 tensor([-0.0465])\n",
						"第 8659 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0141]])\n",
						"模型中偏参梯度 tensor([-0.0464])\n",
						"第 8660 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0141]])\n",
						"模型中偏参梯度 tensor([-0.0464])\n",
						"第 433 次epoch\n",
						"第 8661 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0141]])\n",
						"模型中偏参梯度 tensor([-0.0464])\n",
						"第 8662 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0141]])\n",
						"模型中偏参梯度 tensor([-0.0464])\n",
						"第 8663 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0141]])\n",
						"模型中偏参梯度 tensor([-0.0464])\n",
						"第 8664 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0141]])\n",
						"模型中偏参梯度 tensor([-0.0463])\n",
						"第 8665 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0141]])\n",
						"模型中偏参梯度 tensor([-0.0463])\n",
						"第 8666 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0141]])\n",
						"模型中偏参梯度 tensor([-0.0463])\n",
						"第 8667 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0141]])\n",
						"模型中偏参梯度 tensor([-0.0463])\n",
						"第 8668 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0141]])\n",
						"模型中偏参梯度 tensor([-0.0463])\n",
						"第 8669 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0141]])\n",
						"模型中偏参梯度 tensor([-0.0463])\n",
						"第 8670 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0141]])\n",
						"模型中偏参梯度 tensor([-0.0462])\n",
						"第 8671 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0141]])\n",
						"模型中偏参梯度 tensor([-0.0462])\n",
						"第 8672 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0140]])\n",
						"模型中偏参梯度 tensor([-0.0462])\n",
						"第 8673 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0140]])\n",
						"模型中偏参梯度 tensor([-0.0462])\n",
						"第 8674 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0140]])\n",
						"模型中偏参梯度 tensor([-0.0462])\n",
						"第 8675 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0140]])\n",
						"模型中偏参梯度 tensor([-0.0461])\n",
						"第 8676 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0140]])\n",
						"模型中偏参梯度 tensor([-0.0461])\n",
						"第 8677 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0140]])\n",
						"模型中偏参梯度 tensor([-0.0461])\n",
						"第 8678 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0140]])\n",
						"模型中偏参梯度 tensor([-0.0461])\n",
						"第 8679 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0140]])\n",
						"模型中偏参梯度 tensor([-0.0461])\n",
						"第 8680 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0140]])\n",
						"模型中偏参梯度 tensor([-0.0461])\n",
						"第 434 次epoch\n",
						"第 8681 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0139]])\n",
						"模型中偏参梯度 tensor([-0.0460])\n",
						"第 8682 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0139]])\n",
						"模型中偏参梯度 tensor([-0.0460])\n",
						"第 8683 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0139]])\n",
						"模型中偏参梯度 tensor([-0.0460])\n",
						"第 8684 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0139]])\n",
						"模型中偏参梯度 tensor([-0.0460])\n",
						"第 8685 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0139]])\n",
						"模型中偏参梯度 tensor([-0.0460])\n",
						"第 8686 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0139]])\n",
						"模型中偏参梯度 tensor([-0.0460])\n",
						"第 8687 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0139]])\n",
						"模型中偏参梯度 tensor([-0.0459])\n",
						"第 8688 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0139]])\n",
						"模型中偏参梯度 tensor([-0.0459])\n",
						"第 8689 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0139]])\n",
						"模型中偏参梯度 tensor([-0.0459])\n",
						"第 8690 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0139]])\n",
						"模型中偏参梯度 tensor([-0.0459])\n",
						"第 8691 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0139]])\n",
						"模型中偏参梯度 tensor([-0.0459])\n",
						"第 8692 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0138]])\n",
						"模型中偏参梯度 tensor([-0.0459])\n",
						"第 8693 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0138]])\n",
						"模型中偏参梯度 tensor([-0.0458])\n",
						"第 8694 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0138]])\n",
						"模型中偏参梯度 tensor([-0.0458])\n",
						"第 8695 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0138]])\n",
						"模型中偏参梯度 tensor([-0.0458])\n",
						"第 8696 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0138]])\n",
						"模型中偏参梯度 tensor([-0.0458])\n",
						"第 8697 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0138]])\n",
						"模型中偏参梯度 tensor([-0.0458])\n",
						"第 8698 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0138]])\n",
						"模型中偏参梯度 tensor([-0.0458])\n",
						"第 8699 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0138]])\n",
						"模型中偏参梯度 tensor([-0.0457])\n",
						"第 8700 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0138]])\n",
						"模型中偏参梯度 tensor([-0.0457])\n",
						"第 435 次epoch\n",
						"第 8701 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0138]])\n",
						"模型中偏参梯度 tensor([-0.0457])\n",
						"第 8702 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0137]])\n",
						"模型中偏参梯度 tensor([-0.0457])\n",
						"第 8703 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0137]])\n",
						"模型中偏参梯度 tensor([-0.0457])\n",
						"第 8704 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0137]])\n",
						"模型中偏参梯度 tensor([-0.0457])\n",
						"第 8705 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0137]])\n",
						"模型中偏参梯度 tensor([-0.0456])\n",
						"第 8706 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0137]])\n",
						"模型中偏参梯度 tensor([-0.0456])\n",
						"第 8707 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0137]])\n",
						"模型中偏参梯度 tensor([-0.0456])\n",
						"第 8708 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0137]])\n",
						"模型中偏参梯度 tensor([-0.0456])\n",
						"第 8709 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0137]])\n",
						"模型中偏参梯度 tensor([-0.0456])\n",
						"第 8710 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0137]])\n",
						"模型中偏参梯度 tensor([-0.0455])\n",
						"第 8711 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0137]])\n",
						"模型中偏参梯度 tensor([-0.0455])\n",
						"第 8712 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0136]])\n",
						"模型中偏参梯度 tensor([-0.0455])\n",
						"第 8713 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0136]])\n",
						"模型中偏参梯度 tensor([-0.0455])\n",
						"第 8714 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0136]])\n",
						"模型中偏参梯度 tensor([-0.0455])\n",
						"第 8715 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0136]])\n",
						"模型中偏参梯度 tensor([-0.0455])\n",
						"第 8716 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0136]])\n",
						"模型中偏参梯度 tensor([-0.0454])\n",
						"第 8717 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0136]])\n",
						"模型中偏参梯度 tensor([-0.0454])\n",
						"第 8718 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0136]])\n",
						"模型中偏参梯度 tensor([-0.0454])\n",
						"第 8719 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0136]])\n",
						"模型中偏参梯度 tensor([-0.0454])\n",
						"第 8720 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0136]])\n",
						"模型中偏参梯度 tensor([-0.0454])\n",
						"第 436 次epoch\n",
						"第 8721 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0136]])\n",
						"模型中偏参梯度 tensor([-0.0454])\n",
						"第 8722 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0135]])\n",
						"模型中偏参梯度 tensor([-0.0453])\n",
						"第 8723 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0135]])\n",
						"模型中偏参梯度 tensor([-0.0453])\n",
						"第 8724 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0135]])\n",
						"模型中偏参梯度 tensor([-0.0453])\n",
						"第 8725 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0135]])\n",
						"模型中偏参梯度 tensor([-0.0453])\n",
						"第 8726 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0135]])\n",
						"模型中偏参梯度 tensor([-0.0453])\n",
						"第 8727 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0135]])\n",
						"模型中偏参梯度 tensor([-0.0453])\n",
						"第 8728 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0135]])\n",
						"模型中偏参梯度 tensor([-0.0452])\n",
						"第 8729 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0135]])\n",
						"模型中偏参梯度 tensor([-0.0452])\n",
						"第 8730 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0134]])\n",
						"模型中偏参梯度 tensor([-0.0452])\n",
						"第 8731 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0134]])\n",
						"模型中偏参梯度 tensor([-0.0452])\n",
						"第 8732 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0134]])\n",
						"模型中偏参梯度 tensor([-0.0452])\n",
						"第 8733 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0134]])\n",
						"模型中偏参梯度 tensor([-0.0452])\n",
						"第 8734 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0134]])\n",
						"模型中偏参梯度 tensor([-0.0452])\n",
						"第 8735 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0134]])\n",
						"模型中偏参梯度 tensor([-0.0451])\n",
						"第 8736 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0133]])\n",
						"模型中偏参梯度 tensor([-0.0451])\n",
						"第 8737 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0133]])\n",
						"模型中偏参梯度 tensor([-0.0451])\n",
						"第 8738 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0133]])\n",
						"模型中偏参梯度 tensor([-0.0451])\n",
						"第 8739 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0133]])\n",
						"模型中偏参梯度 tensor([-0.0451])\n",
						"第 8740 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0133]])\n",
						"模型中偏参梯度 tensor([-0.0451])\n",
						"第 437 次epoch\n",
						"第 8741 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0133]])\n",
						"模型中偏参梯度 tensor([-0.0450])\n",
						"第 8742 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0133]])\n",
						"模型中偏参梯度 tensor([-0.0450])\n",
						"第 8743 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0132]])\n",
						"模型中偏参梯度 tensor([-0.0450])\n",
						"第 8744 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0132]])\n",
						"模型中偏参梯度 tensor([-0.0450])\n",
						"第 8745 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0132]])\n",
						"模型中偏参梯度 tensor([-0.0450])\n",
						"第 8746 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0132]])\n",
						"模型中偏参梯度 tensor([-0.0450])\n",
						"第 8747 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0132]])\n",
						"模型中偏参梯度 tensor([-0.0450])\n",
						"第 8748 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0132]])\n",
						"模型中偏参梯度 tensor([-0.0449])\n",
						"第 8749 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0131]])\n",
						"模型中偏参梯度 tensor([-0.0449])\n",
						"第 8750 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0131]])\n",
						"模型中偏参梯度 tensor([-0.0449])\n",
						"第 8751 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0131]])\n",
						"模型中偏参梯度 tensor([-0.0449])\n",
						"第 8752 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0131]])\n",
						"模型中偏参梯度 tensor([-0.0449])\n",
						"第 8753 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0131]])\n",
						"模型中偏参梯度 tensor([-0.0449])\n",
						"第 8754 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0131]])\n",
						"模型中偏参梯度 tensor([-0.0449])\n",
						"第 8755 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0131]])\n",
						"模型中偏参梯度 tensor([-0.0448])\n",
						"第 8756 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0130]])\n",
						"模型中偏参梯度 tensor([-0.0448])\n",
						"第 8757 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0130]])\n",
						"模型中偏参梯度 tensor([-0.0448])\n",
						"第 8758 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0130]])\n",
						"模型中偏参梯度 tensor([-0.0448])\n",
						"第 8759 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0130]])\n",
						"模型中偏参梯度 tensor([-0.0448])\n",
						"第 8760 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0130]])\n",
						"模型中偏参梯度 tensor([-0.0448])\n",
						"第 438 次epoch\n",
						"第 8761 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0130]])\n",
						"模型中偏参梯度 tensor([-0.0447])\n",
						"第 8762 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0129]])\n",
						"模型中偏参梯度 tensor([-0.0447])\n",
						"第 8763 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0129]])\n",
						"模型中偏参梯度 tensor([-0.0447])\n",
						"第 8764 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0129]])\n",
						"模型中偏参梯度 tensor([-0.0447])\n",
						"第 8765 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0129]])\n",
						"模型中偏参梯度 tensor([-0.0447])\n",
						"第 8766 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0129]])\n",
						"模型中偏参梯度 tensor([-0.0447])\n",
						"第 8767 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0129]])\n",
						"模型中偏参梯度 tensor([-0.0447])\n",
						"第 8768 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0129]])\n",
						"模型中偏参梯度 tensor([-0.0446])\n",
						"第 8769 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0128]])\n",
						"模型中偏参梯度 tensor([-0.0446])\n",
						"第 8770 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0128]])\n",
						"模型中偏参梯度 tensor([-0.0446])\n",
						"第 8771 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0128]])\n",
						"模型中偏参梯度 tensor([-0.0446])\n",
						"第 8772 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0128]])\n",
						"模型中偏参梯度 tensor([-0.0446])\n",
						"第 8773 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0128]])\n",
						"模型中偏参梯度 tensor([-0.0446])\n",
						"第 8774 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0128]])\n",
						"模型中偏参梯度 tensor([-0.0445])\n",
						"第 8775 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0128]])\n",
						"模型中偏参梯度 tensor([-0.0445])\n",
						"第 8776 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0127]])\n",
						"模型中偏参梯度 tensor([-0.0445])\n",
						"第 8777 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0127]])\n",
						"模型中偏参梯度 tensor([-0.0445])\n",
						"第 8778 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0127]])\n",
						"模型中偏参梯度 tensor([-0.0445])\n",
						"第 8779 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0127]])\n",
						"模型中偏参梯度 tensor([-0.0445])\n",
						"第 8780 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0127]])\n",
						"模型中偏参梯度 tensor([-0.0445])\n",
						"第 439 次epoch\n",
						"第 8781 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0127]])\n",
						"模型中偏参梯度 tensor([-0.0444])\n",
						"第 8782 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0126]])\n",
						"模型中偏参梯度 tensor([-0.0444])\n",
						"第 8783 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0126]])\n",
						"模型中偏参梯度 tensor([-0.0444])\n",
						"第 8784 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0126]])\n",
						"模型中偏参梯度 tensor([-0.0444])\n",
						"第 8785 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0126]])\n",
						"模型中偏参梯度 tensor([-0.0444])\n",
						"第 8786 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0126]])\n",
						"模型中偏参梯度 tensor([-0.0444])\n",
						"第 8787 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0126]])\n",
						"模型中偏参梯度 tensor([-0.0443])\n",
						"第 8788 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0126]])\n",
						"模型中偏参梯度 tensor([-0.0443])\n",
						"第 8789 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0125]])\n",
						"模型中偏参梯度 tensor([-0.0443])\n",
						"第 8790 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0125]])\n",
						"模型中偏参梯度 tensor([-0.0443])\n",
						"第 8791 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0125]])\n",
						"模型中偏参梯度 tensor([-0.0443])\n",
						"第 8792 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0125]])\n",
						"模型中偏参梯度 tensor([-0.0443])\n",
						"第 8793 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0125]])\n",
						"模型中偏参梯度 tensor([-0.0443])\n",
						"第 8794 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0443])\n",
						"第 8795 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0442])\n",
						"第 8796 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0442])\n",
						"第 8797 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0442])\n",
						"第 8798 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0442])\n",
						"第 8799 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0442])\n",
						"第 8800 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0442])\n",
						"第 440 次epoch\n",
						"第 8801 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0441])\n",
						"第 8802 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0441])\n",
						"第 8803 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0441])\n",
						"第 8804 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0441])\n",
						"第 8805 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0441])\n",
						"第 8806 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0440])\n",
						"第 8807 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0440])\n",
						"第 8808 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0440])\n",
						"第 8809 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0440])\n",
						"第 8810 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0440])\n",
						"第 8811 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0439])\n",
						"第 8812 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0439])\n",
						"第 8813 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0439])\n",
						"第 8814 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0439])\n",
						"第 8815 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0439])\n",
						"第 8816 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0438])\n",
						"第 8817 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0438])\n",
						"第 8818 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0438])\n",
						"第 8819 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0438])\n",
						"第 8820 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0438])\n",
						"第 441 次epoch\n",
						"第 8821 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0437])\n",
						"第 8822 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0437])\n",
						"第 8823 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0437])\n",
						"第 8824 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0437])\n",
						"第 8825 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0437])\n",
						"第 8826 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0437])\n",
						"第 8827 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0436])\n",
						"第 8828 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0436])\n",
						"第 8829 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0436])\n",
						"第 8830 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0436])\n",
						"第 8831 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0436])\n",
						"第 8832 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0435])\n",
						"第 8833 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0435])\n",
						"第 8834 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0435])\n",
						"第 8835 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0435])\n",
						"第 8836 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0435])\n",
						"第 8837 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0434])\n",
						"第 8838 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0434])\n",
						"第 8839 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0434])\n",
						"第 8840 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0434])\n",
						"第 442 次epoch\n",
						"第 8841 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0434])\n",
						"第 8842 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0434])\n",
						"第 8843 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0433])\n",
						"第 8844 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0433])\n",
						"第 8845 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0433])\n",
						"第 8846 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0433])\n",
						"第 8847 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0433])\n",
						"第 8848 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0432])\n",
						"第 8849 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0432])\n",
						"第 8850 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0432])\n",
						"第 8851 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0432])\n",
						"第 8852 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0432])\n",
						"第 8853 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0431])\n",
						"第 8854 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0431])\n",
						"第 8855 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0431])\n",
						"第 8856 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0431])\n",
						"第 8857 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0431])\n",
						"第 8858 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0431])\n",
						"第 8859 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0430])\n",
						"第 8860 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0430])\n",
						"第 443 次epoch\n",
						"第 8861 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0430])\n",
						"第 8862 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0430])\n",
						"第 8863 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0430])\n",
						"第 8864 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0429])\n",
						"第 8865 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0429])\n",
						"第 8866 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0429])\n",
						"第 8867 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0429])\n",
						"第 8868 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0429])\n",
						"第 8869 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0428])\n",
						"第 8870 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0428])\n",
						"第 8871 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0428])\n",
						"第 8872 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0428])\n",
						"第 8873 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0428])\n",
						"第 8874 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0428])\n",
						"第 8875 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0427])\n",
						"第 8876 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0427])\n",
						"第 8877 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0427])\n",
						"第 8878 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0427])\n",
						"第 8879 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0427])\n",
						"第 8880 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0426])\n",
						"第 444 次epoch\n",
						"第 8881 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0426])\n",
						"第 8882 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0426])\n",
						"第 8883 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0426])\n",
						"第 8884 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0426])\n",
						"第 8885 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0426])\n",
						"第 8886 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0425])\n",
						"第 8887 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0425])\n",
						"第 8888 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0425])\n",
						"第 8889 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0425])\n",
						"第 8890 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0425])\n",
						"第 8891 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0424])\n",
						"第 8892 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0424])\n",
						"第 8893 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0424])\n",
						"第 8894 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0424])\n",
						"第 8895 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0424])\n",
						"第 8896 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0423])\n",
						"第 8897 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0423])\n",
						"第 8898 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0423])\n",
						"第 8899 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0423])\n",
						"第 8900 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0423])\n",
						"第 445 次epoch\n",
						"第 8901 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0423])\n",
						"第 8902 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0422])\n",
						"第 8903 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0422])\n",
						"第 8904 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0422])\n",
						"第 8905 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0422])\n",
						"第 8906 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0422])\n",
						"第 8907 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0421])\n",
						"第 8908 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0421])\n",
						"第 8909 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0421])\n",
						"第 8910 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0421])\n",
						"第 8911 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0421])\n",
						"第 8912 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0421])\n",
						"第 8913 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0420])\n",
						"第 8914 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0420])\n",
						"第 8915 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0420])\n",
						"第 8916 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0420])\n",
						"第 8917 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0420])\n",
						"第 8918 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0419])\n",
						"第 8919 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0419])\n",
						"第 8920 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0419])\n",
						"第 446 次epoch\n",
						"第 8921 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0419])\n",
						"第 8922 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0419])\n",
						"第 8923 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0419])\n",
						"第 8924 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0418])\n",
						"第 8925 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0418])\n",
						"第 8926 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0418])\n",
						"第 8927 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0418])\n",
						"第 8928 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0418])\n",
						"第 8929 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0417])\n",
						"第 8930 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0417])\n",
						"第 8931 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0417])\n",
						"第 8932 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0417])\n",
						"第 8933 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0417])\n",
						"第 8934 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0417])\n",
						"第 8935 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0416])\n",
						"第 8936 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0416])\n",
						"第 8937 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0416])\n",
						"第 8938 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0416])\n",
						"第 8939 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0416])\n",
						"第 8940 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0415])\n",
						"第 447 次epoch\n",
						"第 8941 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0415])\n",
						"第 8942 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0415])\n",
						"第 8943 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0415])\n",
						"第 8944 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0415])\n",
						"第 8945 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0415])\n",
						"第 8946 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0414])\n",
						"第 8947 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0414])\n",
						"第 8948 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0414])\n",
						"第 8949 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0414])\n",
						"第 8950 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0414])\n",
						"第 8951 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0413])\n",
						"第 8952 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0413])\n",
						"第 8953 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0413])\n",
						"第 8954 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0413])\n",
						"第 8955 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0413])\n",
						"第 8956 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0413])\n",
						"第 8957 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0412])\n",
						"第 8958 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0412])\n",
						"第 8959 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0412])\n",
						"第 8960 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0412])\n",
						"第 448 次epoch\n",
						"第 8961 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0412])\n",
						"第 8962 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0412])\n",
						"第 8963 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0411])\n",
						"第 8964 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0411])\n",
						"第 8965 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0411])\n",
						"第 8966 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0411])\n",
						"第 8967 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0411])\n",
						"第 8968 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0410])\n",
						"第 8969 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0410])\n",
						"第 8970 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0410])\n",
						"第 8971 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0410])\n",
						"第 8972 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0410])\n",
						"第 8973 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0410])\n",
						"第 8974 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0409])\n",
						"第 8975 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0409])\n",
						"第 8976 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0409])\n",
						"第 8977 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0409])\n",
						"第 8978 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0409])\n",
						"第 8979 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0408])\n",
						"第 8980 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0408])\n",
						"第 449 次epoch\n",
						"第 8981 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0408])\n",
						"第 8982 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0408])\n",
						"第 8983 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0408])\n",
						"第 8984 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0408])\n",
						"第 8985 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0407])\n",
						"第 8986 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0407])\n",
						"第 8987 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0407])\n",
						"第 8988 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0407])\n",
						"第 8989 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0407])\n",
						"第 8990 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0407])\n",
						"第 8991 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0406])\n",
						"第 8992 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0406])\n",
						"第 8993 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0406])\n",
						"第 8994 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0406])\n",
						"第 8995 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0406])\n",
						"第 8996 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0405])\n",
						"第 8997 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0405])\n",
						"第 8998 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0405])\n",
						"第 8999 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0405])\n",
						"第 9000 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0405])\n",
						"第 450 次epoch\n",
						"第 9001 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0405])\n",
						"第 9002 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0404])\n",
						"第 9003 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0404])\n",
						"第 9004 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0124]])\n",
						"模型中偏参梯度 tensor([-0.0404])\n",
						"第 9005 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0123]])\n",
						"模型中偏参梯度 tensor([-0.0404])\n",
						"第 9006 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0123]])\n",
						"模型中偏参梯度 tensor([-0.0404])\n",
						"第 9007 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0123]])\n",
						"模型中偏参梯度 tensor([-0.0404])\n",
						"第 9008 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0123]])\n",
						"模型中偏参梯度 tensor([-0.0404])\n",
						"第 9009 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0123]])\n",
						"模型中偏参梯度 tensor([-0.0403])\n",
						"第 9010 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0123]])\n",
						"模型中偏参梯度 tensor([-0.0403])\n",
						"第 9011 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0123]])\n",
						"模型中偏参梯度 tensor([-0.0403])\n",
						"第 9012 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0123]])\n",
						"模型中偏参梯度 tensor([-0.0403])\n",
						"第 9013 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0123]])\n",
						"模型中偏参梯度 tensor([-0.0403])\n",
						"第 9014 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0123]])\n",
						"模型中偏参梯度 tensor([-0.0403])\n",
						"第 9015 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0123]])\n",
						"模型中偏参梯度 tensor([-0.0402])\n",
						"第 9016 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0123]])\n",
						"模型中偏参梯度 tensor([-0.0402])\n",
						"第 9017 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0123]])\n",
						"模型中偏参梯度 tensor([-0.0402])\n",
						"第 9018 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0123]])\n",
						"模型中偏参梯度 tensor([-0.0402])\n",
						"第 9019 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0123]])\n",
						"模型中偏参梯度 tensor([-0.0402])\n",
						"第 9020 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0123]])\n",
						"模型中偏参梯度 tensor([-0.0402])\n",
						"第 451 次epoch\n",
						"第 9021 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0123]])\n",
						"模型中偏参梯度 tensor([-0.0401])\n",
						"第 9022 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0123]])\n",
						"模型中偏参梯度 tensor([-0.0401])\n",
						"第 9023 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0123]])\n",
						"模型中偏参梯度 tensor([-0.0401])\n",
						"第 9024 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0123]])\n",
						"模型中偏参梯度 tensor([-0.0401])\n",
						"第 9025 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0123]])\n",
						"模型中偏参梯度 tensor([-0.0401])\n",
						"第 9026 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0123]])\n",
						"模型中偏参梯度 tensor([-0.0401])\n",
						"第 9027 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0123]])\n",
						"模型中偏参梯度 tensor([-0.0400])\n",
						"第 9028 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0123]])\n",
						"模型中偏参梯度 tensor([-0.0400])\n",
						"第 9029 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0123]])\n",
						"模型中偏参梯度 tensor([-0.0400])\n",
						"第 9030 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0122]])\n",
						"模型中偏参梯度 tensor([-0.0400])\n",
						"第 9031 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0122]])\n",
						"模型中偏参梯度 tensor([-0.0400])\n",
						"第 9032 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0122]])\n",
						"模型中偏参梯度 tensor([-0.0400])\n",
						"第 9033 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0122]])\n",
						"模型中偏参梯度 tensor([-0.0399])\n",
						"第 9034 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0122]])\n",
						"模型中偏参梯度 tensor([-0.0399])\n",
						"第 9035 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0122]])\n",
						"模型中偏参梯度 tensor([-0.0399])\n",
						"第 9036 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0122]])\n",
						"模型中偏参梯度 tensor([-0.0399])\n",
						"第 9037 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0122]])\n",
						"模型中偏参梯度 tensor([-0.0399])\n",
						"第 9038 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0122]])\n",
						"模型中偏参梯度 tensor([-0.0399])\n",
						"第 9039 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0122]])\n",
						"模型中偏参梯度 tensor([-0.0398])\n",
						"第 9040 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0122]])\n",
						"模型中偏参梯度 tensor([-0.0398])\n",
						"第 452 次epoch\n",
						"第 9041 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0122]])\n",
						"模型中偏参梯度 tensor([-0.0398])\n",
						"第 9042 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0122]])\n",
						"模型中偏参梯度 tensor([-0.0398])\n",
						"第 9043 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0122]])\n",
						"模型中偏参梯度 tensor([-0.0398])\n",
						"第 9044 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0122]])\n",
						"模型中偏参梯度 tensor([-0.0398])\n",
						"第 9045 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0122]])\n",
						"模型中偏参梯度 tensor([-0.0397])\n",
						"第 9046 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0122]])\n",
						"模型中偏参梯度 tensor([-0.0397])\n",
						"第 9047 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0122]])\n",
						"模型中偏参梯度 tensor([-0.0397])\n",
						"第 9048 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0122]])\n",
						"模型中偏参梯度 tensor([-0.0397])\n",
						"第 9049 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0122]])\n",
						"模型中偏参梯度 tensor([-0.0397])\n",
						"第 9050 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0122]])\n",
						"模型中偏参梯度 tensor([-0.0397])\n",
						"第 9051 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0122]])\n",
						"模型中偏参梯度 tensor([-0.0396])\n",
						"第 9052 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0122]])\n",
						"模型中偏参梯度 tensor([-0.0396])\n",
						"第 9053 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0122]])\n",
						"模型中偏参梯度 tensor([-0.0396])\n",
						"第 9054 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0122]])\n",
						"模型中偏参梯度 tensor([-0.0396])\n",
						"第 9055 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0121]])\n",
						"模型中偏参梯度 tensor([-0.0396])\n",
						"第 9056 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0121]])\n",
						"模型中偏参梯度 tensor([-0.0396])\n",
						"第 9057 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0121]])\n",
						"模型中偏参梯度 tensor([-0.0396])\n",
						"第 9058 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0121]])\n",
						"模型中偏参梯度 tensor([-0.0395])\n",
						"第 9059 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0121]])\n",
						"模型中偏参梯度 tensor([-0.0395])\n",
						"第 9060 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0121]])\n",
						"模型中偏参梯度 tensor([-0.0395])\n",
						"第 453 次epoch\n",
						"第 9061 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0121]])\n",
						"模型中偏参梯度 tensor([-0.0395])\n",
						"第 9062 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0121]])\n",
						"模型中偏参梯度 tensor([-0.0395])\n",
						"第 9063 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0121]])\n",
						"模型中偏参梯度 tensor([-0.0395])\n",
						"第 9064 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0121]])\n",
						"模型中偏参梯度 tensor([-0.0395])\n",
						"第 9065 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0121]])\n",
						"模型中偏参梯度 tensor([-0.0394])\n",
						"第 9066 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0120]])\n",
						"模型中偏参梯度 tensor([-0.0394])\n",
						"第 9067 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0120]])\n",
						"模型中偏参梯度 tensor([-0.0394])\n",
						"第 9068 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0120]])\n",
						"模型中偏参梯度 tensor([-0.0394])\n",
						"第 9069 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0120]])\n",
						"模型中偏参梯度 tensor([-0.0394])\n",
						"第 9070 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0120]])\n",
						"模型中偏参梯度 tensor([-0.0394])\n",
						"第 9071 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0120]])\n",
						"模型中偏参梯度 tensor([-0.0394])\n",
						"第 9072 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0120]])\n",
						"模型中偏参梯度 tensor([-0.0393])\n",
						"第 9073 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0120]])\n",
						"模型中偏参梯度 tensor([-0.0393])\n",
						"第 9074 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0120]])\n",
						"模型中偏参梯度 tensor([-0.0393])\n",
						"第 9075 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0120]])\n",
						"模型中偏参梯度 tensor([-0.0393])\n",
						"第 9076 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0120]])\n",
						"模型中偏参梯度 tensor([-0.0393])\n",
						"第 9077 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0119]])\n",
						"模型中偏参梯度 tensor([-0.0393])\n",
						"第 9078 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0119]])\n",
						"模型中偏参梯度 tensor([-0.0393])\n",
						"第 9079 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0119]])\n",
						"模型中偏参梯度 tensor([-0.0392])\n",
						"第 9080 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0119]])\n",
						"模型中偏参梯度 tensor([-0.0392])\n",
						"第 454 次epoch\n",
						"第 9081 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0119]])\n",
						"模型中偏参梯度 tensor([-0.0392])\n",
						"第 9082 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0119]])\n",
						"模型中偏参梯度 tensor([-0.0392])\n",
						"第 9083 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0119]])\n",
						"模型中偏参梯度 tensor([-0.0392])\n",
						"第 9084 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0119]])\n",
						"模型中偏参梯度 tensor([-0.0392])\n",
						"第 9085 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0119]])\n",
						"模型中偏参梯度 tensor([-0.0391])\n",
						"第 9086 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0119]])\n",
						"模型中偏参梯度 tensor([-0.0391])\n",
						"第 9087 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0119]])\n",
						"模型中偏参梯度 tensor([-0.0391])\n",
						"第 9088 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0119]])\n",
						"模型中偏参梯度 tensor([-0.0391])\n",
						"第 9089 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0118]])\n",
						"模型中偏参梯度 tensor([-0.0391])\n",
						"第 9090 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0118]])\n",
						"模型中偏参梯度 tensor([-0.0391])\n",
						"第 9091 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0118]])\n",
						"模型中偏参梯度 tensor([-0.0391])\n",
						"第 9092 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0118]])\n",
						"模型中偏参梯度 tensor([-0.0390])\n",
						"第 9093 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0118]])\n",
						"模型中偏参梯度 tensor([-0.0390])\n",
						"第 9094 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0118]])\n",
						"模型中偏参梯度 tensor([-0.0390])\n",
						"第 9095 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0118]])\n",
						"模型中偏参梯度 tensor([-0.0390])\n",
						"第 9096 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0118]])\n",
						"模型中偏参梯度 tensor([-0.0390])\n",
						"第 9097 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0118]])\n",
						"模型中偏参梯度 tensor([-0.0390])\n",
						"第 9098 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0117]])\n",
						"模型中偏参梯度 tensor([-0.0390])\n",
						"第 9099 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0117]])\n",
						"模型中偏参梯度 tensor([-0.0389])\n",
						"第 9100 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0117]])\n",
						"模型中偏参梯度 tensor([-0.0389])\n",
						"第 455 次epoch\n",
						"第 9101 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0117]])\n",
						"模型中偏参梯度 tensor([-0.0389])\n",
						"第 9102 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0117]])\n",
						"模型中偏参梯度 tensor([-0.0389])\n",
						"第 9103 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0117]])\n",
						"模型中偏参梯度 tensor([-0.0389])\n",
						"第 9104 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0117]])\n",
						"模型中偏参梯度 tensor([-0.0389])\n",
						"第 9105 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0117]])\n",
						"模型中偏参梯度 tensor([-0.0389])\n",
						"第 9106 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0117]])\n",
						"模型中偏参梯度 tensor([-0.0388])\n",
						"第 9107 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0117]])\n",
						"模型中偏参梯度 tensor([-0.0388])\n",
						"第 9108 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0117]])\n",
						"模型中偏参梯度 tensor([-0.0388])\n",
						"第 9109 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0117]])\n",
						"模型中偏参梯度 tensor([-0.0388])\n",
						"第 9110 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0116]])\n",
						"模型中偏参梯度 tensor([-0.0388])\n",
						"第 9111 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0116]])\n",
						"模型中偏参梯度 tensor([-0.0388])\n",
						"第 9112 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0116]])\n",
						"模型中偏参梯度 tensor([-0.0388])\n",
						"第 9113 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0116]])\n",
						"模型中偏参梯度 tensor([-0.0387])\n",
						"第 9114 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0116]])\n",
						"模型中偏参梯度 tensor([-0.0387])\n",
						"第 9115 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0116]])\n",
						"模型中偏参梯度 tensor([-0.0387])\n",
						"第 9116 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0116]])\n",
						"模型中偏参梯度 tensor([-0.0387])\n",
						"第 9117 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0116]])\n",
						"模型中偏参梯度 tensor([-0.0387])\n",
						"第 9118 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0116]])\n",
						"模型中偏参梯度 tensor([-0.0387])\n",
						"第 9119 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0116]])\n",
						"模型中偏参梯度 tensor([-0.0387])\n",
						"第 9120 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0116]])\n",
						"模型中偏参梯度 tensor([-0.0386])\n",
						"第 456 次epoch\n",
						"第 9121 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0115]])\n",
						"模型中偏参梯度 tensor([-0.0386])\n",
						"第 9122 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0115]])\n",
						"模型中偏参梯度 tensor([-0.0386])\n",
						"第 9123 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0115]])\n",
						"模型中偏参梯度 tensor([-0.0386])\n",
						"第 9124 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0115]])\n",
						"模型中偏参梯度 tensor([-0.0386])\n",
						"第 9125 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0115]])\n",
						"模型中偏参梯度 tensor([-0.0386])\n",
						"第 9126 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0115]])\n",
						"模型中偏参梯度 tensor([-0.0386])\n",
						"第 9127 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0115]])\n",
						"模型中偏参梯度 tensor([-0.0386])\n",
						"第 9128 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0115]])\n",
						"模型中偏参梯度 tensor([-0.0385])\n",
						"第 9129 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0114]])\n",
						"模型中偏参梯度 tensor([-0.0385])\n",
						"第 9130 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0114]])\n",
						"模型中偏参梯度 tensor([-0.0385])\n",
						"第 9131 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0114]])\n",
						"模型中偏参梯度 tensor([-0.0385])\n",
						"第 9132 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0114]])\n",
						"模型中偏参梯度 tensor([-0.0385])\n",
						"第 9133 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0114]])\n",
						"模型中偏参梯度 tensor([-0.0385])\n",
						"第 9134 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0114]])\n",
						"模型中偏参梯度 tensor([-0.0385])\n",
						"第 9135 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0113]])\n",
						"模型中偏参梯度 tensor([-0.0385])\n",
						"第 9136 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0113]])\n",
						"模型中偏参梯度 tensor([-0.0384])\n",
						"第 9137 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0113]])\n",
						"模型中偏参梯度 tensor([-0.0384])\n",
						"第 9138 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0113]])\n",
						"模型中偏参梯度 tensor([-0.0384])\n",
						"第 9139 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0113]])\n",
						"模型中偏参梯度 tensor([-0.0384])\n",
						"第 9140 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0113]])\n",
						"模型中偏参梯度 tensor([-0.0384])\n",
						"第 457 次epoch\n",
						"第 9141 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0113]])\n",
						"模型中偏参梯度 tensor([-0.0384])\n",
						"第 9142 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0112]])\n",
						"模型中偏参梯度 tensor([-0.0384])\n",
						"第 9143 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0112]])\n",
						"模型中偏参梯度 tensor([-0.0384])\n",
						"第 9144 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0112]])\n",
						"模型中偏参梯度 tensor([-0.0383])\n",
						"第 9145 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0112]])\n",
						"模型中偏参梯度 tensor([-0.0383])\n",
						"第 9146 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0112]])\n",
						"模型中偏参梯度 tensor([-0.0383])\n",
						"第 9147 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0112]])\n",
						"模型中偏参梯度 tensor([-0.0383])\n",
						"第 9148 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0112]])\n",
						"模型中偏参梯度 tensor([-0.0383])\n",
						"第 9149 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0111]])\n",
						"模型中偏参梯度 tensor([-0.0383])\n",
						"第 9150 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0111]])\n",
						"模型中偏参梯度 tensor([-0.0383])\n",
						"第 9151 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0111]])\n",
						"模型中偏参梯度 tensor([-0.0383])\n",
						"第 9152 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0111]])\n",
						"模型中偏参梯度 tensor([-0.0382])\n",
						"第 9153 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0111]])\n",
						"模型中偏参梯度 tensor([-0.0382])\n",
						"第 9154 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0111]])\n",
						"模型中偏参梯度 tensor([-0.0382])\n",
						"第 9155 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0111]])\n",
						"模型中偏参梯度 tensor([-0.0382])\n",
						"第 9156 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0110]])\n",
						"模型中偏参梯度 tensor([-0.0382])\n",
						"第 9157 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0110]])\n",
						"模型中偏参梯度 tensor([-0.0382])\n",
						"第 9158 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0110]])\n",
						"模型中偏参梯度 tensor([-0.0382])\n",
						"第 9159 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0110]])\n",
						"模型中偏参梯度 tensor([-0.0382])\n",
						"第 9160 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0110]])\n",
						"模型中偏参梯度 tensor([-0.0381])\n",
						"第 458 次epoch\n",
						"第 9161 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0110]])\n",
						"模型中偏参梯度 tensor([-0.0381])\n",
						"第 9162 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0109]])\n",
						"模型中偏参梯度 tensor([-0.0381])\n",
						"第 9163 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0109]])\n",
						"模型中偏参梯度 tensor([-0.0381])\n",
						"第 9164 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0109]])\n",
						"模型中偏参梯度 tensor([-0.0381])\n",
						"第 9165 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0109]])\n",
						"模型中偏参梯度 tensor([-0.0381])\n",
						"第 9166 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0109]])\n",
						"模型中偏参梯度 tensor([-0.0381])\n",
						"第 9167 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0109]])\n",
						"模型中偏参梯度 tensor([-0.0381])\n",
						"第 9168 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0109]])\n",
						"模型中偏参梯度 tensor([-0.0380])\n",
						"第 9169 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0108]])\n",
						"模型中偏参梯度 tensor([-0.0380])\n",
						"第 9170 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0108]])\n",
						"模型中偏参梯度 tensor([-0.0380])\n",
						"第 9171 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0108]])\n",
						"模型中偏参梯度 tensor([-0.0380])\n",
						"第 9172 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0108]])\n",
						"模型中偏参梯度 tensor([-0.0380])\n",
						"第 9173 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0108]])\n",
						"模型中偏参梯度 tensor([-0.0380])\n",
						"第 9174 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0108]])\n",
						"模型中偏参梯度 tensor([-0.0380])\n",
						"第 9175 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0108]])\n",
						"模型中偏参梯度 tensor([-0.0380])\n",
						"第 9176 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0108]])\n",
						"模型中偏参梯度 tensor([-0.0379])\n",
						"第 9177 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0107]])\n",
						"模型中偏参梯度 tensor([-0.0379])\n",
						"第 9178 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0107]])\n",
						"模型中偏参梯度 tensor([-0.0379])\n",
						"第 9179 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0107]])\n",
						"模型中偏参梯度 tensor([-0.0379])\n",
						"第 9180 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0107]])\n",
						"模型中偏参梯度 tensor([-0.0379])\n",
						"第 459 次epoch\n",
						"第 9181 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0107]])\n",
						"模型中偏参梯度 tensor([-0.0379])\n",
						"第 9182 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0107]])\n",
						"模型中偏参梯度 tensor([-0.0379])\n",
						"第 9183 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0106]])\n",
						"模型中偏参梯度 tensor([-0.0379])\n",
						"第 9184 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0106]])\n",
						"模型中偏参梯度 tensor([-0.0378])\n",
						"第 9185 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0106]])\n",
						"模型中偏参梯度 tensor([-0.0378])\n",
						"第 9186 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0106]])\n",
						"模型中偏参梯度 tensor([-0.0378])\n",
						"第 9187 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0106]])\n",
						"模型中偏参梯度 tensor([-0.0378])\n",
						"第 9188 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0106]])\n",
						"模型中偏参梯度 tensor([-0.0378])\n",
						"第 9189 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0106]])\n",
						"模型中偏参梯度 tensor([-0.0378])\n",
						"第 9190 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0378])\n",
						"第 9191 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0378])\n",
						"第 9192 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0377])\n",
						"第 9193 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0377])\n",
						"第 9194 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0377])\n",
						"第 9195 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0377])\n",
						"第 9196 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0377])\n",
						"第 9197 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0377])\n",
						"第 9198 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0376])\n",
						"第 9199 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0376])\n",
						"第 9200 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0376])\n",
						"第 460 次epoch\n",
						"第 9201 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0376])\n",
						"第 9202 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0376])\n",
						"第 9203 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0376])\n",
						"第 9204 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0376])\n",
						"第 9205 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0375])\n",
						"第 9206 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0375])\n",
						"第 9207 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0375])\n",
						"第 9208 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0375])\n",
						"第 9209 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0375])\n",
						"第 9210 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0375])\n",
						"第 9211 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0374])\n",
						"第 9212 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0374])\n",
						"第 9213 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0374])\n",
						"第 9214 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0374])\n",
						"第 9215 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0374])\n",
						"第 9216 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0374])\n",
						"第 9217 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0373])\n",
						"第 9218 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0373])\n",
						"第 9219 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0373])\n",
						"第 9220 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0373])\n",
						"第 461 次epoch\n",
						"第 9221 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0373])\n",
						"第 9222 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0373])\n",
						"第 9223 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0372])\n",
						"第 9224 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0372])\n",
						"第 9225 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0372])\n",
						"第 9226 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0372])\n",
						"第 9227 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0372])\n",
						"第 9228 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0372])\n",
						"第 9229 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0372])\n",
						"第 9230 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0371])\n",
						"第 9231 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0371])\n",
						"第 9232 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0371])\n",
						"第 9233 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0371])\n",
						"第 9234 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0371])\n",
						"第 9235 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0371])\n",
						"第 9236 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0370])\n",
						"第 9237 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0370])\n",
						"第 9238 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0370])\n",
						"第 9239 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0370])\n",
						"第 9240 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0370])\n",
						"第 462 次epoch\n",
						"第 9241 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0370])\n",
						"第 9242 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0369])\n",
						"第 9243 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0369])\n",
						"第 9244 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0369])\n",
						"第 9245 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0369])\n",
						"第 9246 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0369])\n",
						"第 9247 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0369])\n",
						"第 9248 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0368])\n",
						"第 9249 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0368])\n",
						"第 9250 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0368])\n",
						"第 9251 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0368])\n",
						"第 9252 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0368])\n",
						"第 9253 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0368])\n",
						"第 9254 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0367])\n",
						"第 9255 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0367])\n",
						"第 9256 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0367])\n",
						"第 9257 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0367])\n",
						"第 9258 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0367])\n",
						"第 9259 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0367])\n",
						"第 9260 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0366])\n",
						"第 463 次epoch\n",
						"第 9261 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0366])\n",
						"第 9262 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0366])\n",
						"第 9263 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0366])\n",
						"第 9264 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0366])\n",
						"第 9265 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0366])\n",
						"第 9266 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0366])\n",
						"第 9267 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0365])\n",
						"第 9268 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0365])\n",
						"第 9269 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0365])\n",
						"第 9270 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0365])\n",
						"第 9271 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0365])\n",
						"第 9272 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0365])\n",
						"第 9273 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0364])\n",
						"第 9274 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0364])\n",
						"第 9275 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0364])\n",
						"第 9276 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0364])\n",
						"第 9277 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0364])\n",
						"第 9278 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0364])\n",
						"第 9279 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0364])\n",
						"第 9280 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0363])\n",
						"第 464 次epoch\n",
						"第 9281 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0363])\n",
						"第 9282 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0363])\n",
						"第 9283 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0363])\n",
						"第 9284 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0363])\n",
						"第 9285 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0363])\n",
						"第 9286 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0362])\n",
						"第 9287 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0362])\n",
						"第 9288 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0362])\n",
						"第 9289 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0362])\n",
						"第 9290 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0362])\n",
						"第 9291 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0362])\n",
						"第 9292 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0361])\n",
						"第 9293 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0361])\n",
						"第 9294 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0361])\n",
						"第 9295 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0361])\n",
						"第 9296 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0361])\n",
						"第 9297 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0361])\n",
						"第 9298 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0361])\n",
						"第 9299 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0360])\n",
						"第 9300 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0360])\n",
						"第 465 次epoch\n",
						"第 9301 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0360])\n",
						"第 9302 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0360])\n",
						"第 9303 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0360])\n",
						"第 9304 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0360])\n",
						"第 9305 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0359])\n",
						"第 9306 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0359])\n",
						"第 9307 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0359])\n",
						"第 9308 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0359])\n",
						"第 9309 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0359])\n",
						"第 9310 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0359])\n",
						"第 9311 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0358])\n",
						"第 9312 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0358])\n",
						"第 9313 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0358])\n",
						"第 9314 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0358])\n",
						"第 9315 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0358])\n",
						"第 9316 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0358])\n",
						"第 9317 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0357])\n",
						"第 9318 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0357])\n",
						"第 9319 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0357])\n",
						"第 9320 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0357])\n",
						"第 466 次epoch\n",
						"第 9321 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0357])\n",
						"第 9322 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0357])\n",
						"第 9323 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0357])\n",
						"第 9324 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0356])\n",
						"第 9325 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0356])\n",
						"第 9326 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0356])\n",
						"第 9327 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0356])\n",
						"第 9328 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0356])\n",
						"第 9329 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0356])\n",
						"第 9330 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0356])\n",
						"第 9331 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0355])\n",
						"第 9332 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0355])\n",
						"第 9333 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0355])\n",
						"第 9334 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0355])\n",
						"第 9335 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0355])\n",
						"第 9336 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0355])\n",
						"第 9337 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0354])\n",
						"第 9338 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0354])\n",
						"第 9339 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0354])\n",
						"第 9340 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0354])\n",
						"第 467 次epoch\n",
						"第 9341 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0354])\n",
						"第 9342 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0354])\n",
						"第 9343 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0354])\n",
						"第 9344 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0353])\n",
						"第 9345 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0353])\n",
						"第 9346 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0353])\n",
						"第 9347 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0353])\n",
						"第 9348 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0353])\n",
						"第 9349 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0353])\n",
						"第 9350 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0352])\n",
						"第 9351 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0352])\n",
						"第 9352 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0352])\n",
						"第 9353 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0352])\n",
						"第 9354 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0352])\n",
						"第 9355 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0352])\n",
						"第 9356 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0352])\n",
						"第 9357 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0351])\n",
						"第 9358 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0351])\n",
						"第 9359 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0351])\n",
						"第 9360 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0351])\n",
						"第 468 次epoch\n",
						"第 9361 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0351])\n",
						"第 9362 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0351])\n",
						"第 9363 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0350])\n",
						"第 9364 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0350])\n",
						"第 9365 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0350])\n",
						"第 9366 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0350])\n",
						"第 9367 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0350])\n",
						"第 9368 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0350])\n",
						"第 9369 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0350])\n",
						"第 9370 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0349])\n",
						"第 9371 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0349])\n",
						"第 9372 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0349])\n",
						"第 9373 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0349])\n",
						"第 9374 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0349])\n",
						"第 9375 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0349])\n",
						"第 9376 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0349])\n",
						"第 9377 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0348])\n",
						"第 9378 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0348])\n",
						"第 9379 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0348])\n",
						"第 9380 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0348])\n",
						"第 469 次epoch\n",
						"第 9381 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0348])\n",
						"第 9382 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0348])\n",
						"第 9383 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0347])\n",
						"第 9384 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0347])\n",
						"第 9385 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0347])\n",
						"第 9386 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0347])\n",
						"第 9387 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0347])\n",
						"第 9388 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0347])\n",
						"第 9389 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0347])\n",
						"第 9390 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0346])\n",
						"第 9391 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0346])\n",
						"第 9392 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0346])\n",
						"第 9393 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0346])\n",
						"第 9394 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0346])\n",
						"第 9395 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0346])\n",
						"第 9396 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0346])\n",
						"第 9397 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0345])\n",
						"第 9398 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0345])\n",
						"第 9399 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0345])\n",
						"第 9400 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0345])\n",
						"第 470 次epoch\n",
						"第 9401 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0345])\n",
						"第 9402 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0345])\n",
						"第 9403 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0344])\n",
						"第 9404 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0344])\n",
						"第 9405 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0344])\n",
						"第 9406 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0344])\n",
						"第 9407 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0344])\n",
						"第 9408 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0344])\n",
						"第 9409 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0344])\n",
						"第 9410 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0343])\n",
						"第 9411 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0343])\n",
						"第 9412 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0343])\n",
						"第 9413 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0343])\n",
						"第 9414 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0343])\n",
						"第 9415 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0343])\n",
						"第 9416 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0343])\n",
						"第 9417 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0342])\n",
						"第 9418 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0342])\n",
						"第 9419 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0342])\n",
						"第 9420 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0342])\n",
						"第 471 次epoch\n",
						"第 9421 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0342])\n",
						"第 9422 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0342])\n",
						"第 9423 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0341])\n",
						"第 9424 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0341])\n",
						"第 9425 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0341])\n",
						"第 9426 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0341])\n",
						"第 9427 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0341])\n",
						"第 9428 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0341])\n",
						"第 9429 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0341])\n",
						"第 9430 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0340])\n",
						"第 9431 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0340])\n",
						"第 9432 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0340])\n",
						"第 9433 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0340])\n",
						"第 9434 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0340])\n",
						"第 9435 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0340])\n",
						"第 9436 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0340])\n",
						"第 9437 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0339])\n",
						"第 9438 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0339])\n",
						"第 9439 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0339])\n",
						"第 9440 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0339])\n",
						"第 472 次epoch\n",
						"第 9441 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0339])\n",
						"第 9442 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0339])\n",
						"第 9443 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0338])\n",
						"第 9444 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0338])\n",
						"第 9445 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0338])\n",
						"第 9446 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0338])\n",
						"第 9447 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0338])\n",
						"第 9448 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0338])\n",
						"第 9449 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0338])\n",
						"第 9450 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0338])\n",
						"第 9451 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0337])\n",
						"第 9452 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0105]])\n",
						"模型中偏参梯度 tensor([-0.0337])\n",
						"第 9453 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0104]])\n",
						"模型中偏参梯度 tensor([-0.0337])\n",
						"第 9454 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0104]])\n",
						"模型中偏参梯度 tensor([-0.0337])\n",
						"第 9455 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0104]])\n",
						"模型中偏参梯度 tensor([-0.0337])\n",
						"第 9456 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0104]])\n",
						"模型中偏参梯度 tensor([-0.0337])\n",
						"第 9457 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0104]])\n",
						"模型中偏参梯度 tensor([-0.0337])\n",
						"第 9458 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0104]])\n",
						"模型中偏参梯度 tensor([-0.0336])\n",
						"第 9459 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0104]])\n",
						"模型中偏参梯度 tensor([-0.0336])\n",
						"第 9460 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0104]])\n",
						"模型中偏参梯度 tensor([-0.0336])\n",
						"第 473 次epoch\n",
						"第 9461 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0104]])\n",
						"模型中偏参梯度 tensor([-0.0336])\n",
						"第 9462 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0104]])\n",
						"模型中偏参梯度 tensor([-0.0336])\n",
						"第 9463 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0104]])\n",
						"模型中偏参梯度 tensor([-0.0336])\n",
						"第 9464 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0104]])\n",
						"模型中偏参梯度 tensor([-0.0336])\n",
						"第 9465 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0104]])\n",
						"模型中偏参梯度 tensor([-0.0335])\n",
						"第 9466 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0104]])\n",
						"模型中偏参梯度 tensor([-0.0335])\n",
						"第 9467 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0104]])\n",
						"模型中偏参梯度 tensor([-0.0335])\n",
						"第 9468 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0104]])\n",
						"模型中偏参梯度 tensor([-0.0335])\n",
						"第 9469 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0104]])\n",
						"模型中偏参梯度 tensor([-0.0335])\n",
						"第 9470 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0104]])\n",
						"模型中偏参梯度 tensor([-0.0335])\n",
						"第 9471 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0104]])\n",
						"模型中偏参梯度 tensor([-0.0335])\n",
						"第 9472 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0104]])\n",
						"模型中偏参梯度 tensor([-0.0335])\n",
						"第 9473 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0104]])\n",
						"模型中偏参梯度 tensor([-0.0334])\n",
						"第 9474 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0104]])\n",
						"模型中偏参梯度 tensor([-0.0334])\n",
						"第 9475 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0104]])\n",
						"模型中偏参梯度 tensor([-0.0334])\n",
						"第 9476 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0104]])\n",
						"模型中偏参梯度 tensor([-0.0334])\n",
						"第 9477 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0104]])\n",
						"模型中偏参梯度 tensor([-0.0334])\n",
						"第 9478 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0104]])\n",
						"模型中偏参梯度 tensor([-0.0334])\n",
						"第 9479 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0104]])\n",
						"模型中偏参梯度 tensor([-0.0334])\n",
						"第 9480 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0104]])\n",
						"模型中偏参梯度 tensor([-0.0333])\n",
						"第 474 次epoch\n",
						"第 9481 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0104]])\n",
						"模型中偏参梯度 tensor([-0.0333])\n",
						"第 9482 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0104]])\n",
						"模型中偏参梯度 tensor([-0.0333])\n",
						"第 9483 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0103]])\n",
						"模型中偏参梯度 tensor([-0.0333])\n",
						"第 9484 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0103]])\n",
						"模型中偏参梯度 tensor([-0.0333])\n",
						"第 9485 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0103]])\n",
						"模型中偏参梯度 tensor([-0.0333])\n",
						"第 9486 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0103]])\n",
						"模型中偏参梯度 tensor([-0.0333])\n",
						"第 9487 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0103]])\n",
						"模型中偏参梯度 tensor([-0.0332])\n",
						"第 9488 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0103]])\n",
						"模型中偏参梯度 tensor([-0.0332])\n",
						"第 9489 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0103]])\n",
						"模型中偏参梯度 tensor([-0.0332])\n",
						"第 9490 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0103]])\n",
						"模型中偏参梯度 tensor([-0.0332])\n",
						"第 9491 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0103]])\n",
						"模型中偏参梯度 tensor([-0.0332])\n",
						"第 9492 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0103]])\n",
						"模型中偏参梯度 tensor([-0.0332])\n",
						"第 9493 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0103]])\n",
						"模型中偏参梯度 tensor([-0.0332])\n",
						"第 9494 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0103]])\n",
						"模型中偏参梯度 tensor([-0.0332])\n",
						"第 9495 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0103]])\n",
						"模型中偏参梯度 tensor([-0.0331])\n",
						"第 9496 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0103]])\n",
						"模型中偏参梯度 tensor([-0.0331])\n",
						"第 9497 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0103]])\n",
						"模型中偏参梯度 tensor([-0.0331])\n",
						"第 9498 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0103]])\n",
						"模型中偏参梯度 tensor([-0.0331])\n",
						"第 9499 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0103]])\n",
						"模型中偏参梯度 tensor([-0.0331])\n",
						"第 9500 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0103]])\n",
						"模型中偏参梯度 tensor([-0.0331])\n",
						"第 475 次epoch\n",
						"第 9501 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0103]])\n",
						"模型中偏参梯度 tensor([-0.0331])\n",
						"第 9502 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0103]])\n",
						"模型中偏参梯度 tensor([-0.0330])\n",
						"第 9503 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0103]])\n",
						"模型中偏参梯度 tensor([-0.0330])\n",
						"第 9504 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0103]])\n",
						"模型中偏参梯度 tensor([-0.0330])\n",
						"第 9505 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0103]])\n",
						"模型中偏参梯度 tensor([-0.0330])\n",
						"第 9506 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0103]])\n",
						"模型中偏参梯度 tensor([-0.0330])\n",
						"第 9507 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0103]])\n",
						"模型中偏参梯度 tensor([-0.0330])\n",
						"第 9508 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0103]])\n",
						"模型中偏参梯度 tensor([-0.0330])\n",
						"第 9509 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0103]])\n",
						"模型中偏参梯度 tensor([-0.0329])\n",
						"第 9510 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0103]])\n",
						"模型中偏参梯度 tensor([-0.0329])\n",
						"第 9511 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0103]])\n",
						"模型中偏参梯度 tensor([-0.0329])\n",
						"第 9512 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0103]])\n",
						"模型中偏参梯度 tensor([-0.0329])\n",
						"第 9513 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0102]])\n",
						"模型中偏参梯度 tensor([-0.0329])\n",
						"第 9514 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0102]])\n",
						"模型中偏参梯度 tensor([-0.0329])\n",
						"第 9515 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0102]])\n",
						"模型中偏参梯度 tensor([-0.0329])\n",
						"第 9516 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0102]])\n",
						"模型中偏参梯度 tensor([-0.0329])\n",
						"第 9517 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0102]])\n",
						"模型中偏参梯度 tensor([-0.0328])\n",
						"第 9518 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0102]])\n",
						"模型中偏参梯度 tensor([-0.0328])\n",
						"第 9519 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0102]])\n",
						"模型中偏参梯度 tensor([-0.0328])\n",
						"第 9520 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0102]])\n",
						"模型中偏参梯度 tensor([-0.0328])\n",
						"第 476 次epoch\n",
						"第 9521 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0102]])\n",
						"模型中偏参梯度 tensor([-0.0328])\n",
						"第 9522 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0102]])\n",
						"模型中偏参梯度 tensor([-0.0328])\n",
						"第 9523 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0102]])\n",
						"模型中偏参梯度 tensor([-0.0328])\n",
						"第 9524 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0102]])\n",
						"模型中偏参梯度 tensor([-0.0328])\n",
						"第 9525 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0101]])\n",
						"模型中偏参梯度 tensor([-0.0328])\n",
						"第 9526 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0101]])\n",
						"模型中偏参梯度 tensor([-0.0327])\n",
						"第 9527 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0101]])\n",
						"模型中偏参梯度 tensor([-0.0327])\n",
						"第 9528 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0101]])\n",
						"模型中偏参梯度 tensor([-0.0327])\n",
						"第 9529 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0101]])\n",
						"模型中偏参梯度 tensor([-0.0327])\n",
						"第 9530 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0101]])\n",
						"模型中偏参梯度 tensor([-0.0327])\n",
						"第 9531 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0101]])\n",
						"模型中偏参梯度 tensor([-0.0327])\n",
						"第 9532 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0101]])\n",
						"模型中偏参梯度 tensor([-0.0327])\n",
						"第 9533 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0101]])\n",
						"模型中偏参梯度 tensor([-0.0327])\n",
						"第 9534 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0101]])\n",
						"模型中偏参梯度 tensor([-0.0327])\n",
						"第 9535 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0101]])\n",
						"模型中偏参梯度 tensor([-0.0326])\n",
						"第 9536 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0101]])\n",
						"模型中偏参梯度 tensor([-0.0326])\n",
						"第 9537 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0100]])\n",
						"模型中偏参梯度 tensor([-0.0326])\n",
						"第 9538 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0100]])\n",
						"模型中偏参梯度 tensor([-0.0326])\n",
						"第 9539 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0100]])\n",
						"模型中偏参梯度 tensor([-0.0326])\n",
						"第 9540 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0100]])\n",
						"模型中偏参梯度 tensor([-0.0326])\n",
						"第 477 次epoch\n",
						"第 9541 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0100]])\n",
						"模型中偏参梯度 tensor([-0.0326])\n",
						"第 9542 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0100]])\n",
						"模型中偏参梯度 tensor([-0.0326])\n",
						"第 9543 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0100]])\n",
						"模型中偏参梯度 tensor([-0.0325])\n",
						"第 9544 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0100]])\n",
						"模型中偏参梯度 tensor([-0.0325])\n",
						"第 9545 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0100]])\n",
						"模型中偏参梯度 tensor([-0.0325])\n",
						"第 9546 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0100]])\n",
						"模型中偏参梯度 tensor([-0.0325])\n",
						"第 9547 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0100]])\n",
						"模型中偏参梯度 tensor([-0.0325])\n",
						"第 9548 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0100]])\n",
						"模型中偏参梯度 tensor([-0.0325])\n",
						"第 9549 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0099]])\n",
						"模型中偏参梯度 tensor([-0.0325])\n",
						"第 9550 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0099]])\n",
						"模型中偏参梯度 tensor([-0.0325])\n",
						"第 9551 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0099]])\n",
						"模型中偏参梯度 tensor([-0.0325])\n",
						"第 9552 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0099]])\n",
						"模型中偏参梯度 tensor([-0.0324])\n",
						"第 9553 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0099]])\n",
						"模型中偏参梯度 tensor([-0.0324])\n",
						"第 9554 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0099]])\n",
						"模型中偏参梯度 tensor([-0.0324])\n",
						"第 9555 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0099]])\n",
						"模型中偏参梯度 tensor([-0.0324])\n",
						"第 9556 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0099]])\n",
						"模型中偏参梯度 tensor([-0.0324])\n",
						"第 9557 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0099]])\n",
						"模型中偏参梯度 tensor([-0.0324])\n",
						"第 9558 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0099]])\n",
						"模型中偏参梯度 tensor([-0.0324])\n",
						"第 9559 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0099]])\n",
						"模型中偏参梯度 tensor([-0.0324])\n",
						"第 9560 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0099]])\n",
						"模型中偏参梯度 tensor([-0.0323])\n",
						"第 478 次epoch\n",
						"第 9561 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0098]])\n",
						"模型中偏参梯度 tensor([-0.0323])\n",
						"第 9562 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0098]])\n",
						"模型中偏参梯度 tensor([-0.0323])\n",
						"第 9563 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0098]])\n",
						"模型中偏参梯度 tensor([-0.0323])\n",
						"第 9564 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0098]])\n",
						"模型中偏参梯度 tensor([-0.0323])\n",
						"第 9565 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0098]])\n",
						"模型中偏参梯度 tensor([-0.0323])\n",
						"第 9566 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0098]])\n",
						"模型中偏参梯度 tensor([-0.0323])\n",
						"第 9567 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0098]])\n",
						"模型中偏参梯度 tensor([-0.0323])\n",
						"第 9568 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0098]])\n",
						"模型中偏参梯度 tensor([-0.0323])\n",
						"第 9569 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0098]])\n",
						"模型中偏参梯度 tensor([-0.0322])\n",
						"第 9570 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0098]])\n",
						"模型中偏参梯度 tensor([-0.0322])\n",
						"第 9571 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0097]])\n",
						"模型中偏参梯度 tensor([-0.0322])\n",
						"第 9572 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0097]])\n",
						"模型中偏参梯度 tensor([-0.0322])\n",
						"第 9573 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0097]])\n",
						"模型中偏参梯度 tensor([-0.0322])\n",
						"第 9574 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0097]])\n",
						"模型中偏参梯度 tensor([-0.0322])\n",
						"第 9575 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0097]])\n",
						"模型中偏参梯度 tensor([-0.0322])\n",
						"第 9576 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0097]])\n",
						"模型中偏参梯度 tensor([-0.0322])\n",
						"第 9577 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0097]])\n",
						"模型中偏参梯度 tensor([-0.0321])\n",
						"第 9578 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0097]])\n",
						"模型中偏参梯度 tensor([-0.0321])\n",
						"第 9579 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0097]])\n",
						"模型中偏参梯度 tensor([-0.0321])\n",
						"第 9580 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0097]])\n",
						"模型中偏参梯度 tensor([-0.0321])\n",
						"第 479 次epoch\n",
						"第 9581 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0097]])\n",
						"模型中偏参梯度 tensor([-0.0321])\n",
						"第 9582 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0097]])\n",
						"模型中偏参梯度 tensor([-0.0321])\n",
						"第 9583 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0097]])\n",
						"模型中偏参梯度 tensor([-0.0321])\n",
						"第 9584 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0096]])\n",
						"模型中偏参梯度 tensor([-0.0321])\n",
						"第 9585 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0096]])\n",
						"模型中偏参梯度 tensor([-0.0321])\n",
						"第 9586 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0096]])\n",
						"模型中偏参梯度 tensor([-0.0320])\n",
						"第 9587 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0096]])\n",
						"模型中偏参梯度 tensor([-0.0320])\n",
						"第 9588 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0096]])\n",
						"模型中偏参梯度 tensor([-0.0320])\n",
						"第 9589 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0096]])\n",
						"模型中偏参梯度 tensor([-0.0320])\n",
						"第 9590 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0096]])\n",
						"模型中偏参梯度 tensor([-0.0320])\n",
						"第 9591 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0096]])\n",
						"模型中偏参梯度 tensor([-0.0320])\n",
						"第 9592 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0096]])\n",
						"模型中偏参梯度 tensor([-0.0320])\n",
						"第 9593 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0096]])\n",
						"模型中偏参梯度 tensor([-0.0320])\n",
						"第 9594 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0096]])\n",
						"模型中偏参梯度 tensor([-0.0319])\n",
						"第 9595 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0095]])\n",
						"模型中偏参梯度 tensor([-0.0319])\n",
						"第 9596 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0095]])\n",
						"模型中偏参梯度 tensor([-0.0319])\n",
						"第 9597 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0095]])\n",
						"模型中偏参梯度 tensor([-0.0319])\n",
						"第 9598 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0095]])\n",
						"模型中偏参梯度 tensor([-0.0319])\n",
						"第 9599 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0095]])\n",
						"模型中偏参梯度 tensor([-0.0319])\n",
						"第 9600 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0095]])\n",
						"模型中偏参梯度 tensor([-0.0319])\n",
						"第 480 次epoch\n",
						"第 9601 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0095]])\n",
						"模型中偏参梯度 tensor([-0.0319])\n",
						"第 9602 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0094]])\n",
						"模型中偏参梯度 tensor([-0.0319])\n",
						"第 9603 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0094]])\n",
						"模型中偏参梯度 tensor([-0.0319])\n",
						"第 9604 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0094]])\n",
						"模型中偏参梯度 tensor([-0.0318])\n",
						"第 9605 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0094]])\n",
						"模型中偏参梯度 tensor([-0.0318])\n",
						"第 9606 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0094]])\n",
						"模型中偏参梯度 tensor([-0.0318])\n",
						"第 9607 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0094]])\n",
						"模型中偏参梯度 tensor([-0.0318])\n",
						"第 9608 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0094]])\n",
						"模型中偏参梯度 tensor([-0.0318])\n",
						"第 9609 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0094]])\n",
						"模型中偏参梯度 tensor([-0.0318])\n",
						"第 9610 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0093]])\n",
						"模型中偏参梯度 tensor([-0.0318])\n",
						"第 9611 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0093]])\n",
						"模型中偏参梯度 tensor([-0.0318])\n",
						"第 9612 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0093]])\n",
						"模型中偏参梯度 tensor([-0.0318])\n",
						"第 9613 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0093]])\n",
						"模型中偏参梯度 tensor([-0.0318])\n",
						"第 9614 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0093]])\n",
						"模型中偏参梯度 tensor([-0.0318])\n",
						"第 9615 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0093]])\n",
						"模型中偏参梯度 tensor([-0.0317])\n",
						"第 9616 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0093]])\n",
						"模型中偏参梯度 tensor([-0.0317])\n",
						"第 9617 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0092]])\n",
						"模型中偏参梯度 tensor([-0.0317])\n",
						"第 9618 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0092]])\n",
						"模型中偏参梯度 tensor([-0.0317])\n",
						"第 9619 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0092]])\n",
						"模型中偏参梯度 tensor([-0.0317])\n",
						"第 9620 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0092]])\n",
						"模型中偏参梯度 tensor([-0.0317])\n",
						"第 481 次epoch\n",
						"第 9621 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0092]])\n",
						"模型中偏参梯度 tensor([-0.0317])\n",
						"第 9622 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0092]])\n",
						"模型中偏参梯度 tensor([-0.0317])\n",
						"第 9623 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0092]])\n",
						"模型中偏参梯度 tensor([-0.0317])\n",
						"第 9624 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0091]])\n",
						"模型中偏参梯度 tensor([-0.0317])\n",
						"第 9625 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0091]])\n",
						"模型中偏参梯度 tensor([-0.0316])\n",
						"第 9626 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0091]])\n",
						"模型中偏参梯度 tensor([-0.0316])\n",
						"第 9627 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0091]])\n",
						"模型中偏参梯度 tensor([-0.0316])\n",
						"第 9628 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0091]])\n",
						"模型中偏参梯度 tensor([-0.0316])\n",
						"第 9629 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0091]])\n",
						"模型中偏参梯度 tensor([-0.0316])\n",
						"第 9630 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0091]])\n",
						"模型中偏参梯度 tensor([-0.0316])\n",
						"第 9631 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0090]])\n",
						"模型中偏参梯度 tensor([-0.0316])\n",
						"第 9632 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0090]])\n",
						"模型中偏参梯度 tensor([-0.0316])\n",
						"第 9633 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0090]])\n",
						"模型中偏参梯度 tensor([-0.0316])\n",
						"第 9634 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0090]])\n",
						"模型中偏参梯度 tensor([-0.0316])\n",
						"第 9635 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0090]])\n",
						"模型中偏参梯度 tensor([-0.0315])\n",
						"第 9636 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0090]])\n",
						"模型中偏参梯度 tensor([-0.0315])\n",
						"第 9637 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0090]])\n",
						"模型中偏参梯度 tensor([-0.0315])\n",
						"第 9638 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0089]])\n",
						"模型中偏参梯度 tensor([-0.0315])\n",
						"第 9639 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0089]])\n",
						"模型中偏参梯度 tensor([-0.0315])\n",
						"第 9640 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0089]])\n",
						"模型中偏参梯度 tensor([-0.0315])\n",
						"第 482 次epoch\n",
						"第 9641 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0089]])\n",
						"模型中偏参梯度 tensor([-0.0315])\n",
						"第 9642 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0089]])\n",
						"模型中偏参梯度 tensor([-0.0315])\n",
						"第 9643 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0089]])\n",
						"模型中偏参梯度 tensor([-0.0315])\n",
						"第 9644 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0089]])\n",
						"模型中偏参梯度 tensor([-0.0315])\n",
						"第 9645 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0088]])\n",
						"模型中偏参梯度 tensor([-0.0314])\n",
						"第 9646 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0088]])\n",
						"模型中偏参梯度 tensor([-0.0314])\n",
						"第 9647 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0088]])\n",
						"模型中偏参梯度 tensor([-0.0314])\n",
						"第 9648 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0088]])\n",
						"模型中偏参梯度 tensor([-0.0314])\n",
						"第 9649 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0088]])\n",
						"模型中偏参梯度 tensor([-0.0314])\n",
						"第 9650 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0088]])\n",
						"模型中偏参梯度 tensor([-0.0314])\n",
						"第 9651 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0088]])\n",
						"模型中偏参梯度 tensor([-0.0314])\n",
						"第 9652 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0088]])\n",
						"模型中偏参梯度 tensor([-0.0314])\n",
						"第 9653 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0087]])\n",
						"模型中偏参梯度 tensor([-0.0314])\n",
						"第 9654 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0087]])\n",
						"模型中偏参梯度 tensor([-0.0314])\n",
						"第 9655 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0087]])\n",
						"模型中偏参梯度 tensor([-0.0314])\n",
						"第 9656 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0087]])\n",
						"模型中偏参梯度 tensor([-0.0313])\n",
						"第 9657 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0087]])\n",
						"模型中偏参梯度 tensor([-0.0313])\n",
						"第 9658 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0087]])\n",
						"模型中偏参梯度 tensor([-0.0313])\n",
						"第 9659 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0087]])\n",
						"模型中偏参梯度 tensor([-0.0313])\n",
						"第 9660 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0313])\n",
						"第 483 次epoch\n",
						"第 9661 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0313])\n",
						"第 9662 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0313])\n",
						"第 9663 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0313])\n",
						"第 9664 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0313])\n",
						"第 9665 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0313])\n",
						"第 9666 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0312])\n",
						"第 9667 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0312])\n",
						"第 9668 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0312])\n",
						"第 9669 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0312])\n",
						"第 9670 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0312])\n",
						"第 9671 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0312])\n",
						"第 9672 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0312])\n",
						"第 9673 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0311])\n",
						"第 9674 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0311])\n",
						"第 9675 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0311])\n",
						"第 9676 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0311])\n",
						"第 9677 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0311])\n",
						"第 9678 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0311])\n",
						"第 9679 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0311])\n",
						"第 9680 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0310])\n",
						"第 484 次epoch\n",
						"第 9681 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0310])\n",
						"第 9682 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0310])\n",
						"第 9683 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0310])\n",
						"第 9684 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0310])\n",
						"第 9685 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0310])\n",
						"第 9686 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0310])\n",
						"第 9687 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0309])\n",
						"第 9688 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0309])\n",
						"第 9689 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0309])\n",
						"第 9690 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0309])\n",
						"第 9691 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0309])\n",
						"第 9692 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0309])\n",
						"第 9693 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0309])\n",
						"第 9694 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0309])\n",
						"第 9695 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0308])\n",
						"第 9696 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0308])\n",
						"第 9697 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0308])\n",
						"第 9698 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0308])\n",
						"第 9699 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0308])\n",
						"第 9700 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0308])\n",
						"第 485 次epoch\n",
						"第 9701 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0308])\n",
						"第 9702 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0308])\n",
						"第 9703 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0307])\n",
						"第 9704 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0307])\n",
						"第 9705 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0307])\n",
						"第 9706 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0307])\n",
						"第 9707 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0307])\n",
						"第 9708 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0307])\n",
						"第 9709 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0307])\n",
						"第 9710 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0307])\n",
						"第 9711 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0306])\n",
						"第 9712 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0306])\n",
						"第 9713 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0306])\n",
						"第 9714 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0306])\n",
						"第 9715 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0306])\n",
						"第 9716 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0306])\n",
						"第 9717 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0306])\n",
						"第 9718 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0305])\n",
						"第 9719 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0305])\n",
						"第 9720 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0305])\n",
						"第 486 次epoch\n",
						"第 9721 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0305])\n",
						"第 9722 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0305])\n",
						"第 9723 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0305])\n",
						"第 9724 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0305])\n",
						"第 9725 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0304])\n",
						"第 9726 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0304])\n",
						"第 9727 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0304])\n",
						"第 9728 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0304])\n",
						"第 9729 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0304])\n",
						"第 9730 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0304])\n",
						"第 9731 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0304])\n",
						"第 9732 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0304])\n",
						"第 9733 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0303])\n",
						"第 9734 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0303])\n",
						"第 9735 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0303])\n",
						"第 9736 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0303])\n",
						"第 9737 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0303])\n",
						"第 9738 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0303])\n",
						"第 9739 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0303])\n",
						"第 9740 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0302])\n",
						"第 487 次epoch\n",
						"第 9741 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0302])\n",
						"第 9742 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0302])\n",
						"第 9743 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0302])\n",
						"第 9744 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0302])\n",
						"第 9745 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0302])\n",
						"第 9746 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0302])\n",
						"第 9747 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0302])\n",
						"第 9748 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0301])\n",
						"第 9749 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0301])\n",
						"第 9750 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0301])\n",
						"第 9751 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0301])\n",
						"第 9752 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0301])\n",
						"第 9753 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0301])\n",
						"第 9754 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0301])\n",
						"第 9755 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0301])\n",
						"第 9756 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0300])\n",
						"第 9757 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0300])\n",
						"第 9758 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0300])\n",
						"第 9759 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0300])\n",
						"第 9760 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0300])\n",
						"第 488 次epoch\n",
						"第 9761 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0300])\n",
						"第 9762 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0300])\n",
						"第 9763 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0299])\n",
						"第 9764 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0299])\n",
						"第 9765 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0299])\n",
						"第 9766 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0299])\n",
						"第 9767 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0299])\n",
						"第 9768 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0299])\n",
						"第 9769 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0299])\n",
						"第 9770 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0299])\n",
						"第 9771 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0298])\n",
						"第 9772 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0298])\n",
						"第 9773 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0298])\n",
						"第 9774 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0298])\n",
						"第 9775 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0298])\n",
						"第 9776 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0298])\n",
						"第 9777 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0298])\n",
						"第 9778 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0298])\n",
						"第 9779 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0297])\n",
						"第 9780 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0297])\n",
						"第 489 次epoch\n",
						"第 9781 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0297])\n",
						"第 9782 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0297])\n",
						"第 9783 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0297])\n",
						"第 9784 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0297])\n",
						"第 9785 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0297])\n",
						"第 9786 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0297])\n",
						"第 9787 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0296])\n",
						"第 9788 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0296])\n",
						"第 9789 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0296])\n",
						"第 9790 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0296])\n",
						"第 9791 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0296])\n",
						"第 9792 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0296])\n",
						"第 9793 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0296])\n",
						"第 9794 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0296])\n",
						"第 9795 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0295])\n",
						"第 9796 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0295])\n",
						"第 9797 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0295])\n",
						"第 9798 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0295])\n",
						"第 9799 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0295])\n",
						"第 9800 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0295])\n",
						"第 490 次epoch\n",
						"第 9801 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0295])\n",
						"第 9802 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0295])\n",
						"第 9803 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0294])\n",
						"第 9804 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0294])\n",
						"第 9805 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0294])\n",
						"第 9806 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0294])\n",
						"第 9807 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0294])\n",
						"第 9808 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0294])\n",
						"第 9809 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0294])\n",
						"第 9810 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0293])\n",
						"第 9811 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0293])\n",
						"第 9812 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0293])\n",
						"第 9813 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0293])\n",
						"第 9814 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0293])\n",
						"第 9815 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0293])\n",
						"第 9816 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0293])\n",
						"第 9817 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0293])\n",
						"第 9818 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0292])\n",
						"第 9819 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0292])\n",
						"第 9820 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0292])\n",
						"第 491 次epoch\n",
						"第 9821 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0292])\n",
						"第 9822 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0292])\n",
						"第 9823 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0292])\n",
						"第 9824 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0292])\n",
						"第 9825 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0292])\n",
						"第 9826 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0291])\n",
						"第 9827 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0291])\n",
						"第 9828 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0291])\n",
						"第 9829 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0291])\n",
						"第 9830 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0291])\n",
						"第 9831 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0291])\n",
						"第 9832 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0291])\n",
						"第 9833 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0290])\n",
						"第 9834 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0290])\n",
						"第 9835 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0290])\n",
						"第 9836 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0290])\n",
						"第 9837 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0290])\n",
						"第 9838 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0290])\n",
						"第 9839 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0085]])\n",
						"模型中偏参梯度 tensor([-0.0290])\n",
						"第 9840 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0290])\n",
						"第 492 次epoch\n",
						"第 9841 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0290])\n",
						"第 9842 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0289])\n",
						"第 9843 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0289])\n",
						"第 9844 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0289])\n",
						"第 9845 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0289])\n",
						"第 9846 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0289])\n",
						"第 9847 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0289])\n",
						"第 9848 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0289])\n",
						"第 9849 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0289])\n",
						"第 9850 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0288])\n",
						"第 9851 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0288])\n",
						"第 9852 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0288])\n",
						"第 9853 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0288])\n",
						"第 9854 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0288])\n",
						"第 9855 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0288])\n",
						"第 9856 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0288])\n",
						"第 9857 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0287])\n",
						"第 9858 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0287])\n",
						"第 9859 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0287])\n",
						"第 9860 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0287])\n",
						"第 493 次epoch\n",
						"第 9861 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0287])\n",
						"第 9862 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0287])\n",
						"第 9863 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0287])\n",
						"第 9864 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0287])\n",
						"第 9865 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0287])\n",
						"第 9866 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0286])\n",
						"第 9867 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0286])\n",
						"第 9868 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0286])\n",
						"第 9869 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0286])\n",
						"第 9870 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0286])\n",
						"第 9871 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0286])\n",
						"第 9872 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0286])\n",
						"第 9873 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0286])\n",
						"第 9874 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0285])\n",
						"第 9875 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0285])\n",
						"第 9876 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0285])\n",
						"第 9877 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0285])\n",
						"第 9878 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0285])\n",
						"第 9879 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0285])\n",
						"第 9880 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0285])\n",
						"第 494 次epoch\n",
						"第 9881 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0285])\n",
						"第 9882 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0284])\n",
						"第 9883 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0284])\n",
						"第 9884 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0284])\n",
						"第 9885 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0284])\n",
						"第 9886 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0284])\n",
						"第 9887 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0284])\n",
						"第 9888 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0284])\n",
						"第 9889 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0284])\n",
						"第 9890 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0283])\n",
						"第 9891 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0283])\n",
						"第 9892 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0283])\n",
						"第 9893 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0283])\n",
						"第 9894 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0283])\n",
						"第 9895 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0283])\n",
						"第 9896 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0283])\n",
						"第 9897 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0283])\n",
						"第 9898 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0282])\n",
						"第 9899 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0282])\n",
						"第 9900 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0282])\n",
						"第 495 次epoch\n",
						"第 9901 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0282])\n",
						"第 9902 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0282])\n",
						"第 9903 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0282])\n",
						"第 9904 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0282])\n",
						"第 9905 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0282])\n",
						"第 9906 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0281])\n",
						"第 9907 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0281])\n",
						"第 9908 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0281])\n",
						"第 9909 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0281])\n",
						"第 9910 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0281])\n",
						"第 9911 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0281])\n",
						"第 9912 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0281])\n",
						"第 9913 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0281])\n",
						"第 9914 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0281])\n",
						"第 9915 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0280])\n",
						"第 9916 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0280])\n",
						"第 9917 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0085]])\n",
						"模型中偏参梯度 tensor([-0.0280])\n",
						"第 9918 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0280])\n",
						"第 9919 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0280])\n",
						"第 9920 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0280])\n",
						"第 496 次epoch\n",
						"第 9921 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0280])\n",
						"第 9922 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0280])\n",
						"第 9923 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0279])\n",
						"第 9924 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0279])\n",
						"第 9925 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0279])\n",
						"第 9926 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0279])\n",
						"第 9927 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0279])\n",
						"第 9928 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0279])\n",
						"第 9929 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0085]])\n",
						"模型中偏参梯度 tensor([-0.0279])\n",
						"第 9930 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0279])\n",
						"第 9931 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0278])\n",
						"第 9932 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0278])\n",
						"第 9933 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0278])\n",
						"第 9934 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0278])\n",
						"第 9935 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0278])\n",
						"第 9936 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0278])\n",
						"第 9937 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0278])\n",
						"第 9938 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0278])\n",
						"第 9939 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0277])\n",
						"第 9940 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0277])\n",
						"第 497 次epoch\n",
						"第 9941 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0277])\n",
						"第 9942 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0085]])\n",
						"模型中偏参梯度 tensor([-0.0277])\n",
						"第 9943 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0085]])\n",
						"模型中偏参梯度 tensor([-0.0277])\n",
						"第 9944 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0277])\n",
						"第 9945 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0277])\n",
						"第 9946 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0277])\n",
						"第 9947 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0277])\n",
						"第 9948 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0276])\n",
						"第 9949 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0276])\n",
						"第 9950 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0276])\n",
						"第 9951 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0276])\n",
						"第 9952 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0276])\n",
						"第 9953 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0276])\n",
						"第 9954 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0276])\n",
						"第 9955 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0276])\n",
						"第 9956 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0275])\n",
						"第 9957 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0085]])\n",
						"模型中偏参梯度 tensor([-0.0275])\n",
						"第 9958 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0275])\n",
						"第 9959 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0275])\n",
						"第 9960 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0275])\n",
						"第 498 次epoch\n",
						"第 9961 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0275])\n",
						"第 9962 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0275])\n",
						"第 9963 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0275])\n",
						"第 9964 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0274])\n",
						"第 9965 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0274])\n",
						"第 9966 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0274])\n",
						"第 9967 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0274])\n",
						"第 9968 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0274])\n",
						"第 9969 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0274])\n",
						"第 9970 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0274])\n",
						"第 9971 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0085]])\n",
						"模型中偏参梯度 tensor([-0.0274])\n",
						"第 9972 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0274])\n",
						"第 9973 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0273])\n",
						"第 9974 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0273])\n",
						"第 9975 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0273])\n",
						"第 9976 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0273])\n",
						"第 9977 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0273])\n",
						"第 9978 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0273])\n",
						"第 9979 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0273])\n",
						"第 9980 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0273])\n",
						"第 499 次epoch\n",
						"第 9981 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0272])\n",
						"第 9982 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0272])\n",
						"第 9983 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0272])\n",
						"第 9984 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0272])\n",
						"第 9985 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0085]])\n",
						"模型中偏参梯度 tensor([-0.0272])\n",
						"第 9986 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0272])\n",
						"第 9987 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0272])\n",
						"第 9988 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0085]])\n",
						"模型中偏参梯度 tensor([-0.0272])\n",
						"第 9989 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0086]])\n",
						"模型中偏参梯度 tensor([-0.0272])\n",
						"第 9990 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0085]])\n",
						"模型中偏参梯度 tensor([-0.0271])\n",
						"第 9991 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0085]])\n",
						"模型中偏参梯度 tensor([-0.0271])\n",
						"第 9992 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0085]])\n",
						"模型中偏参梯度 tensor([-0.0271])\n",
						"第 9993 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0085]])\n",
						"模型中偏参梯度 tensor([-0.0271])\n",
						"第 9994 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0085]])\n",
						"模型中偏参梯度 tensor([-0.0271])\n",
						"第 9995 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0085]])\n",
						"模型中偏参梯度 tensor([-0.0271])\n",
						"第 9996 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0085]])\n",
						"模型中偏参梯度 tensor([-0.0271])\n",
						"第 9997 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0085]])\n",
						"模型中偏参梯度 tensor([-0.0271])\n",
						"第 9998 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0085]])\n",
						"模型中偏参梯度 tensor([-0.0271])\n",
						"第 9999 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0085]])\n",
						"模型中偏参梯度 tensor([-0.0270])\n",
						"第 10000 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0085]])\n",
						"模型中偏参梯度 tensor([-0.0270])\n",
						"第 500 次epoch\n",
						"第 10001 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0085]])\n",
						"模型中偏参梯度 tensor([-0.0270])\n",
						"第 10002 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0085]])\n",
						"模型中偏参梯度 tensor([-0.0270])\n",
						"第 10003 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0085]])\n",
						"模型中偏参梯度 tensor([-0.0270])\n",
						"第 10004 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0085]])\n",
						"模型中偏参梯度 tensor([-0.0270])\n",
						"第 10005 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0085]])\n",
						"模型中偏参梯度 tensor([-0.0270])\n",
						"第 10006 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0085]])\n",
						"模型中偏参梯度 tensor([-0.0270])\n",
						"第 10007 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0085]])\n",
						"模型中偏参梯度 tensor([-0.0270])\n",
						"第 10008 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0085]])\n",
						"模型中偏参梯度 tensor([-0.0269])\n",
						"第 10009 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0085]])\n",
						"模型中偏参梯度 tensor([-0.0269])\n",
						"第 10010 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0085]])\n",
						"模型中偏参梯度 tensor([-0.0269])\n",
						"第 10011 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0085]])\n",
						"模型中偏参梯度 tensor([-0.0269])\n",
						"第 10012 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0085]])\n",
						"模型中偏参梯度 tensor([-0.0269])\n",
						"第 10013 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0085]])\n",
						"模型中偏参梯度 tensor([-0.0269])\n",
						"第 10014 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0085]])\n",
						"模型中偏参梯度 tensor([-0.0269])\n",
						"第 10015 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0085]])\n",
						"模型中偏参梯度 tensor([-0.0269])\n",
						"第 10016 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0085]])\n",
						"模型中偏参梯度 tensor([-0.0269])\n",
						"第 10017 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0085]])\n",
						"模型中偏参梯度 tensor([-0.0268])\n",
						"第 10018 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0085]])\n",
						"模型中偏参梯度 tensor([-0.0268])\n",
						"第 10019 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0085]])\n",
						"模型中偏参梯度 tensor([-0.0268])\n",
						"第 10020 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0085]])\n",
						"模型中偏参梯度 tensor([-0.0268])\n",
						"第 501 次epoch\n",
						"第 10021 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0085]])\n",
						"模型中偏参梯度 tensor([-0.0268])\n",
						"第 10022 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0085]])\n",
						"模型中偏参梯度 tensor([-0.0268])\n",
						"第 10023 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0085]])\n",
						"模型中偏参梯度 tensor([-0.0268])\n",
						"第 10024 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0085]])\n",
						"模型中偏参梯度 tensor([-0.0268])\n",
						"第 10025 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0085]])\n",
						"模型中偏参梯度 tensor([-0.0268])\n",
						"第 10026 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0085]])\n",
						"模型中偏参梯度 tensor([-0.0267])\n",
						"第 10027 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0084]])\n",
						"模型中偏参梯度 tensor([-0.0267])\n",
						"第 10028 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0084]])\n",
						"模型中偏参梯度 tensor([-0.0267])\n",
						"第 10029 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0084]])\n",
						"模型中偏参梯度 tensor([-0.0267])\n",
						"第 10030 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0084]])\n",
						"模型中偏参梯度 tensor([-0.0267])\n",
						"第 10031 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0084]])\n",
						"模型中偏参梯度 tensor([-0.0267])\n",
						"第 10032 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0084]])\n",
						"模型中偏参梯度 tensor([-0.0267])\n",
						"第 10033 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0084]])\n",
						"模型中偏参梯度 tensor([-0.0267])\n",
						"第 10034 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0084]])\n",
						"模型中偏参梯度 tensor([-0.0267])\n",
						"第 10035 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0084]])\n",
						"模型中偏参梯度 tensor([-0.0267])\n",
						"第 10036 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0084]])\n",
						"模型中偏参梯度 tensor([-0.0266])\n",
						"第 10037 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0084]])\n",
						"模型中偏参梯度 tensor([-0.0266])\n",
						"第 10038 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0084]])\n",
						"模型中偏参梯度 tensor([-0.0266])\n",
						"第 10039 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0084]])\n",
						"模型中偏参梯度 tensor([-0.0266])\n",
						"第 10040 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0084]])\n",
						"模型中偏参梯度 tensor([-0.0266])\n",
						"第 502 次epoch\n",
						"第 10041 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0084]])\n",
						"模型中偏参梯度 tensor([-0.0266])\n",
						"第 10042 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0084]])\n",
						"模型中偏参梯度 tensor([-0.0266])\n",
						"第 10043 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0084]])\n",
						"模型中偏参梯度 tensor([-0.0266])\n",
						"第 10044 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0084]])\n",
						"模型中偏参梯度 tensor([-0.0266])\n",
						"第 10045 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0084]])\n",
						"模型中偏参梯度 tensor([-0.0265])\n",
						"第 10046 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0084]])\n",
						"模型中偏参梯度 tensor([-0.0265])\n",
						"第 10047 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0084]])\n",
						"模型中偏参梯度 tensor([-0.0265])\n",
						"第 10048 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0084]])\n",
						"模型中偏参梯度 tensor([-0.0265])\n",
						"第 10049 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0084]])\n",
						"模型中偏参梯度 tensor([-0.0265])\n",
						"第 10050 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0084]])\n",
						"模型中偏参梯度 tensor([-0.0265])\n",
						"第 10051 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0084]])\n",
						"模型中偏参梯度 tensor([-0.0265])\n",
						"第 10052 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0084]])\n",
						"模型中偏参梯度 tensor([-0.0265])\n",
						"第 10053 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0084]])\n",
						"模型中偏参梯度 tensor([-0.0265])\n",
						"第 10054 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0084]])\n",
						"模型中偏参梯度 tensor([-0.0264])\n",
						"第 10055 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0084]])\n",
						"模型中偏参梯度 tensor([-0.0264])\n",
						"第 10056 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0084]])\n",
						"模型中偏参梯度 tensor([-0.0264])\n",
						"第 10057 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0084]])\n",
						"模型中偏参梯度 tensor([-0.0264])\n",
						"第 10058 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0084]])\n",
						"模型中偏参梯度 tensor([-0.0264])\n",
						"第 10059 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0084]])\n",
						"模型中偏参梯度 tensor([-0.0264])\n",
						"第 10060 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0084]])\n",
						"模型中偏参梯度 tensor([-0.0264])\n",
						"第 503 次epoch\n",
						"第 10061 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0084]])\n",
						"模型中偏参梯度 tensor([-0.0264])\n",
						"第 10062 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0084]])\n",
						"模型中偏参梯度 tensor([-0.0264])\n",
						"第 10063 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0084]])\n",
						"模型中偏参梯度 tensor([-0.0263])\n",
						"第 10064 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0083]])\n",
						"模型中偏参梯度 tensor([-0.0263])\n",
						"第 10065 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0084]])\n",
						"模型中偏参梯度 tensor([-0.0263])\n",
						"第 10066 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0083]])\n",
						"模型中偏参梯度 tensor([-0.0263])\n",
						"第 10067 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0083]])\n",
						"模型中偏参梯度 tensor([-0.0263])\n",
						"第 10068 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0083]])\n",
						"模型中偏参梯度 tensor([-0.0263])\n",
						"第 10069 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0083]])\n",
						"模型中偏参梯度 tensor([-0.0263])\n",
						"第 10070 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0083]])\n",
						"模型中偏参梯度 tensor([-0.0263])\n",
						"第 10071 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0083]])\n",
						"模型中偏参梯度 tensor([-0.0263])\n",
						"第 10072 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0083]])\n",
						"模型中偏参梯度 tensor([-0.0263])\n",
						"第 10073 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0083]])\n",
						"模型中偏参梯度 tensor([-0.0262])\n",
						"第 10074 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0083]])\n",
						"模型中偏参梯度 tensor([-0.0262])\n",
						"第 10075 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0083]])\n",
						"模型中偏参梯度 tensor([-0.0262])\n",
						"第 10076 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0083]])\n",
						"模型中偏参梯度 tensor([-0.0262])\n",
						"第 10077 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0083]])\n",
						"模型中偏参梯度 tensor([-0.0262])\n",
						"第 10078 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0083]])\n",
						"模型中偏参梯度 tensor([-0.0262])\n",
						"第 10079 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0083]])\n",
						"模型中偏参梯度 tensor([-0.0262])\n",
						"第 10080 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0083]])\n",
						"模型中偏参梯度 tensor([-0.0262])\n",
						"第 504 次epoch\n",
						"第 10081 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0083]])\n",
						"模型中偏参梯度 tensor([-0.0262])\n",
						"第 10082 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0083]])\n",
						"模型中偏参梯度 tensor([-0.0262])\n",
						"第 10083 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0083]])\n",
						"模型中偏参梯度 tensor([-0.0261])\n",
						"第 10084 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0083]])\n",
						"模型中偏参梯度 tensor([-0.0261])\n",
						"第 10085 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0082]])\n",
						"模型中偏参梯度 tensor([-0.0261])\n",
						"第 10086 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0082]])\n",
						"模型中偏参梯度 tensor([-0.0261])\n",
						"第 10087 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0082]])\n",
						"模型中偏参梯度 tensor([-0.0261])\n",
						"第 10088 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0082]])\n",
						"模型中偏参梯度 tensor([-0.0261])\n",
						"第 10089 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0082]])\n",
						"模型中偏参梯度 tensor([-0.0261])\n",
						"第 10090 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0082]])\n",
						"模型中偏参梯度 tensor([-0.0261])\n",
						"第 10091 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0082]])\n",
						"模型中偏参梯度 tensor([-0.0261])\n",
						"第 10092 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0082]])\n",
						"模型中偏参梯度 tensor([-0.0261])\n",
						"第 10093 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0082]])\n",
						"模型中偏参梯度 tensor([-0.0261])\n",
						"第 10094 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0082]])\n",
						"模型中偏参梯度 tensor([-0.0260])\n",
						"第 10095 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0082]])\n",
						"模型中偏参梯度 tensor([-0.0260])\n",
						"第 10096 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0082]])\n",
						"模型中偏参梯度 tensor([-0.0260])\n",
						"第 10097 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0081]])\n",
						"模型中偏参梯度 tensor([-0.0260])\n",
						"第 10098 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0081]])\n",
						"模型中偏参梯度 tensor([-0.0260])\n",
						"第 10099 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0081]])\n",
						"模型中偏参梯度 tensor([-0.0260])\n",
						"第 10100 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0081]])\n",
						"模型中偏参梯度 tensor([-0.0260])\n",
						"第 505 次epoch\n",
						"第 10101 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0081]])\n",
						"模型中偏参梯度 tensor([-0.0260])\n",
						"第 10102 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0081]])\n",
						"模型中偏参梯度 tensor([-0.0260])\n",
						"第 10103 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0081]])\n",
						"模型中偏参梯度 tensor([-0.0260])\n",
						"第 10104 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0081]])\n",
						"模型中偏参梯度 tensor([-0.0260])\n",
						"第 10105 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0081]])\n",
						"模型中偏参梯度 tensor([-0.0259])\n",
						"第 10106 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0081]])\n",
						"模型中偏参梯度 tensor([-0.0259])\n",
						"第 10107 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0081]])\n",
						"模型中偏参梯度 tensor([-0.0259])\n",
						"第 10108 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0081]])\n",
						"模型中偏参梯度 tensor([-0.0259])\n",
						"第 10109 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0081]])\n",
						"模型中偏参梯度 tensor([-0.0259])\n",
						"第 10110 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0080]])\n",
						"模型中偏参梯度 tensor([-0.0259])\n",
						"第 10111 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0080]])\n",
						"模型中偏参梯度 tensor([-0.0259])\n",
						"第 10112 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0080]])\n",
						"模型中偏参梯度 tensor([-0.0259])\n",
						"第 10113 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0080]])\n",
						"模型中偏参梯度 tensor([-0.0259])\n",
						"第 10114 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0080]])\n",
						"模型中偏参梯度 tensor([-0.0259])\n",
						"第 10115 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0080]])\n",
						"模型中偏参梯度 tensor([-0.0259])\n",
						"第 10116 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0080]])\n",
						"模型中偏参梯度 tensor([-0.0258])\n",
						"第 10117 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0080]])\n",
						"模型中偏参梯度 tensor([-0.0258])\n",
						"第 10118 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0080]])\n",
						"模型中偏参梯度 tensor([-0.0258])\n",
						"第 10119 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0080]])\n",
						"模型中偏参梯度 tensor([-0.0258])\n",
						"第 10120 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0080]])\n",
						"模型中偏参梯度 tensor([-0.0258])\n",
						"第 506 次epoch\n",
						"第 10121 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0080]])\n",
						"模型中偏参梯度 tensor([-0.0258])\n",
						"第 10122 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0080]])\n",
						"模型中偏参梯度 tensor([-0.0258])\n",
						"第 10123 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0079]])\n",
						"模型中偏参梯度 tensor([-0.0258])\n",
						"第 10124 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0079]])\n",
						"模型中偏参梯度 tensor([-0.0258])\n",
						"第 10125 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0079]])\n",
						"模型中偏参梯度 tensor([-0.0258])\n",
						"第 10126 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0079]])\n",
						"模型中偏参梯度 tensor([-0.0258])\n",
						"第 10127 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0079]])\n",
						"模型中偏参梯度 tensor([-0.0258])\n",
						"第 10128 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0079]])\n",
						"模型中偏参梯度 tensor([-0.0257])\n",
						"第 10129 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0079]])\n",
						"模型中偏参梯度 tensor([-0.0257])\n",
						"第 10130 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0079]])\n",
						"模型中偏参梯度 tensor([-0.0257])\n",
						"第 10131 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0079]])\n",
						"模型中偏参梯度 tensor([-0.0257])\n",
						"第 10132 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0079]])\n",
						"模型中偏参梯度 tensor([-0.0257])\n",
						"第 10133 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0079]])\n",
						"模型中偏参梯度 tensor([-0.0257])\n",
						"第 10134 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0079]])\n",
						"模型中偏参梯度 tensor([-0.0257])\n",
						"第 10135 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0078]])\n",
						"模型中偏参梯度 tensor([-0.0257])\n",
						"第 10136 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0078]])\n",
						"模型中偏参梯度 tensor([-0.0257])\n",
						"第 10137 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0078]])\n",
						"模型中偏参梯度 tensor([-0.0257])\n",
						"第 10138 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0078]])\n",
						"模型中偏参梯度 tensor([-0.0257])\n",
						"第 10139 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0078]])\n",
						"模型中偏参梯度 tensor([-0.0256])\n",
						"第 10140 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0078]])\n",
						"模型中偏参梯度 tensor([-0.0256])\n",
						"第 507 次epoch\n",
						"第 10141 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0078]])\n",
						"模型中偏参梯度 tensor([-0.0256])\n",
						"第 10142 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0078]])\n",
						"模型中偏参梯度 tensor([-0.0256])\n",
						"第 10143 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0078]])\n",
						"模型中偏参梯度 tensor([-0.0256])\n",
						"第 10144 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0078]])\n",
						"模型中偏参梯度 tensor([-0.0256])\n",
						"第 10145 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0078]])\n",
						"模型中偏参梯度 tensor([-0.0256])\n",
						"第 10146 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0078]])\n",
						"模型中偏参梯度 tensor([-0.0256])\n",
						"第 10147 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0078]])\n",
						"模型中偏参梯度 tensor([-0.0256])\n",
						"第 10148 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0077]])\n",
						"模型中偏参梯度 tensor([-0.0256])\n",
						"第 10149 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0077]])\n",
						"模型中偏参梯度 tensor([-0.0256])\n",
						"第 10150 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0077]])\n",
						"模型中偏参梯度 tensor([-0.0255])\n",
						"第 10151 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0077]])\n",
						"模型中偏参梯度 tensor([-0.0255])\n",
						"第 10152 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0077]])\n",
						"模型中偏参梯度 tensor([-0.0255])\n",
						"第 10153 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0077]])\n",
						"模型中偏参梯度 tensor([-0.0255])\n",
						"第 10154 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0077]])\n",
						"模型中偏参梯度 tensor([-0.0255])\n",
						"第 10155 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0077]])\n",
						"模型中偏参梯度 tensor([-0.0255])\n",
						"第 10156 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0077]])\n",
						"模型中偏参梯度 tensor([-0.0255])\n",
						"第 10157 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0077]])\n",
						"模型中偏参梯度 tensor([-0.0255])\n",
						"第 10158 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0077]])\n",
						"模型中偏参梯度 tensor([-0.0255])\n",
						"第 10159 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0077]])\n",
						"模型中偏参梯度 tensor([-0.0255])\n",
						"第 10160 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0077]])\n",
						"模型中偏参梯度 tensor([-0.0255])\n",
						"第 508 次epoch\n",
						"第 10161 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0076]])\n",
						"模型中偏参梯度 tensor([-0.0254])\n",
						"第 10162 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0076]])\n",
						"模型中偏参梯度 tensor([-0.0254])\n",
						"第 10163 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0076]])\n",
						"模型中偏参梯度 tensor([-0.0254])\n",
						"第 10164 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0076]])\n",
						"模型中偏参梯度 tensor([-0.0254])\n",
						"第 10165 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0076]])\n",
						"模型中偏参梯度 tensor([-0.0254])\n",
						"第 10166 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0076]])\n",
						"模型中偏参梯度 tensor([-0.0254])\n",
						"第 10167 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0076]])\n",
						"模型中偏参梯度 tensor([-0.0254])\n",
						"第 10168 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0076]])\n",
						"模型中偏参梯度 tensor([-0.0254])\n",
						"第 10169 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0076]])\n",
						"模型中偏参梯度 tensor([-0.0254])\n",
						"第 10170 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0076]])\n",
						"模型中偏参梯度 tensor([-0.0254])\n",
						"第 10171 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0076]])\n",
						"模型中偏参梯度 tensor([-0.0254])\n",
						"第 10172 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0076]])\n",
						"模型中偏参梯度 tensor([-0.0253])\n",
						"第 10173 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0075]])\n",
						"模型中偏参梯度 tensor([-0.0253])\n",
						"第 10174 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0075]])\n",
						"模型中偏参梯度 tensor([-0.0253])\n",
						"第 10175 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0075]])\n",
						"模型中偏参梯度 tensor([-0.0253])\n",
						"第 10176 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0075]])\n",
						"模型中偏参梯度 tensor([-0.0253])\n",
						"第 10177 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0075]])\n",
						"模型中偏参梯度 tensor([-0.0253])\n",
						"第 10178 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0075]])\n",
						"模型中偏参梯度 tensor([-0.0253])\n",
						"第 10179 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0075]])\n",
						"模型中偏参梯度 tensor([-0.0253])\n",
						"第 10180 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0075]])\n",
						"模型中偏参梯度 tensor([-0.0253])\n",
						"第 509 次epoch\n",
						"第 10181 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0075]])\n",
						"模型中偏参梯度 tensor([-0.0253])\n",
						"第 10182 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0075]])\n",
						"模型中偏参梯度 tensor([-0.0253])\n",
						"第 10183 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0075]])\n",
						"模型中偏参梯度 tensor([-0.0253])\n",
						"第 10184 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0074]])\n",
						"模型中偏参梯度 tensor([-0.0252])\n",
						"第 10185 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0074]])\n",
						"模型中偏参梯度 tensor([-0.0252])\n",
						"第 10186 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0074]])\n",
						"模型中偏参梯度 tensor([-0.0252])\n",
						"第 10187 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0074]])\n",
						"模型中偏参梯度 tensor([-0.0252])\n",
						"第 10188 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0074]])\n",
						"模型中偏参梯度 tensor([-0.0252])\n",
						"第 10189 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0074]])\n",
						"模型中偏参梯度 tensor([-0.0252])\n",
						"第 10190 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0074]])\n",
						"模型中偏参梯度 tensor([-0.0252])\n",
						"第 10191 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0074]])\n",
						"模型中偏参梯度 tensor([-0.0252])\n",
						"第 10192 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0073]])\n",
						"模型中偏参梯度 tensor([-0.0252])\n",
						"第 10193 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0073]])\n",
						"模型中偏参梯度 tensor([-0.0252])\n",
						"第 10194 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0073]])\n",
						"模型中偏参梯度 tensor([-0.0252])\n",
						"第 10195 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0073]])\n",
						"模型中偏参梯度 tensor([-0.0252])\n",
						"第 10196 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0073]])\n",
						"模型中偏参梯度 tensor([-0.0252])\n",
						"第 10197 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0073]])\n",
						"模型中偏参梯度 tensor([-0.0252])\n",
						"第 10198 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0073]])\n",
						"模型中偏参梯度 tensor([-0.0251])\n",
						"第 10199 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0072]])\n",
						"模型中偏参梯度 tensor([-0.0251])\n",
						"第 10200 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0072]])\n",
						"模型中偏参梯度 tensor([-0.0251])\n",
						"第 510 次epoch\n",
						"第 10201 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0072]])\n",
						"模型中偏参梯度 tensor([-0.0251])\n",
						"第 10202 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0072]])\n",
						"模型中偏参梯度 tensor([-0.0251])\n",
						"第 10203 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0072]])\n",
						"模型中偏参梯度 tensor([-0.0251])\n",
						"第 10204 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0072]])\n",
						"模型中偏参梯度 tensor([-0.0251])\n",
						"第 10205 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0072]])\n",
						"模型中偏参梯度 tensor([-0.0251])\n",
						"第 10206 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0071]])\n",
						"模型中偏参梯度 tensor([-0.0251])\n",
						"第 10207 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0071]])\n",
						"模型中偏参梯度 tensor([-0.0251])\n",
						"第 10208 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0071]])\n",
						"模型中偏参梯度 tensor([-0.0251])\n",
						"第 10209 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0071]])\n",
						"模型中偏参梯度 tensor([-0.0251])\n",
						"第 10210 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0071]])\n",
						"模型中偏参梯度 tensor([-0.0251])\n",
						"第 10211 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0071]])\n",
						"模型中偏参梯度 tensor([-0.0251])\n",
						"第 10212 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0071]])\n",
						"模型中偏参梯度 tensor([-0.0250])\n",
						"第 10213 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0071]])\n",
						"模型中偏参梯度 tensor([-0.0250])\n",
						"第 10214 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0070]])\n",
						"模型中偏参梯度 tensor([-0.0250])\n",
						"第 10215 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0070]])\n",
						"模型中偏参梯度 tensor([-0.0250])\n",
						"第 10216 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0070]])\n",
						"模型中偏参梯度 tensor([-0.0250])\n",
						"第 10217 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0070]])\n",
						"模型中偏参梯度 tensor([-0.0250])\n",
						"第 10218 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0070]])\n",
						"模型中偏参梯度 tensor([-0.0250])\n",
						"第 10219 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0070]])\n",
						"模型中偏参梯度 tensor([-0.0250])\n",
						"第 10220 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0070]])\n",
						"模型中偏参梯度 tensor([-0.0250])\n",
						"第 511 次epoch\n",
						"第 10221 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0070]])\n",
						"模型中偏参梯度 tensor([-0.0250])\n",
						"第 10222 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0069]])\n",
						"模型中偏参梯度 tensor([-0.0250])\n",
						"第 10223 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0069]])\n",
						"模型中偏参梯度 tensor([-0.0250])\n",
						"第 10224 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0069]])\n",
						"模型中偏参梯度 tensor([-0.0250])\n",
						"第 10225 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0069]])\n",
						"模型中偏参梯度 tensor([-0.0250])\n",
						"第 10226 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0069]])\n",
						"模型中偏参梯度 tensor([-0.0249])\n",
						"第 10227 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0069]])\n",
						"模型中偏参梯度 tensor([-0.0249])\n",
						"第 10228 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0069]])\n",
						"模型中偏参梯度 tensor([-0.0249])\n",
						"第 10229 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0068]])\n",
						"模型中偏参梯度 tensor([-0.0249])\n",
						"第 10230 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0068]])\n",
						"模型中偏参梯度 tensor([-0.0249])\n",
						"第 10231 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0068]])\n",
						"模型中偏参梯度 tensor([-0.0249])\n",
						"第 10232 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0068]])\n",
						"模型中偏参梯度 tensor([-0.0249])\n",
						"第 10233 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0068]])\n",
						"模型中偏参梯度 tensor([-0.0249])\n",
						"第 10234 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0068]])\n",
						"模型中偏参梯度 tensor([-0.0249])\n",
						"第 10235 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0068]])\n",
						"模型中偏参梯度 tensor([-0.0249])\n",
						"第 10236 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0068]])\n",
						"模型中偏参梯度 tensor([-0.0249])\n",
						"第 10237 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0249])\n",
						"第 10238 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0249])\n",
						"第 10239 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0249])\n",
						"第 10240 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0249])\n",
						"第 512 次epoch\n",
						"第 10241 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0248])\n",
						"第 10242 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0248])\n",
						"第 10243 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0248])\n",
						"第 10244 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0248])\n",
						"第 10245 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0248])\n",
						"第 10246 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0248])\n",
						"第 10247 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0248])\n",
						"第 10248 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0248])\n",
						"第 10249 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0248])\n",
						"第 10250 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0247])\n",
						"第 10251 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0247])\n",
						"第 10252 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0247])\n",
						"第 10253 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0247])\n",
						"第 10254 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0247])\n",
						"第 10255 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0247])\n",
						"第 10256 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0247])\n",
						"第 10257 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0247])\n",
						"第 10258 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0247])\n",
						"第 10259 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0247])\n",
						"第 10260 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0246])\n",
						"第 513 次epoch\n",
						"第 10261 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0246])\n",
						"第 10262 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0246])\n",
						"第 10263 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0246])\n",
						"第 10264 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0246])\n",
						"第 10265 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0246])\n",
						"第 10266 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0246])\n",
						"第 10267 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0246])\n",
						"第 10268 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0246])\n",
						"第 10269 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0245])\n",
						"第 10270 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0245])\n",
						"第 10271 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0245])\n",
						"第 10272 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0245])\n",
						"第 10273 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0245])\n",
						"第 10274 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0245])\n",
						"第 10275 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0245])\n",
						"第 10276 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0245])\n",
						"第 10277 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0245])\n",
						"第 10278 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0244])\n",
						"第 10279 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0244])\n",
						"第 10280 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0244])\n",
						"第 514 次epoch\n",
						"第 10281 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0244])\n",
						"第 10282 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0244])\n",
						"第 10283 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0244])\n",
						"第 10284 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0244])\n",
						"第 10285 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0244])\n",
						"第 10286 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0244])\n",
						"第 10287 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0243])\n",
						"第 10288 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0243])\n",
						"第 10289 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0243])\n",
						"第 10290 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0243])\n",
						"第 10291 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0243])\n",
						"第 10292 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0243])\n",
						"第 10293 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0243])\n",
						"第 10294 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0243])\n",
						"第 10295 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0243])\n",
						"第 10296 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0243])\n",
						"第 10297 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0242])\n",
						"第 10298 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0242])\n",
						"第 10299 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0242])\n",
						"第 10300 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0242])\n",
						"第 515 次epoch\n",
						"第 10301 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0242])\n",
						"第 10302 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0242])\n",
						"第 10303 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0242])\n",
						"第 10304 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0242])\n",
						"第 10305 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0242])\n",
						"第 10306 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0241])\n",
						"第 10307 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0241])\n",
						"第 10308 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0241])\n",
						"第 10309 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0241])\n",
						"第 10310 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0241])\n",
						"第 10311 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0241])\n",
						"第 10312 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0241])\n",
						"第 10313 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0241])\n",
						"第 10314 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0241])\n",
						"第 10315 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0241])\n",
						"第 10316 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0240])\n",
						"第 10317 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0240])\n",
						"第 10318 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0240])\n",
						"第 10319 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0240])\n",
						"第 10320 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0240])\n",
						"第 516 次epoch\n",
						"第 10321 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0240])\n",
						"第 10322 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0240])\n",
						"第 10323 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0240])\n",
						"第 10324 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0240])\n",
						"第 10325 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0240])\n",
						"第 10326 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0240])\n",
						"第 10327 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0239])\n",
						"第 10328 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0239])\n",
						"第 10329 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0239])\n",
						"第 10330 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0239])\n",
						"第 10331 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0239])\n",
						"第 10332 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0239])\n",
						"第 10333 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0239])\n",
						"第 10334 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0239])\n",
						"第 10335 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0239])\n",
						"第 10336 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0238])\n",
						"第 10337 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0238])\n",
						"第 10338 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0238])\n",
						"第 10339 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0238])\n",
						"第 10340 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0238])\n",
						"第 517 次epoch\n",
						"第 10341 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0238])\n",
						"第 10342 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0238])\n",
						"第 10343 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0238])\n",
						"第 10344 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0238])\n",
						"第 10345 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0237])\n",
						"第 10346 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0237])\n",
						"第 10347 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0237])\n",
						"第 10348 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0237])\n",
						"第 10349 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0237])\n",
						"第 10350 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0237])\n",
						"第 10351 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0237])\n",
						"第 10352 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0237])\n",
						"第 10353 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0237])\n",
						"第 10354 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0237])\n",
						"第 10355 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0236])\n",
						"第 10356 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0236])\n",
						"第 10357 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0236])\n",
						"第 10358 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0236])\n",
						"第 10359 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0236])\n",
						"第 10360 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0236])\n",
						"第 518 次epoch\n",
						"第 10361 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0236])\n",
						"第 10362 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0236])\n",
						"第 10363 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0236])\n",
						"第 10364 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0236])\n",
						"第 10365 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0235])\n",
						"第 10366 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0235])\n",
						"第 10367 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0235])\n",
						"第 10368 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0235])\n",
						"第 10369 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0235])\n",
						"第 10370 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0235])\n",
						"第 10371 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0235])\n",
						"第 10372 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0235])\n",
						"第 10373 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0235])\n",
						"第 10374 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0234])\n",
						"第 10375 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0234])\n",
						"第 10376 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0234])\n",
						"第 10377 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0234])\n",
						"第 10378 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0234])\n",
						"第 10379 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0234])\n",
						"第 10380 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0234])\n",
						"第 519 次epoch\n",
						"第 10381 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0234])\n",
						"第 10382 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0234])\n",
						"第 10383 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0234])\n",
						"第 10384 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0233])\n",
						"第 10385 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0233])\n",
						"第 10386 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0233])\n",
						"第 10387 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0233])\n",
						"第 10388 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0233])\n",
						"第 10389 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0233])\n",
						"第 10390 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0233])\n",
						"第 10391 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0233])\n",
						"第 10392 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0233])\n",
						"第 10393 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0233])\n",
						"第 10394 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0232])\n",
						"第 10395 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0232])\n",
						"第 10396 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0232])\n",
						"第 10397 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0232])\n",
						"第 10398 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0232])\n",
						"第 10399 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0232])\n",
						"第 10400 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0232])\n",
						"第 520 次epoch\n",
						"第 10401 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0232])\n",
						"第 10402 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0232])\n",
						"第 10403 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0232])\n",
						"第 10404 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0231])\n",
						"第 10405 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0231])\n",
						"第 10406 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0231])\n",
						"第 10407 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0231])\n",
						"第 10408 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0231])\n",
						"第 10409 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0231])\n",
						"第 10410 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0231])\n",
						"第 10411 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0231])\n",
						"第 10412 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0231])\n",
						"第 10413 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0231])\n",
						"第 10414 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0230])\n",
						"第 10415 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0230])\n",
						"第 10416 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0230])\n",
						"第 10417 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0230])\n",
						"第 10418 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0230])\n",
						"第 10419 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0230])\n",
						"第 10420 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0230])\n",
						"第 521 次epoch\n",
						"第 10421 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0230])\n",
						"第 10422 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0230])\n",
						"第 10423 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0230])\n",
						"第 10424 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0230])\n",
						"第 10425 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0229])\n",
						"第 10426 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0229])\n",
						"第 10427 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0229])\n",
						"第 10428 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0229])\n",
						"第 10429 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0229])\n",
						"第 10430 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0229])\n",
						"第 10431 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0229])\n",
						"第 10432 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0229])\n",
						"第 10433 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0229])\n",
						"第 10434 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0228])\n",
						"第 10435 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0228])\n",
						"第 10436 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0228])\n",
						"第 10437 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0228])\n",
						"第 10438 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0228])\n",
						"第 10439 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0228])\n",
						"第 10440 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0228])\n",
						"第 522 次epoch\n",
						"第 10441 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0228])\n",
						"第 10442 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0228])\n",
						"第 10443 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0228])\n",
						"第 10444 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0227])\n",
						"第 10445 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0227])\n",
						"第 10446 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0227])\n",
						"第 10447 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0227])\n",
						"第 10448 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0227])\n",
						"第 10449 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0227])\n",
						"第 10450 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0227])\n",
						"第 10451 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0227])\n",
						"第 10452 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0227])\n",
						"第 10453 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0227])\n",
						"第 10454 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0227])\n",
						"第 10455 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0226])\n",
						"第 10456 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0226])\n",
						"第 10457 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0226])\n",
						"第 10458 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0226])\n",
						"第 10459 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0226])\n",
						"第 10460 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0226])\n",
						"第 523 次epoch\n",
						"第 10461 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0226])\n",
						"第 10462 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0226])\n",
						"第 10463 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0226])\n",
						"第 10464 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0225])\n",
						"第 10465 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0225])\n",
						"第 10466 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0225])\n",
						"第 10467 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0225])\n",
						"第 10468 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0225])\n",
						"第 10469 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0225])\n",
						"第 10470 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0225])\n",
						"第 10471 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0225])\n",
						"第 10472 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0225])\n",
						"第 10473 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0225])\n",
						"第 10474 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0225])\n",
						"第 10475 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0224])\n",
						"第 10476 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0224])\n",
						"第 10477 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0224])\n",
						"第 10478 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0224])\n",
						"第 10479 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0224])\n",
						"第 10480 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0224])\n",
						"第 524 次epoch\n",
						"第 10481 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0224])\n",
						"第 10482 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0224])\n",
						"第 10483 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0224])\n",
						"第 10484 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0224])\n",
						"第 10485 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0223])\n",
						"第 10486 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0223])\n",
						"第 10487 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0223])\n",
						"第 10488 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0223])\n",
						"第 10489 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0223])\n",
						"第 10490 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0223])\n",
						"第 10491 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0223])\n",
						"第 10492 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0223])\n",
						"第 10493 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0223])\n",
						"第 10494 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0066]])\n",
						"模型中偏参梯度 tensor([-0.0223])\n",
						"第 10495 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0223])\n",
						"第 10496 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0222])\n",
						"第 10497 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0222])\n",
						"第 10498 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0066]])\n",
						"模型中偏参梯度 tensor([-0.0222])\n",
						"第 10499 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0222])\n",
						"第 10500 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0222])\n",
						"第 525 次epoch\n",
						"第 10501 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0222])\n",
						"第 10502 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0222])\n",
						"第 10503 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0066]])\n",
						"模型中偏参梯度 tensor([-0.0222])\n",
						"第 10504 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0222])\n",
						"第 10505 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0222])\n",
						"第 10506 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0221])\n",
						"第 10507 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0066]])\n",
						"模型中偏参梯度 tensor([-0.0221])\n",
						"第 10508 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0221])\n",
						"第 10509 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0221])\n",
						"第 10510 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0221])\n",
						"第 10511 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0221])\n",
						"第 10512 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0221])\n",
						"第 10513 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0221])\n",
						"第 10514 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0221])\n",
						"第 10515 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0221])\n",
						"第 10516 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0221])\n",
						"第 10517 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0220])\n",
						"第 10518 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0220])\n",
						"第 10519 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0220])\n",
						"第 10520 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0066]])\n",
						"模型中偏参梯度 tensor([-0.0220])\n",
						"第 526 次epoch\n",
						"第 10521 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0220])\n",
						"第 10522 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0220])\n",
						"第 10523 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0220])\n",
						"第 10524 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0066]])\n",
						"模型中偏参梯度 tensor([-0.0220])\n",
						"第 10525 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0220])\n",
						"第 10526 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0220])\n",
						"第 10527 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0219])\n",
						"第 10528 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0219])\n",
						"第 10529 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0219])\n",
						"第 10530 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0219])\n",
						"第 10531 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0219])\n",
						"第 10532 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0219])\n",
						"第 10533 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0219])\n",
						"第 10534 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0219])\n",
						"第 10535 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0219])\n",
						"第 10536 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0219])\n",
						"第 10537 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0218])\n",
						"第 10538 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0218])\n",
						"第 10539 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0218])\n",
						"第 10540 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0218])\n",
						"第 527 次epoch\n",
						"第 10541 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0218])\n",
						"第 10542 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0218])\n",
						"第 10543 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0218])\n",
						"第 10544 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0218])\n",
						"第 10545 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0218])\n",
						"第 10546 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0218])\n",
						"第 10547 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0218])\n",
						"第 10548 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0217])\n",
						"第 10549 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0217])\n",
						"第 10550 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0217])\n",
						"第 10551 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0066]])\n",
						"模型中偏参梯度 tensor([-0.0217])\n",
						"第 10552 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0217])\n",
						"第 10553 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0217])\n",
						"第 10554 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0217])\n",
						"第 10555 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0217])\n",
						"第 10556 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0217])\n",
						"第 10557 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0217])\n",
						"第 10558 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0216])\n",
						"第 10559 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0216])\n",
						"第 10560 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0066]])\n",
						"模型中偏参梯度 tensor([-0.0216])\n",
						"第 528 次epoch\n",
						"第 10561 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0216])\n",
						"第 10562 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0216])\n",
						"第 10563 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0216])\n",
						"第 10564 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0066]])\n",
						"模型中偏参梯度 tensor([-0.0216])\n",
						"第 10565 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0216])\n",
						"第 10566 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0216])\n",
						"第 10567 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0216])\n",
						"第 10568 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0215])\n",
						"第 10569 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0215])\n",
						"第 10570 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0215])\n",
						"第 10571 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0215])\n",
						"第 10572 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0215])\n",
						"第 10573 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0066]])\n",
						"模型中偏参梯度 tensor([-0.0215])\n",
						"第 10574 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0215])\n",
						"第 10575 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0215])\n",
						"第 10576 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0215])\n",
						"第 10577 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0066]])\n",
						"模型中偏参梯度 tensor([-0.0215])\n",
						"第 10578 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0215])\n",
						"第 10579 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0214])\n",
						"第 10580 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0214])\n",
						"第 529 次epoch\n",
						"第 10581 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0214])\n",
						"第 10582 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0214])\n",
						"第 10583 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0214])\n",
						"第 10584 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0066]])\n",
						"模型中偏参梯度 tensor([-0.0214])\n",
						"第 10585 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0066]])\n",
						"模型中偏参梯度 tensor([-0.0214])\n",
						"第 10586 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0066]])\n",
						"模型中偏参梯度 tensor([-0.0214])\n",
						"第 10587 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0214])\n",
						"第 10588 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0214])\n",
						"第 10589 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0214])\n",
						"第 10590 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0213])\n",
						"第 10591 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0213])\n",
						"第 10592 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0213])\n",
						"第 10593 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0213])\n",
						"第 10594 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0213])\n",
						"第 10595 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0066]])\n",
						"模型中偏参梯度 tensor([-0.0213])\n",
						"第 10596 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0066]])\n",
						"模型中偏参梯度 tensor([-0.0213])\n",
						"第 10597 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0213])\n",
						"第 10598 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0066]])\n",
						"模型中偏参梯度 tensor([-0.0213])\n",
						"第 10599 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0213])\n",
						"第 10600 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0213])\n",
						"第 530 次epoch\n",
						"第 10601 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0212])\n",
						"第 10602 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0212])\n",
						"第 10603 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0212])\n",
						"第 10604 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0212])\n",
						"第 10605 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0212])\n",
						"第 10606 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0212])\n",
						"第 10607 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0066]])\n",
						"模型中偏参梯度 tensor([-0.0212])\n",
						"第 10608 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0212])\n",
						"第 10609 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0212])\n",
						"第 10610 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0212])\n",
						"第 10611 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0212])\n",
						"第 10612 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0211])\n",
						"第 10613 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0211])\n",
						"第 10614 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0211])\n",
						"第 10615 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0211])\n",
						"第 10616 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0211])\n",
						"第 10617 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0066]])\n",
						"模型中偏参梯度 tensor([-0.0211])\n",
						"第 10618 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0066]])\n",
						"模型中偏参梯度 tensor([-0.0211])\n",
						"第 10619 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0066]])\n",
						"模型中偏参梯度 tensor([-0.0211])\n",
						"第 10620 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0211])\n",
						"第 531 次epoch\n",
						"第 10621 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0211])\n",
						"第 10622 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0211])\n",
						"第 10623 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0210])\n",
						"第 10624 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0210])\n",
						"第 10625 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0210])\n",
						"第 10626 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0210])\n",
						"第 10627 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0210])\n",
						"第 10628 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0066]])\n",
						"模型中偏参梯度 tensor([-0.0210])\n",
						"第 10629 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0066]])\n",
						"模型中偏参梯度 tensor([-0.0210])\n",
						"第 10630 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0066]])\n",
						"模型中偏参梯度 tensor([-0.0210])\n",
						"第 10631 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0210])\n",
						"第 10632 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0210])\n",
						"第 10633 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0210])\n",
						"第 10634 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0209])\n",
						"第 10635 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0209])\n",
						"第 10636 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0209])\n",
						"第 10637 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0209])\n",
						"第 10638 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0209])\n",
						"第 10639 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0209])\n",
						"第 10640 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0066]])\n",
						"模型中偏参梯度 tensor([-0.0209])\n",
						"第 532 次epoch\n",
						"第 10641 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0066]])\n",
						"模型中偏参梯度 tensor([-0.0209])\n",
						"第 10642 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0066]])\n",
						"模型中偏参梯度 tensor([-0.0209])\n",
						"第 10643 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0209])\n",
						"第 10644 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0209])\n",
						"第 10645 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0208])\n",
						"第 10646 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0208])\n",
						"第 10647 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0208])\n",
						"第 10648 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0208])\n",
						"第 10649 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0208])\n",
						"第 10650 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0208])\n",
						"第 10651 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0208])\n",
						"第 10652 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0066]])\n",
						"模型中偏参梯度 tensor([-0.0208])\n",
						"第 10653 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0066]])\n",
						"模型中偏参梯度 tensor([-0.0208])\n",
						"第 10654 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0208])\n",
						"第 10655 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0208])\n",
						"第 10656 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0207])\n",
						"第 10657 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0207])\n",
						"第 10658 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0207])\n",
						"第 10659 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0207])\n",
						"第 10660 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0207])\n",
						"第 533 次epoch\n",
						"第 10661 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0066]])\n",
						"模型中偏参梯度 tensor([-0.0207])\n",
						"第 10662 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0066]])\n",
						"模型中偏参梯度 tensor([-0.0207])\n",
						"第 10663 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0066]])\n",
						"模型中偏参梯度 tensor([-0.0207])\n",
						"第 10664 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0066]])\n",
						"模型中偏参梯度 tensor([-0.0207])\n",
						"第 10665 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0207])\n",
						"第 10666 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0207])\n",
						"第 10667 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0206])\n",
						"第 10668 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0206])\n",
						"第 10669 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0206])\n",
						"第 10670 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0206])\n",
						"第 10671 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0206])\n",
						"第 10672 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0066]])\n",
						"模型中偏参梯度 tensor([-0.0206])\n",
						"第 10673 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0066]])\n",
						"模型中偏参梯度 tensor([-0.0206])\n",
						"第 10674 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0066]])\n",
						"模型中偏参梯度 tensor([-0.0206])\n",
						"第 10675 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0066]])\n",
						"模型中偏参梯度 tensor([-0.0206])\n",
						"第 10676 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0066]])\n",
						"模型中偏参梯度 tensor([-0.0206])\n",
						"第 10677 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0206])\n",
						"第 10678 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0205])\n",
						"第 10679 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0205])\n",
						"第 10680 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0205])\n",
						"第 534 次epoch\n",
						"第 10681 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0205])\n",
						"第 10682 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0205])\n",
						"第 10683 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0205])\n",
						"第 10684 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0205])\n",
						"第 10685 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0205])\n",
						"第 10686 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0205])\n",
						"第 10687 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0205])\n",
						"第 10688 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0205])\n",
						"第 10689 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0204])\n",
						"第 10690 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0204])\n",
						"第 10691 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0204])\n",
						"第 10692 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0066]])\n",
						"模型中偏参梯度 tensor([-0.0204])\n",
						"第 10693 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0204])\n",
						"第 10694 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0066]])\n",
						"模型中偏参梯度 tensor([-0.0204])\n",
						"第 10695 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0066]])\n",
						"模型中偏参梯度 tensor([-0.0204])\n",
						"第 10696 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0066]])\n",
						"模型中偏参梯度 tensor([-0.0204])\n",
						"第 10697 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0067]])\n",
						"模型中偏参梯度 tensor([-0.0204])\n",
						"第 10698 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0066]])\n",
						"模型中偏参梯度 tensor([-0.0204])\n",
						"第 10699 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0066]])\n",
						"模型中偏参梯度 tensor([-0.0204])\n",
						"第 10700 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0066]])\n",
						"模型中偏参梯度 tensor([-0.0204])\n",
						"第 535 次epoch\n",
						"第 10701 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0066]])\n",
						"模型中偏参梯度 tensor([-0.0204])\n",
						"第 10702 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0066]])\n",
						"模型中偏参梯度 tensor([-0.0203])\n",
						"第 10703 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0066]])\n",
						"模型中偏参梯度 tensor([-0.0203])\n",
						"第 10704 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0066]])\n",
						"模型中偏参梯度 tensor([-0.0203])\n",
						"第 10705 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0066]])\n",
						"模型中偏参梯度 tensor([-0.0203])\n",
						"第 10706 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0066]])\n",
						"模型中偏参梯度 tensor([-0.0203])\n",
						"第 10707 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0066]])\n",
						"模型中偏参梯度 tensor([-0.0203])\n",
						"第 10708 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0066]])\n",
						"模型中偏参梯度 tensor([-0.0203])\n",
						"第 10709 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0066]])\n",
						"模型中偏参梯度 tensor([-0.0203])\n",
						"第 10710 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0066]])\n",
						"模型中偏参梯度 tensor([-0.0203])\n",
						"第 10711 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0066]])\n",
						"模型中偏参梯度 tensor([-0.0203])\n",
						"第 10712 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0066]])\n",
						"模型中偏参梯度 tensor([-0.0203])\n",
						"第 10713 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0066]])\n",
						"模型中偏参梯度 tensor([-0.0203])\n",
						"第 10714 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0066]])\n",
						"模型中偏参梯度 tensor([-0.0202])\n",
						"第 10715 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0066]])\n",
						"模型中偏参梯度 tensor([-0.0202])\n",
						"第 10716 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0066]])\n",
						"模型中偏参梯度 tensor([-0.0202])\n",
						"第 10717 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0066]])\n",
						"模型中偏参梯度 tensor([-0.0202])\n",
						"第 10718 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0066]])\n",
						"模型中偏参梯度 tensor([-0.0202])\n",
						"第 10719 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0066]])\n",
						"模型中偏参梯度 tensor([-0.0202])\n",
						"第 10720 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0066]])\n",
						"模型中偏参梯度 tensor([-0.0202])\n",
						"第 536 次epoch\n",
						"第 10721 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0066]])\n",
						"模型中偏参梯度 tensor([-0.0202])\n",
						"第 10722 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0066]])\n",
						"模型中偏参梯度 tensor([-0.0202])\n",
						"第 10723 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0066]])\n",
						"模型中偏参梯度 tensor([-0.0202])\n",
						"第 10724 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0066]])\n",
						"模型中偏参梯度 tensor([-0.0202])\n",
						"第 10725 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0066]])\n",
						"模型中偏参梯度 tensor([-0.0202])\n",
						"第 10726 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0066]])\n",
						"模型中偏参梯度 tensor([-0.0201])\n",
						"第 10727 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0066]])\n",
						"模型中偏参梯度 tensor([-0.0201])\n",
						"第 10728 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0066]])\n",
						"模型中偏参梯度 tensor([-0.0201])\n",
						"第 10729 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0066]])\n",
						"模型中偏参梯度 tensor([-0.0201])\n",
						"第 10730 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0066]])\n",
						"模型中偏参梯度 tensor([-0.0201])\n",
						"第 10731 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0066]])\n",
						"模型中偏参梯度 tensor([-0.0201])\n",
						"第 10732 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0066]])\n",
						"模型中偏参梯度 tensor([-0.0201])\n",
						"第 10733 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0066]])\n",
						"模型中偏参梯度 tensor([-0.0201])\n",
						"第 10734 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0066]])\n",
						"模型中偏参梯度 tensor([-0.0201])\n",
						"第 10735 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0066]])\n",
						"模型中偏参梯度 tensor([-0.0201])\n",
						"第 10736 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0066]])\n",
						"模型中偏参梯度 tensor([-0.0201])\n",
						"第 10737 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0066]])\n",
						"模型中偏参梯度 tensor([-0.0201])\n",
						"第 10738 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0066]])\n",
						"模型中偏参梯度 tensor([-0.0200])\n",
						"第 10739 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0066]])\n",
						"模型中偏参梯度 tensor([-0.0200])\n",
						"第 10740 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0066]])\n",
						"模型中偏参梯度 tensor([-0.0200])\n",
						"第 537 次epoch\n",
						"第 10741 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0066]])\n",
						"模型中偏参梯度 tensor([-0.0200])\n",
						"第 10742 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0066]])\n",
						"模型中偏参梯度 tensor([-0.0200])\n",
						"第 10743 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0066]])\n",
						"模型中偏参梯度 tensor([-0.0200])\n",
						"第 10744 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0066]])\n",
						"模型中偏参梯度 tensor([-0.0200])\n",
						"第 10745 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0066]])\n",
						"模型中偏参梯度 tensor([-0.0200])\n",
						"第 10746 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0066]])\n",
						"模型中偏参梯度 tensor([-0.0200])\n",
						"第 10747 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0065]])\n",
						"模型中偏参梯度 tensor([-0.0200])\n",
						"第 10748 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0065]])\n",
						"模型中偏参梯度 tensor([-0.0200])\n",
						"第 10749 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0065]])\n",
						"模型中偏参梯度 tensor([-0.0200])\n",
						"第 10750 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0065]])\n",
						"模型中偏参梯度 tensor([-0.0200])\n",
						"第 10751 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0065]])\n",
						"模型中偏参梯度 tensor([-0.0199])\n",
						"第 10752 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0065]])\n",
						"模型中偏参梯度 tensor([-0.0199])\n",
						"第 10753 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0065]])\n",
						"模型中偏参梯度 tensor([-0.0199])\n",
						"第 10754 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0065]])\n",
						"模型中偏参梯度 tensor([-0.0199])\n",
						"第 10755 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0065]])\n",
						"模型中偏参梯度 tensor([-0.0199])\n",
						"第 10756 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0065]])\n",
						"模型中偏参梯度 tensor([-0.0199])\n",
						"第 10757 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0065]])\n",
						"模型中偏参梯度 tensor([-0.0199])\n",
						"第 10758 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0065]])\n",
						"模型中偏参梯度 tensor([-0.0199])\n",
						"第 10759 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0065]])\n",
						"模型中偏参梯度 tensor([-0.0199])\n",
						"第 10760 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0065]])\n",
						"模型中偏参梯度 tensor([-0.0199])\n",
						"第 538 次epoch\n",
						"第 10761 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0065]])\n",
						"模型中偏参梯度 tensor([-0.0199])\n",
						"第 10762 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0065]])\n",
						"模型中偏参梯度 tensor([-0.0199])\n",
						"第 10763 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0065]])\n",
						"模型中偏参梯度 tensor([-0.0198])\n",
						"第 10764 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0065]])\n",
						"模型中偏参梯度 tensor([-0.0198])\n",
						"第 10765 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0065]])\n",
						"模型中偏参梯度 tensor([-0.0198])\n",
						"第 10766 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0065]])\n",
						"模型中偏参梯度 tensor([-0.0198])\n",
						"第 10767 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0065]])\n",
						"模型中偏参梯度 tensor([-0.0198])\n",
						"第 10768 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0065]])\n",
						"模型中偏参梯度 tensor([-0.0198])\n",
						"第 10769 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0065]])\n",
						"模型中偏参梯度 tensor([-0.0198])\n",
						"第 10770 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0065]])\n",
						"模型中偏参梯度 tensor([-0.0198])\n",
						"第 10771 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0065]])\n",
						"模型中偏参梯度 tensor([-0.0198])\n",
						"第 10772 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0065]])\n",
						"模型中偏参梯度 tensor([-0.0198])\n",
						"第 10773 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0065]])\n",
						"模型中偏参梯度 tensor([-0.0198])\n",
						"第 10774 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0065]])\n",
						"模型中偏参梯度 tensor([-0.0198])\n",
						"第 10775 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0065]])\n",
						"模型中偏参梯度 tensor([-0.0197])\n",
						"第 10776 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0065]])\n",
						"模型中偏参梯度 tensor([-0.0197])\n",
						"第 10777 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0065]])\n",
						"模型中偏参梯度 tensor([-0.0197])\n",
						"第 10778 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0065]])\n",
						"模型中偏参梯度 tensor([-0.0197])\n",
						"第 10779 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0065]])\n",
						"模型中偏参梯度 tensor([-0.0197])\n",
						"第 10780 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0065]])\n",
						"模型中偏参梯度 tensor([-0.0197])\n",
						"第 539 次epoch\n",
						"第 10781 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0065]])\n",
						"模型中偏参梯度 tensor([-0.0197])\n",
						"第 10782 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0065]])\n",
						"模型中偏参梯度 tensor([-0.0197])\n",
						"第 10783 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0065]])\n",
						"模型中偏参梯度 tensor([-0.0197])\n",
						"第 10784 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0065]])\n",
						"模型中偏参梯度 tensor([-0.0197])\n",
						"第 10785 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0065]])\n",
						"模型中偏参梯度 tensor([-0.0197])\n",
						"第 10786 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0065]])\n",
						"模型中偏参梯度 tensor([-0.0197])\n",
						"第 10787 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0065]])\n",
						"模型中偏参梯度 tensor([-0.0196])\n",
						"第 10788 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0065]])\n",
						"模型中偏参梯度 tensor([-0.0196])\n",
						"第 10789 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0065]])\n",
						"模型中偏参梯度 tensor([-0.0196])\n",
						"第 10790 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0065]])\n",
						"模型中偏参梯度 tensor([-0.0196])\n",
						"第 10791 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0065]])\n",
						"模型中偏参梯度 tensor([-0.0196])\n",
						"第 10792 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0065]])\n",
						"模型中偏参梯度 tensor([-0.0196])\n",
						"第 10793 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0065]])\n",
						"模型中偏参梯度 tensor([-0.0196])\n",
						"第 10794 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0065]])\n",
						"模型中偏参梯度 tensor([-0.0196])\n",
						"第 10795 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0065]])\n",
						"模型中偏参梯度 tensor([-0.0196])\n",
						"第 10796 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0065]])\n",
						"模型中偏参梯度 tensor([-0.0196])\n",
						"第 10797 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0065]])\n",
						"模型中偏参梯度 tensor([-0.0196])\n",
						"第 10798 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0064]])\n",
						"模型中偏参梯度 tensor([-0.0196])\n",
						"第 10799 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0064]])\n",
						"模型中偏参梯度 tensor([-0.0196])\n",
						"第 10800 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0064]])\n",
						"模型中偏参梯度 tensor([-0.0195])\n",
						"第 540 次epoch\n",
						"第 10801 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0064]])\n",
						"模型中偏参梯度 tensor([-0.0195])\n",
						"第 10802 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0064]])\n",
						"模型中偏参梯度 tensor([-0.0195])\n",
						"第 10803 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0064]])\n",
						"模型中偏参梯度 tensor([-0.0195])\n",
						"第 10804 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0064]])\n",
						"模型中偏参梯度 tensor([-0.0195])\n",
						"第 10805 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0064]])\n",
						"模型中偏参梯度 tensor([-0.0195])\n",
						"第 10806 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0064]])\n",
						"模型中偏参梯度 tensor([-0.0195])\n",
						"第 10807 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0064]])\n",
						"模型中偏参梯度 tensor([-0.0195])\n",
						"第 10808 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0064]])\n",
						"模型中偏参梯度 tensor([-0.0195])\n",
						"第 10809 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0064]])\n",
						"模型中偏参梯度 tensor([-0.0195])\n",
						"第 10810 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0064]])\n",
						"模型中偏参梯度 tensor([-0.0195])\n",
						"第 10811 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0064]])\n",
						"模型中偏参梯度 tensor([-0.0195])\n",
						"第 10812 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0064]])\n",
						"模型中偏参梯度 tensor([-0.0195])\n",
						"第 10813 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0063]])\n",
						"模型中偏参梯度 tensor([-0.0195])\n",
						"第 10814 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0063]])\n",
						"模型中偏参梯度 tensor([-0.0195])\n",
						"第 10815 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0063]])\n",
						"模型中偏参梯度 tensor([-0.0195])\n",
						"第 10816 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0063]])\n",
						"模型中偏参梯度 tensor([-0.0194])\n",
						"第 10817 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0063]])\n",
						"模型中偏参梯度 tensor([-0.0194])\n",
						"第 10818 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0063]])\n",
						"模型中偏参梯度 tensor([-0.0194])\n",
						"第 10819 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0063]])\n",
						"模型中偏参梯度 tensor([-0.0194])\n",
						"第 10820 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0063]])\n",
						"模型中偏参梯度 tensor([-0.0194])\n",
						"第 541 次epoch\n",
						"第 10821 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0063]])\n",
						"模型中偏参梯度 tensor([-0.0194])\n",
						"第 10822 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0063]])\n",
						"模型中偏参梯度 tensor([-0.0194])\n",
						"第 10823 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0063]])\n",
						"模型中偏参梯度 tensor([-0.0194])\n",
						"第 10824 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0063]])\n",
						"模型中偏参梯度 tensor([-0.0194])\n",
						"第 10825 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0063]])\n",
						"模型中偏参梯度 tensor([-0.0194])\n",
						"第 10826 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0063]])\n",
						"模型中偏参梯度 tensor([-0.0194])\n",
						"第 10827 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0062]])\n",
						"模型中偏参梯度 tensor([-0.0194])\n",
						"第 10828 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0062]])\n",
						"模型中偏参梯度 tensor([-0.0194])\n",
						"第 10829 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0062]])\n",
						"模型中偏参梯度 tensor([-0.0194])\n",
						"第 10830 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0062]])\n",
						"模型中偏参梯度 tensor([-0.0194])\n",
						"第 10831 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0062]])\n",
						"模型中偏参梯度 tensor([-0.0194])\n",
						"第 10832 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0062]])\n",
						"模型中偏参梯度 tensor([-0.0193])\n",
						"第 10833 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0062]])\n",
						"模型中偏参梯度 tensor([-0.0193])\n",
						"第 10834 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0062]])\n",
						"模型中偏参梯度 tensor([-0.0193])\n",
						"第 10835 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0062]])\n",
						"模型中偏参梯度 tensor([-0.0193])\n",
						"第 10836 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0062]])\n",
						"模型中偏参梯度 tensor([-0.0193])\n",
						"第 10837 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0062]])\n",
						"模型中偏参梯度 tensor([-0.0193])\n",
						"第 10838 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0062]])\n",
						"模型中偏参梯度 tensor([-0.0193])\n",
						"第 10839 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0062]])\n",
						"模型中偏参梯度 tensor([-0.0193])\n",
						"第 10840 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0062]])\n",
						"模型中偏参梯度 tensor([-0.0193])\n",
						"第 542 次epoch\n",
						"第 10841 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0061]])\n",
						"模型中偏参梯度 tensor([-0.0193])\n",
						"第 10842 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0061]])\n",
						"模型中偏参梯度 tensor([-0.0193])\n",
						"第 10843 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0061]])\n",
						"模型中偏参梯度 tensor([-0.0193])\n",
						"第 10844 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0061]])\n",
						"模型中偏参梯度 tensor([-0.0193])\n",
						"第 10845 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0061]])\n",
						"模型中偏参梯度 tensor([-0.0193])\n",
						"第 10846 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0061]])\n",
						"模型中偏参梯度 tensor([-0.0193])\n",
						"第 10847 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0061]])\n",
						"模型中偏参梯度 tensor([-0.0193])\n",
						"第 10848 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0061]])\n",
						"模型中偏参梯度 tensor([-0.0192])\n",
						"第 10849 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0061]])\n",
						"模型中偏参梯度 tensor([-0.0192])\n",
						"第 10850 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0061]])\n",
						"模型中偏参梯度 tensor([-0.0192])\n",
						"第 10851 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0061]])\n",
						"模型中偏参梯度 tensor([-0.0192])\n",
						"第 10852 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0061]])\n",
						"模型中偏参梯度 tensor([-0.0192])\n",
						"第 10853 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0061]])\n",
						"模型中偏参梯度 tensor([-0.0192])\n",
						"第 10854 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0061]])\n",
						"模型中偏参梯度 tensor([-0.0192])\n",
						"第 10855 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0060]])\n",
						"模型中偏参梯度 tensor([-0.0192])\n",
						"第 10856 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0060]])\n",
						"模型中偏参梯度 tensor([-0.0192])\n",
						"第 10857 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0060]])\n",
						"模型中偏参梯度 tensor([-0.0192])\n",
						"第 10858 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0060]])\n",
						"模型中偏参梯度 tensor([-0.0192])\n",
						"第 10859 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0060]])\n",
						"模型中偏参梯度 tensor([-0.0192])\n",
						"第 10860 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0060]])\n",
						"模型中偏参梯度 tensor([-0.0192])\n",
						"第 543 次epoch\n",
						"第 10861 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0060]])\n",
						"模型中偏参梯度 tensor([-0.0192])\n",
						"第 10862 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0060]])\n",
						"模型中偏参梯度 tensor([-0.0192])\n",
						"第 10863 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0060]])\n",
						"模型中偏参梯度 tensor([-0.0192])\n",
						"第 10864 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0060]])\n",
						"模型中偏参梯度 tensor([-0.0191])\n",
						"第 10865 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0060]])\n",
						"模型中偏参梯度 tensor([-0.0191])\n",
						"第 10866 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0060]])\n",
						"模型中偏参梯度 tensor([-0.0191])\n",
						"第 10867 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0060]])\n",
						"模型中偏参梯度 tensor([-0.0191])\n",
						"第 10868 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0060]])\n",
						"模型中偏参梯度 tensor([-0.0191])\n",
						"第 10869 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0059]])\n",
						"模型中偏参梯度 tensor([-0.0191])\n",
						"第 10870 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0059]])\n",
						"模型中偏参梯度 tensor([-0.0191])\n",
						"第 10871 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0059]])\n",
						"模型中偏参梯度 tensor([-0.0191])\n",
						"第 10872 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0059]])\n",
						"模型中偏参梯度 tensor([-0.0191])\n",
						"第 10873 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0059]])\n",
						"模型中偏参梯度 tensor([-0.0191])\n",
						"第 10874 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0059]])\n",
						"模型中偏参梯度 tensor([-0.0191])\n",
						"第 10875 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0059]])\n",
						"模型中偏参梯度 tensor([-0.0191])\n",
						"第 10876 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0059]])\n",
						"模型中偏参梯度 tensor([-0.0191])\n",
						"第 10877 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0059]])\n",
						"模型中偏参梯度 tensor([-0.0191])\n",
						"第 10878 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0059]])\n",
						"模型中偏参梯度 tensor([-0.0191])\n",
						"第 10879 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0059]])\n",
						"模型中偏参梯度 tensor([-0.0191])\n",
						"第 10880 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0059]])\n",
						"模型中偏参梯度 tensor([-0.0190])\n",
						"第 544 次epoch\n",
						"第 10881 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0059]])\n",
						"模型中偏参梯度 tensor([-0.0190])\n",
						"第 10882 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0058]])\n",
						"模型中偏参梯度 tensor([-0.0190])\n",
						"第 10883 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0058]])\n",
						"模型中偏参梯度 tensor([-0.0190])\n",
						"第 10884 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0058]])\n",
						"模型中偏参梯度 tensor([-0.0190])\n",
						"第 10885 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0058]])\n",
						"模型中偏参梯度 tensor([-0.0190])\n",
						"第 10886 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0058]])\n",
						"模型中偏参梯度 tensor([-0.0190])\n",
						"第 10887 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0058]])\n",
						"模型中偏参梯度 tensor([-0.0190])\n",
						"第 10888 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0058]])\n",
						"模型中偏参梯度 tensor([-0.0190])\n",
						"第 10889 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0058]])\n",
						"模型中偏参梯度 tensor([-0.0190])\n",
						"第 10890 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0058]])\n",
						"模型中偏参梯度 tensor([-0.0190])\n",
						"第 10891 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0058]])\n",
						"模型中偏参梯度 tensor([-0.0190])\n",
						"第 10892 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0058]])\n",
						"模型中偏参梯度 tensor([-0.0190])\n",
						"第 10893 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0058]])\n",
						"模型中偏参梯度 tensor([-0.0190])\n",
						"第 10894 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0058]])\n",
						"模型中偏参梯度 tensor([-0.0190])\n",
						"第 10895 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0057]])\n",
						"模型中偏参梯度 tensor([-0.0190])\n",
						"第 10896 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0057]])\n",
						"模型中偏参梯度 tensor([-0.0189])\n",
						"第 10897 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0057]])\n",
						"模型中偏参梯度 tensor([-0.0189])\n",
						"第 10898 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0057]])\n",
						"模型中偏参梯度 tensor([-0.0189])\n",
						"第 10899 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0057]])\n",
						"模型中偏参梯度 tensor([-0.0189])\n",
						"第 10900 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0057]])\n",
						"模型中偏参梯度 tensor([-0.0189])\n",
						"第 545 次epoch\n",
						"第 10901 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0057]])\n",
						"模型中偏参梯度 tensor([-0.0189])\n",
						"第 10902 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0057]])\n",
						"模型中偏参梯度 tensor([-0.0189])\n",
						"第 10903 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0057]])\n",
						"模型中偏参梯度 tensor([-0.0189])\n",
						"第 10904 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0057]])\n",
						"模型中偏参梯度 tensor([-0.0189])\n",
						"第 10905 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0057]])\n",
						"模型中偏参梯度 tensor([-0.0189])\n",
						"第 10906 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0057]])\n",
						"模型中偏参梯度 tensor([-0.0189])\n",
						"第 10907 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0057]])\n",
						"模型中偏参梯度 tensor([-0.0189])\n",
						"第 10908 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0057]])\n",
						"模型中偏参梯度 tensor([-0.0189])\n",
						"第 10909 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0056]])\n",
						"模型中偏参梯度 tensor([-0.0189])\n",
						"第 10910 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0056]])\n",
						"模型中偏参梯度 tensor([-0.0189])\n",
						"第 10911 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0056]])\n",
						"模型中偏参梯度 tensor([-0.0189])\n",
						"第 10912 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0056]])\n",
						"模型中偏参梯度 tensor([-0.0188])\n",
						"第 10913 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0056]])\n",
						"模型中偏参梯度 tensor([-0.0188])\n",
						"第 10914 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0056]])\n",
						"模型中偏参梯度 tensor([-0.0188])\n",
						"第 10915 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0056]])\n",
						"模型中偏参梯度 tensor([-0.0188])\n",
						"第 10916 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0056]])\n",
						"模型中偏参梯度 tensor([-0.0188])\n",
						"第 10917 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0056]])\n",
						"模型中偏参梯度 tensor([-0.0188])\n",
						"第 10918 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0056]])\n",
						"模型中偏参梯度 tensor([-0.0188])\n",
						"第 10919 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0056]])\n",
						"模型中偏参梯度 tensor([-0.0188])\n",
						"第 10920 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0056]])\n",
						"模型中偏参梯度 tensor([-0.0188])\n",
						"第 546 次epoch\n",
						"第 10921 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0056]])\n",
						"模型中偏参梯度 tensor([-0.0188])\n",
						"第 10922 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0056]])\n",
						"模型中偏参梯度 tensor([-0.0188])\n",
						"第 10923 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0055]])\n",
						"模型中偏参梯度 tensor([-0.0188])\n",
						"第 10924 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0055]])\n",
						"模型中偏参梯度 tensor([-0.0188])\n",
						"第 10925 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0055]])\n",
						"模型中偏参梯度 tensor([-0.0188])\n",
						"第 10926 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0055]])\n",
						"模型中偏参梯度 tensor([-0.0188])\n",
						"第 10927 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0055]])\n",
						"模型中偏参梯度 tensor([-0.0188])\n",
						"第 10928 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0055]])\n",
						"模型中偏参梯度 tensor([-0.0187])\n",
						"第 10929 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0055]])\n",
						"模型中偏参梯度 tensor([-0.0187])\n",
						"第 10930 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0055]])\n",
						"模型中偏参梯度 tensor([-0.0187])\n",
						"第 10931 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0055]])\n",
						"模型中偏参梯度 tensor([-0.0187])\n",
						"第 10932 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0055]])\n",
						"模型中偏参梯度 tensor([-0.0187])\n",
						"第 10933 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0055]])\n",
						"模型中偏参梯度 tensor([-0.0187])\n",
						"第 10934 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0055]])\n",
						"模型中偏参梯度 tensor([-0.0187])\n",
						"第 10935 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0055]])\n",
						"模型中偏参梯度 tensor([-0.0187])\n",
						"第 10936 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0055]])\n",
						"模型中偏参梯度 tensor([-0.0187])\n",
						"第 10937 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0055]])\n",
						"模型中偏参梯度 tensor([-0.0187])\n",
						"第 10938 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0054]])\n",
						"模型中偏参梯度 tensor([-0.0187])\n",
						"第 10939 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0054]])\n",
						"模型中偏参梯度 tensor([-0.0187])\n",
						"第 10940 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0054]])\n",
						"模型中偏参梯度 tensor([-0.0187])\n",
						"第 547 次epoch\n",
						"第 10941 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0054]])\n",
						"模型中偏参梯度 tensor([-0.0187])\n",
						"第 10942 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0054]])\n",
						"模型中偏参梯度 tensor([-0.0187])\n",
						"第 10943 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0054]])\n",
						"模型中偏参梯度 tensor([-0.0187])\n",
						"第 10944 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0054]])\n",
						"模型中偏参梯度 tensor([-0.0186])\n",
						"第 10945 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0054]])\n",
						"模型中偏参梯度 tensor([-0.0186])\n",
						"第 10946 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0054]])\n",
						"模型中偏参梯度 tensor([-0.0186])\n",
						"第 10947 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0054]])\n",
						"模型中偏参梯度 tensor([-0.0186])\n",
						"第 10948 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0054]])\n",
						"模型中偏参梯度 tensor([-0.0186])\n",
						"第 10949 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0054]])\n",
						"模型中偏参梯度 tensor([-0.0186])\n",
						"第 10950 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0054]])\n",
						"模型中偏参梯度 tensor([-0.0186])\n",
						"第 10951 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0053]])\n",
						"模型中偏参梯度 tensor([-0.0186])\n",
						"第 10952 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0053]])\n",
						"模型中偏参梯度 tensor([-0.0186])\n",
						"第 10953 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0053]])\n",
						"模型中偏参梯度 tensor([-0.0186])\n",
						"第 10954 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0053]])\n",
						"模型中偏参梯度 tensor([-0.0186])\n",
						"第 10955 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0053]])\n",
						"模型中偏参梯度 tensor([-0.0186])\n",
						"第 10956 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0053]])\n",
						"模型中偏参梯度 tensor([-0.0186])\n",
						"第 10957 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0053]])\n",
						"模型中偏参梯度 tensor([-0.0186])\n",
						"第 10958 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0053]])\n",
						"模型中偏参梯度 tensor([-0.0186])\n",
						"第 10959 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0052]])\n",
						"模型中偏参梯度 tensor([-0.0186])\n",
						"第 10960 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0052]])\n",
						"模型中偏参梯度 tensor([-0.0186])\n",
						"第 548 次epoch\n",
						"第 10961 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0052]])\n",
						"模型中偏参梯度 tensor([-0.0186])\n",
						"第 10962 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0052]])\n",
						"模型中偏参梯度 tensor([-0.0186])\n",
						"第 10963 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0052]])\n",
						"模型中偏参梯度 tensor([-0.0185])\n",
						"第 10964 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0052]])\n",
						"模型中偏参梯度 tensor([-0.0185])\n",
						"第 10965 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0052]])\n",
						"模型中偏参梯度 tensor([-0.0185])\n",
						"第 10966 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0052]])\n",
						"模型中偏参梯度 tensor([-0.0185])\n",
						"第 10967 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0051]])\n",
						"模型中偏参梯度 tensor([-0.0185])\n",
						"第 10968 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0051]])\n",
						"模型中偏参梯度 tensor([-0.0185])\n",
						"第 10969 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0051]])\n",
						"模型中偏参梯度 tensor([-0.0185])\n",
						"第 10970 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0051]])\n",
						"模型中偏参梯度 tensor([-0.0185])\n",
						"第 10971 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0051]])\n",
						"模型中偏参梯度 tensor([-0.0185])\n",
						"第 10972 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0051]])\n",
						"模型中偏参梯度 tensor([-0.0185])\n",
						"第 10973 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0051]])\n",
						"模型中偏参梯度 tensor([-0.0185])\n",
						"第 10974 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0051]])\n",
						"模型中偏参梯度 tensor([-0.0185])\n",
						"第 10975 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0050]])\n",
						"模型中偏参梯度 tensor([-0.0185])\n",
						"第 10976 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0050]])\n",
						"模型中偏参梯度 tensor([-0.0185])\n",
						"第 10977 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0050]])\n",
						"模型中偏参梯度 tensor([-0.0185])\n",
						"第 10978 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0050]])\n",
						"模型中偏参梯度 tensor([-0.0185])\n",
						"第 10979 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0050]])\n",
						"模型中偏参梯度 tensor([-0.0185])\n",
						"第 10980 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0050]])\n",
						"模型中偏参梯度 tensor([-0.0185])\n",
						"第 549 次epoch\n",
						"第 10981 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0050]])\n",
						"模型中偏参梯度 tensor([-0.0185])\n",
						"第 10982 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0050]])\n",
						"模型中偏参梯度 tensor([-0.0185])\n",
						"第 10983 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0049]])\n",
						"模型中偏参梯度 tensor([-0.0185])\n",
						"第 10984 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0049]])\n",
						"模型中偏参梯度 tensor([-0.0185])\n",
						"第 10985 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0049]])\n",
						"模型中偏参梯度 tensor([-0.0185])\n",
						"第 10986 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0049]])\n",
						"模型中偏参梯度 tensor([-0.0184])\n",
						"第 10987 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0049]])\n",
						"模型中偏参梯度 tensor([-0.0184])\n",
						"第 10988 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0049]])\n",
						"模型中偏参梯度 tensor([-0.0184])\n",
						"第 10989 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0049]])\n",
						"模型中偏参梯度 tensor([-0.0184])\n",
						"第 10990 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0049]])\n",
						"模型中偏参梯度 tensor([-0.0184])\n",
						"第 10991 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0184])\n",
						"第 10992 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0184])\n",
						"第 10993 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0184])\n",
						"第 10994 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0184])\n",
						"第 10995 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0184])\n",
						"第 10996 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0184])\n",
						"第 10997 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0184])\n",
						"第 10998 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0184])\n",
						"第 10999 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0184])\n",
						"第 11000 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0184])\n",
						"第 550 次epoch\n",
						"第 11001 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0184])\n",
						"第 11002 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0184])\n",
						"第 11003 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0184])\n",
						"第 11004 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0183])\n",
						"第 11005 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0183])\n",
						"第 11006 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0183])\n",
						"第 11007 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0183])\n",
						"第 11008 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0183])\n",
						"第 11009 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0183])\n",
						"第 11010 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0183])\n",
						"第 11011 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0183])\n",
						"第 11012 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0183])\n",
						"第 11013 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0183])\n",
						"第 11014 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0183])\n",
						"第 11015 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0183])\n",
						"第 11016 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0183])\n",
						"第 11017 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0182])\n",
						"第 11018 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0182])\n",
						"第 11019 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0182])\n",
						"第 11020 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0182])\n",
						"第 551 次epoch\n",
						"第 11021 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0182])\n",
						"第 11022 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0182])\n",
						"第 11023 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0182])\n",
						"第 11024 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0182])\n",
						"第 11025 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0182])\n",
						"第 11026 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0182])\n",
						"第 11027 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0182])\n",
						"第 11028 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0182])\n",
						"第 11029 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0181])\n",
						"第 11030 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0181])\n",
						"第 11031 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0181])\n",
						"第 11032 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0181])\n",
						"第 11033 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0181])\n",
						"第 11034 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0181])\n",
						"第 11035 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0181])\n",
						"第 11036 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0181])\n",
						"第 11037 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0181])\n",
						"第 11038 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0181])\n",
						"第 11039 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0181])\n",
						"第 11040 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0181])\n",
						"第 552 次epoch\n",
						"第 11041 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0180])\n",
						"第 11042 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0180])\n",
						"第 11043 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0180])\n",
						"第 11044 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0180])\n",
						"第 11045 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0180])\n",
						"第 11046 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0180])\n",
						"第 11047 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0180])\n",
						"第 11048 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0180])\n",
						"第 11049 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0180])\n",
						"第 11050 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0180])\n",
						"第 11051 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0180])\n",
						"第 11052 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0180])\n",
						"第 11053 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0180])\n",
						"第 11054 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0179])\n",
						"第 11055 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0179])\n",
						"第 11056 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0179])\n",
						"第 11057 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0179])\n",
						"第 11058 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0179])\n",
						"第 11059 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0179])\n",
						"第 11060 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0179])\n",
						"第 553 次epoch\n",
						"第 11061 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0179])\n",
						"第 11062 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0179])\n",
						"第 11063 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0179])\n",
						"第 11064 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0179])\n",
						"第 11065 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0179])\n",
						"第 11066 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0179])\n",
						"第 11067 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0178])\n",
						"第 11068 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0178])\n",
						"第 11069 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0178])\n",
						"第 11070 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0178])\n",
						"第 11071 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0178])\n",
						"第 11072 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0178])\n",
						"第 11073 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0178])\n",
						"第 11074 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0178])\n",
						"第 11075 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0178])\n",
						"第 11076 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0178])\n",
						"第 11077 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0178])\n",
						"第 11078 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0178])\n",
						"第 11079 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0178])\n",
						"第 11080 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0177])\n",
						"第 554 次epoch\n",
						"第 11081 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0177])\n",
						"第 11082 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0177])\n",
						"第 11083 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0177])\n",
						"第 11084 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0177])\n",
						"第 11085 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0177])\n",
						"第 11086 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0177])\n",
						"第 11087 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0177])\n",
						"第 11088 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0177])\n",
						"第 11089 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0177])\n",
						"第 11090 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0177])\n",
						"第 11091 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0177])\n",
						"第 11092 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0176])\n",
						"第 11093 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0176])\n",
						"第 11094 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0176])\n",
						"第 11095 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0176])\n",
						"第 11096 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0176])\n",
						"第 11097 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0176])\n",
						"第 11098 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0176])\n",
						"第 11099 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0176])\n",
						"第 11100 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0176])\n",
						"第 555 次epoch\n",
						"第 11101 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0176])\n",
						"第 11102 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0176])\n",
						"第 11103 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0176])\n",
						"第 11104 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0176])\n",
						"第 11105 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0176])\n",
						"第 11106 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0175])\n",
						"第 11107 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0175])\n",
						"第 11108 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0175])\n",
						"第 11109 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0175])\n",
						"第 11110 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0175])\n",
						"第 11111 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0175])\n",
						"第 11112 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0175])\n",
						"第 11113 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0175])\n",
						"第 11114 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0175])\n",
						"第 11115 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0175])\n",
						"第 11116 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0175])\n",
						"第 11117 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0175])\n",
						"第 11118 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0175])\n",
						"第 11119 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0175])\n",
						"第 11120 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0174])\n",
						"第 556 次epoch\n",
						"第 11121 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0174])\n",
						"第 11122 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0174])\n",
						"第 11123 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0174])\n",
						"第 11124 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0174])\n",
						"第 11125 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0174])\n",
						"第 11126 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0174])\n",
						"第 11127 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0174])\n",
						"第 11128 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0174])\n",
						"第 11129 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0174])\n",
						"第 11130 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0174])\n",
						"第 11131 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0174])\n",
						"第 11132 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0174])\n",
						"第 11133 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0173])\n",
						"第 11134 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0173])\n",
						"第 11135 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0173])\n",
						"第 11136 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0173])\n",
						"第 11137 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0173])\n",
						"第 11138 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0173])\n",
						"第 11139 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0173])\n",
						"第 11140 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0173])\n",
						"第 557 次epoch\n",
						"第 11141 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0173])\n",
						"第 11142 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0173])\n",
						"第 11143 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0173])\n",
						"第 11144 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0173])\n",
						"第 11145 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0173])\n",
						"第 11146 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0172])\n",
						"第 11147 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0172])\n",
						"第 11148 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0172])\n",
						"第 11149 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0172])\n",
						"第 11150 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0172])\n",
						"第 11151 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0172])\n",
						"第 11152 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0172])\n",
						"第 11153 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0172])\n",
						"第 11154 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0172])\n",
						"第 11155 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0172])\n",
						"第 11156 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0172])\n",
						"第 11157 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0172])\n",
						"第 11158 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0172])\n",
						"第 11159 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0172])\n",
						"第 11160 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0171])\n",
						"第 558 次epoch\n",
						"第 11161 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0171])\n",
						"第 11162 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0171])\n",
						"第 11163 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0171])\n",
						"第 11164 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0171])\n",
						"第 11165 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0171])\n",
						"第 11166 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0171])\n",
						"第 11167 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0171])\n",
						"第 11168 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0171])\n",
						"第 11169 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0171])\n",
						"第 11170 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0171])\n",
						"第 11171 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0171])\n",
						"第 11172 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0171])\n",
						"第 11173 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0170])\n",
						"第 11174 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0170])\n",
						"第 11175 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0170])\n",
						"第 11176 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0170])\n",
						"第 11177 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0170])\n",
						"第 11178 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0170])\n",
						"第 11179 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0170])\n",
						"第 11180 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0170])\n",
						"第 559 次epoch\n",
						"第 11181 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0170])\n",
						"第 11182 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0170])\n",
						"第 11183 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0170])\n",
						"第 11184 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0170])\n",
						"第 11185 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0170])\n",
						"第 11186 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0169])\n",
						"第 11187 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0169])\n",
						"第 11188 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0169])\n",
						"第 11189 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0169])\n",
						"第 11190 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0169])\n",
						"第 11191 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0169])\n",
						"第 11192 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0169])\n",
						"第 11193 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0169])\n",
						"第 11194 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0169])\n",
						"第 11195 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0169])\n",
						"第 11196 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0169])\n",
						"第 11197 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0169])\n",
						"第 11198 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0169])\n",
						"第 11199 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0169])\n",
						"第 11200 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0168])\n",
						"第 560 次epoch\n",
						"第 11201 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0168])\n",
						"第 11202 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0168])\n",
						"第 11203 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0168])\n",
						"第 11204 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0168])\n",
						"第 11205 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0168])\n",
						"第 11206 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0168])\n",
						"第 11207 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0168])\n",
						"第 11208 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0168])\n",
						"第 11209 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0168])\n",
						"第 11210 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0168])\n",
						"第 11211 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0168])\n",
						"第 11212 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0168])\n",
						"第 11213 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0167])\n",
						"第 11214 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0167])\n",
						"第 11215 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0167])\n",
						"第 11216 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0167])\n",
						"第 11217 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0167])\n",
						"第 11218 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0167])\n",
						"第 11219 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0167])\n",
						"第 11220 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0167])\n",
						"第 561 次epoch\n",
						"第 11221 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0167])\n",
						"第 11222 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0167])\n",
						"第 11223 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0167])\n",
						"第 11224 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0167])\n",
						"第 11225 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0167])\n",
						"第 11226 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0167])\n",
						"第 11227 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0166])\n",
						"第 11228 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0166])\n",
						"第 11229 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0166])\n",
						"第 11230 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0166])\n",
						"第 11231 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0166])\n",
						"第 11232 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0166])\n",
						"第 11233 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0166])\n",
						"第 11234 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0166])\n",
						"第 11235 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0166])\n",
						"第 11236 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0166])\n",
						"第 11237 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0166])\n",
						"第 11238 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0166])\n",
						"第 11239 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0166])\n",
						"第 11240 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0166])\n",
						"第 562 次epoch\n",
						"第 11241 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0165])\n",
						"第 11242 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0165])\n",
						"第 11243 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0165])\n",
						"第 11244 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0165])\n",
						"第 11245 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0165])\n",
						"第 11246 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0165])\n",
						"第 11247 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0165])\n",
						"第 11248 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0165])\n",
						"第 11249 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0165])\n",
						"第 11250 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0165])\n",
						"第 11251 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0165])\n",
						"第 11252 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0165])\n",
						"第 11253 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0165])\n",
						"第 11254 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0165])\n",
						"第 11255 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0164])\n",
						"第 11256 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0164])\n",
						"第 11257 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0164])\n",
						"第 11258 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0164])\n",
						"第 11259 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0164])\n",
						"第 11260 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0164])\n",
						"第 563 次epoch\n",
						"第 11261 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0164])\n",
						"第 11262 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0164])\n",
						"第 11263 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0164])\n",
						"第 11264 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0164])\n",
						"第 11265 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0164])\n",
						"第 11266 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0164])\n",
						"第 11267 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0164])\n",
						"第 11268 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0164])\n",
						"第 11269 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0163])\n",
						"第 11270 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0163])\n",
						"第 11271 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0163])\n",
						"第 11272 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0163])\n",
						"第 11273 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0163])\n",
						"第 11274 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0163])\n",
						"第 11275 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0163])\n",
						"第 11276 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0163])\n",
						"第 11277 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0163])\n",
						"第 11278 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0163])\n",
						"第 11279 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0163])\n",
						"第 11280 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0163])\n",
						"第 564 次epoch\n",
						"第 11281 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0163])\n",
						"第 11282 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0163])\n",
						"第 11283 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0163])\n",
						"第 11284 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0162])\n",
						"第 11285 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0162])\n",
						"第 11286 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0162])\n",
						"第 11287 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0162])\n",
						"第 11288 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0162])\n",
						"第 11289 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0162])\n",
						"第 11290 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0162])\n",
						"第 11291 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0162])\n",
						"第 11292 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0162])\n",
						"第 11293 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0162])\n",
						"第 11294 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0162])\n",
						"第 11295 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0162])\n",
						"第 11296 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0162])\n",
						"第 11297 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0162])\n",
						"第 11298 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0162])\n",
						"第 11299 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0161])\n",
						"第 11300 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0161])\n",
						"第 565 次epoch\n",
						"第 11301 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0161])\n",
						"第 11302 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0161])\n",
						"第 11303 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0161])\n",
						"第 11304 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0161])\n",
						"第 11305 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0161])\n",
						"第 11306 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0161])\n",
						"第 11307 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0161])\n",
						"第 11308 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0161])\n",
						"第 11309 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0161])\n",
						"第 11310 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0161])\n",
						"第 11311 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0161])\n",
						"第 11312 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0160])\n",
						"第 11313 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0160])\n",
						"第 11314 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0160])\n",
						"第 11315 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0160])\n",
						"第 11316 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0160])\n",
						"第 11317 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0160])\n",
						"第 11318 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0160])\n",
						"第 11319 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0160])\n",
						"第 11320 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0160])\n",
						"第 566 次epoch\n",
						"第 11321 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0160])\n",
						"第 11322 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0160])\n",
						"第 11323 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0160])\n",
						"第 11324 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0160])\n",
						"第 11325 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0160])\n",
						"第 11326 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0159])\n",
						"第 11327 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0159])\n",
						"第 11328 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0159])\n",
						"第 11329 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0159])\n",
						"第 11330 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0159])\n",
						"第 11331 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0159])\n",
						"第 11332 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0159])\n",
						"第 11333 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0159])\n",
						"第 11334 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0159])\n",
						"第 11335 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0159])\n",
						"第 11336 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0159])\n",
						"第 11337 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0159])\n",
						"第 11338 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0159])\n",
						"第 11339 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0159])\n",
						"第 11340 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0159])\n",
						"第 567 次epoch\n",
						"第 11341 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0158])\n",
						"第 11342 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0158])\n",
						"第 11343 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0158])\n",
						"第 11344 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0158])\n",
						"第 11345 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0158])\n",
						"第 11346 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0158])\n",
						"第 11347 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0158])\n",
						"第 11348 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0158])\n",
						"第 11349 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0158])\n",
						"第 11350 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0158])\n",
						"第 11351 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0158])\n",
						"第 11352 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0158])\n",
						"第 11353 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0158])\n",
						"第 11354 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0157])\n",
						"第 11355 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0157])\n",
						"第 11356 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0157])\n",
						"第 11357 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0157])\n",
						"第 11358 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0157])\n",
						"第 11359 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0157])\n",
						"第 11360 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0157])\n",
						"第 568 次epoch\n",
						"第 11361 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0157])\n",
						"第 11362 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0157])\n",
						"第 11363 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0157])\n",
						"第 11364 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0157])\n",
						"第 11365 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0157])\n",
						"第 11366 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0157])\n",
						"第 11367 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0157])\n",
						"第 11368 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0157])\n",
						"第 11369 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0156])\n",
						"第 11370 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0156])\n",
						"第 11371 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0156])\n",
						"第 11372 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0156])\n",
						"第 11373 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0156])\n",
						"第 11374 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0156])\n",
						"第 11375 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0156])\n",
						"第 11376 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0156])\n",
						"第 11377 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0156])\n",
						"第 11378 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0156])\n",
						"第 11379 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0156])\n",
						"第 11380 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0156])\n",
						"第 569 次epoch\n",
						"第 11381 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0156])\n",
						"第 11382 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0156])\n",
						"第 11383 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0156])\n",
						"第 11384 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0156])\n",
						"第 11385 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0155])\n",
						"第 11386 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0155])\n",
						"第 11387 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0155])\n",
						"第 11388 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0155])\n",
						"第 11389 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0155])\n",
						"第 11390 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0155])\n",
						"第 11391 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0155])\n",
						"第 11392 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0155])\n",
						"第 11393 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0155])\n",
						"第 11394 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0155])\n",
						"第 11395 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0155])\n",
						"第 11396 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0155])\n",
						"第 11397 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0155])\n",
						"第 11398 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0155])\n",
						"第 11399 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0155])\n",
						"第 11400 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0154])\n",
						"第 570 次epoch\n",
						"第 11401 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0154])\n",
						"第 11402 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0154])\n",
						"第 11403 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0154])\n",
						"第 11404 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0154])\n",
						"第 11405 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0154])\n",
						"第 11406 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0154])\n",
						"第 11407 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0154])\n",
						"第 11408 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0154])\n",
						"第 11409 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0154])\n",
						"第 11410 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0154])\n",
						"第 11411 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0154])\n",
						"第 11412 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0154])\n",
						"第 11413 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0154])\n",
						"第 11414 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0153])\n",
						"第 11415 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0154])\n",
						"第 11416 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0153])\n",
						"第 11417 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0153])\n",
						"第 11418 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0153])\n",
						"第 11419 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0153])\n",
						"第 11420 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0153])\n",
						"第 571 次epoch\n",
						"第 11421 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0153])\n",
						"第 11422 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0153])\n",
						"第 11423 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0153])\n",
						"第 11424 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0153])\n",
						"第 11425 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0153])\n",
						"第 11426 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0153])\n",
						"第 11427 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0153])\n",
						"第 11428 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0153])\n",
						"第 11429 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0153])\n",
						"第 11430 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0152])\n",
						"第 11431 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0152])\n",
						"第 11432 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0152])\n",
						"第 11433 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0152])\n",
						"第 11434 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0152])\n",
						"第 11435 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0152])\n",
						"第 11436 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0152])\n",
						"第 11437 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0152])\n",
						"第 11438 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0152])\n",
						"第 11439 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0152])\n",
						"第 11440 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0152])\n",
						"第 572 次epoch\n",
						"第 11441 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0152])\n",
						"第 11442 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0152])\n",
						"第 11443 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0152])\n",
						"第 11444 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0152])\n",
						"第 11445 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0151])\n",
						"第 11446 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0151])\n",
						"第 11447 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0151])\n",
						"第 11448 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0151])\n",
						"第 11449 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0151])\n",
						"第 11450 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0151])\n",
						"第 11451 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0151])\n",
						"第 11452 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0151])\n",
						"第 11453 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0151])\n",
						"第 11454 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0151])\n",
						"第 11455 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0151])\n",
						"第 11456 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0151])\n",
						"第 11457 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0151])\n",
						"第 11458 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0151])\n",
						"第 11459 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0150])\n",
						"第 11460 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0151])\n",
						"第 573 次epoch\n",
						"第 11461 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0150])\n",
						"第 11462 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0150])\n",
						"第 11463 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0150])\n",
						"第 11464 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0150])\n",
						"第 11465 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0150])\n",
						"第 11466 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0150])\n",
						"第 11467 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0150])\n",
						"第 11468 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0150])\n",
						"第 11469 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0150])\n",
						"第 11470 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0150])\n",
						"第 11471 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0150])\n",
						"第 11472 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0150])\n",
						"第 11473 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0150])\n",
						"第 11474 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0150])\n",
						"第 11475 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0149])\n",
						"第 11476 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0149])\n",
						"第 11477 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0149])\n",
						"第 11478 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0149])\n",
						"第 11479 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0149])\n",
						"第 11480 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0149])\n",
						"第 574 次epoch\n",
						"第 11481 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0149])\n",
						"第 11482 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0149])\n",
						"第 11483 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0149])\n",
						"第 11484 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0149])\n",
						"第 11485 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0149])\n",
						"第 11486 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0149])\n",
						"第 11487 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0149])\n",
						"第 11488 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0149])\n",
						"第 11489 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0149])\n",
						"第 11490 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0148])\n",
						"第 11491 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0148])\n",
						"第 11492 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0148])\n",
						"第 11493 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0148])\n",
						"第 11494 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0148])\n",
						"第 11495 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0148])\n",
						"第 11496 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0148])\n",
						"第 11497 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0148])\n",
						"第 11498 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0148])\n",
						"第 11499 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0148])\n",
						"第 11500 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0148])\n",
						"第 575 次epoch\n",
						"第 11501 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0148])\n",
						"第 11502 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0148])\n",
						"第 11503 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0148])\n",
						"第 11504 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0148])\n",
						"第 11505 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0147])\n",
						"第 11506 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0148])\n",
						"第 11507 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0147])\n",
						"第 11508 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0147])\n",
						"第 11509 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0147])\n",
						"第 11510 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0147])\n",
						"第 11511 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0147])\n",
						"第 11512 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0147])\n",
						"第 11513 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0147])\n",
						"第 11514 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0147])\n",
						"第 11515 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0147])\n",
						"第 11516 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0147])\n",
						"第 11517 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0147])\n",
						"第 11518 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0147])\n",
						"第 11519 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0147])\n",
						"第 11520 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0147])\n",
						"第 576 次epoch\n",
						"第 11521 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0147])\n",
						"第 11522 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0146])\n",
						"第 11523 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0146])\n",
						"第 11524 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0146])\n",
						"第 11525 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0146])\n",
						"第 11526 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0146])\n",
						"第 11527 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0146])\n",
						"第 11528 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0146])\n",
						"第 11529 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0146])\n",
						"第 11530 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0146])\n",
						"第 11531 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0146])\n",
						"第 11532 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0146])\n",
						"第 11533 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0146])\n",
						"第 11534 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0146])\n",
						"第 11535 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0146])\n",
						"第 11536 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0146])\n",
						"第 11537 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0146])\n",
						"第 11538 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0145])\n",
						"第 11539 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0145])\n",
						"第 11540 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0145])\n",
						"第 577 次epoch\n",
						"第 11541 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0145])\n",
						"第 11542 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0145])\n",
						"第 11543 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0145])\n",
						"第 11544 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0145])\n",
						"第 11545 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0145])\n",
						"第 11546 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0145])\n",
						"第 11547 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0145])\n",
						"第 11548 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0145])\n",
						"第 11549 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0145])\n",
						"第 11550 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0145])\n",
						"第 11551 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0145])\n",
						"第 11552 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0145])\n",
						"第 11553 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0145])\n",
						"第 11554 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0145])\n",
						"第 11555 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0144])\n",
						"第 11556 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0144])\n",
						"第 11557 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0144])\n",
						"第 11558 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0144])\n",
						"第 11559 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0144])\n",
						"第 11560 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0144])\n",
						"第 578 次epoch\n",
						"第 11561 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0144])\n",
						"第 11562 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0144])\n",
						"第 11563 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0144])\n",
						"第 11564 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0144])\n",
						"第 11565 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0144])\n",
						"第 11566 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0144])\n",
						"第 11567 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0144])\n",
						"第 11568 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0144])\n",
						"第 11569 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0144])\n",
						"第 11570 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0143])\n",
						"第 11571 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0143])\n",
						"第 11572 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0143])\n",
						"第 11573 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0143])\n",
						"第 11574 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0143])\n",
						"第 11575 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0143])\n",
						"第 11576 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0143])\n",
						"第 11577 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0143])\n",
						"第 11578 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0143])\n",
						"第 11579 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0143])\n",
						"第 11580 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0143])\n",
						"第 579 次epoch\n",
						"第 11581 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0143])\n",
						"第 11582 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0143])\n",
						"第 11583 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0143])\n",
						"第 11584 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0143])\n",
						"第 11585 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0143])\n",
						"第 11586 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0142])\n",
						"第 11587 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0142])\n",
						"第 11588 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0142])\n",
						"第 11589 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0142])\n",
						"第 11590 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0142])\n",
						"第 11591 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0142])\n",
						"第 11592 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0142])\n",
						"第 11593 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0142])\n",
						"第 11594 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0142])\n",
						"第 11595 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0142])\n",
						"第 11596 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0142])\n",
						"第 11597 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0142])\n",
						"第 11598 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0142])\n",
						"第 11599 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0142])\n",
						"第 11600 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0142])\n",
						"第 580 次epoch\n",
						"第 11601 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0142])\n",
						"第 11602 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0142])\n",
						"第 11603 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0141])\n",
						"第 11604 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0141])\n",
						"第 11605 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0141])\n",
						"第 11606 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0141])\n",
						"第 11607 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0141])\n",
						"第 11608 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0141])\n",
						"第 11609 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0141])\n",
						"第 11610 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0141])\n",
						"第 11611 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0141])\n",
						"第 11612 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0141])\n",
						"第 11613 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0141])\n",
						"第 11614 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0141])\n",
						"第 11615 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0141])\n",
						"第 11616 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0141])\n",
						"第 11617 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0141])\n",
						"第 11618 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0140])\n",
						"第 11619 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0140])\n",
						"第 11620 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0140])\n",
						"第 581 次epoch\n",
						"第 11621 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0140])\n",
						"第 11622 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0140])\n",
						"第 11623 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0140])\n",
						"第 11624 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0140])\n",
						"第 11625 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0140])\n",
						"第 11626 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0140])\n",
						"第 11627 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0140])\n",
						"第 11628 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0140])\n",
						"第 11629 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0140])\n",
						"第 11630 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0140])\n",
						"第 11631 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0140])\n",
						"第 11632 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0140])\n",
						"第 11633 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0140])\n",
						"第 11634 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0139])\n",
						"第 11635 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0139])\n",
						"第 11636 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0139])\n",
						"第 11637 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0139])\n",
						"第 11638 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0139])\n",
						"第 11639 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0139])\n",
						"第 11640 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0139])\n",
						"第 582 次epoch\n",
						"第 11641 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0139])\n",
						"第 11642 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0139])\n",
						"第 11643 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0139])\n",
						"第 11644 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0139])\n",
						"第 11645 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0139])\n",
						"第 11646 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0139])\n",
						"第 11647 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0139])\n",
						"第 11648 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0139])\n",
						"第 11649 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0139])\n",
						"第 11650 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0139])\n",
						"第 11651 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0138])\n",
						"第 11652 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0138])\n",
						"第 11653 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0138])\n",
						"第 11654 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0138])\n",
						"第 11655 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0138])\n",
						"第 11656 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0138])\n",
						"第 11657 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0138])\n",
						"第 11658 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0138])\n",
						"第 11659 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0138])\n",
						"第 11660 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0138])\n",
						"第 583 次epoch\n",
						"第 11661 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0138])\n",
						"第 11662 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0138])\n",
						"第 11663 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0048]])\n",
						"模型中偏参梯度 tensor([-0.0138])\n",
						"第 11664 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0138])\n",
						"第 11665 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0138])\n",
						"第 11666 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0138])\n",
						"第 11667 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0138])\n",
						"第 11668 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0137])\n",
						"第 11669 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0137])\n",
						"第 11670 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0137])\n",
						"第 11671 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0137])\n",
						"第 11672 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0137])\n",
						"第 11673 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0137])\n",
						"第 11674 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0137])\n",
						"第 11675 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0137])\n",
						"第 11676 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0137])\n",
						"第 11677 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0137])\n",
						"第 11678 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0137])\n",
						"第 11679 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0137])\n",
						"第 11680 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0137])\n",
						"第 584 次epoch\n",
						"第 11681 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0137])\n",
						"第 11682 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0137])\n",
						"第 11683 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0137])\n",
						"第 11684 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0137])\n",
						"第 11685 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0137])\n",
						"第 11686 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0137])\n",
						"第 11687 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0136])\n",
						"第 11688 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0136])\n",
						"第 11689 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0136])\n",
						"第 11690 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0136])\n",
						"第 11691 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0136])\n",
						"第 11692 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0136])\n",
						"第 11693 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0136])\n",
						"第 11694 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0136])\n",
						"第 11695 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0136])\n",
						"第 11696 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0136])\n",
						"第 11697 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0136])\n",
						"第 11698 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0136])\n",
						"第 11699 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0136])\n",
						"第 11700 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0136])\n",
						"第 585 次epoch\n",
						"第 11701 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0136])\n",
						"第 11702 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0136])\n",
						"第 11703 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0136])\n",
						"第 11704 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0136])\n",
						"第 11705 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0135])\n",
						"第 11706 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0135])\n",
						"第 11707 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0135])\n",
						"第 11708 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0135])\n",
						"第 11709 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0135])\n",
						"第 11710 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0135])\n",
						"第 11711 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0135])\n",
						"第 11712 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0135])\n",
						"第 11713 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0135])\n",
						"第 11714 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0135])\n",
						"第 11715 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0135])\n",
						"第 11716 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0135])\n",
						"第 11717 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0135])\n",
						"第 11718 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0135])\n",
						"第 11719 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0135])\n",
						"第 11720 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0135])\n",
						"第 586 次epoch\n",
						"第 11721 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0135])\n",
						"第 11722 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0135])\n",
						"第 11723 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0134])\n",
						"第 11724 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0134])\n",
						"第 11725 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0134])\n",
						"第 11726 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0134])\n",
						"第 11727 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0134])\n",
						"第 11728 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0134])\n",
						"第 11729 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0134])\n",
						"第 11730 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0134])\n",
						"第 11731 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0134])\n",
						"第 11732 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0134])\n",
						"第 11733 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0134])\n",
						"第 11734 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0134])\n",
						"第 11735 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0134])\n",
						"第 11736 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0134])\n",
						"第 11737 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0134])\n",
						"第 11738 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0134])\n",
						"第 11739 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0047]])\n",
						"模型中偏参梯度 tensor([-0.0134])\n",
						"第 11740 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0046]])\n",
						"模型中偏参梯度 tensor([-0.0134])\n",
						"第 587 次epoch\n",
						"第 11741 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0046]])\n",
						"模型中偏参梯度 tensor([-0.0134])\n",
						"第 11742 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0046]])\n",
						"模型中偏参梯度 tensor([-0.0133])\n",
						"第 11743 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0046]])\n",
						"模型中偏参梯度 tensor([-0.0133])\n",
						"第 11744 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0046]])\n",
						"模型中偏参梯度 tensor([-0.0133])\n",
						"第 11745 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0046]])\n",
						"模型中偏参梯度 tensor([-0.0133])\n",
						"第 11746 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0046]])\n",
						"模型中偏参梯度 tensor([-0.0133])\n",
						"第 11747 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0046]])\n",
						"模型中偏参梯度 tensor([-0.0133])\n",
						"第 11748 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0046]])\n",
						"模型中偏参梯度 tensor([-0.0133])\n",
						"第 11749 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0046]])\n",
						"模型中偏参梯度 tensor([-0.0133])\n",
						"第 11750 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0046]])\n",
						"模型中偏参梯度 tensor([-0.0133])\n",
						"第 11751 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0046]])\n",
						"模型中偏参梯度 tensor([-0.0133])\n",
						"第 11752 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0046]])\n",
						"模型中偏参梯度 tensor([-0.0133])\n",
						"第 11753 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0046]])\n",
						"模型中偏参梯度 tensor([-0.0133])\n",
						"第 11754 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0046]])\n",
						"模型中偏参梯度 tensor([-0.0133])\n",
						"第 11755 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0046]])\n",
						"模型中偏参梯度 tensor([-0.0133])\n",
						"第 11756 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0046]])\n",
						"模型中偏参梯度 tensor([-0.0133])\n",
						"第 11757 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0046]])\n",
						"模型中偏参梯度 tensor([-0.0133])\n",
						"第 11758 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0046]])\n",
						"模型中偏参梯度 tensor([-0.0133])\n",
						"第 11759 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0046]])\n",
						"模型中偏参梯度 tensor([-0.0133])\n",
						"第 11760 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0046]])\n",
						"模型中偏参梯度 tensor([-0.0132])\n",
						"第 588 次epoch\n",
						"第 11761 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0046]])\n",
						"模型中偏参梯度 tensor([-0.0132])\n",
						"第 11762 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0046]])\n",
						"模型中偏参梯度 tensor([-0.0132])\n",
						"第 11763 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0046]])\n",
						"模型中偏参梯度 tensor([-0.0132])\n",
						"第 11764 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0046]])\n",
						"模型中偏参梯度 tensor([-0.0132])\n",
						"第 11765 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0046]])\n",
						"模型中偏参梯度 tensor([-0.0132])\n",
						"第 11766 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0046]])\n",
						"模型中偏参梯度 tensor([-0.0132])\n",
						"第 11767 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0046]])\n",
						"模型中偏参梯度 tensor([-0.0132])\n",
						"第 11768 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0046]])\n",
						"模型中偏参梯度 tensor([-0.0132])\n",
						"第 11769 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0046]])\n",
						"模型中偏参梯度 tensor([-0.0132])\n",
						"第 11770 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0046]])\n",
						"模型中偏参梯度 tensor([-0.0132])\n",
						"第 11771 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0046]])\n",
						"模型中偏参梯度 tensor([-0.0132])\n",
						"第 11772 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0046]])\n",
						"模型中偏参梯度 tensor([-0.0132])\n",
						"第 11773 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0046]])\n",
						"模型中偏参梯度 tensor([-0.0132])\n",
						"第 11774 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0046]])\n",
						"模型中偏参梯度 tensor([-0.0132])\n",
						"第 11775 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0046]])\n",
						"模型中偏参梯度 tensor([-0.0132])\n",
						"第 11776 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0046]])\n",
						"模型中偏参梯度 tensor([-0.0132])\n",
						"第 11777 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0046]])\n",
						"模型中偏参梯度 tensor([-0.0132])\n",
						"第 11778 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0046]])\n",
						"模型中偏参梯度 tensor([-0.0132])\n",
						"第 11779 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0046]])\n",
						"模型中偏参梯度 tensor([-0.0131])\n",
						"第 11780 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0046]])\n",
						"模型中偏参梯度 tensor([-0.0131])\n",
						"第 589 次epoch\n",
						"第 11781 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0046]])\n",
						"模型中偏参梯度 tensor([-0.0131])\n",
						"第 11782 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0046]])\n",
						"模型中偏参梯度 tensor([-0.0131])\n",
						"第 11783 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0046]])\n",
						"模型中偏参梯度 tensor([-0.0131])\n",
						"第 11784 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0046]])\n",
						"模型中偏参梯度 tensor([-0.0131])\n",
						"第 11785 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0046]])\n",
						"模型中偏参梯度 tensor([-0.0131])\n",
						"第 11786 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0046]])\n",
						"模型中偏参梯度 tensor([-0.0131])\n",
						"第 11787 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0046]])\n",
						"模型中偏参梯度 tensor([-0.0131])\n",
						"第 11788 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0046]])\n",
						"模型中偏参梯度 tensor([-0.0131])\n",
						"第 11789 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0046]])\n",
						"模型中偏参梯度 tensor([-0.0131])\n",
						"第 11790 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0046]])\n",
						"模型中偏参梯度 tensor([-0.0131])\n",
						"第 11791 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0046]])\n",
						"模型中偏参梯度 tensor([-0.0131])\n",
						"第 11792 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0046]])\n",
						"模型中偏参梯度 tensor([-0.0131])\n",
						"第 11793 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0046]])\n",
						"模型中偏参梯度 tensor([-0.0131])\n",
						"第 11794 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0046]])\n",
						"模型中偏参梯度 tensor([-0.0131])\n",
						"第 11795 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0046]])\n",
						"模型中偏参梯度 tensor([-0.0131])\n",
						"第 11796 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0046]])\n",
						"模型中偏参梯度 tensor([-0.0131])\n",
						"第 11797 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0046]])\n",
						"模型中偏参梯度 tensor([-0.0130])\n",
						"第 11798 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0046]])\n",
						"模型中偏参梯度 tensor([-0.0130])\n",
						"第 11799 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0046]])\n",
						"模型中偏参梯度 tensor([-0.0130])\n",
						"第 11800 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0046]])\n",
						"模型中偏参梯度 tensor([-0.0130])\n",
						"第 590 次epoch\n",
						"第 11801 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0046]])\n",
						"模型中偏参梯度 tensor([-0.0130])\n",
						"第 11802 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0046]])\n",
						"模型中偏参梯度 tensor([-0.0130])\n",
						"第 11803 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0046]])\n",
						"模型中偏参梯度 tensor([-0.0130])\n",
						"第 11804 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0046]])\n",
						"模型中偏参梯度 tensor([-0.0130])\n",
						"第 11805 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0046]])\n",
						"模型中偏参梯度 tensor([-0.0130])\n",
						"第 11806 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0046]])\n",
						"模型中偏参梯度 tensor([-0.0130])\n",
						"第 11807 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0046]])\n",
						"模型中偏参梯度 tensor([-0.0130])\n",
						"第 11808 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0046]])\n",
						"模型中偏参梯度 tensor([-0.0130])\n",
						"第 11809 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0046]])\n",
						"模型中偏参梯度 tensor([-0.0130])\n",
						"第 11810 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0046]])\n",
						"模型中偏参梯度 tensor([-0.0130])\n",
						"第 11811 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0046]])\n",
						"模型中偏参梯度 tensor([-0.0130])\n",
						"第 11812 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0046]])\n",
						"模型中偏参梯度 tensor([-0.0130])\n",
						"第 11813 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0045]])\n",
						"模型中偏参梯度 tensor([-0.0130])\n",
						"第 11814 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0046]])\n",
						"模型中偏参梯度 tensor([-0.0130])\n",
						"第 11815 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0046]])\n",
						"模型中偏参梯度 tensor([-0.0129])\n",
						"第 11816 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0045]])\n",
						"模型中偏参梯度 tensor([-0.0129])\n",
						"第 11817 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0045]])\n",
						"模型中偏参梯度 tensor([-0.0129])\n",
						"第 11818 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0045]])\n",
						"模型中偏参梯度 tensor([-0.0129])\n",
						"第 11819 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0045]])\n",
						"模型中偏参梯度 tensor([-0.0129])\n",
						"第 11820 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0045]])\n",
						"模型中偏参梯度 tensor([-0.0129])\n",
						"第 591 次epoch\n",
						"第 11821 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0045]])\n",
						"模型中偏参梯度 tensor([-0.0129])\n",
						"第 11822 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0045]])\n",
						"模型中偏参梯度 tensor([-0.0129])\n",
						"第 11823 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0045]])\n",
						"模型中偏参梯度 tensor([-0.0129])\n",
						"第 11824 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0045]])\n",
						"模型中偏参梯度 tensor([-0.0129])\n",
						"第 11825 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0045]])\n",
						"模型中偏参梯度 tensor([-0.0129])\n",
						"第 11826 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0045]])\n",
						"模型中偏参梯度 tensor([-0.0129])\n",
						"第 11827 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0045]])\n",
						"模型中偏参梯度 tensor([-0.0129])\n",
						"第 11828 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0045]])\n",
						"模型中偏参梯度 tensor([-0.0129])\n",
						"第 11829 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0045]])\n",
						"模型中偏参梯度 tensor([-0.0129])\n",
						"第 11830 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0045]])\n",
						"模型中偏参梯度 tensor([-0.0129])\n",
						"第 11831 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0045]])\n",
						"模型中偏参梯度 tensor([-0.0129])\n",
						"第 11832 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0045]])\n",
						"模型中偏参梯度 tensor([-0.0129])\n",
						"第 11833 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0045]])\n",
						"模型中偏参梯度 tensor([-0.0129])\n",
						"第 11834 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0045]])\n",
						"模型中偏参梯度 tensor([-0.0129])\n",
						"第 11835 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0045]])\n",
						"模型中偏参梯度 tensor([-0.0129])\n",
						"第 11836 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0045]])\n",
						"模型中偏参梯度 tensor([-0.0128])\n",
						"第 11837 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0045]])\n",
						"模型中偏参梯度 tensor([-0.0128])\n",
						"第 11838 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0045]])\n",
						"模型中偏参梯度 tensor([-0.0128])\n",
						"第 11839 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0045]])\n",
						"模型中偏参梯度 tensor([-0.0128])\n",
						"第 11840 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0045]])\n",
						"模型中偏参梯度 tensor([-0.0128])\n",
						"第 592 次epoch\n",
						"第 11841 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0045]])\n",
						"模型中偏参梯度 tensor([-0.0128])\n",
						"第 11842 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0044]])\n",
						"模型中偏参梯度 tensor([-0.0128])\n",
						"第 11843 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0044]])\n",
						"模型中偏参梯度 tensor([-0.0128])\n",
						"第 11844 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0044]])\n",
						"模型中偏参梯度 tensor([-0.0128])\n",
						"第 11845 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0044]])\n",
						"模型中偏参梯度 tensor([-0.0128])\n",
						"第 11846 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0044]])\n",
						"模型中偏参梯度 tensor([-0.0128])\n",
						"第 11847 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0044]])\n",
						"模型中偏参梯度 tensor([-0.0128])\n",
						"第 11848 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0044]])\n",
						"模型中偏参梯度 tensor([-0.0128])\n",
						"第 11849 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0044]])\n",
						"模型中偏参梯度 tensor([-0.0128])\n",
						"第 11850 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0044]])\n",
						"模型中偏参梯度 tensor([-0.0128])\n",
						"第 11851 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0044]])\n",
						"模型中偏参梯度 tensor([-0.0128])\n",
						"第 11852 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0044]])\n",
						"模型中偏参梯度 tensor([-0.0128])\n",
						"第 11853 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0044]])\n",
						"模型中偏参梯度 tensor([-0.0128])\n",
						"第 11854 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0044]])\n",
						"模型中偏参梯度 tensor([-0.0128])\n",
						"第 11855 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0044]])\n",
						"模型中偏参梯度 tensor([-0.0128])\n",
						"第 11856 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0044]])\n",
						"模型中偏参梯度 tensor([-0.0128])\n",
						"第 11857 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0044]])\n",
						"模型中偏参梯度 tensor([-0.0128])\n",
						"第 11858 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0043]])\n",
						"模型中偏参梯度 tensor([-0.0128])\n",
						"第 11859 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0043]])\n",
						"模型中偏参梯度 tensor([-0.0128])\n",
						"第 11860 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0043]])\n",
						"模型中偏参梯度 tensor([-0.0128])\n",
						"第 593 次epoch\n",
						"第 11861 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0043]])\n",
						"模型中偏参梯度 tensor([-0.0128])\n",
						"第 11862 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0043]])\n",
						"模型中偏参梯度 tensor([-0.0128])\n",
						"第 11863 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0043]])\n",
						"模型中偏参梯度 tensor([-0.0128])\n",
						"第 11864 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0043]])\n",
						"模型中偏参梯度 tensor([-0.0127])\n",
						"第 11865 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0043]])\n",
						"模型中偏参梯度 tensor([-0.0127])\n",
						"第 11866 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0043]])\n",
						"模型中偏参梯度 tensor([-0.0127])\n",
						"第 11867 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0043]])\n",
						"模型中偏参梯度 tensor([-0.0127])\n",
						"第 11868 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0043]])\n",
						"模型中偏参梯度 tensor([-0.0127])\n",
						"第 11869 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0043]])\n",
						"模型中偏参梯度 tensor([-0.0127])\n",
						"第 11870 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0043]])\n",
						"模型中偏参梯度 tensor([-0.0127])\n",
						"第 11871 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0043]])\n",
						"模型中偏参梯度 tensor([-0.0127])\n",
						"第 11872 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0042]])\n",
						"模型中偏参梯度 tensor([-0.0127])\n",
						"第 11873 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0042]])\n",
						"模型中偏参梯度 tensor([-0.0127])\n",
						"第 11874 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0042]])\n",
						"模型中偏参梯度 tensor([-0.0127])\n",
						"第 11875 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0042]])\n",
						"模型中偏参梯度 tensor([-0.0127])\n",
						"第 11876 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0042]])\n",
						"模型中偏参梯度 tensor([-0.0127])\n",
						"第 11877 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0042]])\n",
						"模型中偏参梯度 tensor([-0.0127])\n",
						"第 11878 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0042]])\n",
						"模型中偏参梯度 tensor([-0.0127])\n",
						"第 11879 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0042]])\n",
						"模型中偏参梯度 tensor([-0.0127])\n",
						"第 11880 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0042]])\n",
						"模型中偏参梯度 tensor([-0.0127])\n",
						"第 594 次epoch\n",
						"第 11881 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0042]])\n",
						"模型中偏参梯度 tensor([-0.0127])\n",
						"第 11882 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0042]])\n",
						"模型中偏参梯度 tensor([-0.0127])\n",
						"第 11883 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0042]])\n",
						"模型中偏参梯度 tensor([-0.0127])\n",
						"第 11884 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0042]])\n",
						"模型中偏参梯度 tensor([-0.0127])\n",
						"第 11885 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0042]])\n",
						"模型中偏参梯度 tensor([-0.0127])\n",
						"第 11886 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0042]])\n",
						"模型中偏参梯度 tensor([-0.0127])\n",
						"第 11887 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0041]])\n",
						"模型中偏参梯度 tensor([-0.0127])\n",
						"第 11888 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0041]])\n",
						"模型中偏参梯度 tensor([-0.0127])\n",
						"第 11889 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0041]])\n",
						"模型中偏参梯度 tensor([-0.0127])\n",
						"第 11890 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0041]])\n",
						"模型中偏参梯度 tensor([-0.0127])\n",
						"第 11891 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0041]])\n",
						"模型中偏参梯度 tensor([-0.0127])\n",
						"第 11892 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0041]])\n",
						"模型中偏参梯度 tensor([-0.0127])\n",
						"第 11893 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0041]])\n",
						"模型中偏参梯度 tensor([-0.0126])\n",
						"第 11894 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0041]])\n",
						"模型中偏参梯度 tensor([-0.0126])\n",
						"第 11895 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0041]])\n",
						"模型中偏参梯度 tensor([-0.0126])\n",
						"第 11896 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0041]])\n",
						"模型中偏参梯度 tensor([-0.0126])\n",
						"第 11897 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0041]])\n",
						"模型中偏参梯度 tensor([-0.0126])\n",
						"第 11898 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0041]])\n",
						"模型中偏参梯度 tensor([-0.0126])\n",
						"第 11899 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0041]])\n",
						"模型中偏参梯度 tensor([-0.0126])\n",
						"第 11900 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0041]])\n",
						"模型中偏参梯度 tensor([-0.0126])\n",
						"第 595 次epoch\n",
						"第 11901 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0041]])\n",
						"模型中偏参梯度 tensor([-0.0126])\n",
						"第 11902 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0040]])\n",
						"模型中偏参梯度 tensor([-0.0126])\n",
						"第 11903 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0040]])\n",
						"模型中偏参梯度 tensor([-0.0126])\n",
						"第 11904 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0040]])\n",
						"模型中偏参梯度 tensor([-0.0126])\n",
						"第 11905 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0040]])\n",
						"模型中偏参梯度 tensor([-0.0126])\n",
						"第 11906 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0040]])\n",
						"模型中偏参梯度 tensor([-0.0126])\n",
						"第 11907 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0040]])\n",
						"模型中偏参梯度 tensor([-0.0126])\n",
						"第 11908 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0040]])\n",
						"模型中偏参梯度 tensor([-0.0126])\n",
						"第 11909 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0040]])\n",
						"模型中偏参梯度 tensor([-0.0126])\n",
						"第 11910 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0040]])\n",
						"模型中偏参梯度 tensor([-0.0126])\n",
						"第 11911 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0040]])\n",
						"模型中偏参梯度 tensor([-0.0126])\n",
						"第 11912 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0040]])\n",
						"模型中偏参梯度 tensor([-0.0126])\n",
						"第 11913 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0040]])\n",
						"模型中偏参梯度 tensor([-0.0126])\n",
						"第 11914 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0040]])\n",
						"模型中偏参梯度 tensor([-0.0126])\n",
						"第 11915 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0040]])\n",
						"模型中偏参梯度 tensor([-0.0126])\n",
						"第 11916 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0040]])\n",
						"模型中偏参梯度 tensor([-0.0126])\n",
						"第 11917 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0039]])\n",
						"模型中偏参梯度 tensor([-0.0126])\n",
						"第 11918 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0039]])\n",
						"模型中偏参梯度 tensor([-0.0126])\n",
						"第 11919 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0039]])\n",
						"模型中偏参梯度 tensor([-0.0126])\n",
						"第 11920 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0039]])\n",
						"模型中偏参梯度 tensor([-0.0126])\n",
						"第 596 次epoch\n",
						"第 11921 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0039]])\n",
						"模型中偏参梯度 tensor([-0.0125])\n",
						"第 11922 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0039]])\n",
						"模型中偏参梯度 tensor([-0.0125])\n",
						"第 11923 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0039]])\n",
						"模型中偏参梯度 tensor([-0.0125])\n",
						"第 11924 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0039]])\n",
						"模型中偏参梯度 tensor([-0.0125])\n",
						"第 11925 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0039]])\n",
						"模型中偏参梯度 tensor([-0.0125])\n",
						"第 11926 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0039]])\n",
						"模型中偏参梯度 tensor([-0.0125])\n",
						"第 11927 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0039]])\n",
						"模型中偏参梯度 tensor([-0.0125])\n",
						"第 11928 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0039]])\n",
						"模型中偏参梯度 tensor([-0.0125])\n",
						"第 11929 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0039]])\n",
						"模型中偏参梯度 tensor([-0.0125])\n",
						"第 11930 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0039]])\n",
						"模型中偏参梯度 tensor([-0.0125])\n",
						"第 11931 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0039]])\n",
						"模型中偏参梯度 tensor([-0.0125])\n",
						"第 11932 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0039]])\n",
						"模型中偏参梯度 tensor([-0.0125])\n",
						"第 11933 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0038]])\n",
						"模型中偏参梯度 tensor([-0.0125])\n",
						"第 11934 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0038]])\n",
						"模型中偏参梯度 tensor([-0.0125])\n",
						"第 11935 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0038]])\n",
						"模型中偏参梯度 tensor([-0.0125])\n",
						"第 11936 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0038]])\n",
						"模型中偏参梯度 tensor([-0.0125])\n",
						"第 11937 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0038]])\n",
						"模型中偏参梯度 tensor([-0.0125])\n",
						"第 11938 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0038]])\n",
						"模型中偏参梯度 tensor([-0.0125])\n",
						"第 11939 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0038]])\n",
						"模型中偏参梯度 tensor([-0.0125])\n",
						"第 11940 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0038]])\n",
						"模型中偏参梯度 tensor([-0.0125])\n",
						"第 597 次epoch\n",
						"第 11941 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0038]])\n",
						"模型中偏参梯度 tensor([-0.0125])\n",
						"第 11942 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0038]])\n",
						"模型中偏参梯度 tensor([-0.0125])\n",
						"第 11943 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0038]])\n",
						"模型中偏参梯度 tensor([-0.0125])\n",
						"第 11944 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0038]])\n",
						"模型中偏参梯度 tensor([-0.0125])\n",
						"第 11945 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0038]])\n",
						"模型中偏参梯度 tensor([-0.0125])\n",
						"第 11946 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0038]])\n",
						"模型中偏参梯度 tensor([-0.0125])\n",
						"第 11947 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0037]])\n",
						"模型中偏参梯度 tensor([-0.0125])\n",
						"第 11948 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0037]])\n",
						"模型中偏参梯度 tensor([-0.0125])\n",
						"第 11949 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0037]])\n",
						"模型中偏参梯度 tensor([-0.0125])\n",
						"第 11950 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0037]])\n",
						"模型中偏参梯度 tensor([-0.0124])\n",
						"第 11951 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0037]])\n",
						"模型中偏参梯度 tensor([-0.0124])\n",
						"第 11952 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0037]])\n",
						"模型中偏参梯度 tensor([-0.0124])\n",
						"第 11953 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0037]])\n",
						"模型中偏参梯度 tensor([-0.0124])\n",
						"第 11954 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0037]])\n",
						"模型中偏参梯度 tensor([-0.0124])\n",
						"第 11955 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0037]])\n",
						"模型中偏参梯度 tensor([-0.0124])\n",
						"第 11956 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0037]])\n",
						"模型中偏参梯度 tensor([-0.0124])\n",
						"第 11957 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0037]])\n",
						"模型中偏参梯度 tensor([-0.0124])\n",
						"第 11958 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0037]])\n",
						"模型中偏参梯度 tensor([-0.0124])\n",
						"第 11959 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0037]])\n",
						"模型中偏参梯度 tensor([-0.0124])\n",
						"第 11960 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0037]])\n",
						"模型中偏参梯度 tensor([-0.0124])\n",
						"第 598 次epoch\n",
						"第 11961 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0037]])\n",
						"模型中偏参梯度 tensor([-0.0124])\n",
						"第 11962 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0037]])\n",
						"模型中偏参梯度 tensor([-0.0124])\n",
						"第 11963 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0036]])\n",
						"模型中偏参梯度 tensor([-0.0124])\n",
						"第 11964 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0036]])\n",
						"模型中偏参梯度 tensor([-0.0124])\n",
						"第 11965 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0036]])\n",
						"模型中偏参梯度 tensor([-0.0124])\n",
						"第 11966 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0036]])\n",
						"模型中偏参梯度 tensor([-0.0124])\n",
						"第 11967 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0036]])\n",
						"模型中偏参梯度 tensor([-0.0124])\n",
						"第 11968 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0036]])\n",
						"模型中偏参梯度 tensor([-0.0124])\n",
						"第 11969 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0036]])\n",
						"模型中偏参梯度 tensor([-0.0124])\n",
						"第 11970 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0036]])\n",
						"模型中偏参梯度 tensor([-0.0124])\n",
						"第 11971 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0036]])\n",
						"模型中偏参梯度 tensor([-0.0124])\n",
						"第 11972 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0036]])\n",
						"模型中偏参梯度 tensor([-0.0124])\n",
						"第 11973 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0036]])\n",
						"模型中偏参梯度 tensor([-0.0124])\n",
						"第 11974 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0036]])\n",
						"模型中偏参梯度 tensor([-0.0124])\n",
						"第 11975 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0036]])\n",
						"模型中偏参梯度 tensor([-0.0124])\n",
						"第 11976 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0036]])\n",
						"模型中偏参梯度 tensor([-0.0124])\n",
						"第 11977 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0036]])\n",
						"模型中偏参梯度 tensor([-0.0124])\n",
						"第 11978 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0035]])\n",
						"模型中偏参梯度 tensor([-0.0123])\n",
						"第 11979 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0035]])\n",
						"模型中偏参梯度 tensor([-0.0123])\n",
						"第 11980 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0035]])\n",
						"模型中偏参梯度 tensor([-0.0123])\n",
						"第 599 次epoch\n",
						"第 11981 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0035]])\n",
						"模型中偏参梯度 tensor([-0.0123])\n",
						"第 11982 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0035]])\n",
						"模型中偏参梯度 tensor([-0.0123])\n",
						"第 11983 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0035]])\n",
						"模型中偏参梯度 tensor([-0.0123])\n",
						"第 11984 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0035]])\n",
						"模型中偏参梯度 tensor([-0.0123])\n",
						"第 11985 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0035]])\n",
						"模型中偏参梯度 tensor([-0.0123])\n",
						"第 11986 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0035]])\n",
						"模型中偏参梯度 tensor([-0.0123])\n",
						"第 11987 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0035]])\n",
						"模型中偏参梯度 tensor([-0.0123])\n",
						"第 11988 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0035]])\n",
						"模型中偏参梯度 tensor([-0.0123])\n",
						"第 11989 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0035]])\n",
						"模型中偏参梯度 tensor([-0.0123])\n",
						"第 11990 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0035]])\n",
						"模型中偏参梯度 tensor([-0.0123])\n",
						"第 11991 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0035]])\n",
						"模型中偏参梯度 tensor([-0.0123])\n",
						"第 11992 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0035]])\n",
						"模型中偏参梯度 tensor([-0.0123])\n",
						"第 11993 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0034]])\n",
						"模型中偏参梯度 tensor([-0.0123])\n",
						"第 11994 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0034]])\n",
						"模型中偏参梯度 tensor([-0.0123])\n",
						"第 11995 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0034]])\n",
						"模型中偏参梯度 tensor([-0.0123])\n",
						"第 11996 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0034]])\n",
						"模型中偏参梯度 tensor([-0.0123])\n",
						"第 11997 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0034]])\n",
						"模型中偏参梯度 tensor([-0.0123])\n",
						"第 11998 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0034]])\n",
						"模型中偏参梯度 tensor([-0.0123])\n",
						"第 11999 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0034]])\n",
						"模型中偏参梯度 tensor([-0.0123])\n",
						"第 12000 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0034]])\n",
						"模型中偏参梯度 tensor([-0.0123])\n",
						"第 600 次epoch\n",
						"第 12001 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0034]])\n",
						"模型中偏参梯度 tensor([-0.0123])\n",
						"第 12002 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0034]])\n",
						"模型中偏参梯度 tensor([-0.0123])\n",
						"第 12003 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0034]])\n",
						"模型中偏参梯度 tensor([-0.0123])\n",
						"第 12004 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0034]])\n",
						"模型中偏参梯度 tensor([-0.0123])\n",
						"第 12005 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0034]])\n",
						"模型中偏参梯度 tensor([-0.0123])\n",
						"第 12006 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0034]])\n",
						"模型中偏参梯度 tensor([-0.0122])\n",
						"第 12007 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0034]])\n",
						"模型中偏参梯度 tensor([-0.0122])\n",
						"第 12008 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0034]])\n",
						"模型中偏参梯度 tensor([-0.0122])\n",
						"第 12009 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0033]])\n",
						"模型中偏参梯度 tensor([-0.0122])\n",
						"第 12010 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0033]])\n",
						"模型中偏参梯度 tensor([-0.0122])\n",
						"第 12011 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0033]])\n",
						"模型中偏参梯度 tensor([-0.0122])\n",
						"第 12012 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0033]])\n",
						"模型中偏参梯度 tensor([-0.0122])\n",
						"第 12013 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0033]])\n",
						"模型中偏参梯度 tensor([-0.0122])\n",
						"第 12014 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0033]])\n",
						"模型中偏参梯度 tensor([-0.0122])\n",
						"第 12015 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0033]])\n",
						"模型中偏参梯度 tensor([-0.0122])\n",
						"第 12016 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0033]])\n",
						"模型中偏参梯度 tensor([-0.0122])\n",
						"第 12017 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0033]])\n",
						"模型中偏参梯度 tensor([-0.0122])\n",
						"第 12018 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0033]])\n",
						"模型中偏参梯度 tensor([-0.0122])\n",
						"第 12019 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0033]])\n",
						"模型中偏参梯度 tensor([-0.0122])\n",
						"第 12020 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0033]])\n",
						"模型中偏参梯度 tensor([-0.0122])\n",
						"第 601 次epoch\n",
						"第 12021 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0033]])\n",
						"模型中偏参梯度 tensor([-0.0122])\n",
						"第 12022 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0033]])\n",
						"模型中偏参梯度 tensor([-0.0122])\n",
						"第 12023 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0032]])\n",
						"模型中偏参梯度 tensor([-0.0122])\n",
						"第 12024 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0032]])\n",
						"模型中偏参梯度 tensor([-0.0122])\n",
						"第 12025 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0032]])\n",
						"模型中偏参梯度 tensor([-0.0122])\n",
						"第 12026 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0032]])\n",
						"模型中偏参梯度 tensor([-0.0122])\n",
						"第 12027 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0032]])\n",
						"模型中偏参梯度 tensor([-0.0122])\n",
						"第 12028 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0032]])\n",
						"模型中偏参梯度 tensor([-0.0122])\n",
						"第 12029 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0032]])\n",
						"模型中偏参梯度 tensor([-0.0122])\n",
						"第 12030 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0032]])\n",
						"模型中偏参梯度 tensor([-0.0122])\n",
						"第 12031 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0032]])\n",
						"模型中偏参梯度 tensor([-0.0122])\n",
						"第 12032 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0032]])\n",
						"模型中偏参梯度 tensor([-0.0122])\n",
						"第 12033 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0032]])\n",
						"模型中偏参梯度 tensor([-0.0122])\n",
						"第 12034 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0032]])\n",
						"模型中偏参梯度 tensor([-0.0121])\n",
						"第 12035 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0032]])\n",
						"模型中偏参梯度 tensor([-0.0121])\n",
						"第 12036 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0032]])\n",
						"模型中偏参梯度 tensor([-0.0121])\n",
						"第 12037 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0031]])\n",
						"模型中偏参梯度 tensor([-0.0121])\n",
						"第 12038 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0031]])\n",
						"模型中偏参梯度 tensor([-0.0121])\n",
						"第 12039 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0031]])\n",
						"模型中偏参梯度 tensor([-0.0121])\n",
						"第 12040 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0031]])\n",
						"模型中偏参梯度 tensor([-0.0121])\n",
						"第 602 次epoch\n",
						"第 12041 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0031]])\n",
						"模型中偏参梯度 tensor([-0.0121])\n",
						"第 12042 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0031]])\n",
						"模型中偏参梯度 tensor([-0.0121])\n",
						"第 12043 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0031]])\n",
						"模型中偏参梯度 tensor([-0.0121])\n",
						"第 12044 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0031]])\n",
						"模型中偏参梯度 tensor([-0.0121])\n",
						"第 12045 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0031]])\n",
						"模型中偏参梯度 tensor([-0.0121])\n",
						"第 12046 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0031]])\n",
						"模型中偏参梯度 tensor([-0.0121])\n",
						"第 12047 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0031]])\n",
						"模型中偏参梯度 tensor([-0.0121])\n",
						"第 12048 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0031]])\n",
						"模型中偏参梯度 tensor([-0.0121])\n",
						"第 12049 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0031]])\n",
						"模型中偏参梯度 tensor([-0.0121])\n",
						"第 12050 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0031]])\n",
						"模型中偏参梯度 tensor([-0.0121])\n",
						"第 12051 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0031]])\n",
						"模型中偏参梯度 tensor([-0.0121])\n",
						"第 12052 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0031]])\n",
						"模型中偏参梯度 tensor([-0.0121])\n",
						"第 12053 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0030]])\n",
						"模型中偏参梯度 tensor([-0.0121])\n",
						"第 12054 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0030]])\n",
						"模型中偏参梯度 tensor([-0.0121])\n",
						"第 12055 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0030]])\n",
						"模型中偏参梯度 tensor([-0.0121])\n",
						"第 12056 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0030]])\n",
						"模型中偏参梯度 tensor([-0.0121])\n",
						"第 12057 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0030]])\n",
						"模型中偏参梯度 tensor([-0.0121])\n",
						"第 12058 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0030]])\n",
						"模型中偏参梯度 tensor([-0.0121])\n",
						"第 12059 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0030]])\n",
						"模型中偏参梯度 tensor([-0.0121])\n",
						"第 12060 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0030]])\n",
						"模型中偏参梯度 tensor([-0.0121])\n",
						"第 603 次epoch\n",
						"第 12061 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0030]])\n",
						"模型中偏参梯度 tensor([-0.0121])\n",
						"第 12062 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0030]])\n",
						"模型中偏参梯度 tensor([-0.0121])\n",
						"第 12063 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0030]])\n",
						"模型中偏参梯度 tensor([-0.0120])\n",
						"第 12064 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0030]])\n",
						"模型中偏参梯度 tensor([-0.0120])\n",
						"第 12065 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0030]])\n",
						"模型中偏参梯度 tensor([-0.0120])\n",
						"第 12066 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0030]])\n",
						"模型中偏参梯度 tensor([-0.0120])\n",
						"第 12067 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0030]])\n",
						"模型中偏参梯度 tensor([-0.0120])\n",
						"第 12068 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0120])\n",
						"第 12069 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0120])\n",
						"第 12070 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0120])\n",
						"第 12071 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0120])\n",
						"第 12072 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0120])\n",
						"第 12073 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0120])\n",
						"第 12074 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0120])\n",
						"第 12075 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0120])\n",
						"第 12076 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0120])\n",
						"第 12077 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0120])\n",
						"第 12078 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0120])\n",
						"第 12079 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0120])\n",
						"第 12080 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0120])\n",
						"第 604 次epoch\n",
						"第 12081 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0120])\n",
						"第 12082 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0120])\n",
						"第 12083 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0120])\n",
						"第 12084 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0120])\n",
						"第 12085 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0120])\n",
						"第 12086 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0120])\n",
						"第 12087 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0120])\n",
						"第 12088 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0119])\n",
						"第 12089 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0119])\n",
						"第 12090 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0119])\n",
						"第 12091 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0119])\n",
						"第 12092 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0119])\n",
						"第 12093 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0119])\n",
						"第 12094 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0119])\n",
						"第 12095 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0119])\n",
						"第 12096 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0119])\n",
						"第 12097 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0119])\n",
						"第 12098 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0119])\n",
						"第 12099 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0119])\n",
						"第 12100 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0119])\n",
						"第 605 次epoch\n",
						"第 12101 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0119])\n",
						"第 12102 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0119])\n",
						"第 12103 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0119])\n",
						"第 12104 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0119])\n",
						"第 12105 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0119])\n",
						"第 12106 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0119])\n",
						"第 12107 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0118])\n",
						"第 12108 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0118])\n",
						"第 12109 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0118])\n",
						"第 12110 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0118])\n",
						"第 12111 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0118])\n",
						"第 12112 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0118])\n",
						"第 12113 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0118])\n",
						"第 12114 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0118])\n",
						"第 12115 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0118])\n",
						"第 12116 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0118])\n",
						"第 12117 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0118])\n",
						"第 12118 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0118])\n",
						"第 12119 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0118])\n",
						"第 12120 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0118])\n",
						"第 606 次epoch\n",
						"第 12121 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0118])\n",
						"第 12122 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0118])\n",
						"第 12123 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0118])\n",
						"第 12124 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0118])\n",
						"第 12125 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0118])\n",
						"第 12126 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0117])\n",
						"第 12127 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0117])\n",
						"第 12128 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0117])\n",
						"第 12129 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0117])\n",
						"第 12130 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0117])\n",
						"第 12131 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0117])\n",
						"第 12132 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0117])\n",
						"第 12133 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0117])\n",
						"第 12134 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0117])\n",
						"第 12135 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0117])\n",
						"第 12136 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0117])\n",
						"第 12137 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0117])\n",
						"第 12138 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0117])\n",
						"第 12139 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0117])\n",
						"第 12140 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0117])\n",
						"第 607 次epoch\n",
						"第 12141 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0117])\n",
						"第 12142 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0117])\n",
						"第 12143 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0117])\n",
						"第 12144 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0117])\n",
						"第 12145 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0117])\n",
						"第 12146 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0117])\n",
						"第 12147 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0117])\n",
						"第 12148 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0116])\n",
						"第 12149 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0116])\n",
						"第 12150 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0116])\n",
						"第 12151 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0116])\n",
						"第 12152 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0116])\n",
						"第 12153 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0116])\n",
						"第 12154 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0116])\n",
						"第 12155 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0116])\n",
						"第 12156 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0116])\n",
						"第 12157 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0116])\n",
						"第 12158 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0116])\n",
						"第 12159 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0116])\n",
						"第 12160 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0116])\n",
						"第 608 次epoch\n",
						"第 12161 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0116])\n",
						"第 12162 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0116])\n",
						"第 12163 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0116])\n",
						"第 12164 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0116])\n",
						"第 12165 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0116])\n",
						"第 12166 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0116])\n",
						"第 12167 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0115])\n",
						"第 12168 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0115])\n",
						"第 12169 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0115])\n",
						"第 12170 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0115])\n",
						"第 12171 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0115])\n",
						"第 12172 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0115])\n",
						"第 12173 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0115])\n",
						"第 12174 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0115])\n",
						"第 12175 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0115])\n",
						"第 12176 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0115])\n",
						"第 12177 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0115])\n",
						"第 12178 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0115])\n",
						"第 12179 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0115])\n",
						"第 12180 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0115])\n",
						"第 609 次epoch\n",
						"第 12181 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0115])\n",
						"第 12182 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0115])\n",
						"第 12183 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0115])\n",
						"第 12184 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0115])\n",
						"第 12185 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0115])\n",
						"第 12186 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0114])\n",
						"第 12187 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0114])\n",
						"第 12188 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0114])\n",
						"第 12189 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0114])\n",
						"第 12190 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0114])\n",
						"第 12191 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0114])\n",
						"第 12192 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0114])\n",
						"第 12193 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0114])\n",
						"第 12194 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0114])\n",
						"第 12195 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0114])\n",
						"第 12196 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0114])\n",
						"第 12197 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0114])\n",
						"第 12198 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0114])\n",
						"第 12199 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0114])\n",
						"第 12200 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0114])\n",
						"第 610 次epoch\n",
						"第 12201 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0114])\n",
						"第 12202 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0114])\n",
						"第 12203 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0114])\n",
						"第 12204 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0114])\n",
						"第 12205 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0114])\n",
						"第 12206 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0114])\n",
						"第 12207 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0114])\n",
						"第 12208 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0113])\n",
						"第 12209 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0113])\n",
						"第 12210 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0113])\n",
						"第 12211 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0113])\n",
						"第 12212 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0113])\n",
						"第 12213 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0113])\n",
						"第 12214 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0113])\n",
						"第 12215 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0113])\n",
						"第 12216 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0113])\n",
						"第 12217 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0113])\n",
						"第 12218 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0113])\n",
						"第 12219 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0113])\n",
						"第 12220 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0113])\n",
						"第 611 次epoch\n",
						"第 12221 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0113])\n",
						"第 12222 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0113])\n",
						"第 12223 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0113])\n",
						"第 12224 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0113])\n",
						"第 12225 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0113])\n",
						"第 12226 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0113])\n",
						"第 12227 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0112])\n",
						"第 12228 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0112])\n",
						"第 12229 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0112])\n",
						"第 12230 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0112])\n",
						"第 12231 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0112])\n",
						"第 12232 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0112])\n",
						"第 12233 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0112])\n",
						"第 12234 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0112])\n",
						"第 12235 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0112])\n",
						"第 12236 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0112])\n",
						"第 12237 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0112])\n",
						"第 12238 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0112])\n",
						"第 12239 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0112])\n",
						"第 12240 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0112])\n",
						"第 612 次epoch\n",
						"第 12241 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0112])\n",
						"第 12242 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0112])\n",
						"第 12243 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0112])\n",
						"第 12244 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0112])\n",
						"第 12245 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0112])\n",
						"第 12246 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0112])\n",
						"第 12247 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0111])\n",
						"第 12248 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0111])\n",
						"第 12249 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0111])\n",
						"第 12250 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0111])\n",
						"第 12251 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0111])\n",
						"第 12252 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0111])\n",
						"第 12253 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0111])\n",
						"第 12254 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0111])\n",
						"第 12255 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0111])\n",
						"第 12256 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0111])\n",
						"第 12257 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0111])\n",
						"第 12258 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0111])\n",
						"第 12259 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0111])\n",
						"第 12260 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0111])\n",
						"第 613 次epoch\n",
						"第 12261 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0111])\n",
						"第 12262 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0111])\n",
						"第 12263 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0111])\n",
						"第 12264 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0111])\n",
						"第 12265 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0111])\n",
						"第 12266 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0111])\n",
						"第 12267 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0111])\n",
						"第 12268 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0111])\n",
						"第 12269 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0110])\n",
						"第 12270 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0110])\n",
						"第 12271 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0110])\n",
						"第 12272 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0110])\n",
						"第 12273 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0110])\n",
						"第 12274 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0110])\n",
						"第 12275 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0110])\n",
						"第 12276 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0110])\n",
						"第 12277 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0110])\n",
						"第 12278 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0110])\n",
						"第 12279 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0110])\n",
						"第 12280 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0110])\n",
						"第 614 次epoch\n",
						"第 12281 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0110])\n",
						"第 12282 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0110])\n",
						"第 12283 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0110])\n",
						"第 12284 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0110])\n",
						"第 12285 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0110])\n",
						"第 12286 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0110])\n",
						"第 12287 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0110])\n",
						"第 12288 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0110])\n",
						"第 12289 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0109])\n",
						"第 12290 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0109])\n",
						"第 12291 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0109])\n",
						"第 12292 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0109])\n",
						"第 12293 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0109])\n",
						"第 12294 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0109])\n",
						"第 12295 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0109])\n",
						"第 12296 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0109])\n",
						"第 12297 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0109])\n",
						"第 12298 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0109])\n",
						"第 12299 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0109])\n",
						"第 12300 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0109])\n",
						"第 615 次epoch\n",
						"第 12301 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0109])\n",
						"第 12302 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0109])\n",
						"第 12303 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0109])\n",
						"第 12304 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0109])\n",
						"第 12305 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0109])\n",
						"第 12306 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0109])\n",
						"第 12307 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0109])\n",
						"第 12308 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0109])\n",
						"第 12309 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0109])\n",
						"第 12310 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0109])\n",
						"第 12311 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0108])\n",
						"第 12312 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0108])\n",
						"第 12313 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0108])\n",
						"第 12314 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0108])\n",
						"第 12315 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0108])\n",
						"第 12316 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0108])\n",
						"第 12317 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0108])\n",
						"第 12318 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0108])\n",
						"第 12319 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0108])\n",
						"第 12320 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0108])\n",
						"第 616 次epoch\n",
						"第 12321 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0108])\n",
						"第 12322 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0108])\n",
						"第 12323 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0108])\n",
						"第 12324 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0108])\n",
						"第 12325 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0108])\n",
						"第 12326 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0108])\n",
						"第 12327 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0108])\n",
						"第 12328 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0108])\n",
						"第 12329 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0108])\n",
						"第 12330 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0108])\n",
						"第 12331 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0108])\n",
						"第 12332 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0108])\n",
						"第 12333 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0107])\n",
						"第 12334 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0107])\n",
						"第 12335 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0107])\n",
						"第 12336 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0107])\n",
						"第 12337 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0107])\n",
						"第 12338 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0107])\n",
						"第 12339 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0107])\n",
						"第 12340 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0107])\n",
						"第 617 次epoch\n",
						"第 12341 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0107])\n",
						"第 12342 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0107])\n",
						"第 12343 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0107])\n",
						"第 12344 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0107])\n",
						"第 12345 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0107])\n",
						"第 12346 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0107])\n",
						"第 12347 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0107])\n",
						"第 12348 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0107])\n",
						"第 12349 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0107])\n",
						"第 12350 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0107])\n",
						"第 12351 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0107])\n",
						"第 12352 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0107])\n",
						"第 12353 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0107])\n",
						"第 12354 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0107])\n",
						"第 12355 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0106])\n",
						"第 12356 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0106])\n",
						"第 12357 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0106])\n",
						"第 12358 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0106])\n",
						"第 12359 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0106])\n",
						"第 12360 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0106])\n",
						"第 618 次epoch\n",
						"第 12361 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0106])\n",
						"第 12362 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0106])\n",
						"第 12363 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0106])\n",
						"第 12364 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0106])\n",
						"第 12365 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0106])\n",
						"第 12366 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0106])\n",
						"第 12367 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0106])\n",
						"第 12368 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0106])\n",
						"第 12369 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0106])\n",
						"第 12370 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0106])\n",
						"第 12371 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0106])\n",
						"第 12372 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0106])\n",
						"第 12373 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0106])\n",
						"第 12374 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0106])\n",
						"第 12375 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0106])\n",
						"第 12376 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0106])\n",
						"第 12377 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0105])\n",
						"第 12378 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0105])\n",
						"第 12379 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0105])\n",
						"第 12380 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0105])\n",
						"第 619 次epoch\n",
						"第 12381 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0105])\n",
						"第 12382 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0105])\n",
						"第 12383 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0105])\n",
						"第 12384 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0105])\n",
						"第 12385 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0105])\n",
						"第 12386 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0105])\n",
						"第 12387 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0105])\n",
						"第 12388 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0105])\n",
						"第 12389 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0105])\n",
						"第 12390 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0105])\n",
						"第 12391 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0105])\n",
						"第 12392 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0105])\n",
						"第 12393 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0105])\n",
						"第 12394 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0105])\n",
						"第 12395 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0105])\n",
						"第 12396 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0105])\n",
						"第 12397 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0105])\n",
						"第 12398 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0105])\n",
						"第 12399 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0104])\n",
						"第 12400 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0104])\n",
						"第 620 次epoch\n",
						"第 12401 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0104])\n",
						"第 12402 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0104])\n",
						"第 12403 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0104])\n",
						"第 12404 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0104])\n",
						"第 12405 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0104])\n",
						"第 12406 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0104])\n",
						"第 12407 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0104])\n",
						"第 12408 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0104])\n",
						"第 12409 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0104])\n",
						"第 12410 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0104])\n",
						"第 12411 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0104])\n",
						"第 12412 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0104])\n",
						"第 12413 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0104])\n",
						"第 12414 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0104])\n",
						"第 12415 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0104])\n",
						"第 12416 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0104])\n",
						"第 12417 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0104])\n",
						"第 12418 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0104])\n",
						"第 12419 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0104])\n",
						"第 12420 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0103])\n",
						"第 621 次epoch\n",
						"第 12421 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0103])\n",
						"第 12422 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0103])\n",
						"第 12423 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0103])\n",
						"第 12424 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0103])\n",
						"第 12425 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0103])\n",
						"第 12426 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0103])\n",
						"第 12427 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0103])\n",
						"第 12428 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0103])\n",
						"第 12429 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0103])\n",
						"第 12430 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0103])\n",
						"第 12431 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0103])\n",
						"第 12432 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0103])\n",
						"第 12433 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0103])\n",
						"第 12434 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0103])\n",
						"第 12435 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0103])\n",
						"第 12436 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0103])\n",
						"第 12437 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0103])\n",
						"第 12438 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0103])\n",
						"第 12439 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0103])\n",
						"第 12440 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0103])\n",
						"第 622 次epoch\n",
						"第 12441 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0103])\n",
						"第 12442 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0103])\n",
						"第 12443 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0102])\n",
						"第 12444 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0102])\n",
						"第 12445 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0102])\n",
						"第 12446 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0102])\n",
						"第 12447 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0102])\n",
						"第 12448 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0102])\n",
						"第 12449 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0102])\n",
						"第 12450 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0102])\n",
						"第 12451 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0102])\n",
						"第 12452 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0102])\n",
						"第 12453 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0102])\n",
						"第 12454 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0102])\n",
						"第 12455 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0102])\n",
						"第 12456 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0102])\n",
						"第 12457 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0102])\n",
						"第 12458 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0102])\n",
						"第 12459 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0102])\n",
						"第 12460 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0102])\n",
						"第 623 次epoch\n",
						"第 12461 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0102])\n",
						"第 12462 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0102])\n",
						"第 12463 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0102])\n",
						"第 12464 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0102])\n",
						"第 12465 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0101])\n",
						"第 12466 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0101])\n",
						"第 12467 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0101])\n",
						"第 12468 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0101])\n",
						"第 12469 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0101])\n",
						"第 12470 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0101])\n",
						"第 12471 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0101])\n",
						"第 12472 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0101])\n",
						"第 12473 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0101])\n",
						"第 12474 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0101])\n",
						"第 12475 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0101])\n",
						"第 12476 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0101])\n",
						"第 12477 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0101])\n",
						"第 12478 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0101])\n",
						"第 12479 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0101])\n",
						"第 12480 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0101])\n",
						"第 624 次epoch\n",
						"第 12481 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0101])\n",
						"第 12482 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0101])\n",
						"第 12483 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0101])\n",
						"第 12484 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0101])\n",
						"第 12485 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0101])\n",
						"第 12486 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0101])\n",
						"第 12487 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0100])\n",
						"第 12488 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0100])\n",
						"第 12489 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0100])\n",
						"第 12490 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0100])\n",
						"第 12491 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0100])\n",
						"第 12492 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0100])\n",
						"第 12493 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0100])\n",
						"第 12494 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0100])\n",
						"第 12495 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0100])\n",
						"第 12496 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0100])\n",
						"第 12497 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0100])\n",
						"第 12498 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0100])\n",
						"第 12499 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0100])\n",
						"第 12500 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0100])\n",
						"第 625 次epoch\n",
						"第 12501 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0100])\n",
						"第 12502 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0100])\n",
						"第 12503 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0100])\n",
						"第 12504 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0100])\n",
						"第 12505 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0100])\n",
						"第 12506 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0100])\n",
						"第 12507 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0100])\n",
						"第 12508 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0100])\n",
						"第 12509 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0100])\n",
						"第 12510 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0099])\n",
						"第 12511 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0099])\n",
						"第 12512 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0099])\n",
						"第 12513 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0099])\n",
						"第 12514 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0099])\n",
						"第 12515 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0099])\n",
						"第 12516 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0099])\n",
						"第 12517 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0099])\n",
						"第 12518 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0099])\n",
						"第 12519 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0099])\n",
						"第 12520 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0099])\n",
						"第 626 次epoch\n",
						"第 12521 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0099])\n",
						"第 12522 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0099])\n",
						"第 12523 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0099])\n",
						"第 12524 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0099])\n",
						"第 12525 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0099])\n",
						"第 12526 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0099])\n",
						"第 12527 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0099])\n",
						"第 12528 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0099])\n",
						"第 12529 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0099])\n",
						"第 12530 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0099])\n",
						"第 12531 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0099])\n",
						"第 12532 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0099])\n",
						"第 12533 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0099])\n",
						"第 12534 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0098])\n",
						"第 12535 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0098])\n",
						"第 12536 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0098])\n",
						"第 12537 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0098])\n",
						"第 12538 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0098])\n",
						"第 12539 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0098])\n",
						"第 12540 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0098])\n",
						"第 627 次epoch\n",
						"第 12541 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0098])\n",
						"第 12542 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0098])\n",
						"第 12543 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0098])\n",
						"第 12544 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0098])\n",
						"第 12545 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0098])\n",
						"第 12546 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0098])\n",
						"第 12547 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0098])\n",
						"第 12548 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0098])\n",
						"第 12549 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0098])\n",
						"第 12550 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0098])\n",
						"第 12551 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0098])\n",
						"第 12552 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0098])\n",
						"第 12553 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0098])\n",
						"第 12554 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0098])\n",
						"第 12555 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0098])\n",
						"第 12556 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0098])\n",
						"第 12557 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0097])\n",
						"第 12558 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0098])\n",
						"第 12559 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0097])\n",
						"第 12560 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0097])\n",
						"第 628 次epoch\n",
						"第 12561 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0097])\n",
						"第 12562 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0097])\n",
						"第 12563 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0097])\n",
						"第 12564 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0097])\n",
						"第 12565 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0097])\n",
						"第 12566 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0097])\n",
						"第 12567 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0097])\n",
						"第 12568 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0097])\n",
						"第 12569 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0097])\n",
						"第 12570 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0097])\n",
						"第 12571 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0097])\n",
						"第 12572 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0097])\n",
						"第 12573 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0097])\n",
						"第 12574 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0097])\n",
						"第 12575 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0097])\n",
						"第 12576 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0097])\n",
						"第 12577 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0097])\n",
						"第 12578 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0097])\n",
						"第 12579 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0097])\n",
						"第 12580 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0097])\n",
						"第 629 次epoch\n",
						"第 12581 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0097])\n",
						"第 12582 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0097])\n",
						"第 12583 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0096])\n",
						"第 12584 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0096])\n",
						"第 12585 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0096])\n",
						"第 12586 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0096])\n",
						"第 12587 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0096])\n",
						"第 12588 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0096])\n",
						"第 12589 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0096])\n",
						"第 12590 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0096])\n",
						"第 12591 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0096])\n",
						"第 12592 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0096])\n",
						"第 12593 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0096])\n",
						"第 12594 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0096])\n",
						"第 12595 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0096])\n",
						"第 12596 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0096])\n",
						"第 12597 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0096])\n",
						"第 12598 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0096])\n",
						"第 12599 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0096])\n",
						"第 12600 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0096])\n",
						"第 630 次epoch\n",
						"第 12601 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0096])\n",
						"第 12602 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0096])\n",
						"第 12603 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0096])\n",
						"第 12604 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0096])\n",
						"第 12605 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0096])\n",
						"第 12606 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0095])\n",
						"第 12607 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0095])\n",
						"第 12608 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0095])\n",
						"第 12609 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0095])\n",
						"第 12610 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0095])\n",
						"第 12611 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0095])\n",
						"第 12612 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0095])\n",
						"第 12613 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0095])\n",
						"第 12614 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0095])\n",
						"第 12615 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0095])\n",
						"第 12616 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0095])\n",
						"第 12617 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0095])\n",
						"第 12618 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0095])\n",
						"第 12619 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0095])\n",
						"第 12620 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0095])\n",
						"第 631 次epoch\n",
						"第 12621 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0095])\n",
						"第 12622 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0095])\n",
						"第 12623 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0095])\n",
						"第 12624 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0095])\n",
						"第 12625 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0095])\n",
						"第 12626 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0095])\n",
						"第 12627 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0095])\n",
						"第 12628 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0095])\n",
						"第 12629 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0095])\n",
						"第 12630 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0095])\n",
						"第 12631 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0094])\n",
						"第 12632 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0094])\n",
						"第 12633 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0094])\n",
						"第 12634 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0094])\n",
						"第 12635 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0094])\n",
						"第 12636 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0094])\n",
						"第 12637 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0094])\n",
						"第 12638 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0094])\n",
						"第 12639 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0094])\n",
						"第 12640 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0094])\n",
						"第 632 次epoch\n",
						"第 12641 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0094])\n",
						"第 12642 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0094])\n",
						"第 12643 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0094])\n",
						"第 12644 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0094])\n",
						"第 12645 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0094])\n",
						"第 12646 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0094])\n",
						"第 12647 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0094])\n",
						"第 12648 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0094])\n",
						"第 12649 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0094])\n",
						"第 12650 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0094])\n",
						"第 12651 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0094])\n",
						"第 12652 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0093])\n",
						"第 12653 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0094])\n",
						"第 12654 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0094])\n",
						"第 12655 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0093])\n",
						"第 12656 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0093])\n",
						"第 12657 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0093])\n",
						"第 12658 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0093])\n",
						"第 12659 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0093])\n",
						"第 12660 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0093])\n",
						"第 633 次epoch\n",
						"第 12661 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0093])\n",
						"第 12662 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0093])\n",
						"第 12663 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0093])\n",
						"第 12664 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0093])\n",
						"第 12665 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0093])\n",
						"第 12666 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0093])\n",
						"第 12667 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0093])\n",
						"第 12668 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0093])\n",
						"第 12669 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0093])\n",
						"第 12670 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0093])\n",
						"第 12671 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0093])\n",
						"第 12672 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0093])\n",
						"第 12673 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0093])\n",
						"第 12674 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0093])\n",
						"第 12675 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0093])\n",
						"第 12676 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0093])\n",
						"第 12677 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0093])\n",
						"第 12678 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0092])\n",
						"第 12679 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0092])\n",
						"第 12680 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0092])\n",
						"第 634 次epoch\n",
						"第 12681 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0092])\n",
						"第 12682 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0092])\n",
						"第 12683 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0092])\n",
						"第 12684 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0092])\n",
						"第 12685 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0092])\n",
						"第 12686 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0092])\n",
						"第 12687 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0092])\n",
						"第 12688 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0092])\n",
						"第 12689 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0092])\n",
						"第 12690 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0092])\n",
						"第 12691 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0092])\n",
						"第 12692 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0092])\n",
						"第 12693 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0092])\n",
						"第 12694 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0092])\n",
						"第 12695 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0092])\n",
						"第 12696 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0092])\n",
						"第 12697 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0092])\n",
						"第 12698 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0092])\n",
						"第 12699 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0092])\n",
						"第 12700 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0092])\n",
						"第 635 次epoch\n",
						"第 12701 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0092])\n",
						"第 12702 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0092])\n",
						"第 12703 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0091])\n",
						"第 12704 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0091])\n",
						"第 12705 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0091])\n",
						"第 12706 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0091])\n",
						"第 12707 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0091])\n",
						"第 12708 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0091])\n",
						"第 12709 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0091])\n",
						"第 12710 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0091])\n",
						"第 12711 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0091])\n",
						"第 12712 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0091])\n",
						"第 12713 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0091])\n",
						"第 12714 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0091])\n",
						"第 12715 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0091])\n",
						"第 12716 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0091])\n",
						"第 12717 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0091])\n",
						"第 12718 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0091])\n",
						"第 12719 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0091])\n",
						"第 12720 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0091])\n",
						"第 636 次epoch\n",
						"第 12721 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0091])\n",
						"第 12722 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0091])\n",
						"第 12723 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0091])\n",
						"第 12724 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0091])\n",
						"第 12725 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0091])\n",
						"第 12726 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0091])\n",
						"第 12727 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0091])\n",
						"第 12728 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0090])\n",
						"第 12729 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0090])\n",
						"第 12730 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0090])\n",
						"第 12731 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0090])\n",
						"第 12732 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0090])\n",
						"第 12733 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0090])\n",
						"第 12734 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0090])\n",
						"第 12735 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0090])\n",
						"第 12736 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0090])\n",
						"第 12737 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0090])\n",
						"第 12738 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0090])\n",
						"第 12739 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0090])\n",
						"第 12740 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0090])\n",
						"第 637 次epoch\n",
						"第 12741 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0090])\n",
						"第 12742 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0090])\n",
						"第 12743 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0090])\n",
						"第 12744 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0090])\n",
						"第 12745 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0090])\n",
						"第 12746 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0090])\n",
						"第 12747 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0090])\n",
						"第 12748 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0090])\n",
						"第 12749 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0090])\n",
						"第 12750 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0090])\n",
						"第 12751 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0090])\n",
						"第 12752 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0090])\n",
						"第 12753 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0090])\n",
						"第 12754 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0089])\n",
						"第 12755 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0089])\n",
						"第 12756 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0089])\n",
						"第 12757 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0089])\n",
						"第 12758 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0089])\n",
						"第 12759 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0089])\n",
						"第 12760 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0089])\n",
						"第 638 次epoch\n",
						"第 12761 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0089])\n",
						"第 12762 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0089])\n",
						"第 12763 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0089])\n",
						"第 12764 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0089])\n",
						"第 12765 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0089])\n",
						"第 12766 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0089])\n",
						"第 12767 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0089])\n",
						"第 12768 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0089])\n",
						"第 12769 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0089])\n",
						"第 12770 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0089])\n",
						"第 12771 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0089])\n",
						"第 12772 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0089])\n",
						"第 12773 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0089])\n",
						"第 12774 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0089])\n",
						"第 12775 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0089])\n",
						"第 12776 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0089])\n",
						"第 12777 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0089])\n",
						"第 12778 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0089])\n",
						"第 12779 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0089])\n",
						"第 12780 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0089])\n",
						"第 639 次epoch\n",
						"第 12781 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0088])\n",
						"第 12782 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0088])\n",
						"第 12783 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0088])\n",
						"第 12784 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0088])\n",
						"第 12785 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0088])\n",
						"第 12786 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0088])\n",
						"第 12787 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0088])\n",
						"第 12788 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0088])\n",
						"第 12789 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0088])\n",
						"第 12790 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0088])\n",
						"第 12791 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0088])\n",
						"第 12792 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0088])\n",
						"第 12793 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0088])\n",
						"第 12794 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0088])\n",
						"第 12795 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0088])\n",
						"第 12796 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0088])\n",
						"第 12797 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0088])\n",
						"第 12798 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0088])\n",
						"第 12799 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0088])\n",
						"第 12800 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0088])\n",
						"第 640 次epoch\n",
						"第 12801 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0088])\n",
						"第 12802 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0088])\n",
						"第 12803 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0088])\n",
						"第 12804 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0088])\n",
						"第 12805 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0088])\n",
						"第 12806 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0088])\n",
						"第 12807 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0088])\n",
						"第 12808 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0087])\n",
						"第 12809 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0087])\n",
						"第 12810 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0087])\n",
						"第 12811 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0087])\n",
						"第 12812 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0087])\n",
						"第 12813 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0087])\n",
						"第 12814 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0087])\n",
						"第 12815 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0087])\n",
						"第 12816 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0087])\n",
						"第 12817 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0087])\n",
						"第 12818 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0087])\n",
						"第 12819 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0087])\n",
						"第 12820 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0087])\n",
						"第 641 次epoch\n",
						"第 12821 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0087])\n",
						"第 12822 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0087])\n",
						"第 12823 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0087])\n",
						"第 12824 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0087])\n",
						"第 12825 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0087])\n",
						"第 12826 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0087])\n",
						"第 12827 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0087])\n",
						"第 12828 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0087])\n",
						"第 12829 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0087])\n",
						"第 12830 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0087])\n",
						"第 12831 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0087])\n",
						"第 12832 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0087])\n",
						"第 12833 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0087])\n",
						"第 12834 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0087])\n",
						"第 12835 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0086])\n",
						"第 12836 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0086])\n",
						"第 12837 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0086])\n",
						"第 12838 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0086])\n",
						"第 12839 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0086])\n",
						"第 12840 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0086])\n",
						"第 642 次epoch\n",
						"第 12841 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0086])\n",
						"第 12842 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0086])\n",
						"第 12843 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0086])\n",
						"第 12844 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0086])\n",
						"第 12845 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0086])\n",
						"第 12846 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0086])\n",
						"第 12847 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0086])\n",
						"第 12848 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0086])\n",
						"第 12849 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0086])\n",
						"第 12850 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0086])\n",
						"第 12851 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0086])\n",
						"第 12852 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0086])\n",
						"第 12853 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0086])\n",
						"第 12854 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0086])\n",
						"第 12855 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0086])\n",
						"第 12856 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0086])\n",
						"第 12857 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0086])\n",
						"第 12858 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0086])\n",
						"第 12859 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0086])\n",
						"第 12860 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0086])\n",
						"第 643 次epoch\n",
						"第 12861 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0085])\n",
						"第 12862 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0085])\n",
						"第 12863 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0085])\n",
						"第 12864 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0085])\n",
						"第 12865 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0085])\n",
						"第 12866 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0085])\n",
						"第 12867 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0085])\n",
						"第 12868 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0085])\n",
						"第 12869 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0085])\n",
						"第 12870 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0085])\n",
						"第 12871 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0085])\n",
						"第 12872 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0085])\n",
						"第 12873 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0085])\n",
						"第 12874 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0085])\n",
						"第 12875 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0085])\n",
						"第 12876 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0085])\n",
						"第 12877 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0085])\n",
						"第 12878 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0085])\n",
						"第 12879 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0085])\n",
						"第 12880 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0085])\n",
						"第 644 次epoch\n",
						"第 12881 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0085])\n",
						"第 12882 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0085])\n",
						"第 12883 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0085])\n",
						"第 12884 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0085])\n",
						"第 12885 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0085])\n",
						"第 12886 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0085])\n",
						"第 12887 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0085])\n",
						"第 12888 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0084])\n",
						"第 12889 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0084])\n",
						"第 12890 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0084])\n",
						"第 12891 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0084])\n",
						"第 12892 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0084])\n",
						"第 12893 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0084])\n",
						"第 12894 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0084])\n",
						"第 12895 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0084])\n",
						"第 12896 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0084])\n",
						"第 12897 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0084])\n",
						"第 12898 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0084])\n",
						"第 12899 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0084])\n",
						"第 12900 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0084])\n",
						"第 645 次epoch\n",
						"第 12901 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0084])\n",
						"第 12902 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0084])\n",
						"第 12903 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0084])\n",
						"第 12904 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0084])\n",
						"第 12905 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0084])\n",
						"第 12906 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0084])\n",
						"第 12907 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0084])\n",
						"第 12908 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0084])\n",
						"第 12909 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0084])\n",
						"第 12910 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0084])\n",
						"第 12911 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0084])\n",
						"第 12912 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0084])\n",
						"第 12913 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0084])\n",
						"第 12914 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0084])\n",
						"第 12915 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0083])\n",
						"第 12916 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0083])\n",
						"第 12917 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0083])\n",
						"第 12918 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0083])\n",
						"第 12919 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0083])\n",
						"第 12920 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0083])\n",
						"第 646 次epoch\n",
						"第 12921 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0083])\n",
						"第 12922 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0083])\n",
						"第 12923 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0083])\n",
						"第 12924 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0083])\n",
						"第 12925 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0083])\n",
						"第 12926 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0083])\n",
						"第 12927 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0083])\n",
						"第 12928 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0083])\n",
						"第 12929 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0083])\n",
						"第 12930 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0083])\n",
						"第 12931 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0083])\n",
						"第 12932 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0083])\n",
						"第 12933 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0083])\n",
						"第 12934 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0083])\n",
						"第 12935 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0083])\n",
						"第 12936 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0083])\n",
						"第 12937 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0083])\n",
						"第 12938 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0083])\n",
						"第 12939 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0083])\n",
						"第 12940 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0083])\n",
						"第 647 次epoch\n",
						"第 12941 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0082])\n",
						"第 12942 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0082])\n",
						"第 12943 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0082])\n",
						"第 12944 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0082])\n",
						"第 12945 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0082])\n",
						"第 12946 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0082])\n",
						"第 12947 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0082])\n",
						"第 12948 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0082])\n",
						"第 12949 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0082])\n",
						"第 12950 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0082])\n",
						"第 12951 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0082])\n",
						"第 12952 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0082])\n",
						"第 12953 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0082])\n",
						"第 12954 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0082])\n",
						"第 12955 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0082])\n",
						"第 12956 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0082])\n",
						"第 12957 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0082])\n",
						"第 12958 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0082])\n",
						"第 12959 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0082])\n",
						"第 12960 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0082])\n",
						"第 648 次epoch\n",
						"第 12961 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0082])\n",
						"第 12962 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0082])\n",
						"第 12963 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0082])\n",
						"第 12964 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0082])\n",
						"第 12965 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0082])\n",
						"第 12966 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0082])\n",
						"第 12967 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0082])\n",
						"第 12968 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0081])\n",
						"第 12969 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0082])\n",
						"第 12970 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0081])\n",
						"第 12971 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0081])\n",
						"第 12972 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0081])\n",
						"第 12973 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0081])\n",
						"第 12974 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0081])\n",
						"第 12975 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0081])\n",
						"第 12976 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0081])\n",
						"第 12977 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0081])\n",
						"第 12978 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0081])\n",
						"第 12979 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0081])\n",
						"第 12980 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0081])\n",
						"第 649 次epoch\n",
						"第 12981 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0081])\n",
						"第 12982 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0081])\n",
						"第 12983 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0081])\n",
						"第 12984 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0081])\n",
						"第 12985 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0081])\n",
						"第 12986 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0081])\n",
						"第 12987 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0081])\n",
						"第 12988 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0081])\n",
						"第 12989 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0081])\n",
						"第 12990 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0081])\n",
						"第 12991 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0081])\n",
						"第 12992 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0081])\n",
						"第 12993 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0081])\n",
						"第 12994 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0081])\n",
						"第 12995 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0081])\n",
						"第 12996 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0081])\n",
						"第 12997 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0081])\n",
						"第 12998 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0080])\n",
						"第 12999 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0080])\n",
						"第 13000 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0080])\n",
						"第 650 次epoch\n",
						"第 13001 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0080])\n",
						"第 13002 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0080])\n",
						"第 13003 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0080])\n",
						"第 13004 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0080])\n",
						"第 13005 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0080])\n",
						"第 13006 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0080])\n",
						"第 13007 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0080])\n",
						"第 13008 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0080])\n",
						"第 13009 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0080])\n",
						"第 13010 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0080])\n",
						"第 13011 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0080])\n",
						"第 13012 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0080])\n",
						"第 13013 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0080])\n",
						"第 13014 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0080])\n",
						"第 13015 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0080])\n",
						"第 13016 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0080])\n",
						"第 13017 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0080])\n",
						"第 13018 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0080])\n",
						"第 13019 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0080])\n",
						"第 13020 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0080])\n",
						"第 651 次epoch\n",
						"第 13021 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0080])\n",
						"第 13022 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0080])\n",
						"第 13023 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0080])\n",
						"第 13024 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0080])\n",
						"第 13025 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0080])\n",
						"第 13026 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0080])\n",
						"第 13027 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0080])\n",
						"第 13028 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0080])\n",
						"第 13029 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0079])\n",
						"第 13030 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0079])\n",
						"第 13031 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0079])\n",
						"第 13032 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0079])\n",
						"第 13033 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0079])\n",
						"第 13034 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0079])\n",
						"第 13035 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0079])\n",
						"第 13036 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0079])\n",
						"第 13037 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0079])\n",
						"第 13038 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0079])\n",
						"第 13039 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0079])\n",
						"第 13040 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0079])\n",
						"第 652 次epoch\n",
						"第 13041 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0079])\n",
						"第 13042 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0079])\n",
						"第 13043 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0079])\n",
						"第 13044 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0079])\n",
						"第 13045 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0079])\n",
						"第 13046 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0079])\n",
						"第 13047 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0079])\n",
						"第 13048 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0079])\n",
						"第 13049 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0079])\n",
						"第 13050 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0079])\n",
						"第 13051 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0079])\n",
						"第 13052 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0079])\n",
						"第 13053 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0079])\n",
						"第 13054 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0079])\n",
						"第 13055 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0079])\n",
						"第 13056 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0079])\n",
						"第 13057 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0078])\n",
						"第 13058 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0078])\n",
						"第 13059 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0078])\n",
						"第 13060 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0078])\n",
						"第 653 次epoch\n",
						"第 13061 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0078])\n",
						"第 13062 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0078])\n",
						"第 13063 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0078])\n",
						"第 13064 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0078])\n",
						"第 13065 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0078])\n",
						"第 13066 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0078])\n",
						"第 13067 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0078])\n",
						"第 13068 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0078])\n",
						"第 13069 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0078])\n",
						"第 13070 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0078])\n",
						"第 13071 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0078])\n",
						"第 13072 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0078])\n",
						"第 13073 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0078])\n",
						"第 13074 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0078])\n",
						"第 13075 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0078])\n",
						"第 13076 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0078])\n",
						"第 13077 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0078])\n",
						"第 13078 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0078])\n",
						"第 13079 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0078])\n",
						"第 13080 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0078])\n",
						"第 654 次epoch\n",
						"第 13081 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0078])\n",
						"第 13082 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0078])\n",
						"第 13083 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0078])\n",
						"第 13084 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0078])\n",
						"第 13085 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0078])\n",
						"第 13086 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0078])\n",
						"第 13087 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0078])\n",
						"第 13088 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0077])\n",
						"第 13089 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0077])\n",
						"第 13090 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0077])\n",
						"第 13091 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0077])\n",
						"第 13092 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0077])\n",
						"第 13093 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0077])\n",
						"第 13094 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0077])\n",
						"第 13095 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0077])\n",
						"第 13096 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0077])\n",
						"第 13097 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0077])\n",
						"第 13098 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0077])\n",
						"第 13099 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0077])\n",
						"第 13100 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0077])\n",
						"第 655 次epoch\n",
						"第 13101 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0077])\n",
						"第 13102 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0077])\n",
						"第 13103 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0077])\n",
						"第 13104 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0077])\n",
						"第 13105 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0077])\n",
						"第 13106 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0077])\n",
						"第 13107 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0077])\n",
						"第 13108 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0077])\n",
						"第 13109 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0077])\n",
						"第 13110 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0077])\n",
						"第 13111 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0077])\n",
						"第 13112 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0077])\n",
						"第 13113 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0077])\n",
						"第 13114 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0077])\n",
						"第 13115 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0077])\n",
						"第 13116 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0077])\n",
						"第 13117 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0077])\n",
						"第 13118 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0077])\n",
						"第 13119 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0076])\n",
						"第 13120 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0076])\n",
						"第 656 次epoch\n",
						"第 13121 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0076])\n",
						"第 13122 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0076])\n",
						"第 13123 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0076])\n",
						"第 13124 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0076])\n",
						"第 13125 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0076])\n",
						"第 13126 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0076])\n",
						"第 13127 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0076])\n",
						"第 13128 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0076])\n",
						"第 13129 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0076])\n",
						"第 13130 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0076])\n",
						"第 13131 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0076])\n",
						"第 13132 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0076])\n",
						"第 13133 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0076])\n",
						"第 13134 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0076])\n",
						"第 13135 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0076])\n",
						"第 13136 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0076])\n",
						"第 13137 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0076])\n",
						"第 13138 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0076])\n",
						"第 13139 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0076])\n",
						"第 13140 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0076])\n",
						"第 657 次epoch\n",
						"第 13141 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0076])\n",
						"第 13142 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0076])\n",
						"第 13143 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0076])\n",
						"第 13144 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0076])\n",
						"第 13145 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0076])\n",
						"第 13146 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0076])\n",
						"第 13147 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0075])\n",
						"第 13148 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0075])\n",
						"第 13149 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0076])\n",
						"第 13150 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0075])\n",
						"第 13151 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0075])\n",
						"第 13152 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0075])\n",
						"第 13153 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0075])\n",
						"第 13154 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0075])\n",
						"第 13155 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0075])\n",
						"第 13156 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0075])\n",
						"第 13157 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0075])\n",
						"第 13158 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0075])\n",
						"第 13159 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0075])\n",
						"第 13160 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0075])\n",
						"第 658 次epoch\n",
						"第 13161 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0075])\n",
						"第 13162 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0075])\n",
						"第 13163 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0075])\n",
						"第 13164 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0075])\n",
						"第 13165 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0075])\n",
						"第 13166 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0075])\n",
						"第 13167 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0075])\n",
						"第 13168 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0075])\n",
						"第 13169 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0075])\n",
						"第 13170 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0075])\n",
						"第 13171 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0075])\n",
						"第 13172 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0075])\n",
						"第 13173 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0075])\n",
						"第 13174 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0075])\n",
						"第 13175 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0075])\n",
						"第 13176 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0075])\n",
						"第 13177 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0075])\n",
						"第 13178 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0074])\n",
						"第 13179 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0074])\n",
						"第 13180 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0074])\n",
						"第 659 次epoch\n",
						"第 13181 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0074])\n",
						"第 13182 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0074])\n",
						"第 13183 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0074])\n",
						"第 13184 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0074])\n",
						"第 13185 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0074])\n",
						"第 13186 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0074])\n",
						"第 13187 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0074])\n",
						"第 13188 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0074])\n",
						"第 13189 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0074])\n",
						"第 13190 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0074])\n",
						"第 13191 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0074])\n",
						"第 13192 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0074])\n",
						"第 13193 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0074])\n",
						"第 13194 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0074])\n",
						"第 13195 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0074])\n",
						"第 13196 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0074])\n",
						"第 13197 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0074])\n",
						"第 13198 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0074])\n",
						"第 13199 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0074])\n",
						"第 13200 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0074])\n",
						"第 660 次epoch\n",
						"第 13201 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0074])\n",
						"第 13202 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0074])\n",
						"第 13203 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0074])\n",
						"第 13204 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0074])\n",
						"第 13205 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0074])\n",
						"第 13206 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0074])\n",
						"第 13207 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0074])\n",
						"第 13208 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0074])\n",
						"第 13209 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0073])\n",
						"第 13210 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0073])\n",
						"第 13211 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0073])\n",
						"第 13212 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0073])\n",
						"第 13213 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0073])\n",
						"第 13214 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0073])\n",
						"第 13215 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0073])\n",
						"第 13216 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0073])\n",
						"第 13217 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0073])\n",
						"第 13218 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0073])\n",
						"第 13219 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0073])\n",
						"第 13220 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0073])\n",
						"第 661 次epoch\n",
						"第 13221 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0073])\n",
						"第 13222 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0073])\n",
						"第 13223 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0073])\n",
						"第 13224 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0073])\n",
						"第 13225 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0073])\n",
						"第 13226 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0073])\n",
						"第 13227 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0073])\n",
						"第 13228 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0073])\n",
						"第 13229 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0073])\n",
						"第 13230 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0073])\n",
						"第 13231 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0073])\n",
						"第 13232 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0073])\n",
						"第 13233 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0073])\n",
						"第 13234 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0073])\n",
						"第 13235 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0073])\n",
						"第 13236 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0073])\n",
						"第 13237 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0073])\n",
						"第 13238 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0072])\n",
						"第 13239 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0073])\n",
						"第 13240 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0072])\n",
						"第 662 次epoch\n",
						"第 13241 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0072])\n",
						"第 13242 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0072])\n",
						"第 13243 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0072])\n",
						"第 13244 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0072])\n",
						"第 13245 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0072])\n",
						"第 13246 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0072])\n",
						"第 13247 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0072])\n",
						"第 13248 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0072])\n",
						"第 13249 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0072])\n",
						"第 13250 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0072])\n",
						"第 13251 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0072])\n",
						"第 13252 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0072])\n",
						"第 13253 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0072])\n",
						"第 13254 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0072])\n",
						"第 13255 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0072])\n",
						"第 13256 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0072])\n",
						"第 13257 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0072])\n",
						"第 13258 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0072])\n",
						"第 13259 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0072])\n",
						"第 13260 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0072])\n",
						"第 663 次epoch\n",
						"第 13261 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0072])\n",
						"第 13262 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0072])\n",
						"第 13263 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0072])\n",
						"第 13264 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0072])\n",
						"第 13265 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0072])\n",
						"第 13266 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0072])\n",
						"第 13267 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0072])\n",
						"第 13268 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0071])\n",
						"第 13269 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0071])\n",
						"第 13270 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0071])\n",
						"第 13271 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0071])\n",
						"第 13272 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0071])\n",
						"第 13273 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0071])\n",
						"第 13274 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0071])\n",
						"第 13275 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0071])\n",
						"第 13276 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0029]])\n",
						"模型中偏参梯度 tensor([-0.0071])\n",
						"第 13277 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0071])\n",
						"第 13278 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0071])\n",
						"第 13279 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0071])\n",
						"第 13280 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0071])\n",
						"第 664 次epoch\n",
						"第 13281 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0071])\n",
						"第 13282 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0071])\n",
						"第 13283 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0071])\n",
						"第 13284 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0071])\n",
						"第 13285 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0071])\n",
						"第 13286 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0071])\n",
						"第 13287 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0071])\n",
						"第 13288 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0071])\n",
						"第 13289 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0071])\n",
						"第 13290 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0071])\n",
						"第 13291 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0071])\n",
						"第 13292 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0071])\n",
						"第 13293 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0071])\n",
						"第 13294 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0071])\n",
						"第 13295 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0071])\n",
						"第 13296 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0071])\n",
						"第 13297 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0071])\n",
						"第 13298 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0071])\n",
						"第 13299 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0071])\n",
						"第 13300 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0071])\n",
						"第 665 次epoch\n",
						"第 13301 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0071])\n",
						"第 13302 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0071])\n",
						"第 13303 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0071])\n",
						"第 13304 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0071])\n",
						"第 13305 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0070])\n",
						"第 13306 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0070])\n",
						"第 13307 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0070])\n",
						"第 13308 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0070])\n",
						"第 13309 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0070])\n",
						"第 13310 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0070])\n",
						"第 13311 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0070])\n",
						"第 13312 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0070])\n",
						"第 13313 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0070])\n",
						"第 13314 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0070])\n",
						"第 13315 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0070])\n",
						"第 13316 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0070])\n",
						"第 13317 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0070])\n",
						"第 13318 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0070])\n",
						"第 13319 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0070])\n",
						"第 13320 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0070])\n",
						"第 666 次epoch\n",
						"第 13321 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0070])\n",
						"第 13322 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0070])\n",
						"第 13323 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0070])\n",
						"第 13324 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0070])\n",
						"第 13325 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0070])\n",
						"第 13326 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0070])\n",
						"第 13327 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0070])\n",
						"第 13328 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0070])\n",
						"第 13329 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0070])\n",
						"第 13330 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0070])\n",
						"第 13331 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0070])\n",
						"第 13332 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0070])\n",
						"第 13333 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0070])\n",
						"第 13334 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0070])\n",
						"第 13335 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0070])\n",
						"第 13336 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0070])\n",
						"第 13337 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0070])\n",
						"第 13338 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0070])\n",
						"第 13339 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0070])\n",
						"第 13340 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0070])\n",
						"第 667 次epoch\n",
						"第 13341 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0070])\n",
						"第 13342 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0069])\n",
						"第 13343 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0069])\n",
						"第 13344 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0069])\n",
						"第 13345 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0069])\n",
						"第 13346 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0069])\n",
						"第 13347 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0069])\n",
						"第 13348 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0069])\n",
						"第 13349 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0069])\n",
						"第 13350 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0069])\n",
						"第 13351 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0069])\n",
						"第 13352 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0069])\n",
						"第 13353 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0069])\n",
						"第 13354 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0069])\n",
						"第 13355 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0069])\n",
						"第 13356 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0069])\n",
						"第 13357 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0069])\n",
						"第 13358 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0069])\n",
						"第 13359 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0069])\n",
						"第 13360 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0069])\n",
						"第 668 次epoch\n",
						"第 13361 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0069])\n",
						"第 13362 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0069])\n",
						"第 13363 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0069])\n",
						"第 13364 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0069])\n",
						"第 13365 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0069])\n",
						"第 13366 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0069])\n",
						"第 13367 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0069])\n",
						"第 13368 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0069])\n",
						"第 13369 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0069])\n",
						"第 13370 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0069])\n",
						"第 13371 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0069])\n",
						"第 13372 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0069])\n",
						"第 13373 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0069])\n",
						"第 13374 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0069])\n",
						"第 13375 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0069])\n",
						"第 13376 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0069])\n",
						"第 13377 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0069])\n",
						"第 13378 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0069])\n",
						"第 13379 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0068])\n",
						"第 13380 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0068])\n",
						"第 669 次epoch\n",
						"第 13381 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0068])\n",
						"第 13382 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0068])\n",
						"第 13383 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0068])\n",
						"第 13384 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0068])\n",
						"第 13385 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0068])\n",
						"第 13386 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0068])\n",
						"第 13387 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0068])\n",
						"第 13388 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0068])\n",
						"第 13389 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0068])\n",
						"第 13390 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0068])\n",
						"第 13391 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0068])\n",
						"第 13392 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0068])\n",
						"第 13393 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0068])\n",
						"第 13394 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0068])\n",
						"第 13395 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0068])\n",
						"第 13396 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0068])\n",
						"第 13397 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0068])\n",
						"第 13398 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0068])\n",
						"第 13399 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0068])\n",
						"第 13400 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0068])\n",
						"第 670 次epoch\n",
						"第 13401 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0068])\n",
						"第 13402 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0068])\n",
						"第 13403 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0068])\n",
						"第 13404 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0068])\n",
						"第 13405 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0068])\n",
						"第 13406 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0068])\n",
						"第 13407 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0068])\n",
						"第 13408 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0068])\n",
						"第 13409 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0068])\n",
						"第 13410 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0068])\n",
						"第 13411 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0068])\n",
						"第 13412 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0068])\n",
						"第 13413 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0068])\n",
						"第 13414 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0068])\n",
						"第 13415 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0068])\n",
						"第 13416 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0067])\n",
						"第 13417 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0067])\n",
						"第 13418 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0067])\n",
						"第 13419 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0067])\n",
						"第 13420 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0067])\n",
						"第 671 次epoch\n",
						"第 13421 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0067])\n",
						"第 13422 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0067])\n",
						"第 13423 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0067])\n",
						"第 13424 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0067])\n",
						"第 13425 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0067])\n",
						"第 13426 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0067])\n",
						"第 13427 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0067])\n",
						"第 13428 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0067])\n",
						"第 13429 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0067])\n",
						"第 13430 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0028]])\n",
						"模型中偏参梯度 tensor([-0.0067])\n",
						"第 13431 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0067])\n",
						"第 13432 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0067])\n",
						"第 13433 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0067])\n",
						"第 13434 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0067])\n",
						"第 13435 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0067])\n",
						"第 13436 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0067])\n",
						"第 13437 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0067])\n",
						"第 13438 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0067])\n",
						"第 13439 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0067])\n",
						"第 13440 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0067])\n",
						"第 672 次epoch\n",
						"第 13441 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0067])\n",
						"第 13442 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0067])\n",
						"第 13443 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0067])\n",
						"第 13444 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0067])\n",
						"第 13445 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0067])\n",
						"第 13446 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0067])\n",
						"第 13447 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0067])\n",
						"第 13448 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0067])\n",
						"第 13449 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0067])\n",
						"第 13450 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0067])\n",
						"第 13451 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0067])\n",
						"第 13452 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0066])\n",
						"第 13453 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0066])\n",
						"第 13454 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0066])\n",
						"第 13455 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0066])\n",
						"第 13456 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0066])\n",
						"第 13457 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0066])\n",
						"第 13458 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0066])\n",
						"第 13459 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0066])\n",
						"第 13460 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0066])\n",
						"第 673 次epoch\n",
						"第 13461 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0066])\n",
						"第 13462 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0066])\n",
						"第 13463 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0066])\n",
						"第 13464 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0066])\n",
						"第 13465 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0066])\n",
						"第 13466 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0066])\n",
						"第 13467 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0066])\n",
						"第 13468 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0066])\n",
						"第 13469 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0066])\n",
						"第 13470 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0066])\n",
						"第 13471 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0066])\n",
						"第 13472 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0066])\n",
						"第 13473 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0066])\n",
						"第 13474 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0066])\n",
						"第 13475 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0066])\n",
						"第 13476 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0066])\n",
						"第 13477 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0066])\n",
						"第 13478 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0066])\n",
						"第 13479 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0066])\n",
						"第 13480 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0066])\n",
						"第 674 次epoch\n",
						"第 13481 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0066])\n",
						"第 13482 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0066])\n",
						"第 13483 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0066])\n",
						"第 13484 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0066])\n",
						"第 13485 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0066])\n",
						"第 13486 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0066])\n",
						"第 13487 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0066])\n",
						"第 13488 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0066])\n",
						"第 13489 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0065])\n",
						"第 13490 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0065])\n",
						"第 13491 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0065])\n",
						"第 13492 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0065])\n",
						"第 13493 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0065])\n",
						"第 13494 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0065])\n",
						"第 13495 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0065])\n",
						"第 13496 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0065])\n",
						"第 13497 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0065])\n",
						"第 13498 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0065])\n",
						"第 13499 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0065])\n",
						"第 13500 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0065])\n",
						"第 675 次epoch\n",
						"第 13501 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0065])\n",
						"第 13502 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0065])\n",
						"第 13503 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0065])\n",
						"第 13504 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0065])\n",
						"第 13505 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0065])\n",
						"第 13506 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0065])\n",
						"第 13507 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0065])\n",
						"第 13508 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0065])\n",
						"第 13509 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0065])\n",
						"第 13510 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0065])\n",
						"第 13511 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0065])\n",
						"第 13512 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0065])\n",
						"第 13513 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0065])\n",
						"第 13514 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0065])\n",
						"第 13515 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0065])\n",
						"第 13516 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0065])\n",
						"第 13517 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0065])\n",
						"第 13518 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0065])\n",
						"第 13519 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0065])\n",
						"第 13520 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0065])\n",
						"第 676 次epoch\n",
						"第 13521 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0065])\n",
						"第 13522 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0065])\n",
						"第 13523 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0065])\n",
						"第 13524 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0065])\n",
						"第 13525 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0065])\n",
						"第 13526 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0064])\n",
						"第 13527 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0064])\n",
						"第 13528 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0064])\n",
						"第 13529 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0064])\n",
						"第 13530 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0064])\n",
						"第 13531 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0064])\n",
						"第 13532 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0064])\n",
						"第 13533 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0064])\n",
						"第 13534 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0064])\n",
						"第 13535 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0064])\n",
						"第 13536 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0064])\n",
						"第 13537 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0064])\n",
						"第 13538 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0064])\n",
						"第 13539 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0064])\n",
						"第 13540 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0064])\n",
						"第 677 次epoch\n",
						"第 13541 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0064])\n",
						"第 13542 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0064])\n",
						"第 13543 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0064])\n",
						"第 13544 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0064])\n",
						"第 13545 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0064])\n",
						"第 13546 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0064])\n",
						"第 13547 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0064])\n",
						"第 13548 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0064])\n",
						"第 13549 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0064])\n",
						"第 13550 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0064])\n",
						"第 13551 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0064])\n",
						"第 13552 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0064])\n",
						"第 13553 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0064])\n",
						"第 13554 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0064])\n",
						"第 13555 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0064])\n",
						"第 13556 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0064])\n",
						"第 13557 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0064])\n",
						"第 13558 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0064])\n",
						"第 13559 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0064])\n",
						"第 13560 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0064])\n",
						"第 678 次epoch\n",
						"第 13561 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0064])\n",
						"第 13562 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0064])\n",
						"第 13563 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0063])\n",
						"第 13564 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0063])\n",
						"第 13565 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0063])\n",
						"第 13566 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0063])\n",
						"第 13567 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0063])\n",
						"第 13568 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0063])\n",
						"第 13569 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0063])\n",
						"第 13570 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0063])\n",
						"第 13571 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0063])\n",
						"第 13572 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0063])\n",
						"第 13573 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0063])\n",
						"第 13574 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0063])\n",
						"第 13575 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0026]])\n",
						"模型中偏参梯度 tensor([-0.0063])\n",
						"第 13576 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0063])\n",
						"第 13577 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0026]])\n",
						"模型中偏参梯度 tensor([-0.0063])\n",
						"第 13578 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0027]])\n",
						"模型中偏参梯度 tensor([-0.0063])\n",
						"第 13579 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0026]])\n",
						"模型中偏参梯度 tensor([-0.0063])\n",
						"第 13580 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0026]])\n",
						"模型中偏参梯度 tensor([-0.0063])\n",
						"第 679 次epoch\n",
						"第 13581 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0026]])\n",
						"模型中偏参梯度 tensor([-0.0063])\n",
						"第 13582 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0026]])\n",
						"模型中偏参梯度 tensor([-0.0063])\n",
						"第 13583 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0026]])\n",
						"模型中偏参梯度 tensor([-0.0063])\n",
						"第 13584 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0026]])\n",
						"模型中偏参梯度 tensor([-0.0063])\n",
						"第 13585 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0026]])\n",
						"模型中偏参梯度 tensor([-0.0063])\n",
						"第 13586 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0026]])\n",
						"模型中偏参梯度 tensor([-0.0063])\n",
						"第 13587 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0026]])\n",
						"模型中偏参梯度 tensor([-0.0063])\n",
						"第 13588 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0026]])\n",
						"模型中偏参梯度 tensor([-0.0063])\n",
						"第 13589 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0026]])\n",
						"模型中偏参梯度 tensor([-0.0063])\n",
						"第 13590 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0026]])\n",
						"模型中偏参梯度 tensor([-0.0063])\n",
						"第 13591 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0026]])\n",
						"模型中偏参梯度 tensor([-0.0063])\n",
						"第 13592 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0026]])\n",
						"模型中偏参梯度 tensor([-0.0063])\n",
						"第 13593 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0026]])\n",
						"模型中偏参梯度 tensor([-0.0063])\n",
						"第 13594 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0026]])\n",
						"模型中偏参梯度 tensor([-0.0063])\n",
						"第 13595 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0026]])\n",
						"模型中偏参梯度 tensor([-0.0063])\n",
						"第 13596 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0026]])\n",
						"模型中偏参梯度 tensor([-0.0063])\n",
						"第 13597 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0026]])\n",
						"模型中偏参梯度 tensor([-0.0063])\n",
						"第 13598 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0026]])\n",
						"模型中偏参梯度 tensor([-0.0063])\n",
						"第 13599 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0026]])\n",
						"模型中偏参梯度 tensor([-0.0063])\n",
						"第 13600 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0026]])\n",
						"模型中偏参梯度 tensor([-0.0062])\n",
						"第 680 次epoch\n",
						"第 13601 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0026]])\n",
						"模型中偏参梯度 tensor([-0.0062])\n",
						"第 13602 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0026]])\n",
						"模型中偏参梯度 tensor([-0.0062])\n",
						"第 13603 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0026]])\n",
						"模型中偏参梯度 tensor([-0.0062])\n",
						"第 13604 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0026]])\n",
						"模型中偏参梯度 tensor([-0.0062])\n",
						"第 13605 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0026]])\n",
						"模型中偏参梯度 tensor([-0.0062])\n",
						"第 13606 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0026]])\n",
						"模型中偏参梯度 tensor([-0.0062])\n",
						"第 13607 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0026]])\n",
						"模型中偏参梯度 tensor([-0.0062])\n",
						"第 13608 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0026]])\n",
						"模型中偏参梯度 tensor([-0.0062])\n",
						"第 13609 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0026]])\n",
						"模型中偏参梯度 tensor([-0.0062])\n",
						"第 13610 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0026]])\n",
						"模型中偏参梯度 tensor([-0.0062])\n",
						"第 13611 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0026]])\n",
						"模型中偏参梯度 tensor([-0.0062])\n",
						"第 13612 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0026]])\n",
						"模型中偏参梯度 tensor([-0.0062])\n",
						"第 13613 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0026]])\n",
						"模型中偏参梯度 tensor([-0.0062])\n",
						"第 13614 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0026]])\n",
						"模型中偏参梯度 tensor([-0.0062])\n",
						"第 13615 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0026]])\n",
						"模型中偏参梯度 tensor([-0.0062])\n",
						"第 13616 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0026]])\n",
						"模型中偏参梯度 tensor([-0.0062])\n",
						"第 13617 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0026]])\n",
						"模型中偏参梯度 tensor([-0.0062])\n",
						"第 13618 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0026]])\n",
						"模型中偏参梯度 tensor([-0.0062])\n",
						"第 13619 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0026]])\n",
						"模型中偏参梯度 tensor([-0.0062])\n",
						"第 13620 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0026]])\n",
						"模型中偏参梯度 tensor([-0.0062])\n",
						"第 681 次epoch\n",
						"第 13621 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0026]])\n",
						"模型中偏参梯度 tensor([-0.0062])\n",
						"第 13622 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0026]])\n",
						"模型中偏参梯度 tensor([-0.0062])\n",
						"第 13623 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0026]])\n",
						"模型中偏参梯度 tensor([-0.0062])\n",
						"第 13624 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0026]])\n",
						"模型中偏参梯度 tensor([-0.0062])\n",
						"第 13625 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0026]])\n",
						"模型中偏参梯度 tensor([-0.0062])\n",
						"第 13626 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0026]])\n",
						"模型中偏参梯度 tensor([-0.0062])\n",
						"第 13627 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0026]])\n",
						"模型中偏参梯度 tensor([-0.0062])\n",
						"第 13628 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0026]])\n",
						"模型中偏参梯度 tensor([-0.0062])\n",
						"第 13629 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0026]])\n",
						"模型中偏参梯度 tensor([-0.0062])\n",
						"第 13630 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0025]])\n",
						"模型中偏参梯度 tensor([-0.0062])\n",
						"第 13631 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0025]])\n",
						"模型中偏参梯度 tensor([-0.0062])\n",
						"第 13632 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0025]])\n",
						"模型中偏参梯度 tensor([-0.0062])\n",
						"第 13633 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0025]])\n",
						"模型中偏参梯度 tensor([-0.0062])\n",
						"第 13634 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0025]])\n",
						"模型中偏参梯度 tensor([-0.0062])\n",
						"第 13635 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0025]])\n",
						"模型中偏参梯度 tensor([-0.0062])\n",
						"第 13636 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0025]])\n",
						"模型中偏参梯度 tensor([-0.0062])\n",
						"第 13637 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0025]])\n",
						"模型中偏参梯度 tensor([-0.0062])\n",
						"第 13638 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0025]])\n",
						"模型中偏参梯度 tensor([-0.0062])\n",
						"第 13639 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0025]])\n",
						"模型中偏参梯度 tensor([-0.0062])\n",
						"第 13640 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0025]])\n",
						"模型中偏参梯度 tensor([-0.0062])\n",
						"第 682 次epoch\n",
						"第 13641 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0025]])\n",
						"模型中偏参梯度 tensor([-0.0062])\n",
						"第 13642 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0025]])\n",
						"模型中偏参梯度 tensor([-0.0062])\n",
						"第 13643 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0025]])\n",
						"模型中偏参梯度 tensor([-0.0062])\n",
						"第 13644 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0025]])\n",
						"模型中偏参梯度 tensor([-0.0062])\n",
						"第 13645 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0025]])\n",
						"模型中偏参梯度 tensor([-0.0062])\n",
						"第 13646 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0025]])\n",
						"模型中偏参梯度 tensor([-0.0062])\n",
						"第 13647 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0025]])\n",
						"模型中偏参梯度 tensor([-0.0062])\n",
						"第 13648 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0024]])\n",
						"模型中偏参梯度 tensor([-0.0062])\n",
						"第 13649 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0024]])\n",
						"模型中偏参梯度 tensor([-0.0062])\n",
						"第 13650 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0024]])\n",
						"模型中偏参梯度 tensor([-0.0062])\n",
						"第 13651 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0024]])\n",
						"模型中偏参梯度 tensor([-0.0062])\n",
						"第 13652 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0024]])\n",
						"模型中偏参梯度 tensor([-0.0062])\n",
						"第 13653 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0024]])\n",
						"模型中偏参梯度 tensor([-0.0062])\n",
						"第 13654 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0024]])\n",
						"模型中偏参梯度 tensor([-0.0062])\n",
						"第 13655 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0024]])\n",
						"模型中偏参梯度 tensor([-0.0062])\n",
						"第 13656 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0024]])\n",
						"模型中偏参梯度 tensor([-0.0062])\n",
						"第 13657 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0024]])\n",
						"模型中偏参梯度 tensor([-0.0062])\n",
						"第 13658 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0024]])\n",
						"模型中偏参梯度 tensor([-0.0062])\n",
						"第 13659 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0024]])\n",
						"模型中偏参梯度 tensor([-0.0062])\n",
						"第 13660 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0024]])\n",
						"模型中偏参梯度 tensor([-0.0062])\n",
						"第 683 次epoch\n",
						"第 13661 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0024]])\n",
						"模型中偏参梯度 tensor([-0.0062])\n",
						"第 13662 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0024]])\n",
						"模型中偏参梯度 tensor([-0.0062])\n",
						"第 13663 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0024]])\n",
						"模型中偏参梯度 tensor([-0.0062])\n",
						"第 13664 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0023]])\n",
						"模型中偏参梯度 tensor([-0.0062])\n",
						"第 13665 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0023]])\n",
						"模型中偏参梯度 tensor([-0.0062])\n",
						"第 13666 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0023]])\n",
						"模型中偏参梯度 tensor([-0.0062])\n",
						"第 13667 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0023]])\n",
						"模型中偏参梯度 tensor([-0.0062])\n",
						"第 13668 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0023]])\n",
						"模型中偏参梯度 tensor([-0.0062])\n",
						"第 13669 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0023]])\n",
						"模型中偏参梯度 tensor([-0.0062])\n",
						"第 13670 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0023]])\n",
						"模型中偏参梯度 tensor([-0.0062])\n",
						"第 13671 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0023]])\n",
						"模型中偏参梯度 tensor([-0.0062])\n",
						"第 13672 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0023]])\n",
						"模型中偏参梯度 tensor([-0.0062])\n",
						"第 13673 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0023]])\n",
						"模型中偏参梯度 tensor([-0.0062])\n",
						"第 13674 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0023]])\n",
						"模型中偏参梯度 tensor([-0.0062])\n",
						"第 13675 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0023]])\n",
						"模型中偏参梯度 tensor([-0.0062])\n",
						"第 13676 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0023]])\n",
						"模型中偏参梯度 tensor([-0.0062])\n",
						"第 13677 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0023]])\n",
						"模型中偏参梯度 tensor([-0.0062])\n",
						"第 13678 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0023]])\n",
						"模型中偏参梯度 tensor([-0.0062])\n",
						"第 13679 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0023]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13680 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0023]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 684 次epoch\n",
						"第 13681 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0022]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13682 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0022]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13683 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0022]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13684 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0022]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13685 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0022]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13686 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0022]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13687 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0022]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13688 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0022]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13689 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0022]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13690 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0022]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13691 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0022]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13692 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0022]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13693 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0022]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13694 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0022]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13695 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0022]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13696 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0022]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13697 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0022]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13698 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0021]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13699 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0021]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13700 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0021]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 685 次epoch\n",
						"第 13701 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0021]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13702 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0021]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13703 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0021]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13704 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0021]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13705 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0021]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13706 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0021]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13707 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0021]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13708 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0021]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13709 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0021]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13710 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0021]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13711 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0021]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13712 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0021]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13713 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0021]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13714 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0021]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13715 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0020]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13716 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0020]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13717 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0020]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13718 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0020]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13719 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0020]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13720 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0020]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 686 次epoch\n",
						"第 13721 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0020]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13722 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0020]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13723 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0020]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13724 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0020]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13725 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0020]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13726 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0020]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13727 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0020]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13728 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0020]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13729 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0020]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13730 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0020]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13731 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0019]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13732 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0019]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13733 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0019]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13734 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0019]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13735 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0019]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13736 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0019]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13737 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0019]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13738 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0019]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13739 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0019]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13740 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0019]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 687 次epoch\n",
						"第 13741 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0019]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13742 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0019]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13743 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0019]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13744 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0019]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13745 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0019]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13746 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0019]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13747 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0019]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13748 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0018]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13749 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0018]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13750 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0018]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13751 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0018]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13752 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0018]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13753 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0018]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13754 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0018]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13755 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0018]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13756 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0018]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13757 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0018]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13758 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0018]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13759 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0018]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13760 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0018]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 688 次epoch\n",
						"第 13761 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0018]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13762 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0018]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13763 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0018]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13764 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0017]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13765 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0017]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13766 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0017]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13767 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0017]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13768 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0017]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13769 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0017]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13770 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0017]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13771 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0017]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13772 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0017]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13773 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0017]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13774 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0017]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13775 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0017]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13776 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0017]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13777 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0017]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13778 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0017]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13779 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0017]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13780 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0017]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 689 次epoch\n",
						"第 13781 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0017]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13782 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0016]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13783 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0016]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13784 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0016]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13785 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0016]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13786 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0016]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13787 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0016]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13788 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0016]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13789 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0016]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13790 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0016]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13791 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0016]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13792 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0016]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13793 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0016]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13794 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0016]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13795 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0016]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13796 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0016]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13797 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0016]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13798 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0015]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13799 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0015]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13800 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0015]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 690 次epoch\n",
						"第 13801 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0015]])\n",
						"模型中偏参梯度 tensor([-0.0061])\n",
						"第 13802 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0015]])\n",
						"模型中偏参梯度 tensor([-0.0060])\n",
						"第 13803 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0015]])\n",
						"模型中偏参梯度 tensor([-0.0060])\n",
						"第 13804 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0015]])\n",
						"模型中偏参梯度 tensor([-0.0060])\n",
						"第 13805 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0015]])\n",
						"模型中偏参梯度 tensor([-0.0060])\n",
						"第 13806 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0015]])\n",
						"模型中偏参梯度 tensor([-0.0060])\n",
						"第 13807 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0015]])\n",
						"模型中偏参梯度 tensor([-0.0060])\n",
						"第 13808 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0015]])\n",
						"模型中偏参梯度 tensor([-0.0060])\n",
						"第 13809 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0015]])\n",
						"模型中偏参梯度 tensor([-0.0060])\n",
						"第 13810 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0015]])\n",
						"模型中偏参梯度 tensor([-0.0060])\n",
						"第 13811 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0015]])\n",
						"模型中偏参梯度 tensor([-0.0060])\n",
						"第 13812 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0015]])\n",
						"模型中偏参梯度 tensor([-0.0060])\n",
						"第 13813 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0015]])\n",
						"模型中偏参梯度 tensor([-0.0060])\n",
						"第 13814 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0014]])\n",
						"模型中偏参梯度 tensor([-0.0060])\n",
						"第 13815 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0014]])\n",
						"模型中偏参梯度 tensor([-0.0060])\n",
						"第 13816 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0014]])\n",
						"模型中偏参梯度 tensor([-0.0060])\n",
						"第 13817 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0014]])\n",
						"模型中偏参梯度 tensor([-0.0060])\n",
						"第 13818 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0014]])\n",
						"模型中偏参梯度 tensor([-0.0060])\n",
						"第 13819 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0014]])\n",
						"模型中偏参梯度 tensor([-0.0060])\n",
						"第 13820 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0014]])\n",
						"模型中偏参梯度 tensor([-0.0060])\n",
						"第 691 次epoch\n",
						"第 13821 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0014]])\n",
						"模型中偏参梯度 tensor([-0.0060])\n",
						"第 13822 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0014]])\n",
						"模型中偏参梯度 tensor([-0.0060])\n",
						"第 13823 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0014]])\n",
						"模型中偏参梯度 tensor([-0.0060])\n",
						"第 13824 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0014]])\n",
						"模型中偏参梯度 tensor([-0.0060])\n",
						"第 13825 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0014]])\n",
						"模型中偏参梯度 tensor([-0.0060])\n",
						"第 13826 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0014]])\n",
						"模型中偏参梯度 tensor([-0.0060])\n",
						"第 13827 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0014]])\n",
						"模型中偏参梯度 tensor([-0.0060])\n",
						"第 13828 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0014]])\n",
						"模型中偏参梯度 tensor([-0.0060])\n",
						"第 13829 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0014]])\n",
						"模型中偏参梯度 tensor([-0.0060])\n",
						"第 13830 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0014]])\n",
						"模型中偏参梯度 tensor([-0.0060])\n",
						"第 13831 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0014]])\n",
						"模型中偏参梯度 tensor([-0.0060])\n",
						"第 13832 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0013]])\n",
						"模型中偏参梯度 tensor([-0.0060])\n",
						"第 13833 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0013]])\n",
						"模型中偏参梯度 tensor([-0.0060])\n",
						"第 13834 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0013]])\n",
						"模型中偏参梯度 tensor([-0.0060])\n",
						"第 13835 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0013]])\n",
						"模型中偏参梯度 tensor([-0.0060])\n",
						"第 13836 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0013]])\n",
						"模型中偏参梯度 tensor([-0.0060])\n",
						"第 13837 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0013]])\n",
						"模型中偏参梯度 tensor([-0.0060])\n",
						"第 13838 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0013]])\n",
						"模型中偏参梯度 tensor([-0.0060])\n",
						"第 13839 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0013]])\n",
						"模型中偏参梯度 tensor([-0.0060])\n",
						"第 13840 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0013]])\n",
						"模型中偏参梯度 tensor([-0.0060])\n",
						"第 692 次epoch\n",
						"第 13841 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0013]])\n",
						"模型中偏参梯度 tensor([-0.0060])\n",
						"第 13842 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0013]])\n",
						"模型中偏参梯度 tensor([-0.0060])\n",
						"第 13843 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0013]])\n",
						"模型中偏参梯度 tensor([-0.0060])\n",
						"第 13844 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0013]])\n",
						"模型中偏参梯度 tensor([-0.0060])\n",
						"第 13845 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0013]])\n",
						"模型中偏参梯度 tensor([-0.0060])\n",
						"第 13846 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0013]])\n",
						"模型中偏参梯度 tensor([-0.0060])\n",
						"第 13847 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0013]])\n",
						"模型中偏参梯度 tensor([-0.0060])\n",
						"第 13848 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0013]])\n",
						"模型中偏参梯度 tensor([-0.0060])\n",
						"第 13849 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0012]])\n",
						"模型中偏参梯度 tensor([-0.0060])\n",
						"第 13850 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0012]])\n",
						"模型中偏参梯度 tensor([-0.0060])\n",
						"第 13851 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0012]])\n",
						"模型中偏参梯度 tensor([-0.0060])\n",
						"第 13852 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0012]])\n",
						"模型中偏参梯度 tensor([-0.0060])\n",
						"第 13853 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0012]])\n",
						"模型中偏参梯度 tensor([-0.0060])\n",
						"第 13854 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0012]])\n",
						"模型中偏参梯度 tensor([-0.0060])\n",
						"第 13855 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0012]])\n",
						"模型中偏参梯度 tensor([-0.0060])\n",
						"第 13856 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0012]])\n",
						"模型中偏参梯度 tensor([-0.0060])\n",
						"第 13857 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0012]])\n",
						"模型中偏参梯度 tensor([-0.0060])\n",
						"第 13858 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0012]])\n",
						"模型中偏参梯度 tensor([-0.0060])\n",
						"第 13859 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0012]])\n",
						"模型中偏参梯度 tensor([-0.0060])\n",
						"第 13860 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0012]])\n",
						"模型中偏参梯度 tensor([-0.0060])\n",
						"第 693 次epoch\n",
						"第 13861 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0012]])\n",
						"模型中偏参梯度 tensor([-0.0060])\n",
						"第 13862 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0012]])\n",
						"模型中偏参梯度 tensor([-0.0060])\n",
						"第 13863 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0012]])\n",
						"模型中偏参梯度 tensor([-0.0060])\n",
						"第 13864 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0012]])\n",
						"模型中偏参梯度 tensor([-0.0060])\n",
						"第 13865 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0011]])\n",
						"模型中偏参梯度 tensor([-0.0060])\n",
						"第 13866 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0011]])\n",
						"模型中偏参梯度 tensor([-0.0060])\n",
						"第 13867 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0011]])\n",
						"模型中偏参梯度 tensor([-0.0060])\n",
						"第 13868 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0011]])\n",
						"模型中偏参梯度 tensor([-0.0060])\n",
						"第 13869 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0011]])\n",
						"模型中偏参梯度 tensor([-0.0060])\n",
						"第 13870 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0011]])\n",
						"模型中偏参梯度 tensor([-0.0060])\n",
						"第 13871 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0011]])\n",
						"模型中偏参梯度 tensor([-0.0060])\n",
						"第 13872 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0011]])\n",
						"模型中偏参梯度 tensor([-0.0060])\n",
						"第 13873 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0011]])\n",
						"模型中偏参梯度 tensor([-0.0060])\n",
						"第 13874 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0011]])\n",
						"模型中偏参梯度 tensor([-0.0060])\n",
						"第 13875 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0011]])\n",
						"模型中偏参梯度 tensor([-0.0060])\n",
						"第 13876 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0011]])\n",
						"模型中偏参梯度 tensor([-0.0060])\n",
						"第 13877 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0011]])\n",
						"模型中偏参梯度 tensor([-0.0060])\n",
						"第 13878 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0011]])\n",
						"模型中偏参梯度 tensor([-0.0060])\n",
						"第 13879 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0011]])\n",
						"模型中偏参梯度 tensor([-0.0060])\n",
						"第 13880 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0011]])\n",
						"模型中偏参梯度 tensor([-0.0060])\n",
						"第 694 次epoch\n",
						"第 13881 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0011]])\n",
						"模型中偏参梯度 tensor([-0.0060])\n",
						"第 13882 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0060])\n",
						"第 13883 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0060])\n",
						"第 13884 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0060])\n",
						"第 13885 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0060])\n",
						"第 13886 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0060])\n",
						"第 13887 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0060])\n",
						"第 13888 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0060])\n",
						"第 13889 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0060])\n",
						"第 13890 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0060])\n",
						"第 13891 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0060])\n",
						"第 13892 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0060])\n",
						"第 13893 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0060])\n",
						"第 13894 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0060])\n",
						"第 13895 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0060])\n",
						"第 13896 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0060])\n",
						"第 13897 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0060])\n",
						"第 13898 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0060])\n",
						"第 13899 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0060])\n",
						"第 13900 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0060])\n",
						"第 695 次epoch\n",
						"第 13901 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0060])\n",
						"第 13902 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0060])\n",
						"第 13903 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0060])\n",
						"第 13904 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0060])\n",
						"第 13905 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0059])\n",
						"第 13906 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0059])\n",
						"第 13907 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0059])\n",
						"第 13908 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0059])\n",
						"第 13909 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0059])\n",
						"第 13910 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0059])\n",
						"第 13911 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0059])\n",
						"第 13912 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0059])\n",
						"第 13913 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0059])\n",
						"第 13914 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0059])\n",
						"第 13915 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0059])\n",
						"第 13916 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0059])\n",
						"第 13917 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0059])\n",
						"第 13918 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0059])\n",
						"第 13919 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0059])\n",
						"第 13920 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0059])\n",
						"第 696 次epoch\n",
						"第 13921 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0059])\n",
						"第 13922 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0059])\n",
						"第 13923 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0059])\n",
						"第 13924 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0059])\n",
						"第 13925 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0059])\n",
						"第 13926 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0059])\n",
						"第 13927 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0059])\n",
						"第 13928 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0059])\n",
						"第 13929 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0059])\n",
						"第 13930 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0059])\n",
						"第 13931 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0059])\n",
						"第 13932 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0059])\n",
						"第 13933 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0059])\n",
						"第 13934 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0059])\n",
						"第 13935 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0059])\n",
						"第 13936 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0059])\n",
						"第 13937 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0059])\n",
						"第 13938 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0059])\n",
						"第 13939 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0059])\n",
						"第 13940 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0059])\n",
						"第 697 次epoch\n",
						"第 13941 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0059])\n",
						"第 13942 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0059])\n",
						"第 13943 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0058])\n",
						"第 13944 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0058])\n",
						"第 13945 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0058])\n",
						"第 13946 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0058])\n",
						"第 13947 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0058])\n",
						"第 13948 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0058])\n",
						"第 13949 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0058])\n",
						"第 13950 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0058])\n",
						"第 13951 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0058])\n",
						"第 13952 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0058])\n",
						"第 13953 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0058])\n",
						"第 13954 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0058])\n",
						"第 13955 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0058])\n",
						"第 13956 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0058])\n",
						"第 13957 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0058])\n",
						"第 13958 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0058])\n",
						"第 13959 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0058])\n",
						"第 13960 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0058])\n",
						"第 698 次epoch\n",
						"第 13961 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0058])\n",
						"第 13962 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0058])\n",
						"第 13963 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0058])\n",
						"第 13964 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0058])\n",
						"第 13965 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0058])\n",
						"第 13966 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0058])\n",
						"第 13967 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0058])\n",
						"第 13968 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0058])\n",
						"第 13969 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0058])\n",
						"第 13970 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0058])\n",
						"第 13971 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0058])\n",
						"第 13972 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0058])\n",
						"第 13973 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0058])\n",
						"第 13974 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0058])\n",
						"第 13975 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0058])\n",
						"第 13976 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0058])\n",
						"第 13977 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0058])\n",
						"第 13978 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0058])\n",
						"第 13979 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0058])\n",
						"第 13980 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0058])\n",
						"第 699 次epoch\n",
						"第 13981 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0058])\n",
						"第 13982 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0058])\n",
						"第 13983 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0058])\n",
						"第 13984 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0058])\n",
						"第 13985 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0058])\n",
						"第 13986 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0058])\n",
						"第 13987 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0058])\n",
						"第 13988 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0057])\n",
						"第 13989 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0057])\n",
						"第 13990 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0057])\n",
						"第 13991 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0057])\n",
						"第 13992 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0057])\n",
						"第 13993 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0057])\n",
						"第 13994 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0057])\n",
						"第 13995 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0057])\n",
						"第 13996 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0057])\n",
						"第 13997 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0057])\n",
						"第 13998 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0057])\n",
						"第 13999 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0057])\n",
						"第 14000 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0057])\n",
						"第 700 次epoch\n",
						"第 14001 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0057])\n",
						"第 14002 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0057])\n",
						"第 14003 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0057])\n",
						"第 14004 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0057])\n",
						"第 14005 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0057])\n",
						"第 14006 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0057])\n",
						"第 14007 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0057])\n",
						"第 14008 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0057])\n",
						"第 14009 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0057])\n",
						"第 14010 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0057])\n",
						"第 14011 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0057])\n",
						"第 14012 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0057])\n",
						"第 14013 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0057])\n",
						"第 14014 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0057])\n",
						"第 14015 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0057])\n",
						"第 14016 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0057])\n",
						"第 14017 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0057])\n",
						"第 14018 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0057])\n",
						"第 14019 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0057])\n",
						"第 14020 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0057])\n",
						"第 701 次epoch\n",
						"第 14021 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0057])\n",
						"第 14022 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0057])\n",
						"第 14023 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0057])\n",
						"第 14024 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0057])\n",
						"第 14025 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0057])\n",
						"第 14026 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0056])\n",
						"第 14027 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0056])\n",
						"第 14028 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0056])\n",
						"第 14029 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0056])\n",
						"第 14030 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0056])\n",
						"第 14031 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0056])\n",
						"第 14032 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0056])\n",
						"第 14033 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0056])\n",
						"第 14034 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0056])\n",
						"第 14035 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0056])\n",
						"第 14036 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0056])\n",
						"第 14037 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0056])\n",
						"第 14038 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0056])\n",
						"第 14039 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0056])\n",
						"第 14040 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0056])\n",
						"第 702 次epoch\n",
						"第 14041 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0056])\n",
						"第 14042 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0056])\n",
						"第 14043 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0056])\n",
						"第 14044 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0056])\n",
						"第 14045 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0056])\n",
						"第 14046 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0056])\n",
						"第 14047 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0056])\n",
						"第 14048 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0056])\n",
						"第 14049 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0056])\n",
						"第 14050 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0056])\n",
						"第 14051 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0056])\n",
						"第 14052 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0056])\n",
						"第 14053 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0056])\n",
						"第 14054 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0056])\n",
						"第 14055 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0056])\n",
						"第 14056 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0056])\n",
						"第 14057 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0056])\n",
						"第 14058 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0056])\n",
						"第 14059 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0056])\n",
						"第 14060 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0056])\n",
						"第 703 次epoch\n",
						"第 14061 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0056])\n",
						"第 14062 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0056])\n",
						"第 14063 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0056])\n",
						"第 14064 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0055])\n",
						"第 14065 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0056])\n",
						"第 14066 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0055])\n",
						"第 14067 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0055])\n",
						"第 14068 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0055])\n",
						"第 14069 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0055])\n",
						"第 14070 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0055])\n",
						"第 14071 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0055])\n",
						"第 14072 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0055])\n",
						"第 14073 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0055])\n",
						"第 14074 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0055])\n",
						"第 14075 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0055])\n",
						"第 14076 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0055])\n",
						"第 14077 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0055])\n",
						"第 14078 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0055])\n",
						"第 14079 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0055])\n",
						"第 14080 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0055])\n",
						"第 704 次epoch\n",
						"第 14081 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0055])\n",
						"第 14082 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0055])\n",
						"第 14083 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0055])\n",
						"第 14084 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0055])\n",
						"第 14085 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0055])\n",
						"第 14086 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0055])\n",
						"第 14087 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0055])\n",
						"第 14088 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0055])\n",
						"第 14089 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0055])\n",
						"第 14090 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0055])\n",
						"第 14091 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0055])\n",
						"第 14092 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0055])\n",
						"第 14093 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0055])\n",
						"第 14094 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0055])\n",
						"第 14095 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0055])\n",
						"第 14096 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0055])\n",
						"第 14097 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0055])\n",
						"第 14098 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0055])\n",
						"第 14099 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0055])\n",
						"第 14100 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0055])\n",
						"第 705 次epoch\n",
						"第 14101 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0055])\n",
						"第 14102 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0055])\n",
						"第 14103 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0055])\n",
						"第 14104 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0055])\n",
						"第 14105 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0055])\n",
						"第 14106 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0055])\n",
						"第 14107 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0055])\n",
						"第 14108 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0054])\n",
						"第 14109 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0054])\n",
						"第 14110 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0054])\n",
						"第 14111 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0054])\n",
						"第 14112 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0054])\n",
						"第 14113 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0054])\n",
						"第 14114 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0054])\n",
						"第 14115 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0054])\n",
						"第 14116 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0054])\n",
						"第 14117 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0054])\n",
						"第 14118 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0054])\n",
						"第 14119 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0054])\n",
						"第 14120 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0054])\n",
						"第 706 次epoch\n",
						"第 14121 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0054])\n",
						"第 14122 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0054])\n",
						"第 14123 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0054])\n",
						"第 14124 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0054])\n",
						"第 14125 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0054])\n",
						"第 14126 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0054])\n",
						"第 14127 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0054])\n",
						"第 14128 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0054])\n",
						"第 14129 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0054])\n",
						"第 14130 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0054])\n",
						"第 14131 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0054])\n",
						"第 14132 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0054])\n",
						"第 14133 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0054])\n",
						"第 14134 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0054])\n",
						"第 14135 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0054])\n",
						"第 14136 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0054])\n",
						"第 14137 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0054])\n",
						"第 14138 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0054])\n",
						"第 14139 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0054])\n",
						"第 14140 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0054])\n",
						"第 707 次epoch\n",
						"第 14141 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0054])\n",
						"第 14142 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0054])\n",
						"第 14143 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0054])\n",
						"第 14144 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0054])\n",
						"第 14145 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0054])\n",
						"第 14146 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0053])\n",
						"第 14147 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0053])\n",
						"第 14148 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0053])\n",
						"第 14149 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0053])\n",
						"第 14150 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0053])\n",
						"第 14151 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0053])\n",
						"第 14152 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0053])\n",
						"第 14153 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0053])\n",
						"第 14154 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0053])\n",
						"第 14155 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0053])\n",
						"第 14156 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0053])\n",
						"第 14157 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0053])\n",
						"第 14158 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0053])\n",
						"第 14159 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0053])\n",
						"第 14160 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0053])\n",
						"第 708 次epoch\n",
						"第 14161 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0053])\n",
						"第 14162 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0053])\n",
						"第 14163 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0053])\n",
						"第 14164 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0053])\n",
						"第 14165 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0053])\n",
						"第 14166 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0053])\n",
						"第 14167 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0053])\n",
						"第 14168 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0053])\n",
						"第 14169 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0053])\n",
						"第 14170 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0053])\n",
						"第 14171 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0053])\n",
						"第 14172 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0053])\n",
						"第 14173 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0053])\n",
						"第 14174 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0053])\n",
						"第 14175 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0053])\n",
						"第 14176 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0053])\n",
						"第 14177 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0053])\n",
						"第 14178 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0053])\n",
						"第 14179 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0053])\n",
						"第 14180 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0053])\n",
						"第 709 次epoch\n",
						"第 14181 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0053])\n",
						"第 14182 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0053])\n",
						"第 14183 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0053])\n",
						"第 14184 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0053])\n",
						"第 14185 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0053])\n",
						"第 14186 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0052])\n",
						"第 14187 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0052])\n",
						"第 14188 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0052])\n",
						"第 14189 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0052])\n",
						"第 14190 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0052])\n",
						"第 14191 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0052])\n",
						"第 14192 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0052])\n",
						"第 14193 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0052])\n",
						"第 14194 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0052])\n",
						"第 14195 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0052])\n",
						"第 14196 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0052])\n",
						"第 14197 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0052])\n",
						"第 14198 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0052])\n",
						"第 14199 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0052])\n",
						"第 14200 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0052])\n",
						"第 710 次epoch\n",
						"第 14201 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0052])\n",
						"第 14202 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0052])\n",
						"第 14203 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0052])\n",
						"第 14204 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0052])\n",
						"第 14205 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0052])\n",
						"第 14206 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0052])\n",
						"第 14207 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0052])\n",
						"第 14208 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0052])\n",
						"第 14209 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0052])\n",
						"第 14210 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0052])\n",
						"第 14211 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0052])\n",
						"第 14212 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0052])\n",
						"第 14213 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0052])\n",
						"第 14214 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0052])\n",
						"第 14215 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0052])\n",
						"第 14216 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0052])\n",
						"第 14217 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0052])\n",
						"第 14218 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0052])\n",
						"第 14219 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0052])\n",
						"第 14220 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0052])\n",
						"第 711 次epoch\n",
						"第 14221 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0052])\n",
						"第 14222 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0052])\n",
						"第 14223 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0052])\n",
						"第 14224 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0052])\n",
						"第 14225 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0052])\n",
						"第 14226 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0052])\n",
						"第 14227 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0052])\n",
						"第 14228 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0052])\n",
						"第 14229 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0052])\n",
						"第 14230 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0052])\n",
						"第 14231 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0052])\n",
						"第 14232 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0052])\n",
						"第 14233 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0052])\n",
						"第 14234 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0052])\n",
						"第 14235 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0051])\n",
						"第 14236 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0051])\n",
						"第 14237 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0051])\n",
						"第 14238 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0051])\n",
						"第 14239 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0051])\n",
						"第 14240 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0051])\n",
						"第 712 次epoch\n",
						"第 14241 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0051])\n",
						"第 14242 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0051])\n",
						"第 14243 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0051])\n",
						"第 14244 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0051])\n",
						"第 14245 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0051])\n",
						"第 14246 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0051])\n",
						"第 14247 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0051])\n",
						"第 14248 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0051])\n",
						"第 14249 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0051])\n",
						"第 14250 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0051])\n",
						"第 14251 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0051])\n",
						"第 14252 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0051])\n",
						"第 14253 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0051])\n",
						"第 14254 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0051])\n",
						"第 14255 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0051])\n",
						"第 14256 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0051])\n",
						"第 14257 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0051])\n",
						"第 14258 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0051])\n",
						"第 14259 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0051])\n",
						"第 14260 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0051])\n",
						"第 713 次epoch\n",
						"第 14261 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0051])\n",
						"第 14262 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0051])\n",
						"第 14263 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0051])\n",
						"第 14264 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0051])\n",
						"第 14265 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0051])\n",
						"第 14266 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0051])\n",
						"第 14267 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0051])\n",
						"第 14268 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0051])\n",
						"第 14269 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0051])\n",
						"第 14270 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0051])\n",
						"第 14271 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0051])\n",
						"第 14272 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0051])\n",
						"第 14273 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0051])\n",
						"第 14274 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0051])\n",
						"第 14275 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0051])\n",
						"第 14276 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0051])\n",
						"第 14277 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0051])\n",
						"第 14278 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0051])\n",
						"第 14279 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0051])\n",
						"第 14280 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0051])\n",
						"第 714 次epoch\n",
						"第 14281 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0051])\n",
						"第 14282 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0050])\n",
						"第 14283 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0050])\n",
						"第 14284 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0051])\n",
						"第 14285 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0050])\n",
						"第 14286 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0050])\n",
						"第 14287 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0050])\n",
						"第 14288 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0050])\n",
						"第 14289 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0050])\n",
						"第 14290 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0050])\n",
						"第 14291 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0050])\n",
						"第 14292 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0050])\n",
						"第 14293 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0050])\n",
						"第 14294 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0050])\n",
						"第 14295 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0050])\n",
						"第 14296 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0050])\n",
						"第 14297 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0050])\n",
						"第 14298 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0050])\n",
						"第 14299 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0050])\n",
						"第 14300 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0050])\n",
						"第 715 次epoch\n",
						"第 14301 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0050])\n",
						"第 14302 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0050])\n",
						"第 14303 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0050])\n",
						"第 14304 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0050])\n",
						"第 14305 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0050])\n",
						"第 14306 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0050])\n",
						"第 14307 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0050])\n",
						"第 14308 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0050])\n",
						"第 14309 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0050])\n",
						"第 14310 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0050])\n",
						"第 14311 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0050])\n",
						"第 14312 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0050])\n",
						"第 14313 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0050])\n",
						"第 14314 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0050])\n",
						"第 14315 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0050])\n",
						"第 14316 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0050])\n",
						"第 14317 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0050])\n",
						"第 14318 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0050])\n",
						"第 14319 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0050])\n",
						"第 14320 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0050])\n",
						"第 716 次epoch\n",
						"第 14321 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0050])\n",
						"第 14322 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0050])\n",
						"第 14323 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0050])\n",
						"第 14324 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0050])\n",
						"第 14325 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0050])\n",
						"第 14326 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0050])\n",
						"第 14327 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0050])\n",
						"第 14328 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0050])\n",
						"第 14329 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0050])\n",
						"第 14330 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0050])\n",
						"第 14331 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0050])\n",
						"第 14332 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0049])\n",
						"第 14333 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0049])\n",
						"第 14334 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0049])\n",
						"第 14335 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0049])\n",
						"第 14336 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0049])\n",
						"第 14337 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0049])\n",
						"第 14338 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0049])\n",
						"第 14339 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0049])\n",
						"第 14340 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0049])\n",
						"第 717 次epoch\n",
						"第 14341 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0049])\n",
						"第 14342 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0049])\n",
						"第 14343 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0049])\n",
						"第 14344 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0049])\n",
						"第 14345 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0049])\n",
						"第 14346 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0049])\n",
						"第 14347 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0049])\n",
						"第 14348 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0049])\n",
						"第 14349 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0049])\n",
						"第 14350 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0049])\n",
						"第 14351 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0049])\n",
						"第 14352 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0049])\n",
						"第 14353 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0049])\n",
						"第 14354 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0049])\n",
						"第 14355 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0049])\n",
						"第 14356 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0049])\n",
						"第 14357 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0049])\n",
						"第 14358 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0049])\n",
						"第 14359 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0049])\n",
						"第 14360 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0049])\n",
						"第 718 次epoch\n",
						"第 14361 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0049])\n",
						"第 14362 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0049])\n",
						"第 14363 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0049])\n",
						"第 14364 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0049])\n",
						"第 14365 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0049])\n",
						"第 14366 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0049])\n",
						"第 14367 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0049])\n",
						"第 14368 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0049])\n",
						"第 14369 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0049])\n",
						"第 14370 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0049])\n",
						"第 14371 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0049])\n",
						"第 14372 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0049])\n",
						"第 14373 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0049])\n",
						"第 14374 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0049])\n",
						"第 14375 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0049])\n",
						"第 14376 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0049])\n",
						"第 14377 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0049])\n",
						"第 14378 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0049])\n",
						"第 14379 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0048])\n",
						"第 14380 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0048])\n",
						"第 719 次epoch\n",
						"第 14381 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0049])\n",
						"第 14382 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0048])\n",
						"第 14383 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0048])\n",
						"第 14384 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0048])\n",
						"第 14385 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0048])\n",
						"第 14386 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0048])\n",
						"第 14387 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0048])\n",
						"第 14388 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0048])\n",
						"第 14389 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0048])\n",
						"第 14390 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0048])\n",
						"第 14391 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0048])\n",
						"第 14392 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0048])\n",
						"第 14393 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0048])\n",
						"第 14394 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0048])\n",
						"第 14395 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0048])\n",
						"第 14396 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0048])\n",
						"第 14397 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0048])\n",
						"第 14398 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0048])\n",
						"第 14399 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0048])\n",
						"第 14400 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0048])\n",
						"第 720 次epoch\n",
						"第 14401 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0048])\n",
						"第 14402 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0048])\n",
						"第 14403 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0048])\n",
						"第 14404 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0048])\n",
						"第 14405 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0048])\n",
						"第 14406 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0048])\n",
						"第 14407 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0048])\n",
						"第 14408 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0048])\n",
						"第 14409 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0048])\n",
						"第 14410 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0048])\n",
						"第 14411 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0048])\n",
						"第 14412 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0048])\n",
						"第 14413 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0048])\n",
						"第 14414 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0048])\n",
						"第 14415 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0048])\n",
						"第 14416 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0048])\n",
						"第 14417 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0048])\n",
						"第 14418 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0048])\n",
						"第 14419 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0048])\n",
						"第 14420 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0048])\n",
						"第 721 次epoch\n",
						"第 14421 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0048])\n",
						"第 14422 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0048])\n",
						"第 14423 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0048])\n",
						"第 14424 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0048])\n",
						"第 14425 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0048])\n",
						"第 14426 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0047])\n",
						"第 14427 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0048])\n",
						"第 14428 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0047])\n",
						"第 14429 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0047])\n",
						"第 14430 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0047])\n",
						"第 14431 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0047])\n",
						"第 14432 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0047])\n",
						"第 14433 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0047])\n",
						"第 14434 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0047])\n",
						"第 14435 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0047])\n",
						"第 14436 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0047])\n",
						"第 14437 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0047])\n",
						"第 14438 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0047])\n",
						"第 14439 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0047])\n",
						"第 14440 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0047])\n",
						"第 722 次epoch\n",
						"第 14441 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0047])\n",
						"第 14442 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0047])\n",
						"第 14443 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0047])\n",
						"第 14444 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0047])\n",
						"第 14445 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0047])\n",
						"第 14446 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0047])\n",
						"第 14447 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0047])\n",
						"第 14448 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0047])\n",
						"第 14449 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0047])\n",
						"第 14450 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0047])\n",
						"第 14451 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0047])\n",
						"第 14452 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0047])\n",
						"第 14453 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0047])\n",
						"第 14454 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0047])\n",
						"第 14455 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0047])\n",
						"第 14456 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0047])\n",
						"第 14457 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0047])\n",
						"第 14458 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0047])\n",
						"第 14459 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0047])\n",
						"第 14460 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0047])\n",
						"第 723 次epoch\n",
						"第 14461 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0047])\n",
						"第 14462 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0047])\n",
						"第 14463 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0047])\n",
						"第 14464 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0047])\n",
						"第 14465 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0047])\n",
						"第 14466 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0047])\n",
						"第 14467 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0047])\n",
						"第 14468 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0047])\n",
						"第 14469 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0047])\n",
						"第 14470 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0047])\n",
						"第 14471 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0047])\n",
						"第 14472 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0047])\n",
						"第 14473 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0047])\n",
						"第 14474 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0047])\n",
						"第 14475 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0047])\n",
						"第 14476 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0046])\n",
						"第 14477 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0046])\n",
						"第 14478 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0046])\n",
						"第 14479 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0046])\n",
						"第 14480 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0046])\n",
						"第 724 次epoch\n",
						"第 14481 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0046])\n",
						"第 14482 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0046])\n",
						"第 14483 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0046])\n",
						"第 14484 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0046])\n",
						"第 14485 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0046])\n",
						"第 14486 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0046])\n",
						"第 14487 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0046])\n",
						"第 14488 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0046])\n",
						"第 14489 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0046])\n",
						"第 14490 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0046])\n",
						"第 14491 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0046])\n",
						"第 14492 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0046])\n",
						"第 14493 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0046])\n",
						"第 14494 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0046])\n",
						"第 14495 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0046])\n",
						"第 14496 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0046])\n",
						"第 14497 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0046])\n",
						"第 14498 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0046])\n",
						"第 14499 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0046])\n",
						"第 14500 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0046])\n",
						"第 725 次epoch\n",
						"第 14501 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0046])\n",
						"第 14502 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0046])\n",
						"第 14503 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0046])\n",
						"第 14504 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0046])\n",
						"第 14505 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0046])\n",
						"第 14506 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0046])\n",
						"第 14507 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0046])\n",
						"第 14508 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0046])\n",
						"第 14509 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0046])\n",
						"第 14510 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0046])\n",
						"第 14511 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0046])\n",
						"第 14512 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0046])\n",
						"第 14513 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0046])\n",
						"第 14514 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0046])\n",
						"第 14515 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0046])\n",
						"第 14516 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0046])\n",
						"第 14517 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0046])\n",
						"第 14518 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0046])\n",
						"第 14519 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0046])\n",
						"第 14520 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0046])\n",
						"第 726 次epoch\n",
						"第 14521 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0046])\n",
						"第 14522 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0046])\n",
						"第 14523 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0045])\n",
						"第 14524 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0045])\n",
						"第 14525 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0045])\n",
						"第 14526 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0046])\n",
						"第 14527 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0045])\n",
						"第 14528 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0045])\n",
						"第 14529 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0045])\n",
						"第 14530 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0045])\n",
						"第 14531 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0045])\n",
						"第 14532 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0045])\n",
						"第 14533 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0045])\n",
						"第 14534 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0045])\n",
						"第 14535 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0045])\n",
						"第 14536 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0045])\n",
						"第 14537 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0045])\n",
						"第 14538 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0045])\n",
						"第 14539 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0045])\n",
						"第 14540 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0045])\n",
						"第 727 次epoch\n",
						"第 14541 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0045])\n",
						"第 14542 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0045])\n",
						"第 14543 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0045])\n",
						"第 14544 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0045])\n",
						"第 14545 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0045])\n",
						"第 14546 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0045])\n",
						"第 14547 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0045])\n",
						"第 14548 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0045])\n",
						"第 14549 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0045])\n",
						"第 14550 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0045])\n",
						"第 14551 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0045])\n",
						"第 14552 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0045])\n",
						"第 14553 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0045])\n",
						"第 14554 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0045])\n",
						"第 14555 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0045])\n",
						"第 14556 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0045])\n",
						"第 14557 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0045])\n",
						"第 14558 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0045])\n",
						"第 14559 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0045])\n",
						"第 14560 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0045])\n",
						"第 728 次epoch\n",
						"第 14561 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0045])\n",
						"第 14562 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0045])\n",
						"第 14563 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0045])\n",
						"第 14564 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0045])\n",
						"第 14565 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0045])\n",
						"第 14566 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0045])\n",
						"第 14567 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0045])\n",
						"第 14568 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0045])\n",
						"第 14569 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0045])\n",
						"第 14570 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0045])\n",
						"第 14571 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0045])\n",
						"第 14572 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0045])\n",
						"第 14573 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0045])\n",
						"第 14574 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0044])\n",
						"第 14575 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0044])\n",
						"第 14576 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0044])\n",
						"第 14577 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0044])\n",
						"第 14578 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0044])\n",
						"第 14579 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0044])\n",
						"第 14580 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0044])\n",
						"第 729 次epoch\n",
						"第 14581 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0044])\n",
						"第 14582 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0044])\n",
						"第 14583 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0044])\n",
						"第 14584 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0044])\n",
						"第 14585 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0044])\n",
						"第 14586 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0044])\n",
						"第 14587 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0044])\n",
						"第 14588 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0044])\n",
						"第 14589 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0044])\n",
						"第 14590 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0044])\n",
						"第 14591 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0044])\n",
						"第 14592 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0044])\n",
						"第 14593 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0044])\n",
						"第 14594 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0044])\n",
						"第 14595 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0044])\n",
						"第 14596 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0044])\n",
						"第 14597 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0044])\n",
						"第 14598 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0044])\n",
						"第 14599 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0044])\n",
						"第 14600 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0044])\n",
						"第 730 次epoch\n",
						"第 14601 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0044])\n",
						"第 14602 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0044])\n",
						"第 14603 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0044])\n",
						"第 14604 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0044])\n",
						"第 14605 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0044])\n",
						"第 14606 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0044])\n",
						"第 14607 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0044])\n",
						"第 14608 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0044])\n",
						"第 14609 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0044])\n",
						"第 14610 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0044])\n",
						"第 14611 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0044])\n",
						"第 14612 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0044])\n",
						"第 14613 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0044])\n",
						"第 14614 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0044])\n",
						"第 14615 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0044])\n",
						"第 14616 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0044])\n",
						"第 14617 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0044])\n",
						"第 14618 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0044])\n",
						"第 14619 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0044])\n",
						"第 14620 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0043])\n",
						"第 731 次epoch\n",
						"第 14621 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0043])\n",
						"第 14622 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0043])\n",
						"第 14623 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0043])\n",
						"第 14624 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0043])\n",
						"第 14625 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0043])\n",
						"第 14626 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0043])\n",
						"第 14627 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0043])\n",
						"第 14628 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0043])\n",
						"第 14629 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0043])\n",
						"第 14630 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0043])\n",
						"第 14631 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0043])\n",
						"第 14632 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0043])\n",
						"第 14633 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0043])\n",
						"第 14634 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0043])\n",
						"第 14635 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0043])\n",
						"第 14636 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0043])\n",
						"第 14637 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0043])\n",
						"第 14638 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0043])\n",
						"第 14639 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0043])\n",
						"第 14640 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0043])\n",
						"第 732 次epoch\n",
						"第 14641 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0043])\n",
						"第 14642 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0043])\n",
						"第 14643 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0043])\n",
						"第 14644 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0043])\n",
						"第 14645 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0043])\n",
						"第 14646 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0043])\n",
						"第 14647 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0043])\n",
						"第 14648 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0043])\n",
						"第 14649 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0043])\n",
						"第 14650 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0043])\n",
						"第 14651 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0043])\n",
						"第 14652 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0043])\n",
						"第 14653 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0043])\n",
						"第 14654 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0043])\n",
						"第 14655 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0043])\n",
						"第 14656 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0043])\n",
						"第 14657 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0043])\n",
						"第 14658 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0043])\n",
						"第 14659 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0043])\n",
						"第 14660 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0043])\n",
						"第 733 次epoch\n",
						"第 14661 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0043])\n",
						"第 14662 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0043])\n",
						"第 14663 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0043])\n",
						"第 14664 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0043])\n",
						"第 14665 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0043])\n",
						"第 14666 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0043])\n",
						"第 14667 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0043])\n",
						"第 14668 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0043])\n",
						"第 14669 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0043])\n",
						"第 14670 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0043])\n",
						"第 14671 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0043])\n",
						"第 14672 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0043])\n",
						"第 14673 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0042])\n",
						"第 14674 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0043])\n",
						"第 14675 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0043])\n",
						"第 14676 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0042])\n",
						"第 14677 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0042])\n",
						"第 14678 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0042])\n",
						"第 14679 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0042])\n",
						"第 14680 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0042])\n",
						"第 734 次epoch\n",
						"第 14681 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0042])\n",
						"第 14682 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0042])\n",
						"第 14683 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0042])\n",
						"第 14684 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0042])\n",
						"第 14685 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0042])\n",
						"第 14686 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0042])\n",
						"第 14687 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0042])\n",
						"第 14688 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0042])\n",
						"第 14689 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0042])\n",
						"第 14690 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0042])\n",
						"第 14691 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0042])\n",
						"第 14692 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0042])\n",
						"第 14693 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0042])\n",
						"第 14694 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0042])\n",
						"第 14695 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0042])\n",
						"第 14696 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0042])\n",
						"第 14697 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0042])\n",
						"第 14698 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0042])\n",
						"第 14699 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0042])\n",
						"第 14700 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0042])\n",
						"第 735 次epoch\n",
						"第 14701 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0042])\n",
						"第 14702 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0042])\n",
						"第 14703 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0042])\n",
						"第 14704 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0042])\n",
						"第 14705 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0042])\n",
						"第 14706 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0042])\n",
						"第 14707 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0042])\n",
						"第 14708 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0042])\n",
						"第 14709 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0042])\n",
						"第 14710 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0042])\n",
						"第 14711 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0042])\n",
						"第 14712 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0042])\n",
						"第 14713 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0042])\n",
						"第 14714 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0042])\n",
						"第 14715 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0042])\n",
						"第 14716 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0042])\n",
						"第 14717 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0042])\n",
						"第 14718 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0042])\n",
						"第 14719 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0042])\n",
						"第 14720 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0042])\n",
						"第 736 次epoch\n",
						"第 14721 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0042])\n",
						"第 14722 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0042])\n",
						"第 14723 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0042])\n",
						"第 14724 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0042])\n",
						"第 14725 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0042])\n",
						"第 14726 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0042])\n",
						"第 14727 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0042])\n",
						"第 14728 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0042])\n",
						"第 14729 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0042])\n",
						"第 14730 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0042])\n",
						"第 14731 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0042])\n",
						"第 14732 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0041])\n",
						"第 14733 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0042])\n",
						"第 14734 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0042])\n",
						"第 14735 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0041])\n",
						"第 14736 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0041])\n",
						"第 14737 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0041])\n",
						"第 14738 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0041])\n",
						"第 14739 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0041])\n",
						"第 14740 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0041])\n",
						"第 737 次epoch\n",
						"第 14741 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0041])\n",
						"第 14742 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0041])\n",
						"第 14743 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0041])\n",
						"第 14744 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0041])\n",
						"第 14745 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0041])\n",
						"第 14746 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0041])\n",
						"第 14747 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0041])\n",
						"第 14748 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0041])\n",
						"第 14749 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0041])\n",
						"第 14750 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0041])\n",
						"第 14751 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0041])\n",
						"第 14752 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0041])\n",
						"第 14753 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0041])\n",
						"第 14754 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0041])\n",
						"第 14755 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0041])\n",
						"第 14756 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0041])\n",
						"第 14757 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0041])\n",
						"第 14758 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0041])\n",
						"第 14759 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0041])\n",
						"第 14760 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0041])\n",
						"第 738 次epoch\n",
						"第 14761 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0041])\n",
						"第 14762 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0041])\n",
						"第 14763 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0041])\n",
						"第 14764 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0041])\n",
						"第 14765 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0041])\n",
						"第 14766 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0041])\n",
						"第 14767 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0041])\n",
						"第 14768 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0041])\n",
						"第 14769 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0041])\n",
						"第 14770 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0041])\n",
						"第 14771 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0041])\n",
						"第 14772 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0041])\n",
						"第 14773 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0041])\n",
						"第 14774 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0041])\n",
						"第 14775 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0041])\n",
						"第 14776 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0041])\n",
						"第 14777 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0041])\n",
						"第 14778 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0041])\n",
						"第 14779 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0041])\n",
						"第 14780 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0041])\n",
						"第 739 次epoch\n",
						"第 14781 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0041])\n",
						"第 14782 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0041])\n",
						"第 14783 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0041])\n",
						"第 14784 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0041])\n",
						"第 14785 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0041])\n",
						"第 14786 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0041])\n",
						"第 14787 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0041])\n",
						"第 14788 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0041])\n",
						"第 14789 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0041])\n",
						"第 14790 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0041])\n",
						"第 14791 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0041])\n",
						"第 14792 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0041])\n",
						"第 14793 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0041])\n",
						"第 14794 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0040])\n",
						"第 14795 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0041])\n",
						"第 14796 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0041])\n",
						"第 14797 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0040])\n",
						"第 14798 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0040])\n",
						"第 14799 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0040])\n",
						"第 14800 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0040])\n",
						"第 740 次epoch\n",
						"第 14801 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0040])\n",
						"第 14802 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0040])\n",
						"第 14803 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0040])\n",
						"第 14804 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0040])\n",
						"第 14805 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0040])\n",
						"第 14806 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0040])\n",
						"第 14807 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0040])\n",
						"第 14808 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0040])\n",
						"第 14809 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0040])\n",
						"第 14810 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0040])\n",
						"第 14811 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0040])\n",
						"第 14812 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0040])\n",
						"第 14813 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0040])\n",
						"第 14814 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0040])\n",
						"第 14815 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0040])\n",
						"第 14816 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0040])\n",
						"第 14817 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0040])\n",
						"第 14818 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0040])\n",
						"第 14819 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0040])\n",
						"第 14820 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0040])\n",
						"第 741 次epoch\n",
						"第 14821 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0040])\n",
						"第 14822 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0040])\n",
						"第 14823 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0040])\n",
						"第 14824 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0040])\n",
						"第 14825 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0040])\n",
						"第 14826 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0040])\n",
						"第 14827 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0040])\n",
						"第 14828 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0040])\n",
						"第 14829 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0040])\n",
						"第 14830 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0040])\n",
						"第 14831 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0040])\n",
						"第 14832 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0040])\n",
						"第 14833 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0040])\n",
						"第 14834 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0040])\n",
						"第 14835 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0040])\n",
						"第 14836 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0040])\n",
						"第 14837 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0040])\n",
						"第 14838 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0040])\n",
						"第 14839 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0040])\n",
						"第 14840 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0040])\n",
						"第 742 次epoch\n",
						"第 14841 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0040])\n",
						"第 14842 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0040])\n",
						"第 14843 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0040])\n",
						"第 14844 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0040])\n",
						"第 14845 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0040])\n",
						"第 14846 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0040])\n",
						"第 14847 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0040])\n",
						"第 14848 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0040])\n",
						"第 14849 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0040])\n",
						"第 14850 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0040])\n",
						"第 14851 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0040])\n",
						"第 14852 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0040])\n",
						"第 14853 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0040])\n",
						"第 14854 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0040])\n",
						"第 14855 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0040])\n",
						"第 14856 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0039])\n",
						"第 14857 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0039])\n",
						"第 14858 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0039])\n",
						"第 14859 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0039])\n",
						"第 14860 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0039])\n",
						"第 743 次epoch\n",
						"第 14861 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0039])\n",
						"第 14862 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0039])\n",
						"第 14863 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0039])\n",
						"第 14864 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0039])\n",
						"第 14865 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0039])\n",
						"第 14866 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0039])\n",
						"第 14867 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0039])\n",
						"第 14868 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0039])\n",
						"第 14869 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0039])\n",
						"第 14870 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0039])\n",
						"第 14871 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0039])\n",
						"第 14872 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0039])\n",
						"第 14873 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0039])\n",
						"第 14874 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0039])\n",
						"第 14875 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0039])\n",
						"第 14876 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0039])\n",
						"第 14877 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0039])\n",
						"第 14878 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0039])\n",
						"第 14879 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0039])\n",
						"第 14880 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0039])\n",
						"第 744 次epoch\n",
						"第 14881 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0039])\n",
						"第 14882 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0039])\n",
						"第 14883 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0039])\n",
						"第 14884 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0039])\n",
						"第 14885 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0039])\n",
						"第 14886 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0039])\n",
						"第 14887 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0039])\n",
						"第 14888 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0039])\n",
						"第 14889 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0039])\n",
						"第 14890 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0039])\n",
						"第 14891 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0039])\n",
						"第 14892 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0039])\n",
						"第 14893 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0039])\n",
						"第 14894 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0039])\n",
						"第 14895 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0039])\n",
						"第 14896 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0039])\n",
						"第 14897 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0039])\n",
						"第 14898 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0039])\n",
						"第 14899 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0039])\n",
						"第 14900 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0039])\n",
						"第 745 次epoch\n",
						"第 14901 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0039])\n",
						"第 14902 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0039])\n",
						"第 14903 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0039])\n",
						"第 14904 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0039])\n",
						"第 14905 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0039])\n",
						"第 14906 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0039])\n",
						"第 14907 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0039])\n",
						"第 14908 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0039])\n",
						"第 14909 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0039])\n",
						"第 14910 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0039])\n",
						"第 14911 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0039])\n",
						"第 14912 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0039])\n",
						"第 14913 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0039])\n",
						"第 14914 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0039])\n",
						"第 14915 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0038])\n",
						"第 14916 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0039])\n",
						"第 14917 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0038])\n",
						"第 14918 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0038])\n",
						"第 14919 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0038])\n",
						"第 14920 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0038])\n",
						"第 746 次epoch\n",
						"第 14921 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0038])\n",
						"第 14922 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0038])\n",
						"第 14923 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0038])\n",
						"第 14924 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0038])\n",
						"第 14925 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0038])\n",
						"第 14926 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0038])\n",
						"第 14927 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0038])\n",
						"第 14928 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0038])\n",
						"第 14929 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0038])\n",
						"第 14930 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0038])\n",
						"第 14931 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0038])\n",
						"第 14932 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0038])\n",
						"第 14933 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0038])\n",
						"第 14934 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0038])\n",
						"第 14935 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0038])\n",
						"第 14936 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0038])\n",
						"第 14937 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0038])\n",
						"第 14938 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0038])\n",
						"第 14939 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0038])\n",
						"第 14940 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0038])\n",
						"第 747 次epoch\n",
						"第 14941 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0038])\n",
						"第 14942 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0038])\n",
						"第 14943 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0038])\n",
						"第 14944 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0038])\n",
						"第 14945 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0038])\n",
						"第 14946 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0038])\n",
						"第 14947 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0038])\n",
						"第 14948 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0038])\n",
						"第 14949 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0038])\n",
						"第 14950 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0038])\n",
						"第 14951 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0038])\n",
						"第 14952 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0038])\n",
						"第 14953 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0038])\n",
						"第 14954 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0038])\n",
						"第 14955 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0038])\n",
						"第 14956 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0038])\n",
						"第 14957 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0038])\n",
						"第 14958 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0038])\n",
						"第 14959 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0038])\n",
						"第 14960 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0038])\n",
						"第 748 次epoch\n",
						"第 14961 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0038])\n",
						"第 14962 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0038])\n",
						"第 14963 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0038])\n",
						"第 14964 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0038])\n",
						"第 14965 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0038])\n",
						"第 14966 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0038])\n",
						"第 14967 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0038])\n",
						"第 14968 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0038])\n",
						"第 14969 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0038])\n",
						"第 14970 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0038])\n",
						"第 14971 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0038])\n",
						"第 14972 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0038])\n",
						"第 14973 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0038])\n",
						"第 14974 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0038])\n",
						"第 14975 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0038])\n",
						"第 14976 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0038])\n",
						"第 14977 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0037])\n",
						"第 14978 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0037])\n",
						"第 14979 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0037])\n",
						"第 14980 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0037])\n",
						"第 749 次epoch\n",
						"第 14981 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0037])\n",
						"第 14982 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0037])\n",
						"第 14983 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0037])\n",
						"第 14984 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0037])\n",
						"第 14985 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0037])\n",
						"第 14986 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0037])\n",
						"第 14987 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0037])\n",
						"第 14988 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0037])\n",
						"第 14989 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0037])\n",
						"第 14990 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0037])\n",
						"第 14991 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0037])\n",
						"第 14992 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0037])\n",
						"第 14993 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0037])\n",
						"第 14994 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0037])\n",
						"第 14995 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0037])\n",
						"第 14996 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0037])\n",
						"第 14997 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0037])\n",
						"第 14998 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0037])\n",
						"第 14999 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0037])\n",
						"第 15000 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0037])\n",
						"第 750 次epoch\n",
						"第 15001 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0037])\n",
						"第 15002 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0037])\n",
						"第 15003 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0037])\n",
						"第 15004 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0037])\n",
						"第 15005 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0037])\n",
						"第 15006 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0037])\n",
						"第 15007 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0037])\n",
						"第 15008 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0037])\n",
						"第 15009 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0037])\n",
						"第 15010 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0037])\n",
						"第 15011 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0037])\n",
						"第 15012 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0037])\n",
						"第 15013 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0037])\n",
						"第 15014 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0037])\n",
						"第 15015 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0037])\n",
						"第 15016 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0037])\n",
						"第 15017 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0037])\n",
						"第 15018 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0037])\n",
						"第 15019 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0037])\n",
						"第 15020 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0037])\n",
						"第 751 次epoch\n",
						"第 15021 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0037])\n",
						"第 15022 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0037])\n",
						"第 15023 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0037])\n",
						"第 15024 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0037])\n",
						"第 15025 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0037])\n",
						"第 15026 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0037])\n",
						"第 15027 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0037])\n",
						"第 15028 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0037])\n",
						"第 15029 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0037])\n",
						"第 15030 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0037])\n",
						"第 15031 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0037])\n",
						"第 15032 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0037])\n",
						"第 15033 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0037])\n",
						"第 15034 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0037])\n",
						"第 15035 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0037])\n",
						"第 15036 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0036])\n",
						"第 15037 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0037])\n",
						"第 15038 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0036])\n",
						"第 15039 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0036])\n",
						"第 15040 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0036])\n",
						"第 752 次epoch\n",
						"第 15041 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0036])\n",
						"第 15042 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0036])\n",
						"第 15043 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0036])\n",
						"第 15044 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0036])\n",
						"第 15045 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0036])\n",
						"第 15046 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0036])\n",
						"第 15047 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0036])\n",
						"第 15048 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0036])\n",
						"第 15049 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0036])\n",
						"第 15050 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0036])\n",
						"第 15051 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0036])\n",
						"第 15052 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0036])\n",
						"第 15053 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0036])\n",
						"第 15054 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0036])\n",
						"第 15055 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0036])\n",
						"第 15056 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0036])\n",
						"第 15057 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0036])\n",
						"第 15058 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0036])\n",
						"第 15059 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0036])\n",
						"第 15060 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0036])\n",
						"第 753 次epoch\n",
						"第 15061 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0036])\n",
						"第 15062 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0036])\n",
						"第 15063 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0036])\n",
						"第 15064 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0036])\n",
						"第 15065 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0036])\n",
						"第 15066 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0036])\n",
						"第 15067 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0036])\n",
						"第 15068 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0036])\n",
						"第 15069 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0036])\n",
						"第 15070 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0036])\n",
						"第 15071 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0036])\n",
						"第 15072 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0036])\n",
						"第 15073 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0036])\n",
						"第 15074 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0036])\n",
						"第 15075 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0036])\n",
						"第 15076 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0036])\n",
						"第 15077 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0036])\n",
						"第 15078 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0036])\n",
						"第 15079 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0036])\n",
						"第 15080 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0036])\n",
						"第 754 次epoch\n",
						"第 15081 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0036])\n",
						"第 15082 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0036])\n",
						"第 15083 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0036])\n",
						"第 15084 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0036])\n",
						"第 15085 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0036])\n",
						"第 15086 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0036])\n",
						"第 15087 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0036])\n",
						"第 15088 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0036])\n",
						"第 15089 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0036])\n",
						"第 15090 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0036])\n",
						"第 15091 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0036])\n",
						"第 15092 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0036])\n",
						"第 15093 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0036])\n",
						"第 15094 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0036])\n",
						"第 15095 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0035])\n",
						"第 15096 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0036])\n",
						"第 15097 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0036])\n",
						"第 15098 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0035])\n",
						"第 15099 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0035])\n",
						"第 15100 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0035])\n",
						"第 755 次epoch\n",
						"第 15101 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0035])\n",
						"第 15102 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0035])\n",
						"第 15103 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0035])\n",
						"第 15104 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0035])\n",
						"第 15105 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0035])\n",
						"第 15106 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0035])\n",
						"第 15107 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0035])\n",
						"第 15108 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0035])\n",
						"第 15109 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0035])\n",
						"第 15110 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0035])\n",
						"第 15111 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0035])\n",
						"第 15112 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0035])\n",
						"第 15113 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0035])\n",
						"第 15114 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0035])\n",
						"第 15115 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0035])\n",
						"第 15116 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0035])\n",
						"第 15117 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0035])\n",
						"第 15118 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0035])\n",
						"第 15119 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0035])\n",
						"第 15120 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0035])\n",
						"第 756 次epoch\n",
						"第 15121 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0035])\n",
						"第 15122 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0035])\n",
						"第 15123 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0035])\n",
						"第 15124 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0035])\n",
						"第 15125 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0035])\n",
						"第 15126 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0035])\n",
						"第 15127 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0035])\n",
						"第 15128 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0035])\n",
						"第 15129 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0035])\n",
						"第 15130 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0035])\n",
						"第 15131 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0035])\n",
						"第 15132 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0035])\n",
						"第 15133 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0035])\n",
						"第 15134 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0035])\n",
						"第 15135 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0035])\n",
						"第 15136 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0035])\n",
						"第 15137 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0035])\n",
						"第 15138 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0035])\n",
						"第 15139 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0035])\n",
						"第 15140 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0035])\n",
						"第 757 次epoch\n",
						"第 15141 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0035])\n",
						"第 15142 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0035])\n",
						"第 15143 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0035])\n",
						"第 15144 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0035])\n",
						"第 15145 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0035])\n",
						"第 15146 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0035])\n",
						"第 15147 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0035])\n",
						"第 15148 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0035])\n",
						"第 15149 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0035])\n",
						"第 15150 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0035])\n",
						"第 15151 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0035])\n",
						"第 15152 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0035])\n",
						"第 15153 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0035])\n",
						"第 15154 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0035])\n",
						"第 15155 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0035])\n",
						"第 15156 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0035])\n",
						"第 15157 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0034])\n",
						"第 15158 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0035])\n",
						"第 15159 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0034])\n",
						"第 15160 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0034])\n",
						"第 758 次epoch\n",
						"第 15161 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0034])\n",
						"第 15162 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0034])\n",
						"第 15163 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0034])\n",
						"第 15164 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0034])\n",
						"第 15165 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0034])\n",
						"第 15166 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0034])\n",
						"第 15167 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0034])\n",
						"第 15168 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0034])\n",
						"第 15169 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0034])\n",
						"第 15170 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0034])\n",
						"第 15171 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0034])\n",
						"第 15172 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0034])\n",
						"第 15173 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0034])\n",
						"第 15174 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0034])\n",
						"第 15175 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0034])\n",
						"第 15176 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0034])\n",
						"第 15177 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0034])\n",
						"第 15178 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0034])\n",
						"第 15179 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0034])\n",
						"第 15180 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0034])\n",
						"第 759 次epoch\n",
						"第 15181 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0034])\n",
						"第 15182 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0034])\n",
						"第 15183 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0034])\n",
						"第 15184 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0034])\n",
						"第 15185 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0034])\n",
						"第 15186 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0034])\n",
						"第 15187 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0034])\n",
						"第 15188 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0034])\n",
						"第 15189 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0034])\n",
						"第 15190 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0034])\n",
						"第 15191 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0034])\n",
						"第 15192 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0034])\n",
						"第 15193 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0034])\n",
						"第 15194 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0034])\n",
						"第 15195 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0034])\n",
						"第 15196 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0034])\n",
						"第 15197 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0034])\n",
						"第 15198 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0034])\n",
						"第 15199 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0034])\n",
						"第 15200 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0034])\n",
						"第 760 次epoch\n",
						"第 15201 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0034])\n",
						"第 15202 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0034])\n",
						"第 15203 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0034])\n",
						"第 15204 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0034])\n",
						"第 15205 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0034])\n",
						"第 15206 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0034])\n",
						"第 15207 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0034])\n",
						"第 15208 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0034])\n",
						"第 15209 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0034])\n",
						"第 15210 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0034])\n",
						"第 15211 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0034])\n",
						"第 15212 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0034])\n",
						"第 15213 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0034])\n",
						"第 15214 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0034])\n",
						"第 15215 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0034])\n",
						"第 15216 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0033])\n",
						"第 15217 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0034])\n",
						"第 15218 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0033])\n",
						"第 15219 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0033])\n",
						"第 15220 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0033])\n",
						"第 761 次epoch\n",
						"第 15221 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0033])\n",
						"第 15222 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0033])\n",
						"第 15223 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0033])\n",
						"第 15224 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0033])\n",
						"第 15225 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0033])\n",
						"第 15226 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0033])\n",
						"第 15227 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0033])\n",
						"第 15228 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0033])\n",
						"第 15229 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0033])\n",
						"第 15230 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0033])\n",
						"第 15231 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0033])\n",
						"第 15232 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0033])\n",
						"第 15233 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0033])\n",
						"第 15234 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0033])\n",
						"第 15235 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0033])\n",
						"第 15236 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0033])\n",
						"第 15237 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0033])\n",
						"第 15238 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0033])\n",
						"第 15239 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0033])\n",
						"第 15240 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0033])\n",
						"第 762 次epoch\n",
						"第 15241 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0033])\n",
						"第 15242 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0033])\n",
						"第 15243 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0033])\n",
						"第 15244 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0033])\n",
						"第 15245 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0033])\n",
						"第 15246 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0033])\n",
						"第 15247 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0033])\n",
						"第 15248 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0033])\n",
						"第 15249 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0033])\n",
						"第 15250 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0033])\n",
						"第 15251 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0033])\n",
						"第 15252 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0033])\n",
						"第 15253 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0033])\n",
						"第 15254 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0033])\n",
						"第 15255 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0033])\n",
						"第 15256 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0033])\n",
						"第 15257 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0033])\n",
						"第 15258 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0033])\n",
						"第 15259 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0033])\n",
						"第 15260 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0033])\n",
						"第 763 次epoch\n",
						"第 15261 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0033])\n",
						"第 15262 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0033])\n",
						"第 15263 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0033])\n",
						"第 15264 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0033])\n",
						"第 15265 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0033])\n",
						"第 15266 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0033])\n",
						"第 15267 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0033])\n",
						"第 15268 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0033])\n",
						"第 15269 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0033])\n",
						"第 15270 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0033])\n",
						"第 15271 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0033])\n",
						"第 15272 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0033])\n",
						"第 15273 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0033])\n",
						"第 15274 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0033])\n",
						"第 15275 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0033])\n",
						"第 15276 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0033])\n",
						"第 15277 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0033])\n",
						"第 15278 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0033])\n",
						"第 15279 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0033])\n",
						"第 15280 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0033])\n",
						"第 764 次epoch\n",
						"第 15281 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0033])\n",
						"第 15282 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0033])\n",
						"第 15283 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0033])\n",
						"第 15284 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0033])\n",
						"第 15285 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0033])\n",
						"第 15286 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0033])\n",
						"第 15287 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0033])\n",
						"第 15288 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0033])\n",
						"第 15289 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0033])\n",
						"第 15290 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0033])\n",
						"第 15291 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0033])\n",
						"第 15292 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0033])\n",
						"第 15293 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0033])\n",
						"第 15294 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0033])\n",
						"第 15295 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0033])\n",
						"第 15296 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0032])\n",
						"第 15297 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0032])\n",
						"第 15298 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0032])\n",
						"第 15299 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0032])\n",
						"第 15300 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0032])\n",
						"第 765 次epoch\n",
						"第 15301 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0033])\n",
						"第 15302 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0032])\n",
						"第 15303 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0032])\n",
						"第 15304 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0032])\n",
						"第 15305 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0032])\n",
						"第 15306 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0032])\n",
						"第 15307 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0032])\n",
						"第 15308 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0032])\n",
						"第 15309 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0032])\n",
						"第 15310 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0032])\n",
						"第 15311 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0032])\n",
						"第 15312 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0032])\n",
						"第 15313 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0032])\n",
						"第 15314 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0032])\n",
						"第 15315 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0032])\n",
						"第 15316 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0032])\n",
						"第 15317 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0032])\n",
						"第 15318 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0032])\n",
						"第 15319 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0032])\n",
						"第 15320 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0032])\n",
						"第 766 次epoch\n",
						"第 15321 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0032])\n",
						"第 15322 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0032])\n",
						"第 15323 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0032])\n",
						"第 15324 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0032])\n",
						"第 15325 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0032])\n",
						"第 15326 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0032])\n",
						"第 15327 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0032])\n",
						"第 15328 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0032])\n",
						"第 15329 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0032])\n",
						"第 15330 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0032])\n",
						"第 15331 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0032])\n",
						"第 15332 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0032])\n",
						"第 15333 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0032])\n",
						"第 15334 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0032])\n",
						"第 15335 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0032])\n",
						"第 15336 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0032])\n",
						"第 15337 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0032])\n",
						"第 15338 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0032])\n",
						"第 15339 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0032])\n",
						"第 15340 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0032])\n",
						"第 767 次epoch\n",
						"第 15341 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0032])\n",
						"第 15342 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0032])\n",
						"第 15343 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0032])\n",
						"第 15344 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0032])\n",
						"第 15345 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0032])\n",
						"第 15346 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0032])\n",
						"第 15347 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0032])\n",
						"第 15348 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0032])\n",
						"第 15349 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0032])\n",
						"第 15350 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0032])\n",
						"第 15351 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0032])\n",
						"第 15352 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0032])\n",
						"第 15353 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0032])\n",
						"第 15354 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0032])\n",
						"第 15355 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0032])\n",
						"第 15356 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0032])\n",
						"第 15357 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0032])\n",
						"第 15358 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0032])\n",
						"第 15359 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0032])\n",
						"第 15360 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0032])\n",
						"第 768 次epoch\n",
						"第 15361 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0032])\n",
						"第 15362 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0032])\n",
						"第 15363 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0032])\n",
						"第 15364 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0032])\n",
						"第 15365 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0032])\n",
						"第 15366 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0032])\n",
						"第 15367 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0032])\n",
						"第 15368 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0032])\n",
						"第 15369 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0032])\n",
						"第 15370 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0032])\n",
						"第 15371 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0032])\n",
						"第 15372 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0032])\n",
						"第 15373 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0032])\n",
						"第 15374 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0031])\n",
						"第 15375 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0032])\n",
						"第 15376 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0031])\n",
						"第 15377 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0032])\n",
						"第 15378 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0031])\n",
						"第 15379 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0031])\n",
						"第 15380 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0031])\n",
						"第 769 次epoch\n",
						"第 15381 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0031])\n",
						"第 15382 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0031])\n",
						"第 15383 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0031])\n",
						"第 15384 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0031])\n",
						"第 15385 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0031])\n",
						"第 15386 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0031])\n",
						"第 15387 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0031])\n",
						"第 15388 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0031])\n",
						"第 15389 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0031])\n",
						"第 15390 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0031])\n",
						"第 15391 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0031])\n",
						"第 15392 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0031])\n",
						"第 15393 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0031])\n",
						"第 15394 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0031])\n",
						"第 15395 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0031])\n",
						"第 15396 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0031])\n",
						"第 15397 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0031])\n",
						"第 15398 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0031])\n",
						"第 15399 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0031])\n",
						"第 15400 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0031])\n",
						"第 770 次epoch\n",
						"第 15401 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0031])\n",
						"第 15402 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0031])\n",
						"第 15403 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0031])\n",
						"第 15404 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0031])\n",
						"第 15405 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0031])\n",
						"第 15406 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0031])\n",
						"第 15407 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0031])\n",
						"第 15408 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0031])\n",
						"第 15409 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0031])\n",
						"第 15410 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0031])\n",
						"第 15411 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0031])\n",
						"第 15412 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0031])\n",
						"第 15413 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0031])\n",
						"第 15414 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0031])\n",
						"第 15415 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0031])\n",
						"第 15416 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0031])\n",
						"第 15417 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0031])\n",
						"第 15418 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0031])\n",
						"第 15419 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0031])\n",
						"第 15420 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0031])\n",
						"第 771 次epoch\n",
						"第 15421 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0031])\n",
						"第 15422 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0031])\n",
						"第 15423 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0031])\n",
						"第 15424 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0031])\n",
						"第 15425 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0031])\n",
						"第 15426 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0031])\n",
						"第 15427 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0031])\n",
						"第 15428 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0031])\n",
						"第 15429 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0031])\n",
						"第 15430 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0031])\n",
						"第 15431 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0031])\n",
						"第 15432 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0031])\n",
						"第 15433 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0031])\n",
						"第 15434 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0031])\n",
						"第 15435 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0031])\n",
						"第 15436 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0031])\n",
						"第 15437 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0031])\n",
						"第 15438 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0031])\n",
						"第 15439 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0031])\n",
						"第 15440 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0031])\n",
						"第 772 次epoch\n",
						"第 15441 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0031])\n",
						"第 15442 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0031])\n",
						"第 15443 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0031])\n",
						"第 15444 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0031])\n",
						"第 15445 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0031])\n",
						"第 15446 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0031])\n",
						"第 15447 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0031])\n",
						"第 15448 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0031])\n",
						"第 15449 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0031])\n",
						"第 15450 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0031])\n",
						"第 15451 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0031])\n",
						"第 15452 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0031])\n",
						"第 15453 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0030])\n",
						"第 15454 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0031])\n",
						"第 15455 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0031])\n",
						"第 15456 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0031])\n",
						"第 15457 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0030])\n",
						"第 15458 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0031])\n",
						"第 15459 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0030])\n",
						"第 15460 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0031])\n",
						"第 773 次epoch\n",
						"第 15461 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0030])\n",
						"第 15462 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0030])\n",
						"第 15463 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0030])\n",
						"第 15464 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0030])\n",
						"第 15465 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0030])\n",
						"第 15466 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0030])\n",
						"第 15467 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0030])\n",
						"第 15468 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0030])\n",
						"第 15469 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0030])\n",
						"第 15470 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0030])\n",
						"第 15471 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0030])\n",
						"第 15472 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0030])\n",
						"第 15473 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0030])\n",
						"第 15474 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0030])\n",
						"第 15475 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0030])\n",
						"第 15476 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0030])\n",
						"第 15477 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0030])\n",
						"第 15478 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0030])\n",
						"第 15479 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0030])\n",
						"第 15480 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0030])\n",
						"第 774 次epoch\n",
						"第 15481 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0030])\n",
						"第 15482 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0030])\n",
						"第 15483 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0030])\n",
						"第 15484 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0030])\n",
						"第 15485 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0030])\n",
						"第 15486 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0030])\n",
						"第 15487 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0030])\n",
						"第 15488 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0030])\n",
						"第 15489 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0030])\n",
						"第 15490 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0030])\n",
						"第 15491 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0030])\n",
						"第 15492 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0030])\n",
						"第 15493 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0030])\n",
						"第 15494 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0030])\n",
						"第 15495 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0030])\n",
						"第 15496 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0030])\n",
						"第 15497 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0030])\n",
						"第 15498 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0030])\n",
						"第 15499 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0030])\n",
						"第 15500 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0030])\n",
						"第 775 次epoch\n",
						"第 15501 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0030])\n",
						"第 15502 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0030])\n",
						"第 15503 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0030])\n",
						"第 15504 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0030])\n",
						"第 15505 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0030])\n",
						"第 15506 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0030])\n",
						"第 15507 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0030])\n",
						"第 15508 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0030])\n",
						"第 15509 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0030])\n",
						"第 15510 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0030])\n",
						"第 15511 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0030])\n",
						"第 15512 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0030])\n",
						"第 15513 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0030])\n",
						"第 15514 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0030])\n",
						"第 15515 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0030])\n",
						"第 15516 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0030])\n",
						"第 15517 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0030])\n",
						"第 15518 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0030])\n",
						"第 15519 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0030])\n",
						"第 15520 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0030])\n",
						"第 776 次epoch\n",
						"第 15521 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0030])\n",
						"第 15522 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0030])\n",
						"第 15523 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0030])\n",
						"第 15524 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0030])\n",
						"第 15525 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0030])\n",
						"第 15526 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0030])\n",
						"第 15527 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0030])\n",
						"第 15528 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0030])\n",
						"第 15529 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0030])\n",
						"第 15530 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0030])\n",
						"第 15531 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0030])\n",
						"第 15532 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0030])\n",
						"第 15533 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0030])\n",
						"第 15534 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0030])\n",
						"第 15535 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0030])\n",
						"第 15536 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0030])\n",
						"第 15537 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0030])\n",
						"第 15538 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0029])\n",
						"第 15539 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0029])\n",
						"第 15540 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0029])\n",
						"第 777 次epoch\n",
						"第 15541 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0029])\n",
						"第 15542 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0029])\n",
						"第 15543 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0029])\n",
						"第 15544 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0029])\n",
						"第 15545 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0029])\n",
						"第 15546 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0029])\n",
						"第 15547 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0029])\n",
						"第 15548 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0029])\n",
						"第 15549 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0029])\n",
						"第 15550 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0029])\n",
						"第 15551 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0029])\n",
						"第 15552 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0029])\n",
						"第 15553 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0029])\n",
						"第 15554 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0029])\n",
						"第 15555 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0029])\n",
						"第 15556 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0029])\n",
						"第 15557 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0029])\n",
						"第 15558 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0029])\n",
						"第 15559 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0029])\n",
						"第 15560 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0029])\n",
						"第 778 次epoch\n",
						"第 15561 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0029])\n",
						"第 15562 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0029])\n",
						"第 15563 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0029])\n",
						"第 15564 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0029])\n",
						"第 15565 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0029])\n",
						"第 15566 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0029])\n",
						"第 15567 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0029])\n",
						"第 15568 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0029])\n",
						"第 15569 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0029])\n",
						"第 15570 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0029])\n",
						"第 15571 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0029])\n",
						"第 15572 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0029])\n",
						"第 15573 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0029])\n",
						"第 15574 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0029])\n",
						"第 15575 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0029])\n",
						"第 15576 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0029])\n",
						"第 15577 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0029])\n",
						"第 15578 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0029])\n",
						"第 15579 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0029])\n",
						"第 15580 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0029])\n",
						"第 779 次epoch\n",
						"第 15581 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0029])\n",
						"第 15582 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0029])\n",
						"第 15583 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0029])\n",
						"第 15584 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0029])\n",
						"第 15585 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0029])\n",
						"第 15586 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0029])\n",
						"第 15587 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0029])\n",
						"第 15588 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0029])\n",
						"第 15589 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0029])\n",
						"第 15590 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0029])\n",
						"第 15591 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0029])\n",
						"第 15592 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0029])\n",
						"第 15593 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0029])\n",
						"第 15594 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0029])\n",
						"第 15595 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0029])\n",
						"第 15596 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0029])\n",
						"第 15597 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0029])\n",
						"第 15598 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0029])\n",
						"第 15599 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0029])\n",
						"第 15600 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0029])\n",
						"第 780 次epoch\n",
						"第 15601 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0029])\n",
						"第 15602 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0029])\n",
						"第 15603 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0029])\n",
						"第 15604 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0029])\n",
						"第 15605 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0029])\n",
						"第 15606 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0029])\n",
						"第 15607 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0029])\n",
						"第 15608 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0029])\n",
						"第 15609 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0029])\n",
						"第 15610 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0029])\n",
						"第 15611 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0029])\n",
						"第 15612 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0029])\n",
						"第 15613 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0029])\n",
						"第 15614 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0029])\n",
						"第 15615 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0029])\n",
						"第 15616 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0028])\n",
						"第 15617 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0029])\n",
						"第 15618 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0029])\n",
						"第 15619 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0028])\n",
						"第 15620 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0028])\n",
						"第 781 次epoch\n",
						"第 15621 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0028])\n",
						"第 15622 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0028])\n",
						"第 15623 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0028])\n",
						"第 15624 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0028])\n",
						"第 15625 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0028])\n",
						"第 15626 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0028])\n",
						"第 15627 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0028])\n",
						"第 15628 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0028])\n",
						"第 15629 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0028])\n",
						"第 15630 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0028])\n",
						"第 15631 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0028])\n",
						"第 15632 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0028])\n",
						"第 15633 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0028])\n",
						"第 15634 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0028])\n",
						"第 15635 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0028])\n",
						"第 15636 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0028])\n",
						"第 15637 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0028])\n",
						"第 15638 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0028])\n",
						"第 15639 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0028])\n",
						"第 15640 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0028])\n",
						"第 782 次epoch\n",
						"第 15641 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0028])\n",
						"第 15642 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0028])\n",
						"第 15643 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0028])\n",
						"第 15644 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0028])\n",
						"第 15645 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0028])\n",
						"第 15646 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0028])\n",
						"第 15647 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0028])\n",
						"第 15648 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0028])\n",
						"第 15649 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0028])\n",
						"第 15650 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0028])\n",
						"第 15651 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0028])\n",
						"第 15652 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0028])\n",
						"第 15653 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0028])\n",
						"第 15654 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0028])\n",
						"第 15655 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0028])\n",
						"第 15656 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0028])\n",
						"第 15657 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0028])\n",
						"第 15658 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0028])\n",
						"第 15659 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0028])\n",
						"第 15660 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0028])\n",
						"第 783 次epoch\n",
						"第 15661 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0028])\n",
						"第 15662 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0028])\n",
						"第 15663 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0028])\n",
						"第 15664 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0028])\n",
						"第 15665 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0028])\n",
						"第 15666 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0028])\n",
						"第 15667 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0028])\n",
						"第 15668 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0028])\n",
						"第 15669 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0028])\n",
						"第 15670 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0028])\n",
						"第 15671 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0028])\n",
						"第 15672 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0028])\n",
						"第 15673 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0028])\n",
						"第 15674 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0028])\n",
						"第 15675 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0028])\n",
						"第 15676 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0028])\n",
						"第 15677 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0028])\n",
						"第 15678 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0028])\n",
						"第 15679 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0028])\n",
						"第 15680 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0028])\n",
						"第 784 次epoch\n",
						"第 15681 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0028])\n",
						"第 15682 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0028])\n",
						"第 15683 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0028])\n",
						"第 15684 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0028])\n",
						"第 15685 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0028])\n",
						"第 15686 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0028])\n",
						"第 15687 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0028])\n",
						"第 15688 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0028])\n",
						"第 15689 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0028])\n",
						"第 15690 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0028])\n",
						"第 15691 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0028])\n",
						"第 15692 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0028])\n",
						"第 15693 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0028])\n",
						"第 15694 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0028])\n",
						"第 15695 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0028])\n",
						"第 15696 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0028])\n",
						"第 15697 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0027])\n",
						"第 15698 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0028])\n",
						"第 15699 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0027])\n",
						"第 15700 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0028])\n",
						"第 785 次epoch\n",
						"第 15701 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0027])\n",
						"第 15702 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0028])\n",
						"第 15703 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0027])\n",
						"第 15704 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0027])\n",
						"第 15705 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0027])\n",
						"第 15706 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0027])\n",
						"第 15707 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0027])\n",
						"第 15708 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0027])\n",
						"第 15709 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0027])\n",
						"第 15710 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0027])\n",
						"第 15711 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0027])\n",
						"第 15712 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0027])\n",
						"第 15713 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0027])\n",
						"第 15714 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0027])\n",
						"第 15715 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0027])\n",
						"第 15716 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0027])\n",
						"第 15717 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0027])\n",
						"第 15718 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0027])\n",
						"第 15719 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0027])\n",
						"第 15720 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0027])\n",
						"第 786 次epoch\n",
						"第 15721 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0027])\n",
						"第 15722 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0027])\n",
						"第 15723 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0027])\n",
						"第 15724 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0027])\n",
						"第 15725 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0027])\n",
						"第 15726 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0027])\n",
						"第 15727 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0027])\n",
						"第 15728 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0027])\n",
						"第 15729 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0027])\n",
						"第 15730 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0027])\n",
						"第 15731 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0027])\n",
						"第 15732 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0027])\n",
						"第 15733 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0027])\n",
						"第 15734 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0027])\n",
						"第 15735 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0027])\n",
						"第 15736 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0027])\n",
						"第 15737 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0027])\n",
						"第 15738 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0027])\n",
						"第 15739 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0027])\n",
						"第 15740 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0027])\n",
						"第 787 次epoch\n",
						"第 15741 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0027])\n",
						"第 15742 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0027])\n",
						"第 15743 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0027])\n",
						"第 15744 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0027])\n",
						"第 15745 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0027])\n",
						"第 15746 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0027])\n",
						"第 15747 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0027])\n",
						"第 15748 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0027])\n",
						"第 15749 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0027])\n",
						"第 15750 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0027])\n",
						"第 15751 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0027])\n",
						"第 15752 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0027])\n",
						"第 15753 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0027])\n",
						"第 15754 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0027])\n",
						"第 15755 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0027])\n",
						"第 15756 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0027])\n",
						"第 15757 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0027])\n",
						"第 15758 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0027])\n",
						"第 15759 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0027])\n",
						"第 15760 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0027])\n",
						"第 788 次epoch\n",
						"第 15761 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0027])\n",
						"第 15762 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0027])\n",
						"第 15763 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0027])\n",
						"第 15764 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0027])\n",
						"第 15765 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0027])\n",
						"第 15766 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0027])\n",
						"第 15767 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0027])\n",
						"第 15768 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0027])\n",
						"第 15769 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0027])\n",
						"第 15770 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0027])\n",
						"第 15771 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0027])\n",
						"第 15772 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0027])\n",
						"第 15773 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0027])\n",
						"第 15774 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0027])\n",
						"第 15775 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0027])\n",
						"第 15776 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0027])\n",
						"第 15777 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0027])\n",
						"第 15778 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0026])\n",
						"第 15779 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0027])\n",
						"第 15780 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0026])\n",
						"第 789 次epoch\n",
						"第 15781 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0027])\n",
						"第 15782 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0026])\n",
						"第 15783 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0026])\n",
						"第 15784 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0026])\n",
						"第 15785 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0026])\n",
						"第 15786 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0026])\n",
						"第 15787 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0026])\n",
						"第 15788 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0026])\n",
						"第 15789 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0026])\n",
						"第 15790 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0026])\n",
						"第 15791 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0026])\n",
						"第 15792 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0026])\n",
						"第 15793 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0026])\n",
						"第 15794 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0026])\n",
						"第 15795 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0026])\n",
						"第 15796 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0026])\n",
						"第 15797 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0026])\n",
						"第 15798 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0026])\n",
						"第 15799 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0026])\n",
						"第 15800 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0026])\n",
						"第 790 次epoch\n",
						"第 15801 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0026])\n",
						"第 15802 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0026])\n",
						"第 15803 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0026])\n",
						"第 15804 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0026])\n",
						"第 15805 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0026])\n",
						"第 15806 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0026])\n",
						"第 15807 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0026])\n",
						"第 15808 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0026])\n",
						"第 15809 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0026])\n",
						"第 15810 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0026])\n",
						"第 15811 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0026])\n",
						"第 15812 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0026])\n",
						"第 15813 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0026])\n",
						"第 15814 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0026])\n",
						"第 15815 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0026])\n",
						"第 15816 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0026])\n",
						"第 15817 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0026])\n",
						"第 15818 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0026])\n",
						"第 15819 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0026])\n",
						"第 15820 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0026])\n",
						"第 791 次epoch\n",
						"第 15821 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0026])\n",
						"第 15822 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0026])\n",
						"第 15823 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0026])\n",
						"第 15824 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0026])\n",
						"第 15825 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0026])\n",
						"第 15826 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0026])\n",
						"第 15827 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0026])\n",
						"第 15828 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0026])\n",
						"第 15829 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0026])\n",
						"第 15830 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0026])\n",
						"第 15831 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0026])\n",
						"第 15832 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0026])\n",
						"第 15833 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0026])\n",
						"第 15834 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0026])\n",
						"第 15835 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0026])\n",
						"第 15836 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0026])\n",
						"第 15837 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0026])\n",
						"第 15838 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0026])\n",
						"第 15839 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0026])\n",
						"第 15840 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0026])\n",
						"第 792 次epoch\n",
						"第 15841 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0026])\n",
						"第 15842 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0026])\n",
						"第 15843 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0026])\n",
						"第 15844 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0026])\n",
						"第 15845 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0026])\n",
						"第 15846 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0026])\n",
						"第 15847 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0026])\n",
						"第 15848 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0026])\n",
						"第 15849 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0026])\n",
						"第 15850 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0026])\n",
						"第 15851 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0026])\n",
						"第 15852 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0026])\n",
						"第 15853 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0026])\n",
						"第 15854 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0025])\n",
						"第 15855 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0026])\n",
						"第 15856 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0026])\n",
						"第 15857 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0026])\n",
						"第 15858 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0025])\n",
						"第 15859 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0026])\n",
						"第 15860 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0025])\n",
						"第 793 次epoch\n",
						"第 15861 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0025])\n",
						"第 15862 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0025])\n",
						"第 15863 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0025])\n",
						"第 15864 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0025])\n",
						"第 15865 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0025])\n",
						"第 15866 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0025])\n",
						"第 15867 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0025])\n",
						"第 15868 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0025])\n",
						"第 15869 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0025])\n",
						"第 15870 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0025])\n",
						"第 15871 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0025])\n",
						"第 15872 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0025])\n",
						"第 15873 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0025])\n",
						"第 15874 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0025])\n",
						"第 15875 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0025])\n",
						"第 15876 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0025])\n",
						"第 15877 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0025])\n",
						"第 15878 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0025])\n",
						"第 15879 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0025])\n",
						"第 15880 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0025])\n",
						"第 794 次epoch\n",
						"第 15881 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0025])\n",
						"第 15882 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0025])\n",
						"第 15883 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0025])\n",
						"第 15884 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0025])\n",
						"第 15885 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0025])\n",
						"第 15886 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0025])\n",
						"第 15887 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0025])\n",
						"第 15888 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0025])\n",
						"第 15889 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0025])\n",
						"第 15890 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0025])\n",
						"第 15891 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0025])\n",
						"第 15892 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0025])\n",
						"第 15893 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0025])\n",
						"第 15894 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0025])\n",
						"第 15895 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0025])\n",
						"第 15896 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0025])\n",
						"第 15897 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0025])\n",
						"第 15898 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0025])\n",
						"第 15899 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0025])\n",
						"第 15900 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0025])\n",
						"第 795 次epoch\n",
						"第 15901 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0025])\n",
						"第 15902 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0025])\n",
						"第 15903 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0025])\n",
						"第 15904 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0025])\n",
						"第 15905 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0025])\n",
						"第 15906 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0025])\n",
						"第 15907 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0025])\n",
						"第 15908 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0025])\n",
						"第 15909 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0025])\n",
						"第 15910 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0025])\n",
						"第 15911 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0025])\n",
						"第 15912 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0025])\n",
						"第 15913 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0025])\n",
						"第 15914 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0025])\n",
						"第 15915 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0025])\n",
						"第 15916 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0025])\n",
						"第 15917 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0025])\n",
						"第 15918 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0025])\n",
						"第 15919 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0025])\n",
						"第 15920 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0025])\n",
						"第 796 次epoch\n",
						"第 15921 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0025])\n",
						"第 15922 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0025])\n",
						"第 15923 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0025])\n",
						"第 15924 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0025])\n",
						"第 15925 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0025])\n",
						"第 15926 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0025])\n",
						"第 15927 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0025])\n",
						"第 15928 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0025])\n",
						"第 15929 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0025])\n",
						"第 15930 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0025])\n",
						"第 15931 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0025])\n",
						"第 15932 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0025])\n",
						"第 15933 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0025])\n",
						"第 15934 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0025])\n",
						"第 15935 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0025])\n",
						"第 15936 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0025])\n",
						"第 15937 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0025])\n",
						"第 15938 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0025])\n",
						"第 15939 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0024])\n",
						"第 15940 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0025])\n",
						"第 797 次epoch\n",
						"第 15941 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0024])\n",
						"第 15942 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0025])\n",
						"第 15943 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0024])\n",
						"第 15944 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0024])\n",
						"第 15945 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0024])\n",
						"第 15946 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0024])\n",
						"第 15947 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0024])\n",
						"第 15948 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0024])\n",
						"第 15949 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0024])\n",
						"第 15950 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0024])\n",
						"第 15951 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0024])\n",
						"第 15952 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0024])\n",
						"第 15953 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0024])\n",
						"第 15954 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0024])\n",
						"第 15955 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0024])\n",
						"第 15956 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0024])\n",
						"第 15957 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0024])\n",
						"第 15958 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0024])\n",
						"第 15959 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0024])\n",
						"第 15960 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0024])\n",
						"第 798 次epoch\n",
						"第 15961 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0024])\n",
						"第 15962 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0024])\n",
						"第 15963 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0024])\n",
						"第 15964 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0024])\n",
						"第 15965 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0024])\n",
						"第 15966 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0024])\n",
						"第 15967 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0024])\n",
						"第 15968 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0024])\n",
						"第 15969 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0024])\n",
						"第 15970 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0024])\n",
						"第 15971 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0024])\n",
						"第 15972 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0024])\n",
						"第 15973 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0024])\n",
						"第 15974 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0024])\n",
						"第 15975 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0024])\n",
						"第 15976 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0024])\n",
						"第 15977 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0024])\n",
						"第 15978 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0024])\n",
						"第 15979 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0024])\n",
						"第 15980 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0024])\n",
						"第 799 次epoch\n",
						"第 15981 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0024])\n",
						"第 15982 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0024])\n",
						"第 15983 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0024])\n",
						"第 15984 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0024])\n",
						"第 15985 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0024])\n",
						"第 15986 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0024])\n",
						"第 15987 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0024])\n",
						"第 15988 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0024])\n",
						"第 15989 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0024])\n",
						"第 15990 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0024])\n",
						"第 15991 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0024])\n",
						"第 15992 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0024])\n",
						"第 15993 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0024])\n",
						"第 15994 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0024])\n",
						"第 15995 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0024])\n",
						"第 15996 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0024])\n",
						"第 15997 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0024])\n",
						"第 15998 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0024])\n",
						"第 15999 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0024])\n",
						"第 16000 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0024])\n",
						"第 800 次epoch\n",
						"第 16001 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0024])\n",
						"第 16002 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0024])\n",
						"第 16003 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0024])\n",
						"第 16004 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0024])\n",
						"第 16005 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0024])\n",
						"第 16006 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0024])\n",
						"第 16007 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0024])\n",
						"第 16008 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0024])\n",
						"第 16009 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0024])\n",
						"第 16010 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0024])\n",
						"第 16011 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0024])\n",
						"第 16012 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0024])\n",
						"第 16013 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0024])\n",
						"第 16014 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0024])\n",
						"第 16015 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0024])\n",
						"第 16016 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0024])\n",
						"第 16017 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0024])\n",
						"第 16018 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0024])\n",
						"第 16019 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0024])\n",
						"第 16020 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0024])\n",
						"第 801 次epoch\n",
						"第 16021 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0024])\n",
						"第 16022 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0024])\n",
						"第 16023 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0024])\n",
						"第 16024 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0024])\n",
						"第 16025 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0024])\n",
						"第 16026 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0024])\n",
						"第 16027 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0024])\n",
						"第 16028 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0024])\n",
						"第 16029 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0024])\n",
						"第 16030 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0024])\n",
						"第 16031 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0024])\n",
						"第 16032 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16033 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0024])\n",
						"第 16034 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0024])\n",
						"第 16035 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16036 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0024])\n",
						"第 16037 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0024])\n",
						"第 16038 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16039 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16040 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0024])\n",
						"第 802 次epoch\n",
						"第 16041 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16042 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16043 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16044 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16045 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16046 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16047 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16048 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16049 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16050 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16051 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16052 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16053 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16054 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16055 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16056 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16057 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16058 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16059 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16060 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 803 次epoch\n",
						"第 16061 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16062 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16063 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16064 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16065 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16066 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16067 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16068 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16069 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16070 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16071 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16072 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16073 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16074 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16075 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16076 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16077 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16078 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16079 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16080 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 804 次epoch\n",
						"第 16081 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16082 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16083 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16084 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16085 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16086 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16087 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16088 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16089 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16090 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16091 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16092 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16093 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16094 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16095 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16096 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16097 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16098 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16099 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16100 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 805 次epoch\n",
						"第 16101 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16102 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16103 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16104 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16105 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16106 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16107 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16108 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16109 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16110 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16111 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16112 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16113 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16114 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16115 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16116 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16117 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16118 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16119 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16120 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 806 次epoch\n",
						"第 16121 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16122 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16123 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16124 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16125 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16126 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16127 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16128 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16129 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16130 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16131 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16132 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16133 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16134 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16135 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16136 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16137 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16138 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16139 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16140 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 807 次epoch\n",
						"第 16141 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16142 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16143 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16144 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16145 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16146 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16147 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16148 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16149 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16150 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16151 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16152 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16153 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16154 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16155 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16156 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16157 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16158 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0023])\n",
						"第 16159 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16160 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 808 次epoch\n",
						"第 16161 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16162 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16163 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16164 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16165 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16166 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16167 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16168 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16169 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16170 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16171 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16172 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16173 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16174 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16175 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16176 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16177 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16178 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16179 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16180 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 809 次epoch\n",
						"第 16181 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16182 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16183 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16184 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16185 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16186 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16187 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16188 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16189 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16190 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16191 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16192 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16193 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16194 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16195 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16196 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16197 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16198 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16199 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16200 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 810 次epoch\n",
						"第 16201 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16202 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16203 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16204 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16205 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16206 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16207 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16208 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16209 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16210 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16211 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16212 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16213 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16214 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16215 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16216 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16217 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16218 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16219 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16220 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 811 次epoch\n",
						"第 16221 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16222 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16223 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16224 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16225 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16226 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16227 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16228 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16229 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16230 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16231 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16232 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16233 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16234 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16235 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16236 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16237 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16238 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16239 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16240 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 812 次epoch\n",
						"第 16241 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16242 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16243 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16244 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16245 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16246 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16247 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16248 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16249 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16250 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16251 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16252 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16253 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16254 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16255 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16256 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16257 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16258 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16259 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16260 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 813 次epoch\n",
						"第 16261 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16262 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16263 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16264 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16265 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16266 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16267 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16268 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16269 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16270 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16271 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16272 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16273 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16274 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16275 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16276 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16277 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16278 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16279 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0022])\n",
						"第 16280 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 814 次epoch\n",
						"第 16281 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16282 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16283 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16284 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16285 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16286 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16287 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16288 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16289 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16290 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16291 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16292 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16293 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16294 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16295 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16296 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16297 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16298 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16299 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16300 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 815 次epoch\n",
						"第 16301 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16302 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16303 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16304 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16305 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16306 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16307 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16308 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16309 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16310 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16311 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16312 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16313 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16314 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16315 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16316 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16317 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16318 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16319 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16320 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 816 次epoch\n",
						"第 16321 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16322 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16323 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16324 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16325 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16326 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16327 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16328 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16329 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16330 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16331 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16332 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16333 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16334 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16335 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16336 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16337 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16338 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16339 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16340 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 817 次epoch\n",
						"第 16341 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16342 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16343 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16344 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16345 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16346 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16347 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16348 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16349 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16350 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16351 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16352 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16353 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16354 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16355 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16356 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16357 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16358 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16359 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16360 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 818 次epoch\n",
						"第 16361 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16362 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16363 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16364 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16365 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16366 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16367 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16368 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16369 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16370 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16371 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16372 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16373 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16374 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16375 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16376 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16377 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16378 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16379 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16380 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 819 次epoch\n",
						"第 16381 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16382 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16383 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16384 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16385 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16386 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16387 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16388 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16389 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16390 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16391 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16392 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16393 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16394 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16395 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16396 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16397 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16398 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 16399 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16400 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0021])\n",
						"第 820 次epoch\n",
						"第 16401 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16402 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16403 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16404 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16405 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16406 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16407 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16408 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16409 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16410 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16411 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16412 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16413 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16414 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16415 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16416 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16417 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16418 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16419 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16420 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 821 次epoch\n",
						"第 16421 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16422 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16423 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16424 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16425 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16426 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16427 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16428 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16429 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16430 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16431 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16432 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16433 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16434 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16435 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16436 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16437 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16438 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16439 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16440 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 822 次epoch\n",
						"第 16441 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16442 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16443 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16444 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16445 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16446 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16447 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16448 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16449 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16450 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16451 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16452 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16453 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16454 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16455 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16456 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16457 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16458 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16459 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16460 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 823 次epoch\n",
						"第 16461 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16462 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16463 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16464 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16465 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16466 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16467 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16468 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16469 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16470 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16471 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16472 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16473 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16474 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16475 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16476 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16477 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16478 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16479 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16480 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 824 次epoch\n",
						"第 16481 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16482 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16483 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16484 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16485 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16486 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16487 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16488 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16489 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16490 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16491 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16492 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16493 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16494 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16495 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16496 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16497 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16498 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16499 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16500 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 825 次epoch\n",
						"第 16501 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16502 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16503 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16504 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16505 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16506 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16507 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16508 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16509 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16510 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16511 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16512 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16513 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16514 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16515 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16516 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16517 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16518 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16519 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16520 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 826 次epoch\n",
						"第 16521 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0020])\n",
						"第 16522 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16523 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16524 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16525 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16526 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16527 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16528 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16529 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16530 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16531 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16532 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16533 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16534 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16535 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16536 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16537 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16538 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16539 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16540 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 827 次epoch\n",
						"第 16541 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16542 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16543 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16544 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16545 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16546 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16547 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16548 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16549 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16550 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16551 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16552 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16553 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16554 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16555 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16556 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16557 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16558 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16559 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16560 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 828 次epoch\n",
						"第 16561 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16562 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16563 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16564 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16565 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16566 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16567 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16568 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16569 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16570 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16571 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16572 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16573 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16574 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16575 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16576 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16577 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16578 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16579 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16580 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 829 次epoch\n",
						"第 16581 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16582 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16583 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16584 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16585 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16586 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16587 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16588 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16589 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16590 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16591 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16592 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16593 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16594 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16595 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16596 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16597 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16598 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16599 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16600 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 830 次epoch\n",
						"第 16601 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16602 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16603 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16604 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16605 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16606 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16607 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16608 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16609 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16610 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16611 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16612 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16613 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16614 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16615 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16616 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16617 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16618 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16619 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16620 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 831 次epoch\n",
						"第 16621 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16622 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16623 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16624 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16625 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16626 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16627 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16628 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16629 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16630 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16631 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16632 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16633 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16634 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16635 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16636 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16637 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16638 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16639 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16640 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 832 次epoch\n",
						"第 16641 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16642 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0019])\n",
						"第 16643 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16644 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16645 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16646 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16647 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16648 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16649 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16650 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16651 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16652 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16653 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16654 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16655 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16656 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16657 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16658 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16659 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16660 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 833 次epoch\n",
						"第 16661 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16662 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16663 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16664 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16665 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16666 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16667 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16668 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16669 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16670 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16671 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16672 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16673 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16674 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16675 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16676 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16677 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16678 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16679 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16680 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 834 次epoch\n",
						"第 16681 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16682 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16683 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16684 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16685 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16686 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16687 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16688 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16689 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16690 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16691 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16692 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16693 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16694 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16695 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16696 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16697 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16698 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16699 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16700 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 835 次epoch\n",
						"第 16701 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16702 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16703 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16704 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16705 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16706 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16707 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16708 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16709 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16710 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16711 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16712 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16713 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16714 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16715 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16716 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16717 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16718 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16719 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16720 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 836 次epoch\n",
						"第 16721 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16722 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16723 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16724 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16725 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16726 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16727 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16728 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16729 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16730 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16731 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16732 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16733 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16734 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16735 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16736 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16737 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16738 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16739 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16740 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 837 次epoch\n",
						"第 16741 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16742 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16743 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16744 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16745 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16746 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16747 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16748 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16749 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16750 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16751 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16752 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16753 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16754 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16755 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16756 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16757 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16758 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16759 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16760 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 838 次epoch\n",
						"第 16761 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16762 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16763 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0018])\n",
						"第 16764 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16765 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16766 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16767 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16768 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16769 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16770 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16771 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16772 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16773 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16774 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16775 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16776 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16777 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16778 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16779 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16780 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 839 次epoch\n",
						"第 16781 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16782 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16783 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16784 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16785 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16786 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16787 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16788 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16789 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16790 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16791 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16792 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16793 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16794 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16795 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16796 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16797 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16798 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16799 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16800 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 840 次epoch\n",
						"第 16801 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16802 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16803 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16804 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16805 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16806 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16807 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16808 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16809 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16810 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16811 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16812 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16813 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16814 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16815 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16816 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16817 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16818 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16819 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16820 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 841 次epoch\n",
						"第 16821 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16822 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16823 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16824 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16825 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16826 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16827 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16828 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16829 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16830 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16831 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16832 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16833 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16834 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16835 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16836 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16837 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16838 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16839 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16840 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 842 次epoch\n",
						"第 16841 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16842 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16843 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16844 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16845 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16846 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16847 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16848 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16849 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16850 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16851 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16852 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16853 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16854 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16855 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16856 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16857 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16858 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16859 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16860 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 843 次epoch\n",
						"第 16861 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16862 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16863 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16864 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16865 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16866 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16867 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16868 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16869 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16870 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16871 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16872 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16873 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16874 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16875 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16876 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16877 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16878 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16879 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16880 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 844 次epoch\n",
						"第 16881 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0017])\n",
						"第 16882 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16883 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16884 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16885 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16886 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16887 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16888 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16889 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16890 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16891 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16892 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16893 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16894 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16895 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16896 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16897 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16898 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16899 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16900 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 845 次epoch\n",
						"第 16901 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16902 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16903 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16904 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16905 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16906 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16907 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16908 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16909 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16910 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16911 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16912 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16913 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16914 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16915 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16916 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16917 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16918 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16919 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16920 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 846 次epoch\n",
						"第 16921 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16922 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16923 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16924 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16925 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16926 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16927 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16928 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16929 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16930 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16931 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16932 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16933 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16934 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16935 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16936 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16937 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16938 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16939 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16940 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 847 次epoch\n",
						"第 16941 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16942 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16943 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16944 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16945 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16946 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16947 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16948 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16949 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16950 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16951 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16952 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16953 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16954 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16955 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16956 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16957 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16958 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16959 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16960 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 848 次epoch\n",
						"第 16961 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16962 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16963 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16964 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16965 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16966 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16967 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16968 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16969 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16970 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16971 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16972 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16973 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16974 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16975 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16976 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16977 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16978 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16979 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16980 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 849 次epoch\n",
						"第 16981 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16982 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16983 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16984 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16985 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16986 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16987 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16988 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16989 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16990 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16991 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16992 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16993 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16994 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16995 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16996 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16997 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 16998 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 16999 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 17000 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 850 次epoch\n",
						"第 17001 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17002 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0016])\n",
						"第 17003 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17004 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17005 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17006 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17007 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17008 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17009 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17010 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17011 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17012 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17013 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17014 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17015 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17016 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17017 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17018 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17019 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17020 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 851 次epoch\n",
						"第 17021 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17022 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17023 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17024 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17025 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17026 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17027 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17028 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17029 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17030 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17031 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17032 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17033 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17034 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17035 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17036 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17037 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17038 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17039 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17040 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 852 次epoch\n",
						"第 17041 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17042 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17043 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17044 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17045 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17046 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17047 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17048 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17049 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17050 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17051 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17052 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17053 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17054 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17055 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17056 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17057 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17058 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17059 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17060 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 853 次epoch\n",
						"第 17061 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17062 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17063 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17064 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17065 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17066 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17067 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17068 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17069 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17070 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17071 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17072 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17073 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17074 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17075 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17076 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17077 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17078 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17079 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17080 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 854 次epoch\n",
						"第 17081 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17082 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17083 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17084 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17085 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17086 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17087 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17088 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17089 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17090 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17091 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17092 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17093 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17094 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17095 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17096 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17097 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17098 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17099 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17100 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 855 次epoch\n",
						"第 17101 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17102 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17103 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17104 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17105 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17106 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17107 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17108 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17109 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17110 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17111 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17112 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17113 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17114 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17115 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17116 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17117 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17118 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17119 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17120 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 856 次epoch\n",
						"第 17121 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0015])\n",
						"第 17122 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17123 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17124 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17125 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17126 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17127 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17128 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17129 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17130 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17131 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17132 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17133 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17134 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17135 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17136 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17137 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17138 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17139 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17140 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 857 次epoch\n",
						"第 17141 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17142 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17143 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17144 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17145 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17146 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17147 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17148 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17149 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17150 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17151 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17152 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17153 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17154 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17155 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17156 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17157 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17158 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17159 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17160 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 858 次epoch\n",
						"第 17161 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17162 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17163 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17164 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17165 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17166 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17167 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17168 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17169 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17170 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17171 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17172 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17173 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17174 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17175 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17176 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17177 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17178 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17179 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17180 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 859 次epoch\n",
						"第 17181 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17182 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17183 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17184 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17185 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17186 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17187 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17188 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17189 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17190 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17191 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17192 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17193 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17194 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17195 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17196 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17197 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17198 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17199 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17200 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 860 次epoch\n",
						"第 17201 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17202 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17203 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17204 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17205 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17206 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17207 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17208 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17209 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17210 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17211 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17212 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17213 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17214 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17215 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17216 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17217 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17218 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17219 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17220 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 861 次epoch\n",
						"第 17221 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17222 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17223 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17224 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17225 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17226 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17227 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17228 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17229 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17230 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17231 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17232 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17233 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17234 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17235 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17236 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17237 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17238 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17239 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17240 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 862 次epoch\n",
						"第 17241 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17242 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17243 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17244 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17245 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17246 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17247 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17248 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17249 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17250 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17251 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17252 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17253 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17254 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17255 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17256 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17257 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17258 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17259 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17260 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 863 次epoch\n",
						"第 17261 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17262 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17263 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17264 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17265 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17266 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17267 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17268 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17269 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17270 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17271 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17272 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17273 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17274 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17275 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17276 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17277 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17278 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17279 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17280 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 864 次epoch\n",
						"第 17281 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17282 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17283 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17284 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17285 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17286 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17287 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17288 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17289 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17290 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17291 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17292 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17293 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17294 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17295 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17296 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17297 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17298 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17299 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17300 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 865 次epoch\n",
						"第 17301 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17302 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17303 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17304 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17305 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17306 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17307 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17308 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17309 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17310 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17311 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17312 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17313 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17314 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17315 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17316 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17317 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17318 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17319 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17320 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 866 次epoch\n",
						"第 17321 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17322 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17323 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17324 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17325 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17326 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17327 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17328 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17329 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17330 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17331 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17332 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17333 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17334 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17335 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17336 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17337 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17338 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17339 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17340 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 867 次epoch\n",
						"第 17341 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17342 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17343 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17344 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0014])\n",
						"第 17345 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17346 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17347 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17348 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17349 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17350 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17351 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17352 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17353 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17354 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17355 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17356 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17357 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17358 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17359 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17360 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 868 次epoch\n",
						"第 17361 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17362 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17363 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17364 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17365 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17366 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17367 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17368 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17369 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17370 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17371 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17372 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17373 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17374 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17375 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17376 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17377 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17378 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17379 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17380 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 869 次epoch\n",
						"第 17381 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17382 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17383 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17384 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17385 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17386 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17387 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17388 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17389 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17390 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17391 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17392 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17393 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17394 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17395 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17396 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17397 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17398 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17399 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17400 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 870 次epoch\n",
						"第 17401 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17402 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17403 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17404 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17405 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17406 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17407 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17408 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17409 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17410 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17411 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17412 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17413 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17414 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17415 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17416 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17417 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17418 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17419 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17420 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 871 次epoch\n",
						"第 17421 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17422 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17423 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17424 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17425 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17426 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17427 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17428 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17429 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17430 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17431 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17432 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17433 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17434 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17435 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17436 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17437 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17438 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17439 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17440 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 872 次epoch\n",
						"第 17441 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17442 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17443 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17444 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17445 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17446 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17447 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17448 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17449 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17450 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17451 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17452 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17453 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17454 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17455 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17456 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17457 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17458 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17459 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17460 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 873 次epoch\n",
						"第 17461 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17462 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17463 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17464 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17465 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17466 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17467 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17468 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17469 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17470 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17471 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17472 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17473 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17474 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17475 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17476 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17477 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17478 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17479 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17480 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 874 次epoch\n",
						"第 17481 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17482 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17483 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17484 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17485 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17486 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17487 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17488 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17489 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17490 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17491 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17492 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17493 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17494 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17495 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17496 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17497 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17498 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17499 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17500 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 875 次epoch\n",
						"第 17501 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17502 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17503 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17504 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17505 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17506 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17507 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17508 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17509 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17510 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17511 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17512 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17513 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17514 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17515 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17516 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17517 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17518 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17519 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17520 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 876 次epoch\n",
						"第 17521 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17522 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17523 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17524 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17525 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17526 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17527 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17528 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17529 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17530 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17531 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17532 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17533 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17534 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17535 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17536 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17537 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17538 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17539 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17540 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 877 次epoch\n",
						"第 17541 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17542 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17543 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17544 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17545 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17546 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17547 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17548 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17549 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17550 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17551 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17552 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17553 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17554 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17555 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17556 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17557 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17558 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17559 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17560 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 878 次epoch\n",
						"第 17561 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17562 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17563 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17564 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17565 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17566 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17567 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17568 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17569 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17570 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17571 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17572 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17573 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17574 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17575 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17576 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17577 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17578 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17579 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17580 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 879 次epoch\n",
						"第 17581 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17582 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17583 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17584 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17585 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17586 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17587 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17588 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17589 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17590 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17591 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0013])\n",
						"第 17592 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17593 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17594 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17595 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17596 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17597 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17598 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17599 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17600 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 880 次epoch\n",
						"第 17601 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17602 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17603 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17604 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17605 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17606 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17607 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17608 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17609 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17610 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17611 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17612 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17613 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17614 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17615 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17616 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17617 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17618 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17619 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17620 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 881 次epoch\n",
						"第 17621 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17622 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17623 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17624 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17625 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17626 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17627 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17628 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17629 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17630 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17631 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17632 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17633 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17634 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17635 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17636 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17637 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17638 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17639 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17640 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 882 次epoch\n",
						"第 17641 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17642 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17643 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17644 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17645 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17646 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17647 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17648 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17649 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17650 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17651 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17652 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17653 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17654 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17655 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17656 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17657 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17658 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17659 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17660 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 883 次epoch\n",
						"第 17661 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17662 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17663 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17664 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17665 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17666 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17667 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17668 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17669 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17670 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17671 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17672 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17673 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17674 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17675 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17676 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17677 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17678 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17679 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17680 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 884 次epoch\n",
						"第 17681 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17682 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17683 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17684 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17685 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17686 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17687 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17688 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17689 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17690 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17691 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17692 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17693 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17694 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17695 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17696 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17697 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17698 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17699 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17700 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 885 次epoch\n",
						"第 17701 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17702 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17703 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17704 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17705 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17706 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17707 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17708 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17709 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17710 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17711 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17712 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17713 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17714 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17715 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17716 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17717 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17718 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17719 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17720 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 886 次epoch\n",
						"第 17721 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17722 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17723 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17724 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17725 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17726 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17727 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17728 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17729 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17730 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17731 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17732 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17733 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17734 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17735 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17736 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17737 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17738 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17739 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17740 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 887 次epoch\n",
						"第 17741 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17742 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17743 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17744 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17745 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17746 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17747 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17748 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17749 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17750 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17751 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17752 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17753 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17754 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17755 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17756 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17757 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17758 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17759 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17760 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 888 次epoch\n",
						"第 17761 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17762 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17763 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17764 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17765 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17766 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17767 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17768 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17769 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17770 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17771 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17772 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17773 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17774 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17775 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17776 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17777 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17778 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17779 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17780 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 889 次epoch\n",
						"第 17781 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17782 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17783 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17784 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17785 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17786 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17787 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17788 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17789 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17790 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17791 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17792 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17793 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17794 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17795 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17796 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17797 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17798 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17799 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17800 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 890 次epoch\n",
						"第 17801 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17802 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17803 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17804 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17805 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17806 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17807 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17808 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17809 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17810 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17811 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17812 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17813 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17814 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17815 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17816 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17817 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17818 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17819 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17820 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 891 次epoch\n",
						"第 17821 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17822 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17823 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17824 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17825 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17826 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17827 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17828 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0012])\n",
						"第 17829 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17830 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17831 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17832 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17833 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17834 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17835 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17836 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17837 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17838 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17839 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17840 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 892 次epoch\n",
						"第 17841 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17842 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17843 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17844 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17845 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17846 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17847 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17848 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17849 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17850 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17851 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17852 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17853 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17854 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17855 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17856 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17857 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17858 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17859 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17860 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 893 次epoch\n",
						"第 17861 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17862 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17863 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17864 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17865 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17866 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17867 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17868 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17869 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17870 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17871 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17872 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17873 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17874 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17875 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17876 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17877 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17878 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17879 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17880 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 894 次epoch\n",
						"第 17881 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17882 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17883 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17884 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17885 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17886 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17887 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17888 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17889 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17890 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17891 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17892 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17893 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17894 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17895 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17896 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17897 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17898 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17899 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17900 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 895 次epoch\n",
						"第 17901 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17902 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17903 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17904 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17905 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17906 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17907 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17908 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17909 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17910 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17911 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17912 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17913 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17914 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17915 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17916 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17917 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17918 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17919 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17920 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 896 次epoch\n",
						"第 17921 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17922 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17923 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17924 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17925 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17926 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17927 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17928 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17929 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17930 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17931 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17932 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17933 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17934 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17935 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17936 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17937 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17938 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17939 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17940 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 897 次epoch\n",
						"第 17941 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17942 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17943 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17944 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17945 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17946 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17947 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17948 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17949 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17950 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17951 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17952 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17953 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17954 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17955 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17956 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17957 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17958 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17959 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17960 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 898 次epoch\n",
						"第 17961 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17962 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17963 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17964 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17965 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17966 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17967 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17968 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17969 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17970 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17971 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17972 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17973 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17974 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17975 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17976 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17977 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17978 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17979 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17980 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 899 次epoch\n",
						"第 17981 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17982 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17983 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17984 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17985 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17986 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17987 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17988 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17989 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17990 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17991 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17992 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17993 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17994 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17995 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17996 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17997 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17998 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 17999 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 18000 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 900 次epoch\n",
						"第 18001 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 18002 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 18003 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 18004 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 18005 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 18006 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 18007 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 18008 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 18009 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 18010 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 18011 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 18012 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 18013 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 18014 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 18015 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 18016 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 18017 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 18018 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 18019 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 18020 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 901 次epoch\n",
						"第 18021 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 18022 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 18023 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 18024 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 18025 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 18026 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 18027 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 18028 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 18029 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 18030 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 18031 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 18032 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 18033 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 18034 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 18035 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 18036 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 18037 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 18038 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 18039 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 18040 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 902 次epoch\n",
						"第 18041 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 18042 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 18043 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 18044 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 18045 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 18046 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 18047 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 18048 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 18049 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 18050 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 18051 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 18052 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 18053 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 18054 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18055 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 18056 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 18057 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 18058 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 18059 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 18060 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 903 次epoch\n",
						"第 18061 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 18062 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 18063 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 18064 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 18065 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 18066 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18067 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18068 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18069 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 18070 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0011])\n",
						"第 18071 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18072 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18073 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18074 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18075 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18076 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18077 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18078 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18079 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18080 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 904 次epoch\n",
						"第 18081 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18082 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18083 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18084 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18085 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18086 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18087 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18088 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18089 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18090 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18091 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18092 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18093 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18094 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18095 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18096 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18097 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18098 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18099 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18100 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 905 次epoch\n",
						"第 18101 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18102 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18103 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18104 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18105 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18106 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18107 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18108 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18109 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18110 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18111 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18112 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18113 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18114 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18115 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18116 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18117 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18118 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18119 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18120 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 906 次epoch\n",
						"第 18121 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18122 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18123 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18124 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18125 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18126 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18127 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18128 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18129 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18130 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18131 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18132 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18133 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18134 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18135 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18136 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18137 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18138 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18139 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18140 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 907 次epoch\n",
						"第 18141 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18142 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18143 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18144 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18145 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18146 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18147 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18148 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18149 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18150 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18151 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18152 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18153 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18154 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18155 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18156 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18157 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18158 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18159 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18160 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 908 次epoch\n",
						"第 18161 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18162 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18163 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18164 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18165 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18166 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18167 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18168 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18169 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18170 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18171 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18172 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18173 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18174 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18175 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18176 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18177 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18178 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18179 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18180 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 909 次epoch\n",
						"第 18181 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18182 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18183 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18184 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18185 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18186 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18187 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18188 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18189 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18190 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18191 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18192 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18193 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18194 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18195 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18196 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18197 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18198 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18199 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18200 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 910 次epoch\n",
						"第 18201 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18202 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18203 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18204 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18205 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18206 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18207 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18208 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18209 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18210 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18211 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18212 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18213 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18214 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18215 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18216 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18217 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18218 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18219 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18220 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 911 次epoch\n",
						"第 18221 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18222 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18223 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18224 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18225 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18226 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18227 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18228 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18229 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18230 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18231 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18232 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18233 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18234 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18235 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18236 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18237 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18238 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18239 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18240 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 912 次epoch\n",
						"第 18241 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18242 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18243 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18244 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18245 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18246 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18247 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18248 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18249 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18250 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18251 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18252 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18253 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18254 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18255 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18256 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18257 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18258 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18259 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18260 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 913 次epoch\n",
						"第 18261 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18262 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18263 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18264 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18265 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18266 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18267 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18268 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18269 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18270 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18271 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18272 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18273 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18274 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18275 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18276 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18277 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18278 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18279 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18280 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 914 次epoch\n",
						"第 18281 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18282 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18283 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18284 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18285 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18286 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18287 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18288 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18289 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18290 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18291 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18292 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18293 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18294 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18295 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18296 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18297 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18298 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18299 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18300 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 915 次epoch\n",
						"第 18301 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18302 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18303 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18304 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18305 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18306 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18307 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18308 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18309 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18310 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18311 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18312 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0010])\n",
						"第 18313 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18314 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18315 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18316 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18317 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18318 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18319 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18320 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 916 次epoch\n",
						"第 18321 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18322 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18323 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18324 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18325 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18326 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18327 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18328 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18329 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18330 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18331 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18332 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18333 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18334 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18335 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18336 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18337 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18338 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18339 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18340 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 917 次epoch\n",
						"第 18341 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18342 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18343 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18344 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18345 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18346 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18347 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18348 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18349 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18350 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18351 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18352 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18353 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18354 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18355 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18356 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18357 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18358 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18359 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18360 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 918 次epoch\n",
						"第 18361 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18362 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18363 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18364 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18365 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18366 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18367 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18368 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18369 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18370 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18371 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18372 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18373 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18374 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18375 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18376 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18377 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18378 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18379 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18380 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 919 次epoch\n",
						"第 18381 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18382 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18383 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18384 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18385 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18386 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18387 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18388 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18389 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18390 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18391 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18392 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18393 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18394 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18395 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18396 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18397 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18398 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18399 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18400 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 920 次epoch\n",
						"第 18401 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18402 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18403 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18404 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18405 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18406 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18407 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18408 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18409 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18410 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18411 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18412 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18413 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18414 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18415 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18416 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18417 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18418 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18419 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18420 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 921 次epoch\n",
						"第 18421 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18422 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18423 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18424 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18425 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18426 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18427 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18428 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18429 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18430 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18431 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18432 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18433 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18434 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18435 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18436 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18437 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18438 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18439 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18440 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 922 次epoch\n",
						"第 18441 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18442 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18443 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18444 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18445 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18446 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18447 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18448 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18449 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18450 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18451 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18452 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18453 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18454 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18455 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18456 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18457 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18458 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18459 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18460 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 923 次epoch\n",
						"第 18461 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18462 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18463 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18464 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18465 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18466 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18467 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18468 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18469 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18470 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18471 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18472 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18473 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18474 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18475 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18476 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18477 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18478 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18479 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18480 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 924 次epoch\n",
						"第 18481 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18482 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18483 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18484 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18485 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18486 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18487 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18488 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18489 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18490 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18491 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18492 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18493 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18494 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18495 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18496 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18497 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18498 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18499 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18500 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 925 次epoch\n",
						"第 18501 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18502 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18503 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18504 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18505 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18506 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18507 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18508 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18509 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18510 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18511 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18512 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18513 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18514 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18515 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18516 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18517 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18518 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18519 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18520 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 926 次epoch\n",
						"第 18521 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18522 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18523 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18524 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18525 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18526 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18527 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18528 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18529 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18530 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18531 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18532 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18533 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18534 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18535 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18536 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18537 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18538 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18539 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18540 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 927 次epoch\n",
						"第 18541 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18542 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18543 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18544 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18545 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18546 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18547 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18548 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18549 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18550 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18551 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18552 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18553 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18554 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0009])\n",
						"第 18555 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18556 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18557 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18558 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18559 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18560 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 928 次epoch\n",
						"第 18561 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18562 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18563 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18564 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18565 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18566 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18567 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18568 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18569 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18570 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18571 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18572 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18573 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18574 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18575 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18576 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18577 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18578 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18579 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18580 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 929 次epoch\n",
						"第 18581 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18582 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18583 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18584 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18585 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18586 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18587 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18588 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18589 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18590 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18591 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18592 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18593 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18594 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18595 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18596 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18597 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18598 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18599 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18600 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 930 次epoch\n",
						"第 18601 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18602 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18603 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18604 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18605 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18606 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18607 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18608 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18609 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18610 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18611 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18612 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18613 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18614 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18615 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18616 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18617 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18618 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18619 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18620 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 931 次epoch\n",
						"第 18621 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18622 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18623 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18624 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18625 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18626 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18627 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18628 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18629 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18630 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18631 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18632 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18633 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18634 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18635 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18636 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18637 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18638 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18639 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18640 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 932 次epoch\n",
						"第 18641 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18642 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18643 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18644 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18645 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18646 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18647 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18648 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18649 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18650 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18651 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18652 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18653 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18654 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18655 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18656 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18657 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18658 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18659 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18660 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 933 次epoch\n",
						"第 18661 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18662 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18663 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18664 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18665 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18666 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18667 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18668 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18669 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18670 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18671 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18672 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18673 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18674 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18675 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18676 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18677 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18678 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18679 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18680 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 934 次epoch\n",
						"第 18681 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18682 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18683 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18684 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18685 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18686 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18687 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18688 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18689 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18690 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18691 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18692 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18693 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18694 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18695 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18696 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18697 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18698 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18699 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18700 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 935 次epoch\n",
						"第 18701 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18702 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18703 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18704 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18705 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18706 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18707 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18708 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18709 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18710 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18711 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18712 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18713 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18714 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18715 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18716 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18717 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18718 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18719 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18720 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 936 次epoch\n",
						"第 18721 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18722 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18723 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18724 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18725 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18726 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18727 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18728 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18729 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18730 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18731 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18732 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18733 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18734 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18735 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18736 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18737 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18738 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18739 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18740 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 937 次epoch\n",
						"第 18741 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18742 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18743 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18744 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18745 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18746 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18747 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18748 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18749 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18750 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18751 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18752 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18753 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18754 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18755 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18756 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18757 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18758 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18759 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18760 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 938 次epoch\n",
						"第 18761 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18762 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18763 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18764 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18765 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18766 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18767 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18768 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18769 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18770 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18771 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18772 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18773 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18774 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18775 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18776 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18777 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18778 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18779 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18780 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 939 次epoch\n",
						"第 18781 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18782 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18783 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18784 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18785 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18786 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18787 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18788 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18789 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18790 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0008])\n",
						"第 18791 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18792 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18793 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18794 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18795 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18796 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18797 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18798 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18799 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18800 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 940 次epoch\n",
						"第 18801 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18802 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18803 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18804 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18805 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18806 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18807 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18808 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18809 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18810 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18811 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18812 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18813 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18814 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18815 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18816 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18817 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18818 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18819 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18820 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 941 次epoch\n",
						"第 18821 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18822 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18823 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18824 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18825 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18826 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18827 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18828 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18829 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18830 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18831 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18832 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18833 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18834 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18835 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18836 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18837 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18838 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18839 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18840 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 942 次epoch\n",
						"第 18841 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18842 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18843 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18844 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18845 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18846 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18847 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18848 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18849 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18850 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18851 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18852 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18853 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18854 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18855 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18856 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18857 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18858 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18859 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18860 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 943 次epoch\n",
						"第 18861 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18862 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18863 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18864 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18865 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18866 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18867 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18868 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18869 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18870 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18871 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18872 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18873 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18874 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18875 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18876 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18877 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18878 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18879 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18880 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 944 次epoch\n",
						"第 18881 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18882 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18883 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18884 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18885 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18886 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18887 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18888 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18889 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18890 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18891 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18892 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18893 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18894 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18895 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18896 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18897 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18898 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18899 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18900 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 945 次epoch\n",
						"第 18901 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18902 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18903 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18904 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18905 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18906 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18907 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18908 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18909 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18910 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18911 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18912 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18913 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18914 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18915 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18916 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18917 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18918 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18919 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18920 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 946 次epoch\n",
						"第 18921 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18922 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18923 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18924 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18925 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18926 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18927 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18928 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18929 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18930 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18931 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18932 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18933 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18934 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18935 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18936 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18937 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18938 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18939 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18940 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 947 次epoch\n",
						"第 18941 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18942 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18943 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18944 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18945 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18946 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18947 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18948 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18949 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18950 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18951 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18952 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18953 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18954 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18955 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18956 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18957 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18958 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18959 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18960 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 948 次epoch\n",
						"第 18961 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18962 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18963 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18964 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18965 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18966 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18967 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18968 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18969 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18970 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18971 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18972 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18973 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18974 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18975 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18976 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18977 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18978 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18979 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18980 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 949 次epoch\n",
						"第 18981 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18982 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18983 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18984 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18985 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18986 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18987 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18988 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18989 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18990 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18991 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18992 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18993 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18994 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18995 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18996 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18997 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18998 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 18999 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 19000 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 950 次epoch\n",
						"第 19001 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 19002 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 19003 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 19004 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 19005 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 19006 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 19007 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 19008 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 19009 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 19010 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 19011 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 19012 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 19013 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 19014 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 19015 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 19016 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 19017 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 19018 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 19019 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 19020 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 951 次epoch\n",
						"第 19021 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 19022 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19023 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 19024 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 19025 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 19026 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 19027 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19028 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19029 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19030 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 19031 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 19032 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 19033 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0007])\n",
						"第 19034 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19035 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19036 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19037 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19038 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19039 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19040 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 952 次epoch\n",
						"第 19041 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19042 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19043 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19044 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19045 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19046 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19047 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19048 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19049 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19050 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19051 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19052 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19053 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19054 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19055 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19056 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19057 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19058 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19059 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19060 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 953 次epoch\n",
						"第 19061 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19062 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19063 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19064 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19065 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19066 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19067 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19068 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19069 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19070 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19071 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19072 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19073 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19074 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19075 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19076 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19077 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19078 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19079 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19080 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 954 次epoch\n",
						"第 19081 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19082 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19083 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19084 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19085 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19086 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19087 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19088 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19089 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19090 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19091 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19092 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19093 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19094 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19095 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19096 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19097 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19098 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19099 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19100 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 955 次epoch\n",
						"第 19101 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19102 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19103 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19104 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19105 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19106 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19107 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19108 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19109 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19110 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19111 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19112 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19113 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19114 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19115 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19116 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19117 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19118 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19119 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19120 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 956 次epoch\n",
						"第 19121 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19122 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19123 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19124 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19125 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19126 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19127 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19128 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19129 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19130 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19131 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19132 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19133 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19134 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19135 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19136 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19137 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19138 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19139 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19140 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 957 次epoch\n",
						"第 19141 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19142 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19143 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19144 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19145 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19146 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19147 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19148 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19149 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19150 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19151 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19152 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19153 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19154 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19155 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19156 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19157 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19158 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19159 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19160 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 958 次epoch\n",
						"第 19161 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19162 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19163 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19164 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19165 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19166 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19167 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19168 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19169 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19170 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19171 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19172 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19173 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19174 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19175 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19176 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19177 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19178 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19179 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19180 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 959 次epoch\n",
						"第 19181 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19182 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19183 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19184 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19185 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19186 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19187 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19188 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19189 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19190 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19191 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19192 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19193 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19194 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19195 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19196 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19197 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19198 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19199 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19200 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 960 次epoch\n",
						"第 19201 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19202 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19203 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19204 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19205 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19206 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19207 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19208 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19209 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19210 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19211 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19212 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19213 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19214 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19215 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19216 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19217 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19218 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19219 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19220 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 961 次epoch\n",
						"第 19221 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19222 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19223 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19224 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19225 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19226 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19227 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19228 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19229 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19230 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19231 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19232 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19233 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19234 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19235 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19236 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19237 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19238 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19239 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19240 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 962 次epoch\n",
						"第 19241 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19242 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19243 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19244 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19245 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19246 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19247 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19248 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19249 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19250 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19251 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19252 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19253 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19254 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19255 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19256 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19257 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19258 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19259 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19260 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 963 次epoch\n",
						"第 19261 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19262 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19263 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19264 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19265 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19266 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19267 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19268 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19269 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19270 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19271 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19272 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19273 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19274 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 19275 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19276 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19277 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19278 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19279 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19280 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0006])\n",
						"第 964 次epoch\n",
						"第 19281 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19282 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19283 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19284 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19285 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19286 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19287 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19288 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19289 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19290 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19291 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19292 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19293 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19294 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19295 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19296 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19297 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19298 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19299 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19300 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 965 次epoch\n",
						"第 19301 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19302 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19303 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19304 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19305 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19306 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19307 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19308 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19309 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19310 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19311 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19312 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19313 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19314 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19315 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19316 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19317 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19318 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19319 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19320 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 966 次epoch\n",
						"第 19321 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19322 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19323 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19324 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19325 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19326 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19327 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19328 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19329 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19330 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19331 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19332 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19333 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19334 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19335 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19336 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19337 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19338 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19339 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19340 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 967 次epoch\n",
						"第 19341 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19342 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19343 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19344 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19345 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19346 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19347 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19348 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19349 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19350 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19351 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19352 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19353 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19354 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19355 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19356 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19357 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19358 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19359 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19360 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 968 次epoch\n",
						"第 19361 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19362 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19363 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19364 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19365 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19366 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19367 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19368 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19369 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19370 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19371 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19372 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19373 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19374 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19375 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19376 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19377 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19378 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19379 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19380 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 969 次epoch\n",
						"第 19381 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19382 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19383 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19384 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19385 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19386 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19387 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19388 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19389 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19390 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19391 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19392 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19393 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19394 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19395 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19396 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19397 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19398 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19399 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19400 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 970 次epoch\n",
						"第 19401 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19402 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19403 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19404 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19405 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19406 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19407 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19408 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19409 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19410 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19411 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19412 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19413 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19414 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19415 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19416 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19417 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19418 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19419 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19420 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 971 次epoch\n",
						"第 19421 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19422 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19423 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19424 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19425 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19426 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19427 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19428 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19429 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19430 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19431 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19432 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19433 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19434 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19435 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19436 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0010]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19437 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19438 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19439 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19440 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 972 次epoch\n",
						"第 19441 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19442 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19443 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19444 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19445 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19446 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19447 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19448 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19449 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19450 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19451 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19452 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19453 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19454 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19455 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19456 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19457 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19458 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19459 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19460 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 973 次epoch\n",
						"第 19461 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19462 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19463 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19464 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19465 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19466 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19467 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19468 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19469 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19470 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19471 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19472 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19473 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19474 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19475 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19476 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19477 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19478 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19479 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19480 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 974 次epoch\n",
						"第 19481 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19482 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19483 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19484 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19485 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19486 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19487 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19488 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19489 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19490 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19491 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19492 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19493 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19494 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19495 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19496 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19497 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19498 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19499 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19500 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 975 次epoch\n",
						"第 19501 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19502 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19503 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19504 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19505 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19506 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19507 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19508 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19509 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19510 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19511 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19512 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19513 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19514 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19515 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19516 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19517 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19518 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19519 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19520 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 976 次epoch\n",
						"第 19521 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19522 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19523 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19524 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19525 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19526 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19527 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19528 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19529 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19530 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19531 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19532 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19533 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19534 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19535 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19536 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19537 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19538 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19539 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19540 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 977 次epoch\n",
						"第 19541 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19542 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19543 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19544 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19545 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19546 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19547 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19548 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19549 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19550 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19551 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19552 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19553 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19554 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19555 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19556 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19557 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19558 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19559 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19560 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 978 次epoch\n",
						"第 19561 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19562 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19563 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19564 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19565 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19566 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19567 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19568 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19569 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19570 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19571 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19572 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19573 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19574 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19575 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19576 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19577 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19578 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19579 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19580 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 979 次epoch\n",
						"第 19581 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19582 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19583 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19584 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19585 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19586 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19587 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19588 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19589 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19590 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19591 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19592 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19593 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19594 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19595 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19596 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19597 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19598 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19599 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19600 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 980 次epoch\n",
						"第 19601 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19602 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19603 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19604 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19605 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19606 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19607 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19608 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19609 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19610 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19611 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19612 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19613 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19614 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19615 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19616 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19617 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19618 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19619 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19620 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 981 次epoch\n",
						"第 19621 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19622 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19623 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19624 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19625 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19626 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19627 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19628 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19629 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19630 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19631 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19632 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19633 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19634 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19635 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19636 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19637 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19638 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19639 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19640 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 982 次epoch\n",
						"第 19641 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19642 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19643 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19644 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19645 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19646 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19647 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19648 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19649 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19650 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19651 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19652 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19653 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19654 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19655 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19656 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19657 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19658 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19659 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19660 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 983 次epoch\n",
						"第 19661 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19662 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19663 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19664 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19665 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19666 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19667 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19668 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19669 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19670 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19671 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19672 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19673 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19674 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19675 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19676 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19677 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19678 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19679 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19680 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 984 次epoch\n",
						"第 19681 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19682 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19683 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19684 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19685 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19686 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19687 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19688 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19689 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19690 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19691 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19692 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19693 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19694 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19695 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19696 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19697 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19698 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19699 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19700 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 985 次epoch\n",
						"第 19701 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19702 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19703 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19704 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19705 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19706 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19707 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19708 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19709 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19710 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19711 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19712 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19713 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19714 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19715 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19716 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19717 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19718 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19719 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19720 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 986 次epoch\n",
						"第 19721 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19722 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19723 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19724 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19725 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19726 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19727 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19728 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19729 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19730 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19731 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19732 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19733 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19734 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19735 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19736 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19737 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19738 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19739 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19740 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 987 次epoch\n",
						"第 19741 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19742 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19743 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19744 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19745 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19746 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19747 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19748 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19749 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19750 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19751 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19752 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19753 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19754 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19755 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19756 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19757 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19758 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19759 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19760 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 988 次epoch\n",
						"第 19761 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19762 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19763 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19764 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19765 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19766 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19767 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19768 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19769 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19770 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19771 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19772 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19773 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19774 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19775 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19776 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19777 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19778 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19779 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19780 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 989 次epoch\n",
						"第 19781 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19782 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19783 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19784 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19785 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19786 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19787 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19788 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19789 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19790 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19791 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19792 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19793 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19794 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19795 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19796 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19797 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19798 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19799 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19800 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 990 次epoch\n",
						"第 19801 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19802 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19803 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19804 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19805 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19806 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19807 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19808 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19809 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19810 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19811 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19812 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19813 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19814 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19815 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19816 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19817 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19818 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19819 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19820 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 991 次epoch\n",
						"第 19821 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19822 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19823 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19824 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19825 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19826 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19827 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19828 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19829 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19830 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19831 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19832 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19833 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19834 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19835 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19836 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19837 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19838 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19839 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19840 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 992 次epoch\n",
						"第 19841 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19842 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19843 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19844 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19845 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19846 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19847 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19848 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19849 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19850 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19851 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19852 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19853 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19854 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19855 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19856 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19857 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19858 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19859 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19860 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 993 次epoch\n",
						"第 19861 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19862 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19863 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19864 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19865 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19866 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19867 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19868 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19869 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19870 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19871 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19872 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19873 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19874 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19875 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19876 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19877 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19878 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19879 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19880 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 994 次epoch\n",
						"第 19881 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19882 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19883 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19884 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19885 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19886 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19887 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19888 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19889 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19890 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19891 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19892 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19893 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19894 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19895 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19896 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19897 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19898 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19899 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19900 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 995 次epoch\n",
						"第 19901 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19902 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19903 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19904 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19905 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19906 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19907 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19908 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19909 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19910 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19911 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19912 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19913 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19914 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19915 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19916 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19917 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19918 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19919 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19920 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 996 次epoch\n",
						"第 19921 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19922 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19923 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19924 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19925 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19926 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19927 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19928 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19929 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19930 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19931 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19932 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19933 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19934 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19935 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19936 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19937 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19938 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19939 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19940 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 997 次epoch\n",
						"第 19941 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19942 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19943 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19944 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19945 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19946 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19947 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19948 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19949 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19950 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19951 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19952 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19953 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19954 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19955 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19956 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19957 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19958 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19959 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19960 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 998 次epoch\n",
						"第 19961 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19962 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19963 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19964 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19965 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19966 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19967 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19968 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19969 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19970 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19971 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19972 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19973 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19974 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19975 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19976 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19977 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19978 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19979 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19980 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 999 次epoch\n",
						"第 19981 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19982 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19983 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19984 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19985 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19986 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19987 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19988 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19989 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19990 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19991 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19992 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19993 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19994 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19995 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19996 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19997 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19998 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 19999 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"第 20000 次梯度下降后\n",
						"模型中权参梯度： tensor([[0.0009]])\n",
						"模型中偏参梯度 tensor([-0.0005])\n",
						"优化后得到权参、偏参分别为： [('weight', Parameter containing:\n",
						"tensor([[16.2073]], requires_grad=True)), ('bias', Parameter containing:\n",
						"tensor([8.5219], requires_grad=True))]\n"
					]
				},
				{
					"data": {
						"image/png": "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",
						"text/plain": [
							"<Figure size 640x480 with 1 Axes>"
						]
					},
					"metadata": {},
					"output_type": "display_data"
				}
			],
			"source": [
				"import torch as t \n",
				"import numpy as np\n",
				"import pandas as pd\n",
				"import matplotlib.pyplot as plt\n",
				"from torch import nn\n",
				"class LinerModel(nn.Module):\n",
				"    def __init__(self):\n",
				"        super(LinerModel, self).__init__()\n",
				"        self.linear=nn.Linear(in_features=1,out_features=1)\n",
				"        self.weight=self.linear.weight\n",
				"        self.bias=self.linear.bias\n",
				"    \n",
				"    def forward(self,x):\n",
				"        return self.linear(x)\n",
				"    \n",
				"    def getParamters(self):\n",
				"        return self.weight,self.bias\n",
				"if  __name__ == '__main__':\n",
				"    \n",
				" \n",
				"\n",
				"    #plt.scatter(x,y)\n",
				"    x_t=t.tensor([[0.50,0.75,1.00,1.25,1.50,1.75,1.75,2.00,2.25,2.50,2.75,3.00,3.25,3.50,4.00,4.25,4.50,4.75,5.00,5.50]]).T\n",
				"    print('初始的tensor，x_t的shape：',x_t.shape)\n",
				"    y_t=t.tensor([[10,  22,  13,  43,  20,  22,  33,  50,  62, 48,  55,  75,  62,  73,  81,  76,  64,  82,  90,  93]]).T\n",
				"    print('初始的tensor,y_t的shape：',y_t.shape)\n",
				"    \n",
				"    x_n=x_t.numpy().T\n",
				"    y_n=y_t.numpy().T\n",
				"    plt.scatter(x_n,y_n)\n",
				"    print(\"numpy转换后的数据x_n,shape\",x_n.shape,'变成了一个元组')\n",
				"    print(\"numpy转换后的数据y_n,shape\",y_n.shape,'变成了一个元组')\n",
				"    linear_module=LinerModel()\n",
				"    y_pred=linear_module.forward(x_t)\n",
				"    print(\"通过一次forwad后得到y predict，其形状是\",y_pred.shape)  \n",
				"    weight,bias=linear_module.getParamters()#获得模型的权参、偏参\n",
				"    print(\"模型中参数：\",linear_module.parameters())\n",
				"    print(\"初始权参值:\",weight)\n",
				"    print(\"初始偏参值:\",bias)\n",
				"    ########################实例化损失函数，优化函数########################################\n",
				"    loss_fn=nn.MSELoss()#定义均方误差函数作为损失函数\n",
				"    optimizer=t.optim.SGD(linear_module.parameters(),lr=0.001)#使用SGD优化函数，对inear_module.parameters()中权参、偏参进行梯度下降法优化，学习率为0.001\n",
				"    \n",
				"    iter=1000\n",
				"    i=0\n",
				"    for epoch in range(iter):#循环10000次epoch\n",
				"        print(\"第\",epoch,\"次epoch\")\n",
				"        for x,y in zip(x_t,y_t):#对训练集中每一个值都投入模型运算并求得对应梯度，并运行一次梯度下降，完成一个epoch\n",
				"            i+=1\n",
				"            y_predict=linear_module(x_t)\n",
				"            y_predict=y_predict.to(t.float32)#转换为float\n",
				"            y_t=y_t.to(t.float32)\n",
				"            loss=loss_fn(y_predict, y_t)\n",
				"            optimizer.zero_grad()#清空上次的梯度积累\n",
				"            loss.backward()#损失函数进行backward反向传播\n",
				"            if iter>900:\n",
				"                \n",
				"                print(\"第\",i,\"次梯度下降后\")\n",
				"                print(\"模型中权参梯度：\",linear_module.weight.grad)\n",
				"                print(\"模型中偏参梯度\",linear_module.bias.grad)\n",
				"            optimizer.step()#根据计算得到的梯度开始梯度下降更新即W=W-∇w*learningrate\n",
				"    \n",
				"    ################################输出最终优化的权参和偏参##############################################\n",
				"    print(\"优化后得到权参、偏参分别为：\",list(linear_module.named_parameters()))\n",
				"    y_predict=linear_module(x_t).detach().numpy()#通过模型进行预测.detach()实现返回一个新的tensor，从当前计算图中分离下来的，但是仍指向原变量的存放位置,不同之处只是requires_grad为false，得到的这个tensor永远不需要计算其梯度，不具有grad。\n",
				"    plt.scatter(x_n,y_n)\n",
				"    plt.plot(x_t,y_predict)\n",
				"    \n",
				"    "
			]
		},
		{
			"cell_type": "code",
			"execution_count": 11,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"example_tensor torch.Size([3, 1])\n",
						"transormed torch.Size([3, 4])\n",
						"\n",
						"We can see that the weights exist in the background\n",
						"\n",
						"W: Parameter containing:\n",
						"tensor([[ 0.2080],\n",
						"        [ 0.9801],\n",
						"        [-0.2610],\n",
						"        [-0.1039]], requires_grad=True)\n",
						"b: Parameter containing:\n",
						"tensor([ 0.9507,  0.8385,  0.5706, -0.3836], requires_grad=True)\n"
					]
				}
			],
			"source": [
				"import torch\n",
				"d_in = 3\n",
				"d_out = 4\n",
				"linear_module2 = nn.Linear(1, d_out)\n",
				"\n",
				"example_tensor = torch.tensor([[1.,2,3]]).T#这里由于希望输入的是元组（或者说一个样本）所以转置\n",
				"# applys a linear transformation to the data\n",
				"transformed = linear_module2(example_tensor)\n",
				"print('example_tensor', example_tensor.shape)\n",
				"print('transormed', transformed.shape)\n",
				"print()\n",
				"print('We can see that the weights exist in the background\\n')\n",
				"print('W:', linear_module.weight)\n",
				"print('b:', linear_module.bias)"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"实验：\n",
				"\n",
				"基本的linear层的表示：\n",
				"\n",
				"输入，3个元组构成的矩阵\n",
				"\n",
				"A: [0.1,0.2,0.3,0.3,0.3]\n",
				"B: [0.4,0.5,0.6,0.6,0.6]\n",
				"C: [0.7,0.8,0.9,0.9,0.9]\n",
				"\n",
				"输出：一个预测标量，以及相关的权参，偏参\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 25,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"torch.Size([3])\n",
						"输入自变量的形状 torch.Size([3, 5])\n",
						"输出因变量的形状 torch.Size([3, 1])\n",
						"得到的预测因变量 tensor([[0.2705],\n",
						"        [0.2945],\n",
						"        [0.3186]], grad_fn=<AddmmBackward0>)\n",
						"得到的权参矩阵形状 torch.Size([1, 5])\n",
						"得到的偏参形状 torch.Size([1])\n"
					]
				},
				{
					"name": "stderr",
					"output_type": "stream",
					"text": [
						"C:\\Users\\tom\\AppData\\Local\\Temp\\ipykernel_22896\\1423085501.py:5: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\TensorShape.cpp:3575.)\n",
						"  y=t.tensor([2,3,2],dtype=t.float32).T\n"
					]
				}
			],
			"source": [
				"import numpy as np \n",
				"import torch as t\n",
				"linear_model=t.nn.Linear(5,1,bias=True)\n",
				"input=t.tensor([[0.1,0.2,0.3,0.3,0.3],[0.4,0.5,0.6,0.6,0.6],[0.7,0.8,0.9,0.9,0.9]],dtype=t.float32)\n",
				"y=t.tensor([2,3,2],dtype=t.float32).T\n",
				"print(y.shape) \n",
				"output=linear_model(input)\n",
				"print('输入自变量的形状',input.shape)\n",
				"print('输出因变量的形状',output.shape)\n",
				"print('得到的预测因变量',output)\n",
				"print('得到的权参矩阵形状',linear_model.weight.shape)\n",
				"print('得到的偏参形状',linear_model.bias.shape)"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"以上的linear层并没有实现模型的拟合，而是自动分配了权参weight，以及偏参bias，以下实现一次梯度下降，从而更新模型，实现拟合。"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 59,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"torch.Size([3, 1])\n",
						"torch.Size([3, 1])\n",
						"没有进行方向传播进行梯度下降之前的误差 tensor(3.6238, grad_fn=<MseLossBackward0>)\n",
						"初始参数\n",
						"权参Parameter containing:\n",
						"tensor([[-0.2257,  0.2285, -0.1705, -0.0341,  0.3153]], requires_grad=True)，偏参Parameter containing:\n",
						"tensor([0.3989], requires_grad=True)\n",
						"梯度\n",
						"权参梯度tensor([[-1.4617, -1.8305, -2.1993, -2.1993, -2.1993]])，偏参梯度tensor([-3.6883])\n",
						"再次forwad，计算对应的loss\n",
						"优化后拟合函数得到的的预测值 tensor([[1.0114],\n",
						"        [1.3124],\n",
						"        [1.6135]], grad_fn=<AddmmBackward0>)\n",
						"计算优化后的损失函得到误差 tensor(1.3249, grad_fn=<MseLossBackward0>)\n"
					]
				}
			],
			"source": [
				"import torch as t \n",
				"import numpy as np \n",
				"from torch import Tensor, nn\n",
				"class Mylinear(nn.Module):\n",
				"    def __init__(self,input,output):\n",
				"        super(Mylinear, self).__init__()\n",
				"        self.Mylinear=nn.Linear(input,output,bias=True)\n",
				"    def forward(self, input: Tensor) -> Tensor:\n",
				"       # return super().forward(input)\n",
				"         return self.Mylinear(input)\n",
				"    \n",
				"if  __name__ == \"__main__\": \n",
				"    input=t.tensor([[0.1,0.2,0.3,0.3,0.3],[0.4,0.5,0.6,0.6,0.6],[0.7,0.8,0.9,0.9,0.9]])\n",
				"    y=t.tensor([[2,3,2]],dtype=t.float32).T\n",
				"    print(y.shape)\n",
				"    iter=100\n",
				"    mylinear=Mylinear(5,1)\n",
				"    y_pred=mylinear.forward(input)\n",
				"    print(y_pred.shape)\n",
				"    loss_fn=nn.MSELoss()#定义均方误差函数作为损失函数\n",
				"\n",
				"    loss_v=loss_fn(y_pred,y)\n",
				"    print(\"没有进行方向传播进行梯度下降之前的误差\",loss_v)\n",
				"  \n",
				"    #grad=loss_v.backward()#实现反向传播，并进行\n",
				"    #w_grad=mylinear.Mylinear.weight.grad\n",
				"    #b_grad=mylinear.Mylinear.bias.grad\n",
				"\n",
				"    print(\"初始参数\")\n",
				"    print(\"权参{}，偏参{}\".format(mylinear.Mylinear.weight,mylinear.Mylinear.bias))\n",
				"    #print(\"梯度\")\n",
				"    #print(\"权参梯度{}，偏参梯度{}\".format(mylinear.Mylinear.weight.grad,mylinear.Mylinear.bias.grad))\n",
				"#pytorch 中无法显式的更新参数，必须使用其优化器，但是原理一致\n",
				"    #mylinear.Mylinear.weight-=0.01*w_grad\n",
				"    #mylinear.Mylinear.bias-=0.01*b_grad\n",
				"    optimizer=t.optim.SGD(mylinear.parameters(),lr=0.09)\n",
				"    optimizer.zero_grad()\n",
				"    loss_v.backward()\n",
				"    #通过梯度下降更新权参，偏参\n",
				"    print(\"梯度\")\n",
				"    print(\"权参梯度{}，偏参梯度{}\".format(mylinear.Mylinear.weight.grad,mylinear.Mylinear.bias.grad))\n",
				"    optimizer.step()\n",
				"    print(\"再次forwad，计算对应的loss\")\n",
				"    y_pred2=mylinear.forward(input)\n",
				"    print(\"优化后拟合函数得到的的预测值\",y_pred2)\n",
				"    print(\"计算优化后的损失函得到误差\",loss_fn(y_pred2,y))"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"基于以上的梯度下降方法，现引入iter=100的迭代，实现模型更新\n",
				"\n",
				"**在每次迭代中，应该先清零梯度，然后进行前向传播，计算损失，进行反向传播，最后更新模型参数**"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 65,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"tensor(8.2502, grad_fn=<MseLossBackward0>)\n",
						"tensor(2.6822, grad_fn=<MseLossBackward0>)\n",
						"tensor(1.1721, grad_fn=<MseLossBackward0>)\n",
						"tensor(0.7540, grad_fn=<MseLossBackward0>)\n",
						"tensor(0.6301, grad_fn=<MseLossBackward0>)\n",
						"tensor(0.5859, grad_fn=<MseLossBackward0>)\n",
						"tensor(0.5635, grad_fn=<MseLossBackward0>)\n",
						"tensor(0.5475, grad_fn=<MseLossBackward0>)\n",
						"tensor(0.5335, grad_fn=<MseLossBackward0>)\n",
						"tensor(0.5205, grad_fn=<MseLossBackward0>)\n",
						"tensor(0.5082, grad_fn=<MseLossBackward0>)\n",
						"tensor(0.4964, grad_fn=<MseLossBackward0>)\n",
						"tensor(0.4851, grad_fn=<MseLossBackward0>)\n",
						"tensor(0.4742, grad_fn=<MseLossBackward0>)\n",
						"tensor(0.4638, grad_fn=<MseLossBackward0>)\n",
						"tensor(0.4539, grad_fn=<MseLossBackward0>)\n",
						"tensor(0.4443, grad_fn=<MseLossBackward0>)\n",
						"tensor(0.4352, grad_fn=<MseLossBackward0>)\n",
						"tensor(0.4264, grad_fn=<MseLossBackward0>)\n",
						"tensor(0.4180, grad_fn=<MseLossBackward0>)\n",
						"tensor(0.4099, grad_fn=<MseLossBackward0>)\n",
						"tensor(0.4021, grad_fn=<MseLossBackward0>)\n",
						"tensor(0.3947, grad_fn=<MseLossBackward0>)\n",
						"tensor(0.3876, grad_fn=<MseLossBackward0>)\n",
						"tensor(0.3808, grad_fn=<MseLossBackward0>)\n",
						"tensor(0.3742, grad_fn=<MseLossBackward0>)\n",
						"tensor(0.3680, grad_fn=<MseLossBackward0>)\n",
						"tensor(0.3620, grad_fn=<MseLossBackward0>)\n",
						"tensor(0.3562, grad_fn=<MseLossBackward0>)\n",
						"tensor(0.3507, grad_fn=<MseLossBackward0>)\n",
						"tensor(0.3454, grad_fn=<MseLossBackward0>)\n",
						"tensor(0.3403, grad_fn=<MseLossBackward0>)\n",
						"tensor(0.3354, grad_fn=<MseLossBackward0>)\n",
						"tensor(0.3308, grad_fn=<MseLossBackward0>)\n",
						"tensor(0.3263, grad_fn=<MseLossBackward0>)\n",
						"tensor(0.3220, grad_fn=<MseLossBackward0>)\n",
						"tensor(0.3179, grad_fn=<MseLossBackward0>)\n",
						"tensor(0.3139, grad_fn=<MseLossBackward0>)\n",
						"tensor(0.3102, grad_fn=<MseLossBackward0>)\n",
						"tensor(0.3065, grad_fn=<MseLossBackward0>)\n",
						"tensor(0.3030, grad_fn=<MseLossBackward0>)\n",
						"tensor(0.2997, grad_fn=<MseLossBackward0>)\n",
						"tensor(0.2965, grad_fn=<MseLossBackward0>)\n",
						"tensor(0.2935, grad_fn=<MseLossBackward0>)\n",
						"tensor(0.2905, grad_fn=<MseLossBackward0>)\n",
						"tensor(0.2877, grad_fn=<MseLossBackward0>)\n",
						"tensor(0.2850, grad_fn=<MseLossBackward0>)\n",
						"tensor(0.2824, grad_fn=<MseLossBackward0>)\n",
						"tensor(0.2799, grad_fn=<MseLossBackward0>)\n",
						"tensor(0.2775, grad_fn=<MseLossBackward0>)\n",
						"tensor(0.2753, grad_fn=<MseLossBackward0>)\n",
						"tensor(0.2731, grad_fn=<MseLossBackward0>)\n",
						"tensor(0.2710, grad_fn=<MseLossBackward0>)\n",
						"tensor(0.2690, grad_fn=<MseLossBackward0>)\n",
						"tensor(0.2670, grad_fn=<MseLossBackward0>)\n",
						"tensor(0.2652, grad_fn=<MseLossBackward0>)\n",
						"tensor(0.2634, grad_fn=<MseLossBackward0>)\n",
						"tensor(0.2617, grad_fn=<MseLossBackward0>)\n",
						"tensor(0.2601, grad_fn=<MseLossBackward0>)\n",
						"tensor(0.2585, grad_fn=<MseLossBackward0>)\n",
						"tensor(0.2570, grad_fn=<MseLossBackward0>)\n",
						"tensor(0.2556, grad_fn=<MseLossBackward0>)\n",
						"tensor(0.2542, grad_fn=<MseLossBackward0>)\n",
						"tensor(0.2529, grad_fn=<MseLossBackward0>)\n",
						"tensor(0.2516, grad_fn=<MseLossBackward0>)\n",
						"tensor(0.2504, grad_fn=<MseLossBackward0>)\n",
						"tensor(0.2493, grad_fn=<MseLossBackward0>)\n",
						"tensor(0.2481, grad_fn=<MseLossBackward0>)\n",
						"tensor(0.2471, grad_fn=<MseLossBackward0>)\n",
						"tensor(0.2461, grad_fn=<MseLossBackward0>)\n",
						"tensor(0.2451, grad_fn=<MseLossBackward0>)\n",
						"tensor(0.2441, grad_fn=<MseLossBackward0>)\n",
						"tensor(0.2432, grad_fn=<MseLossBackward0>)\n",
						"tensor(0.2424, grad_fn=<MseLossBackward0>)\n",
						"tensor(0.2415, grad_fn=<MseLossBackward0>)\n",
						"tensor(0.2407, grad_fn=<MseLossBackward0>)\n",
						"tensor(0.2400, grad_fn=<MseLossBackward0>)\n",
						"tensor(0.2392, grad_fn=<MseLossBackward0>)\n",
						"tensor(0.2385, grad_fn=<MseLossBackward0>)\n",
						"tensor(0.2379, grad_fn=<MseLossBackward0>)\n",
						"tensor(0.2372, grad_fn=<MseLossBackward0>)\n",
						"tensor(0.2366, grad_fn=<MseLossBackward0>)\n",
						"tensor(0.2360, grad_fn=<MseLossBackward0>)\n",
						"tensor(0.2354, grad_fn=<MseLossBackward0>)\n",
						"tensor(0.2349, grad_fn=<MseLossBackward0>)\n",
						"tensor(0.2344, grad_fn=<MseLossBackward0>)\n",
						"tensor(0.2339, grad_fn=<MseLossBackward0>)\n",
						"tensor(0.2334, grad_fn=<MseLossBackward0>)\n",
						"tensor(0.2329, grad_fn=<MseLossBackward0>)\n",
						"tensor(0.2325, grad_fn=<MseLossBackward0>)\n",
						"tensor(0.2321, grad_fn=<MseLossBackward0>)\n",
						"tensor(0.2317, grad_fn=<MseLossBackward0>)\n",
						"tensor(0.2313, grad_fn=<MseLossBackward0>)\n",
						"tensor(0.2309, grad_fn=<MseLossBackward0>)\n",
						"tensor(0.2305, grad_fn=<MseLossBackward0>)\n",
						"tensor(0.2302, grad_fn=<MseLossBackward0>)\n",
						"tensor(0.2299, grad_fn=<MseLossBackward0>)\n",
						"tensor(0.2295, grad_fn=<MseLossBackward0>)\n",
						"tensor(0.2292, grad_fn=<MseLossBackward0>)\n",
						"tensor(0.2290, grad_fn=<MseLossBackward0>)\n"
					]
				}
			],
			"source": [
				"import torch as t \n",
				"import numpy as np \n",
				"from torch import Tensor, nn\n",
				"class Mylinear(nn.Module):\n",
				"    def __init__(self,input,output):\n",
				"        super(Mylinear, self).__init__()\n",
				"        self.Mylinear=nn.Linear(input,output,bias=True)\n",
				"    def forward(self, input: Tensor) -> Tensor:\n",
				"       # return super().forward(input)\n",
				"         return self.Mylinear(input)\n",
				"    \n",
				"\n",
				"\n",
				"if  __name__ == \"__main__\": \n",
				"      input=t.tensor([[0.1,0.2,0.3,0.3,0.3],[0.4,0.5,0.6,0.6,0.6],[0.7,0.8,0.9,0.9,0.9]])\n",
				"      y=t.tensor([[2,3,2]],dtype=t.float32).T\n",
				"      linear=Mylinear(5,1)\n",
				"      loss_fn=nn.MSELoss()#定义均方误差函数作为损失函数\n",
				"      op=t.optim.SGD(linear.parameters(),lr=0.09)\n",
				"      for i in range(100):\n",
				"           op.zero_grad()#在进行反向传播之前，应该先调用op.zero_grad()来清除之前的梯度，否则梯度会累加到已有的梯度上\n",
				"           y_pred=linear.forward(input)\n",
				"           loss_v=loss_fn(y_pred,y)\n",
				"           print(loss_v)\n",
				"           loss_v.backward()\n",
				"           \n",
				"           op.step()\n",
				"           \n",
				"           "
			]
		},
		{
			"attachments": {},
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"模型的改进\n",
				"\n",
				"以上模型没有加入激活函数，只是一个简单的一层线性全连接网络。\n",
				"\n",
				"以下改进模型，加入激活层，使用relu激活函数：\n",
				"\n",
				"---\n",
				"\n",
				"Activation functions\n",
				"PyTorch implements a number of activation functions including but not limited to ReLU, Tanh, and Sigmoid. Since they are modules, they need to be instantiated.\n",
				"\n",
				"---\n",
				"\n",
				"pytorch中，激活层的使用与之前numpy构建相似，首先实例化一个激活函数，正向传播全连接层input的数据后，得到激活值，传递给下一个全连接层。"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 66,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"tensor([-0.5379, -0.1048], dtype=torch.float64)\n",
						"relu 激活函数很简单，即如果x>0则输出x反之输出0\n",
						"tensor([0., 0.], dtype=torch.float64)\n"
					]
				}
			],
			"source": [
				"relu_fn=nn.ReLU()#实例化Relu函数\n",
				"x=t.randn(2,dtype=float)\n",
				"print(x)\n",
				"print(\"relu 激活函数很简单，即如果x>0则输出x反之输出0\")\n",
				"y=relu_fn.forward(x)\n",
				"print(y)\n",
				"\n"
			]
		},
		{
			"attachments": {},
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"实现将激活函数加入之前线性层之后，注意输出层也必须为一个线性层，而后在外部使用平均误差函数\n",
				"\n",
				"---\n",
				"出现问题\n",
				"1. 单独将数据放入GPU无法训练，还必须将model放入gpu\n",
				"```python\n",
				"    x_t=x_t.to(device)#将数据移动到gpu\n",
				"    y_t=y_t.to(device)#将数据运动到gpu\n",
				"    linear_module=LinerModel()\n",
				"    linear_module.to(device)#模型也必须移动到GPU\n",
				"```\n",
				"2. 如果想把CUDA tensor格式的数据改成numpy时，需要先将其转换成cpu float-tensor随后再转到numpy格式。 numpy不能读取CUDA tensor 需要将它转化为 CPU tensor\n",
				"```python\n",
				"    x_n=x_t.cpu().numpy().T\n",
				"    y_n=y_t.cpu().numpy().T\n",
				"```"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"CUDA is available. Training on GPU.\n"
					]
				}
			],
			"source": [
				"import torch\n",
				"\n",
				"if torch.cuda.is_available():\n",
				"    print(\"CUDA is available. Training on GPU.\")\n",
				"else:\n",
				"    print(\"CUDA is not available. Training on CPU.\")\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 2,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"torch.Size([20, 1])\n",
						"current device cuda\n",
						"cuda:0\n",
						"torch.Size([20, 1])\n",
						"通过一次forwad后得到y predict\n",
						"模型中参数： <generator object Module.parameters at 0x000001C1C45A0970>\n",
						"初始权参值: Parameter containing:\n",
						"tensor([[-0.9588],\n",
						"        [ 0.2716],\n",
						"        [ 0.3539],\n",
						"        [-0.0950],\n",
						"        [-0.7423],\n",
						"        [-0.2605],\n",
						"        [-0.1598],\n",
						"        [-0.9805],\n",
						"        [-0.3833],\n",
						"        [-0.8836]], device='cuda:0', requires_grad=True)\n",
						"初始偏参值: Parameter containing:\n",
						"tensor([ 0.5543, -0.1738,  0.1890,  0.1448,  0.7271, -0.3638,  0.7303, -0.7050,\n",
						"        -0.2668,  0.1630], device='cuda:0', requires_grad=True)\n",
						"优化后得到权参、偏参分别为： [('weight', Parameter containing:\n",
						"tensor([[-0.9888],\n",
						"        [ 1.8178],\n",
						"        [ 1.4548],\n",
						"        [-0.0039],\n",
						"        [-2.3471],\n",
						"        [-0.2605],\n",
						"        [-2.2496],\n",
						"        [-0.9805],\n",
						"        [-0.3833],\n",
						"        [-0.8836]], device='cuda:0', requires_grad=True)), ('bias', Parameter containing:\n",
						"tensor([ 4.9438e-01,  3.3009e+00,  3.2715e+00,  1.9393e-03,  2.3500e+00,\n",
						"        -3.6384e-01,  5.3797e+00, -7.0504e-01, -2.6676e-01,  1.6300e-01],\n",
						"       device='cuda:0', requires_grad=True)), ('linear2.weight', Parameter containing:\n",
						"tensor([[ 0.0939,  3.7620,  3.5715, -0.2082,  3.1651, -0.2193, -5.7878,  0.2364,\n",
						"         -0.2153, -0.0061]], device='cuda:0', requires_grad=True)), ('linear2.bias', Parameter containing:\n",
						"tensor([1.4845], device='cuda:0', requires_grad=True))]\n"
					]
				},
				{
					"data": {
						"image/png": "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",
						"text/plain": [
							"<Figure size 640x480 with 1 Axes>"
						]
					},
					"metadata": {},
					"output_type": "display_data"
				}
			],
			"source": [
				"import torch as t \n",
				"import numpy as np\n",
				"import pandas as pd\n",
				"import matplotlib.pyplot as plt\n",
				"from torch import nn\n",
				"class LinerModel(nn.Module):\n",
				"    def __init__(self):\n",
				"        super(LinerModel, self).__init__()\n",
				"        self.linear1=nn.Linear(in_features=1,out_features=10)\n",
				"        self.relu1=nn.ReLU()\n",
				"        self.linear2=nn.Linear(in_features=10,out_features=1)\n",
				"        self.weight=self.linear1.weight\n",
				"        self.bias=self.linear1.bias\n",
				"    \n",
				"    def forward(self,x):\n",
				"        x=self.linear1(x)\n",
				"        x=self.relu1(x)\n",
				"        x=self.linear2(x)\n",
				"        return x\n",
				"    \n",
				"    def getParamters(self):\n",
				"        return self.weight,self.bias\n",
				"if  __name__ == '__main__':\n",
				"    \n",
				" \n",
				"\n",
				"    #plt.scatter(x,y)\n",
				"    x_t=t.tensor([[0.50,0.75,1.00,1.25,1.50,1.75,1.75,2.00,2.25,2.50,2.75,3.00,3.25,3.50,4.00,4.25,4.50,4.75,5.00,5.50]]).T\n",
				"    print(x_t.shape)\n",
				"    y_t=t.tensor([[10,  22,  13,  43,  20,  22,  33,  50,  62, 48,  55,  75,  62,  73,  81,  76,  64,  82,  90,  93]]).T\n",
				"    \n",
				"    device=\"cuda\" if t.cuda.is_available() else \"cpu\"\n",
				"    print(\"current device\",device)\n",
				"    x_t=x_t.to(device)#将数据移动到gpu\n",
				"    y_t=y_t.to(device)#将数据运动到gpu\n",
				"    \n",
				"    print(x_t.device)\n",
				"    x_n=x_t.cpu().numpy().T\n",
				"    y_n=y_t.cpu().numpy().T\n",
				"    print(x_t.shape)\n",
				"    linear_module=LinerModel()\n",
				"    linear_module.to(device)#模型也必须移动到GPU\n",
				"    y_pred=linear_module.forward(x_t)\n",
				"    print(\"通过一次forwad后得到y predict\")\n",
				"    weight,bias=linear_module.getParamters()\n",
				"    print(\"模型中参数：\",linear_module.parameters())\n",
				"    print(\"初始权参值:\",weight)\n",
				"    print(\"初始偏参值:\",bias)\n",
				"    ########################实例化损失函数，优化函数########################################\n",
				"    loss_fn=nn.MSELoss()#定义均方误差函数作为损失函数\n",
				"    optimizer=t.optim.SGD(linear_module.parameters(),lr=0.001)#使用SGD优化函数，对inear_module.parameters()中权参、偏参进行梯度下降法优化，学习率为0.001\n",
				"    \n",
				"    iter=1000\n",
				"    i=0\n",
				"    for epoch in range(iter):#循环10000次epoch\n",
				"        #print(\"第\",epoch,\"次epoch\")\n",
				"        for x,y in zip(x_t,y_t):#对训练集中每一个值都投入模型运算并求得对应梯度，并运行一次梯度下降，完成一个epoch\n",
				"            i+=1\n",
				"            y_predict=linear_module(x_t)\n",
				"            y_predict=y_predict.to(t.float32)\n",
				"            y_t=y_t.to(t.float32)\n",
				"            loss=loss_fn(y_predict, y_t)\n",
				"            optimizer.zero_grad()#清空上次的梯度积累\n",
				"            loss.backward()#损失函数进行backward反向传播\n",
				"            if iter>9000:\n",
				"                \n",
				"                print(\"第\",i,\"次梯度下降后\")\n",
				"                print(\"模型中权参梯度：\",linear_module.weight.grad)\n",
				"                print(\"模型中偏参梯度\",linear_module.bias.grad)\n",
				"            optimizer.step()#根据计算得到的梯度开始梯度下降更新即W=W-∇w*learningrate\n",
				"    \n",
				"    ################################输出最终优化的权参和偏参##############################################\n",
				"    print(\"优化后得到权参、偏参分别为：\",list(linear_module.named_parameters()))\n",
				"    y_predict=linear_module(x_t).detach().cpu().numpy()#通过模型进行预测.detach()实现返回一个新的tensor，从当前计算图中分离下来的，但是仍指向原变量的存放位置,不同之处只是requires_grad为false，得到的这个tensor永远不需要计算其梯度，不具有grad。\n",
				"    plt.scatter(x_n,y_n)\n",
				"    plt.plot(x_n,y_predict.T)"
			]
		},
		{
			"attachments": {},
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"基于以上代码，重现华盛顿大学 pytroch课程\n",
				"\n",
				"首先定义相关的待拟合函数\n",
				"$$y=4 \\times sin(\\pi \\times x)\\times cos(6 \\times x^2)$$\n",
				"\n",
				"并展现相关的图像"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 9,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"torch.Size([200, 1]) torch.Size([200, 1])\n"
					]
				},
				{
					"data": {
						"image/png": "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",
						"text/plain": [
							"<Figure size 640x480 with 1 Axes>"
						]
					},
					"metadata": {},
					"output_type": "display_data"
				}
			],
			"source": [
				"%matplotlib inline\n",
				"import torch \n",
				"import matplotlib.pyplot as plt\n",
				"import numpy as np\n",
				"from torch import nn\n",
				"\n",
				"class simpleNet(nn.Module):\n",
				"    def __init__(self,input,output):\n",
				"        super(simpleNet, self).__init__()\n",
				"        self.linear1=nn.Linear(in_features=input, out_features=200)\n",
				"        self.relu1=nn.ReLU()\n",
				"        self.linear2=nn.Linear(in_features=200, out_features=300)\n",
				"        self.relu2=nn.ReLU()\n",
				"        self.linear3=nn.Linear(in_features=300, out_features=output)\n",
				"    \n",
				"    def forward(self, x):\n",
				"        x=self.linear1(x)\n",
				"        x=self.relu1(x)\n",
				"        x=self.linear2(x)\n",
				"        x=self.relu2(x)\n",
				"        x=self.linear3(x)\n",
				"        return x\n",
				"if __name__=='__main__':\n",
				"    \n",
				"\n",
				"    d = 1\n",
				"    n = 200\n",
				"    X = torch.rand(n,d)\n",
				"    iterm=50000\n",
				"    y = 4 * torch.sin(np.pi * X) * torch.cos(6*np.pi*X**2)\n",
				"    print(X.shape, y.shape)\n",
				" \n",
				"################################################################\n",
				"    net=simpleNet(input=d,output=d)\n",
				"    loss_fn=nn.MSELoss()\n",
				"    opt=torch.optim.Adam(params=net.parameters(),lr=0.01)\n",
				"    for epoch in range(iterm):\n",
				"         \n",
				"            y_pred=net.forward(X)\n",
				"            loss=loss_fn(y_pred,y)\n",
				"            opt.zero_grad()\n",
				"            loss.backward()\n",
				"            opt.step()#更新权参、偏参\n",
				"    \n",
				"    X_grid = torch.from_numpy(np.linspace(0,1,50)).float().view(-1, d)\n",
				"    y_hat = net(X_grid)\n",
				"    plt.scatter(X.numpy(), y.numpy())\n",
				"    plt.plot(X_grid.detach().numpy(), y_hat.detach().numpy(), 'r')\n",
				"    plt.title('plot of $f(x)$ and $\\hat{f}(x)$')\n",
				"    plt.xlabel('$x$')\n",
				"    plt.ylabel('$y$')\n",
				"    plt.show()"
			]
		},
		{
			"attachments": {},
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"Sequential\n",
				"---\n",
				"除了使用创建modle类，再进行模型训练方法，也可以通过Sequenltal将模型串联，开始运算，但这种方式正规性不强，与tensorflow类似。\n",
				"但是可以将Sequential集成到modle类中，实现序列包装，并在forwrd中直接调用，可以避免出错。\n",
				"\n",
				"```python\n",
				"class Net(nn.Module):\n",
				"    def __init__(self, input_num, hidden_num, output_num):\n",
				"        super(Net, self).__init__()\n",
				"        self.net = nn.Sequential(\n",
				"            nn.Linear(input_num, hidden_num),\n",
				"            nn.ReLU(),\n",
				"            nn.Linear(hidden_num, output_num),\n",
				"            nn.ReLU()\n",
				"        )\n",
				"\n",
				"    def forward(self, input):\n",
				"        return self.net(input)\n",
				" \n",
				"```\n",
				"__init__ 方法中不为每一层显式地创建一个实例类层，同时在forward中直接调用Squential对象进行运算即可。\n",
				"\n",
				"Many times, we want to compose Modules together. torch.nn.Sequential provides a good interface for composing simple modules."
			]
		},
		{
			"attachments": {},
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"## 实验\n",
				"### 实验1 多元函数\n",
				"在以上案例基础上，进一步实现多元回归的神经网络，包括\n",
				"1. 数据获取\n",
				"2. 数据观察\n",
				"3. 对数据的标准化\n",
				"4. 实现mini-batch载入\n",
				"5. 通过train、test数据划分验证数据\n",
				"6. 结合之前知识，实验模型优化\n",
				"总之，实现一个完整的面向数值多元数据的神经网络构建流程\n",
				"\n",
				"参考\n",
				"* [神经网络多元回归](https://blog.csdn.net/qq_39567427/article/details/111935833)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 10,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"Collecting torchsummary\n",
						"  Downloading torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\n",
						"Installing collected packages: torchsummary\n",
						"Successfully installed torchsummary-1.5.1\n"
					]
				}
			],
			"source": [
				"!pip install torchsummary"
			]
		},
		{
			"attachments": {},
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"载入数据，进行基本数据观察，数据来源于sklearn\n",
				"\n",
				"----\n",
				"注意层数与神经元确定个数：\n",
				"\n",
				"[参考](https://zhuanlan.zhihu.com/p/100419971)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 27,
			"metadata": {},
			"outputs": [
				{
					"name": "stderr",
					"output_type": "stream",
					"text": [
						"c:\\Users\\tom\\.conda\\envs\\luck\\lib\\site-packages\\sklearn\\datasets\\_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
						"  warn(\n"
					]
				},
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"载入数据tpye <class 'sklearn.utils._bunch.Bunch'>\n",
						"dict_keys(['data', 'target', 'frame', 'categories', 'feature_names', 'target_names', 'DESCR', 'details', 'url'])\n",
						"自变量多元数据：\n",
						"['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT']\n",
						"      CRIM    ZN  INDUS CHAS    NOX     RM   AGE   DIS RAD    TAX  PTRATIO  \\\n",
						"0  0.00632  18.0   2.31    0  0.538  6.575  65.2  4.09   1  296.0     15.3   \n",
						"\n",
						"       B  LSTAT  \n",
						"0  396.9   4.98  \n",
						"自变量数据类型： <class 'numpy.ndarray'> 数据形状： (506, 13)\n",
						"因变量数据类型： <class 'numpy.ndarray'> 数据形状： (506, 1)\n",
						"训练集形状 (303, 13) (303, 1)\n",
						"测试集形状 (203, 13) (203, 1)\n",
						"cuda\n",
						"----------------------------------------------------------------\n",
						"        Layer (type)               Output Shape         Param #\n",
						"================================================================\n",
						"            Linear-1                   [-1, 15]             210\n",
						"              ReLU-2                   [-1, 15]               0\n",
						"            Linear-3                   [-1, 15]             240\n",
						"              ReLU-4                   [-1, 15]               0\n",
						"            Linear-5                    [-1, 1]              16\n",
						"              ReLU-6                    [-1, 1]               0\n",
						"================================================================\n",
						"Total params: 466\n",
						"Trainable params: 466\n",
						"Non-trainable params: 0\n",
						"----------------------------------------------------------------\n",
						"Input size (MB): 0.00\n",
						"Forward/backward pass size (MB): 0.00\n",
						"Params size (MB): 0.00\n",
						"Estimated Total Size (MB): 0.00\n",
						"----------------------------------------------------------------\n",
						"完成一个epoch，需要读取 15 个batchs\n",
						"epoch： 0\n",
						"第 0 个epoch\n",
						"train loss: 394.80362\n",
						"test loss: tensor(131.1740, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 1\n",
						"第 1 个epoch\n",
						"train loss: 244.43839\n",
						"test loss: tensor(118.5703, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 2\n",
						"第 2 个epoch\n",
						"train loss: 182.52081\n",
						"test loss: tensor(45.0694, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 3\n",
						"第 3 个epoch\n",
						"train loss: 140.68773\n",
						"test loss: tensor(42.3432, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 4\n",
						"第 4 个epoch\n",
						"train loss: 115.31176\n",
						"test loss: tensor(40.1792, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 5\n",
						"第 5 个epoch\n",
						"train loss: 104.05433\n",
						"test loss: tensor(35.8016, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 6\n",
						"第 6 个epoch\n",
						"train loss: 93.53385\n",
						"test loss: tensor(36.4166, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 7\n",
						"第 7 个epoch\n",
						"train loss: 84.62279\n",
						"test loss: tensor(21.9325, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 8\n",
						"第 8 个epoch\n",
						"train loss: 76.73389\n",
						"test loss: tensor(24.9544, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 9\n",
						"第 9 个epoch\n",
						"train loss: 69.96082\n",
						"test loss: tensor(29.5885, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 10\n",
						"第 10 个epoch\n",
						"train loss: 64.60127\n",
						"test loss: tensor(19.9376, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 11\n",
						"第 11 个epoch\n",
						"train loss: 59.873867\n",
						"test loss: tensor(21.8851, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 12\n",
						"第 12 个epoch\n",
						"train loss: 55.875042\n",
						"test loss: tensor(20.6788, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 13\n",
						"第 13 个epoch\n",
						"train loss: 52.621452\n",
						"test loss: tensor(23.1269, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 14\n",
						"第 14 个epoch\n",
						"train loss: 49.55092\n",
						"test loss: tensor(23.5559, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 15\n",
						"第 15 个epoch\n",
						"train loss: 46.53508\n",
						"test loss: tensor(27.6599, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 16\n",
						"第 16 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(26.8451, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 17\n",
						"第 17 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(26.8397, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 18\n",
						"第 18 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(26.8470, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 19\n",
						"第 19 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(26.8490, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
					]
				},
				{
					"data": {
						"image/png": "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",
						"text/plain": [
							"<Figure size 1000x500 with 1 Axes>"
						]
					},
					"metadata": {},
					"output_type": "display_data"
				},
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"(203, 1)\n",
						"(203, 1)\n",
						"[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
						"  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
						"  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
						"  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
						"  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
						"  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
						" 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
						" 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
						" 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
						" 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
						" 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
						" 198 199 200 201 202]\n"
					]
				},
				{
					"data": {
						"image/png": "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",
						"text/plain": [
							"<Figure size 1000x500 with 1 Axes>"
						]
					},
					"metadata": {},
					"output_type": "display_data"
				}
			],
			"source": [
				"from sklearn.datasets import fetch_openml\n",
				"\n",
				"\n",
				"from sklearn.preprocessing import StandardScaler\n",
				"from sklearn.utils import shuffle\n",
				"from torch import nn\n",
				"import torch\n",
				" \n",
				"import matplotlib.pyplot as plt\n",
				"import numpy as np\n",
				"import pandas as pd\n",
				" \n",
				"from sklearn.preprocessing import scale\n",
				"from torchsummary import summary\n",
				"from matplotlib.font_manager import FontProperties\n",
				"\n",
				"class MyNet(nn.Module):\n",
				"    def __init__(self,input,output) -> None:\n",
				"        super(MyNet, self).__init__()\n",
				"        self.nn=nn.Sequential(\n",
				"            nn.Linear(in_features=13,out_features=15),\n",
				"            nn.ReLU(),\n",
				"            nn.Linear(in_features=15,out_features=15),\n",
				"            nn.ReLU(),\n",
				"            nn.Linear(in_features=15,out_features=1),\n",
				"            nn.ReLU()\n",
				"        )\n",
				"        #self.linear1=nn.Linear(in_features=13,out_features=20)\n",
				"        #self.relu1=nn.ReLU()\n",
				"        #self.linear2=nn.Linear(in_features=20,out_features=1)\n",
				"        #self.relu2=nn.ReLU()\n",
				"        \n",
				"    def forward(self,x):\n",
				"        return self.nn(x)\n",
				"        #x=self.linear1(x)\n",
				"        #x=self.relu1(x)\n",
				"        #x=self.linear2(x)\n",
				"        #x=self.relu2(x)\n",
				"        \n",
				"        return x\n",
				"\n",
				"if __name__ == '__main__':\n",
				"\n",
				"    boston = fetch_openml(data_id=531)\n",
				"    #X, y = boston.data, boston.target\n",
				"    print(\"载入数据tpye\",type(boston))\n",
				"    #获取数据键\n",
				"    print(boston.keys())\n",
				"    #print(\"数据集描述：\",boston['DESCR'])\n",
				"    print(\"自变量多元数据：\")\n",
				"    print(boston['feature_names'])\n",
				"    print(boston['data'][0:1])\n",
				"    #print(\"因变量：\")\n",
				"    #print(boston['target'])\n",
				"    ################################################################\n",
				"    #数据划分#\n",
				"    x=boston['data'].values\n",
				"    print(\"自变量数据类型：\",type(x),\"数据形状：\",x.shape)\n",
				"    y=boston['target'].values.reshape(-1,1)\n",
				"    print(\"因变量数据类型：\",type(y),\"数据形状：\",y.shape)\n",
				"    ################################################################\n",
				"    #数据预处理#\n",
				"    ## 1. 标准化因变量#，在此标准化非常重要，没有标准化得到模型基本不能使用\n",
				"    scaler=StandardScaler()\n",
				"    x=scaler.fit_transform(x)\n",
				"    ## 2. 数据打乱顺序\n",
				"    x,y=shuffle(x,y)\n",
				"    ## 3. 划分train，test\n",
				"    x_size=x.shape[0]\n",
				"    train_size=int(x_size*0.6)\n",
				"    x_train,x_test,y_train,y_test=x[0:train_size,:],x[train_size:,:],y[0:train_size,:],y[train_size:,:]\n",
				"    print(\"训练集形状\",x_train.shape,y_train.shape)\n",
				"    print(\"测试集形状\",x_test.shape,y_test.shape)\n",
				"    #数据载入tensor\n",
				"    ## 1.转换numpy到tensor张量\n",
				"    x_train =torch.from_numpy(x_train)\n",
				"    y_train =torch.from_numpy(y_train)\n",
				"    x_test =torch.from_numpy(x_test)\n",
				"    y_test =torch.from_numpy(y_test)\n",
				"    ## 判断cuda是否可用，选择gpu或cpu载入数据处理\n",
				"    device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
				"    print(device)\n",
				" \n",
				"    x_train=x_train.to(torch.float32).to(device)\n",
				"    y_train=y_train.to(torch.float32).to(device)\n",
				"    x_test=x_test.to(torch.float32).to(device)\n",
				"    y_test=y_test.to(torch.float32).to(device)\n",
				"    ################################################################\n",
				"    ## 1. 构建模型实例,注意要载入gpu或cpu中与数据对应,summary输出网络的结构信息\n",
				"    net=MyNet(input=13,output=1).to(device)\n",
				" \n",
				"    summary(net, input_size=(13,))\n",
				"    \n",
				"    ## 2.超参设置\n",
				"    learning_rate=0.02\n",
				"    epochs=20\n",
				"    batch_size=20\n",
				"    total_steps=int(x_train.shape[0]/batch_size)\n",
				"    print(\"完成一个epoch，需要读取\",total_steps,\"个batchs\")\n",
				"    ## 3.创建损失函数，优化函数实例\n",
				"    loss_fn=nn.MSELoss()\n",
				"    opt=torch.optim.Adam(params=net.parameters(),lr=learning_rate)\n",
				"    ## 4.创建list记录训练loss，以及最后的test loss，作为对比\n",
				"    train_loss_list=[]\n",
				"    test_loss_list=[]\n",
				"    train_acc_list=[]\n",
				"    test_acc_list=[]\n",
				"    step_loss=[]\n",
				"    ## 4.训练模型\n",
				"    for step in range(epochs):#循环1000个epochs\n",
				"        print(\"epoch：\",step)\n",
				"        for i in range(total_steps):#内部完成基于batch的一个epochs数据读取\n",
				"            x_train_batch=x_train[step * batch_size:(step + 1) * batch_size, :]\n",
				"            y_train_batch=y_train[step * batch_size:(step + 1) * batch_size, :]\n",
				"       \n",
				" \n",
				"          \n",
				"            #y_train=y_train.to(torch.float32)\n",
				"            #x_train=x_train.to(torch.float32)\n",
				"            y_pred=net(x_train_batch.to(device))\n",
				"            loss=loss_fn(y_pred,y_train_batch)\n",
				"            #print(loss.cpu().detach().numpy())\n",
				"            step_loss.append(loss.cpu().detach().numpy())#记录每一个batch的loss值\n",
				"            opt.zero_grad()\n",
				"            loss.backward()\n",
				"            opt.step()\n",
				"       \n",
				"        train_loss=np.mean(step_loss)#计算每一个epoch的平均loss\n",
				"        train_loss_list.append(train_loss)\n",
				"        y_predict=net(x_test)\n",
				"        test_loss=loss_fn(y_predict, y_test)\n",
				"        test_loss_list.append(test_loss.cpu().detach().numpy())\n",
				"  \n",
				"        print(\"第\",step,\"个epoch\")\n",
				"        print(\"train loss:\",train_loss)\n",
				"        print(\"test loss:\",test_loss)\n",
				"        \n",
				"    fig = plt.gcf()\n",
				"    fig.set_size_inches(10, 5)\n",
				"\n",
				"    plt.xlabel('Epochs', fontsize=15)\n",
				"    plt.ylabel('Loss', fontsize=15)\n",
				"    plt.plot(train_loss_list, 'blue', label='Train loss')\n",
				"    plt.plot(test_loss_list, 'red', label='Test loss')\n",
				"    plt.legend(loc='best')\n",
				"    plt.title('Training and Test loss', fontsize=15)\n",
				"    plt.show()\n",
				"    ################################################################\n",
				"    # 通过x_test预测数据并与实际值对比\n",
				"    y_predict=net.forward(x_test)\n",
				"    y_pred=y_predict.cpu().detach().numpy()\n",
				"    y_t=y_test.cpu().detach().numpy()\n",
				"    print(y_pred.shape)\n",
				"    print(y_t.shape)\n",
				"    predciton=np.arange(len(y_pred))\n",
				"    print(predciton)\n",
				"    fig = plt.gcf()\n",
				"    fig.set_size_inches(10, 5)\n",
				"    plt.scatter(predciton,y_pred,color='red')\n",
				"    plt.scatter(predciton,y_t,color='blue')\n",
				"    "
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"实验 1.0.1 基于环境数据实现汞含量的深度学习\n",
				"\n",
				"实验步骤\n",
				"1. 读取hg数据（不包含分类数据）\n",
				"2. 实现因变量自变量的tensor转换"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"(753, 1)\n",
						"(753, 19)\n",
						"训练集形状 (451, 19) (451, 1)\n",
						"测试集形状 (302, 19) (302, 1)\n",
						"cuda\n",
						"实现训练集，测试集因变量、自变量的tensor转换\n",
						"----------------------------------------------------------------\n",
						"        Layer (type)               Output Shape         Param #\n",
						"================================================================\n",
						"            Linear-1                  [-1, 100]           2,000\n",
						"              ReLU-2                  [-1, 100]               0\n",
						"            Linear-3                   [-1, 50]           5,050\n",
						"              ReLU-4                   [-1, 50]               0\n",
						"            Linear-5                    [-1, 1]              51\n",
						"================================================================\n",
						"Total params: 7,101\n",
						"Trainable params: 7,101\n",
						"Non-trainable params: 0\n",
						"----------------------------------------------------------------\n",
						"Input size (MB): 0.00\n",
						"Forward/backward pass size (MB): 0.00\n",
						"Params size (MB): 0.03\n",
						"Estimated Total Size (MB): 0.03\n",
						"----------------------------------------------------------------\n",
						"完成一个epoch，需要读取 22 个batchs\n",
						"epoch： 0\n",
						"第 0 个epoch\n",
						"train loss: 7.17056\n",
						"test loss: tensor(372.0953, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 1\n",
						"第 1 个epoch\n",
						"train loss: 12.509714\n",
						"test loss: tensor(435.8342, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 2\n",
						"第 2 个epoch\n",
						"train loss: 13.303075\n",
						"test loss: tensor(359.3307, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 3\n",
						"第 3 个epoch\n",
						"train loss: 30.971521\n",
						"test loss: tensor(489.8028, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 4\n",
						"第 4 个epoch\n",
						"train loss: 34.49207\n",
						"test loss: tensor(395.4861, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 5\n",
						"第 5 个epoch\n",
						"train loss: 36.064175\n",
						"test loss: tensor(380.9381, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 6\n",
						"第 6 个epoch\n",
						"train loss: 197.1773\n",
						"test loss: tensor(367.9444, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 7\n",
						"第 7 个epoch\n",
						"train loss: 203.30908\n",
						"test loss: tensor(765.0760, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 8\n",
						"第 8 个epoch\n",
						"train loss: 198.5035\n",
						"test loss: tensor(371.7705, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 9\n",
						"第 9 个epoch\n",
						"train loss: 213.1688\n",
						"test loss: tensor(305.6234, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 10\n",
						"第 10 个epoch\n",
						"train loss: 212.64159\n",
						"test loss: tensor(651.1713, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 11\n",
						"第 11 个epoch\n",
						"train loss: 196.55698\n",
						"test loss: tensor(890.5571, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 12\n",
						"第 12 个epoch\n",
						"train loss: 184.27751\n",
						"test loss: tensor(918.2139, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 13\n",
						"第 13 个epoch\n",
						"train loss: 180.39005\n",
						"test loss: tensor(361.1442, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 14\n",
						"第 14 个epoch\n",
						"train loss: 200.54231\n",
						"test loss: tensor(576.5906, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 15\n",
						"第 15 个epoch\n",
						"train loss: 192.2986\n",
						"test loss: tensor(357.4177, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 16\n",
						"第 16 个epoch\n",
						"train loss: 193.2355\n",
						"test loss: tensor(355.1517, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 17\n",
						"第 17 个epoch\n",
						"train loss: 195.60501\n",
						"test loss: tensor(363.5042, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 18\n",
						"第 18 个epoch\n",
						"train loss: 186.75273\n",
						"test loss: tensor(412.9684, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 19\n",
						"第 19 个epoch\n",
						"train loss: 181.82788\n",
						"test loss: tensor(398.2012, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 20\n",
						"第 20 个epoch\n",
						"train loss: 176.20674\n",
						"test loss: tensor(352.4946, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 21\n",
						"第 21 个epoch\n",
						"train loss: 169.31544\n",
						"test loss: tensor(351.1248, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 22\n",
						"第 22 个epoch\n",
						"train loss: 164.39906\n",
						"test loss: tensor(350.6393, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 23\n",
						"第 23 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3713, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 24\n",
						"第 24 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3445, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 25\n",
						"第 25 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3418, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 26\n",
						"第 26 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 27\n",
						"第 27 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 28\n",
						"第 28 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 29\n",
						"第 29 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 30\n",
						"第 30 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 31\n",
						"第 31 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 32\n",
						"第 32 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 33\n",
						"第 33 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 34\n",
						"第 34 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 35\n",
						"第 35 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 36\n",
						"第 36 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 37\n",
						"第 37 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 38\n",
						"第 38 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 39\n",
						"第 39 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 40\n",
						"第 40 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 41\n",
						"第 41 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 42\n",
						"第 42 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 43\n",
						"第 43 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 44\n",
						"第 44 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 45\n",
						"第 45 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 46\n",
						"第 46 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 47\n",
						"第 47 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 48\n",
						"第 48 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 49\n",
						"第 49 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 50\n",
						"第 50 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 51\n",
						"第 51 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 52\n",
						"第 52 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 53\n",
						"第 53 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 54\n",
						"第 54 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 55\n",
						"第 55 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 56\n",
						"第 56 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 57\n",
						"第 57 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 58\n",
						"第 58 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 59\n",
						"第 59 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 60\n",
						"第 60 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 61\n",
						"第 61 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 62\n",
						"第 62 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 63\n",
						"第 63 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 64\n",
						"第 64 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 65\n",
						"第 65 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 66\n",
						"第 66 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 67\n",
						"第 67 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 68\n",
						"第 68 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 69\n",
						"第 69 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 70\n",
						"第 70 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 71\n",
						"第 71 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 72\n",
						"第 72 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 73\n",
						"第 73 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 74\n",
						"第 74 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 75\n",
						"第 75 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 76\n",
						"第 76 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 77\n",
						"第 77 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 78\n",
						"第 78 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 79\n",
						"第 79 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 80\n",
						"第 80 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 81\n",
						"第 81 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 82\n",
						"第 82 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 83\n",
						"第 83 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 84\n",
						"第 84 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 85\n",
						"第 85 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 86\n",
						"第 86 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 87\n",
						"第 87 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 88\n",
						"第 88 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 89\n",
						"第 89 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 90\n",
						"第 90 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 91\n",
						"第 91 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 92\n",
						"第 92 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 93\n",
						"第 93 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 94\n",
						"第 94 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 95\n",
						"第 95 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 96\n",
						"第 96 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 97\n",
						"第 97 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 98\n",
						"第 98 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 99\n",
						"第 99 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 100\n",
						"第 100 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 101\n",
						"第 101 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 102\n",
						"第 102 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 103\n",
						"第 103 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 104\n",
						"第 104 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 105\n",
						"第 105 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 106\n",
						"第 106 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 107\n",
						"第 107 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 108\n",
						"第 108 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 109\n",
						"第 109 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 110\n",
						"第 110 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 111\n",
						"第 111 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 112\n",
						"第 112 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 113\n",
						"第 113 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 114\n",
						"第 114 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 115\n",
						"第 115 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 116\n",
						"第 116 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 117\n",
						"第 117 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 118\n",
						"第 118 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 119\n",
						"第 119 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 120\n",
						"第 120 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 121\n",
						"第 121 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 122\n",
						"第 122 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 123\n",
						"第 123 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 124\n",
						"第 124 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 125\n",
						"第 125 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 126\n",
						"第 126 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 127\n",
						"第 127 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 128\n",
						"第 128 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 129\n",
						"第 129 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 130\n",
						"第 130 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 131\n",
						"第 131 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 132\n",
						"第 132 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 133\n",
						"第 133 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 134\n",
						"第 134 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 135\n",
						"第 135 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 136\n",
						"第 136 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 137\n",
						"第 137 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 138\n",
						"第 138 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 139\n",
						"第 139 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 140\n",
						"第 140 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 141\n",
						"第 141 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 142\n",
						"第 142 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 143\n",
						"第 143 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 144\n",
						"第 144 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 145\n",
						"第 145 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 146\n",
						"第 146 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 147\n",
						"第 147 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 148\n",
						"第 148 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 149\n",
						"第 149 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 150\n",
						"第 150 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 151\n",
						"第 151 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 152\n",
						"第 152 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 153\n",
						"第 153 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 154\n",
						"第 154 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 155\n",
						"第 155 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 156\n",
						"第 156 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 157\n",
						"第 157 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 158\n",
						"第 158 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 159\n",
						"第 159 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 160\n",
						"第 160 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 161\n",
						"第 161 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 162\n",
						"第 162 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 163\n",
						"第 163 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 164\n",
						"第 164 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 165\n",
						"第 165 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 166\n",
						"第 166 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 167\n",
						"第 167 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 168\n",
						"第 168 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 169\n",
						"第 169 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 170\n",
						"第 170 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 171\n",
						"第 171 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 172\n",
						"第 172 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 173\n",
						"第 173 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 174\n",
						"第 174 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 175\n",
						"第 175 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 176\n",
						"第 176 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 177\n",
						"第 177 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 178\n",
						"第 178 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 179\n",
						"第 179 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 180\n",
						"第 180 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 181\n",
						"第 181 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 182\n",
						"第 182 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 183\n",
						"第 183 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 184\n",
						"第 184 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 185\n",
						"第 185 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 186\n",
						"第 186 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 187\n",
						"第 187 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 188\n",
						"第 188 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 189\n",
						"第 189 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 190\n",
						"第 190 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 191\n",
						"第 191 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 192\n",
						"第 192 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 193\n",
						"第 193 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 194\n",
						"第 194 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 195\n",
						"第 195 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 196\n",
						"第 196 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 197\n",
						"第 197 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 198\n",
						"第 198 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 199\n",
						"第 199 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 200\n",
						"第 200 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 201\n",
						"第 201 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 202\n",
						"第 202 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 203\n",
						"第 203 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 204\n",
						"第 204 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 205\n",
						"第 205 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 206\n",
						"第 206 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 207\n",
						"第 207 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 208\n",
						"第 208 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 209\n",
						"第 209 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 210\n",
						"第 210 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 211\n",
						"第 211 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 212\n",
						"第 212 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 213\n",
						"第 213 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 214\n",
						"第 214 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 215\n",
						"第 215 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 216\n",
						"第 216 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 217\n",
						"第 217 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 218\n",
						"第 218 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 219\n",
						"第 219 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 220\n",
						"第 220 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 221\n",
						"第 221 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 222\n",
						"第 222 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 223\n",
						"第 223 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 224\n",
						"第 224 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 225\n",
						"第 225 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 226\n",
						"第 226 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 227\n",
						"第 227 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 228\n",
						"第 228 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 229\n",
						"第 229 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 230\n",
						"第 230 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 231\n",
						"第 231 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 232\n",
						"第 232 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 233\n",
						"第 233 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 234\n",
						"第 234 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 235\n",
						"第 235 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 236\n",
						"第 236 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 237\n",
						"第 237 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 238\n",
						"第 238 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 239\n",
						"第 239 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 240\n",
						"第 240 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 241\n",
						"第 241 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 242\n",
						"第 242 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 243\n",
						"第 243 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 244\n",
						"第 244 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 245\n",
						"第 245 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 246\n",
						"第 246 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 247\n",
						"第 247 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 248\n",
						"第 248 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 249\n",
						"第 249 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 250\n",
						"第 250 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 251\n",
						"第 251 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 252\n",
						"第 252 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 253\n",
						"第 253 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 254\n",
						"第 254 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 255\n",
						"第 255 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 256\n",
						"第 256 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 257\n",
						"第 257 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 258\n",
						"第 258 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 259\n",
						"第 259 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 260\n",
						"第 260 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 261\n",
						"第 261 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 262\n",
						"第 262 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 263\n",
						"第 263 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 264\n",
						"第 264 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 265\n",
						"第 265 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 266\n",
						"第 266 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 267\n",
						"第 267 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 268\n",
						"第 268 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 269\n",
						"第 269 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 270\n",
						"第 270 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 271\n",
						"第 271 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 272\n",
						"第 272 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 273\n",
						"第 273 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 274\n",
						"第 274 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 275\n",
						"第 275 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 276\n",
						"第 276 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 277\n",
						"第 277 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 278\n",
						"第 278 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 279\n",
						"第 279 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 280\n",
						"第 280 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 281\n",
						"第 281 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 282\n",
						"第 282 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 283\n",
						"第 283 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 284\n",
						"第 284 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 285\n",
						"第 285 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 286\n",
						"第 286 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 287\n",
						"第 287 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 288\n",
						"第 288 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 289\n",
						"第 289 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 290\n",
						"第 290 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 291\n",
						"第 291 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 292\n",
						"第 292 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 293\n",
						"第 293 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 294\n",
						"第 294 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 295\n",
						"第 295 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 296\n",
						"第 296 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 297\n",
						"第 297 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 298\n",
						"第 298 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 299\n",
						"第 299 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 300\n",
						"第 300 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 301\n",
						"第 301 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 302\n",
						"第 302 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 303\n",
						"第 303 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 304\n",
						"第 304 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 305\n",
						"第 305 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 306\n",
						"第 306 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 307\n",
						"第 307 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 308\n",
						"第 308 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 309\n",
						"第 309 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 310\n",
						"第 310 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 311\n",
						"第 311 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 312\n",
						"第 312 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 313\n",
						"第 313 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 314\n",
						"第 314 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 315\n",
						"第 315 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 316\n",
						"第 316 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 317\n",
						"第 317 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 318\n",
						"第 318 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 319\n",
						"第 319 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 320\n",
						"第 320 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 321\n",
						"第 321 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 322\n",
						"第 322 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 323\n",
						"第 323 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 324\n",
						"第 324 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 325\n",
						"第 325 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 326\n",
						"第 326 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 327\n",
						"第 327 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 328\n",
						"第 328 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 329\n",
						"第 329 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 330\n",
						"第 330 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 331\n",
						"第 331 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 332\n",
						"第 332 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 333\n",
						"第 333 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 334\n",
						"第 334 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 335\n",
						"第 335 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 336\n",
						"第 336 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 337\n",
						"第 337 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 338\n",
						"第 338 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 339\n",
						"第 339 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 340\n",
						"第 340 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 341\n",
						"第 341 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 342\n",
						"第 342 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 343\n",
						"第 343 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 344\n",
						"第 344 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 345\n",
						"第 345 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 346\n",
						"第 346 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 347\n",
						"第 347 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 348\n",
						"第 348 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 349\n",
						"第 349 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 350\n",
						"第 350 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 351\n",
						"第 351 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 352\n",
						"第 352 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 353\n",
						"第 353 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 354\n",
						"第 354 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 355\n",
						"第 355 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 356\n",
						"第 356 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 357\n",
						"第 357 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 358\n",
						"第 358 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 359\n",
						"第 359 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 360\n",
						"第 360 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 361\n",
						"第 361 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 362\n",
						"第 362 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 363\n",
						"第 363 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 364\n",
						"第 364 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 365\n",
						"第 365 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 366\n",
						"第 366 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 367\n",
						"第 367 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 368\n",
						"第 368 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 369\n",
						"第 369 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 370\n",
						"第 370 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 371\n",
						"第 371 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 372\n",
						"第 372 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 373\n",
						"第 373 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 374\n",
						"第 374 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 375\n",
						"第 375 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 376\n",
						"第 376 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 377\n",
						"第 377 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 378\n",
						"第 378 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 379\n",
						"第 379 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 380\n",
						"第 380 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 381\n",
						"第 381 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 382\n",
						"第 382 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 383\n",
						"第 383 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 384\n",
						"第 384 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 385\n",
						"第 385 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 386\n",
						"第 386 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 387\n",
						"第 387 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 388\n",
						"第 388 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 389\n",
						"第 389 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 390\n",
						"第 390 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 391\n",
						"第 391 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 392\n",
						"第 392 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 393\n",
						"第 393 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 394\n",
						"第 394 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 395\n",
						"第 395 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 396\n",
						"第 396 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 397\n",
						"第 397 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 398\n",
						"第 398 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 399\n",
						"第 399 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 400\n",
						"第 400 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 401\n",
						"第 401 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 402\n",
						"第 402 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 403\n",
						"第 403 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 404\n",
						"第 404 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 405\n",
						"第 405 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 406\n",
						"第 406 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 407\n",
						"第 407 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 408\n",
						"第 408 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 409\n",
						"第 409 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 410\n",
						"第 410 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 411\n",
						"第 411 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 412\n",
						"第 412 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 413\n",
						"第 413 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 414\n",
						"第 414 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 415\n",
						"第 415 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 416\n",
						"第 416 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 417\n",
						"第 417 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 418\n",
						"第 418 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 419\n",
						"第 419 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 420\n",
						"第 420 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 421\n",
						"第 421 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 422\n",
						"第 422 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 423\n",
						"第 423 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 424\n",
						"第 424 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 425\n",
						"第 425 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 426\n",
						"第 426 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 427\n",
						"第 427 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 428\n",
						"第 428 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 429\n",
						"第 429 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 430\n",
						"第 430 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 431\n",
						"第 431 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 432\n",
						"第 432 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 433\n",
						"第 433 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 434\n",
						"第 434 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 435\n",
						"第 435 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 436\n",
						"第 436 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 437\n",
						"第 437 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 438\n",
						"第 438 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 439\n",
						"第 439 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 440\n",
						"第 440 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 441\n",
						"第 441 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 442\n",
						"第 442 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 443\n",
						"第 443 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 444\n",
						"第 444 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 445\n",
						"第 445 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 446\n",
						"第 446 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 447\n",
						"第 447 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 448\n",
						"第 448 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 449\n",
						"第 449 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 450\n",
						"第 450 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 451\n",
						"第 451 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 452\n",
						"第 452 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 453\n",
						"第 453 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 454\n",
						"第 454 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 455\n",
						"第 455 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 456\n",
						"第 456 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 457\n",
						"第 457 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 458\n",
						"第 458 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 459\n",
						"第 459 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 460\n",
						"第 460 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 461\n",
						"第 461 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 462\n",
						"第 462 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 463\n",
						"第 463 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 464\n",
						"第 464 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 465\n",
						"第 465 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 466\n",
						"第 466 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 467\n",
						"第 467 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 468\n",
						"第 468 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 469\n",
						"第 469 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 470\n",
						"第 470 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 471\n",
						"第 471 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 472\n",
						"第 472 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 473\n",
						"第 473 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 474\n",
						"第 474 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 475\n",
						"第 475 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 476\n",
						"第 476 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 477\n",
						"第 477 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 478\n",
						"第 478 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 479\n",
						"第 479 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 480\n",
						"第 480 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 481\n",
						"第 481 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 482\n",
						"第 482 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 483\n",
						"第 483 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 484\n",
						"第 484 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 485\n",
						"第 485 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 486\n",
						"第 486 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 487\n",
						"第 487 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 488\n",
						"第 488 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 489\n",
						"第 489 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 490\n",
						"第 490 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 491\n",
						"第 491 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 492\n",
						"第 492 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 493\n",
						"第 493 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 494\n",
						"第 494 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 495\n",
						"第 495 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 496\n",
						"第 496 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 497\n",
						"第 497 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 498\n",
						"第 498 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 499\n",
						"第 499 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 500\n",
						"第 500 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 501\n",
						"第 501 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 502\n",
						"第 502 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 503\n",
						"第 503 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 504\n",
						"第 504 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 505\n",
						"第 505 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 506\n",
						"第 506 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 507\n",
						"第 507 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 508\n",
						"第 508 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 509\n",
						"第 509 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 510\n",
						"第 510 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 511\n",
						"第 511 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 512\n",
						"第 512 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 513\n",
						"第 513 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 514\n",
						"第 514 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 515\n",
						"第 515 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 516\n",
						"第 516 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 517\n",
						"第 517 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 518\n",
						"第 518 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 519\n",
						"第 519 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 520\n",
						"第 520 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 521\n",
						"第 521 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 522\n",
						"第 522 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 523\n",
						"第 523 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 524\n",
						"第 524 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 525\n",
						"第 525 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 526\n",
						"第 526 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 527\n",
						"第 527 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 528\n",
						"第 528 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 529\n",
						"第 529 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 530\n",
						"第 530 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 531\n",
						"第 531 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 532\n",
						"第 532 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 533\n",
						"第 533 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 534\n",
						"第 534 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 535\n",
						"第 535 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 536\n",
						"第 536 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 537\n",
						"第 537 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 538\n",
						"第 538 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 539\n",
						"第 539 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 540\n",
						"第 540 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 541\n",
						"第 541 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 542\n",
						"第 542 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 543\n",
						"第 543 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 544\n",
						"第 544 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 545\n",
						"第 545 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 546\n",
						"第 546 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 547\n",
						"第 547 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 548\n",
						"第 548 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 549\n",
						"第 549 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 550\n",
						"第 550 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 551\n",
						"第 551 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 552\n",
						"第 552 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 553\n",
						"第 553 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 554\n",
						"第 554 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 555\n",
						"第 555 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 556\n",
						"第 556 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 557\n",
						"第 557 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 558\n",
						"第 558 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 559\n",
						"第 559 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 560\n",
						"第 560 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 561\n",
						"第 561 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 562\n",
						"第 562 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 563\n",
						"第 563 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 564\n",
						"第 564 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 565\n",
						"第 565 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 566\n",
						"第 566 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 567\n",
						"第 567 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 568\n",
						"第 568 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 569\n",
						"第 569 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 570\n",
						"第 570 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 571\n",
						"第 571 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 572\n",
						"第 572 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 573\n",
						"第 573 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 574\n",
						"第 574 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 575\n",
						"第 575 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 576\n",
						"第 576 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 577\n",
						"第 577 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 578\n",
						"第 578 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 579\n",
						"第 579 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 580\n",
						"第 580 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 581\n",
						"第 581 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 582\n",
						"第 582 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 583\n",
						"第 583 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 584\n",
						"第 584 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 585\n",
						"第 585 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 586\n",
						"第 586 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 587\n",
						"第 587 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 588\n",
						"第 588 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 589\n",
						"第 589 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 590\n",
						"第 590 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 591\n",
						"第 591 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 592\n",
						"第 592 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 593\n",
						"第 593 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 594\n",
						"第 594 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 595\n",
						"第 595 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 596\n",
						"第 596 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 597\n",
						"第 597 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 598\n",
						"第 598 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 599\n",
						"第 599 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 600\n",
						"第 600 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 601\n",
						"第 601 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 602\n",
						"第 602 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 603\n",
						"第 603 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 604\n",
						"第 604 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 605\n",
						"第 605 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 606\n",
						"第 606 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 607\n",
						"第 607 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 608\n",
						"第 608 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 609\n",
						"第 609 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 610\n",
						"第 610 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 611\n",
						"第 611 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 612\n",
						"第 612 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 613\n",
						"第 613 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 614\n",
						"第 614 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 615\n",
						"第 615 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 616\n",
						"第 616 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 617\n",
						"第 617 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 618\n",
						"第 618 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 619\n",
						"第 619 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 620\n",
						"第 620 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 621\n",
						"第 621 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 622\n",
						"第 622 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 623\n",
						"第 623 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 624\n",
						"第 624 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 625\n",
						"第 625 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 626\n",
						"第 626 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 627\n",
						"第 627 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 628\n",
						"第 628 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 629\n",
						"第 629 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 630\n",
						"第 630 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 631\n",
						"第 631 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 632\n",
						"第 632 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 633\n",
						"第 633 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 634\n",
						"第 634 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 635\n",
						"第 635 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 636\n",
						"第 636 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 637\n",
						"第 637 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 638\n",
						"第 638 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 639\n",
						"第 639 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 640\n",
						"第 640 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 641\n",
						"第 641 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 642\n",
						"第 642 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 643\n",
						"第 643 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 644\n",
						"第 644 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 645\n",
						"第 645 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 646\n",
						"第 646 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 647\n",
						"第 647 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 648\n",
						"第 648 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 649\n",
						"第 649 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 650\n",
						"第 650 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 651\n",
						"第 651 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 652\n",
						"第 652 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 653\n",
						"第 653 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 654\n",
						"第 654 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 655\n",
						"第 655 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 656\n",
						"第 656 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 657\n",
						"第 657 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 658\n",
						"第 658 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 659\n",
						"第 659 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 660\n",
						"第 660 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 661\n",
						"第 661 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 662\n",
						"第 662 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 663\n",
						"第 663 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 664\n",
						"第 664 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 665\n",
						"第 665 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 666\n",
						"第 666 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 667\n",
						"第 667 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 668\n",
						"第 668 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 669\n",
						"第 669 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 670\n",
						"第 670 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 671\n",
						"第 671 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 672\n",
						"第 672 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 673\n",
						"第 673 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 674\n",
						"第 674 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 675\n",
						"第 675 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 676\n",
						"第 676 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 677\n",
						"第 677 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 678\n",
						"第 678 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 679\n",
						"第 679 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 680\n",
						"第 680 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 681\n",
						"第 681 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 682\n",
						"第 682 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 683\n",
						"第 683 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 684\n",
						"第 684 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 685\n",
						"第 685 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 686\n",
						"第 686 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 687\n",
						"第 687 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 688\n",
						"第 688 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 689\n",
						"第 689 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 690\n",
						"第 690 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 691\n",
						"第 691 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 692\n",
						"第 692 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 693\n",
						"第 693 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 694\n",
						"第 694 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 695\n",
						"第 695 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 696\n",
						"第 696 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 697\n",
						"第 697 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 698\n",
						"第 698 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 699\n",
						"第 699 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 700\n",
						"第 700 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 701\n",
						"第 701 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 702\n",
						"第 702 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 703\n",
						"第 703 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 704\n",
						"第 704 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 705\n",
						"第 705 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 706\n",
						"第 706 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 707\n",
						"第 707 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 708\n",
						"第 708 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 709\n",
						"第 709 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 710\n",
						"第 710 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 711\n",
						"第 711 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 712\n",
						"第 712 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 713\n",
						"第 713 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 714\n",
						"第 714 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 715\n",
						"第 715 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 716\n",
						"第 716 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 717\n",
						"第 717 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 718\n",
						"第 718 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 719\n",
						"第 719 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 720\n",
						"第 720 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 721\n",
						"第 721 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 722\n",
						"第 722 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 723\n",
						"第 723 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 724\n",
						"第 724 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 725\n",
						"第 725 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 726\n",
						"第 726 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 727\n",
						"第 727 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 728\n",
						"第 728 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 729\n",
						"第 729 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 730\n",
						"第 730 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 731\n",
						"第 731 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 732\n",
						"第 732 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 733\n",
						"第 733 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 734\n",
						"第 734 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 735\n",
						"第 735 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 736\n",
						"第 736 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 737\n",
						"第 737 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 738\n",
						"第 738 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 739\n",
						"第 739 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 740\n",
						"第 740 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 741\n",
						"第 741 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 742\n",
						"第 742 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 743\n",
						"第 743 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 744\n",
						"第 744 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 745\n",
						"第 745 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 746\n",
						"第 746 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 747\n",
						"第 747 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 748\n",
						"第 748 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 749\n",
						"第 749 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 750\n",
						"第 750 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 751\n",
						"第 751 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 752\n",
						"第 752 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 753\n",
						"第 753 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 754\n",
						"第 754 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 755\n",
						"第 755 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 756\n",
						"第 756 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 757\n",
						"第 757 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 758\n",
						"第 758 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 759\n",
						"第 759 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 760\n",
						"第 760 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 761\n",
						"第 761 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 762\n",
						"第 762 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 763\n",
						"第 763 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 764\n",
						"第 764 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 765\n",
						"第 765 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 766\n",
						"第 766 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 767\n",
						"第 767 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 768\n",
						"第 768 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 769\n",
						"第 769 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 770\n",
						"第 770 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 771\n",
						"第 771 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 772\n",
						"第 772 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 773\n",
						"第 773 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 774\n",
						"第 774 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 775\n",
						"第 775 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 776\n",
						"第 776 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 777\n",
						"第 777 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 778\n",
						"第 778 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 779\n",
						"第 779 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 780\n",
						"第 780 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 781\n",
						"第 781 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 782\n",
						"第 782 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 783\n",
						"第 783 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 784\n",
						"第 784 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 785\n",
						"第 785 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 786\n",
						"第 786 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 787\n",
						"第 787 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 788\n",
						"第 788 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 789\n",
						"第 789 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 790\n",
						"第 790 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 791\n",
						"第 791 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 792\n",
						"第 792 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 793\n",
						"第 793 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 794\n",
						"第 794 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 795\n",
						"第 795 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 796\n",
						"第 796 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 797\n",
						"第 797 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 798\n",
						"第 798 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 799\n",
						"第 799 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 800\n",
						"第 800 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 801\n",
						"第 801 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 802\n",
						"第 802 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 803\n",
						"第 803 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 804\n",
						"第 804 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 805\n",
						"第 805 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 806\n",
						"第 806 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 807\n",
						"第 807 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 808\n",
						"第 808 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 809\n",
						"第 809 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 810\n",
						"第 810 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 811\n",
						"第 811 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 812\n",
						"第 812 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 813\n",
						"第 813 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 814\n",
						"第 814 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 815\n",
						"第 815 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 816\n",
						"第 816 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 817\n",
						"第 817 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 818\n",
						"第 818 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 819\n",
						"第 819 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 820\n",
						"第 820 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 821\n",
						"第 821 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 822\n",
						"第 822 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 823\n",
						"第 823 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 824\n",
						"第 824 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 825\n",
						"第 825 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 826\n",
						"第 826 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 827\n",
						"第 827 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 828\n",
						"第 828 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 829\n",
						"第 829 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 830\n",
						"第 830 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 831\n",
						"第 831 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 832\n",
						"第 832 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 833\n",
						"第 833 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 834\n",
						"第 834 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 835\n",
						"第 835 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 836\n",
						"第 836 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 837\n",
						"第 837 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 838\n",
						"第 838 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 839\n",
						"第 839 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 840\n",
						"第 840 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 841\n",
						"第 841 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 842\n",
						"第 842 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 843\n",
						"第 843 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 844\n",
						"第 844 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 845\n",
						"第 845 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 846\n",
						"第 846 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 847\n",
						"第 847 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 848\n",
						"第 848 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 849\n",
						"第 849 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 850\n",
						"第 850 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 851\n",
						"第 851 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 852\n",
						"第 852 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 853\n",
						"第 853 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 854\n",
						"第 854 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 855\n",
						"第 855 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 856\n",
						"第 856 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 857\n",
						"第 857 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 858\n",
						"第 858 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 859\n",
						"第 859 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 860\n",
						"第 860 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 861\n",
						"第 861 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 862\n",
						"第 862 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 863\n",
						"第 863 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 864\n",
						"第 864 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 865\n",
						"第 865 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 866\n",
						"第 866 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 867\n",
						"第 867 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 868\n",
						"第 868 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 869\n",
						"第 869 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 870\n",
						"第 870 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 871\n",
						"第 871 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 872\n",
						"第 872 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 873\n",
						"第 873 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 874\n",
						"第 874 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 875\n",
						"第 875 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 876\n",
						"第 876 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 877\n",
						"第 877 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 878\n",
						"第 878 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 879\n",
						"第 879 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 880\n",
						"第 880 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 881\n",
						"第 881 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 882\n",
						"第 882 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 883\n",
						"第 883 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 884\n",
						"第 884 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 885\n",
						"第 885 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 886\n",
						"第 886 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 887\n",
						"第 887 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 888\n",
						"第 888 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 889\n",
						"第 889 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 890\n",
						"第 890 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 891\n",
						"第 891 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 892\n",
						"第 892 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 893\n",
						"第 893 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 894\n",
						"第 894 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 895\n",
						"第 895 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 896\n",
						"第 896 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 897\n",
						"第 897 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 898\n",
						"第 898 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 899\n",
						"第 899 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 900\n",
						"第 900 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 901\n",
						"第 901 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 902\n",
						"第 902 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 903\n",
						"第 903 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 904\n",
						"第 904 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 905\n",
						"第 905 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 906\n",
						"第 906 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 907\n",
						"第 907 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 908\n",
						"第 908 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 909\n",
						"第 909 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 910\n",
						"第 910 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 911\n",
						"第 911 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 912\n",
						"第 912 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 913\n",
						"第 913 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 914\n",
						"第 914 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 915\n",
						"第 915 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 916\n",
						"第 916 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 917\n",
						"第 917 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 918\n",
						"第 918 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 919\n",
						"第 919 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 920\n",
						"第 920 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 921\n",
						"第 921 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 922\n",
						"第 922 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 923\n",
						"第 923 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 924\n",
						"第 924 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 925\n",
						"第 925 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 926\n",
						"第 926 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 927\n",
						"第 927 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 928\n",
						"第 928 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 929\n",
						"第 929 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 930\n",
						"第 930 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 931\n",
						"第 931 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 932\n",
						"第 932 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 933\n",
						"第 933 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 934\n",
						"第 934 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 935\n",
						"第 935 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 936\n",
						"第 936 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 937\n",
						"第 937 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 938\n",
						"第 938 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 939\n",
						"第 939 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 940\n",
						"第 940 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 941\n",
						"第 941 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 942\n",
						"第 942 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 943\n",
						"第 943 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 944\n",
						"第 944 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 945\n",
						"第 945 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 946\n",
						"第 946 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 947\n",
						"第 947 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 948\n",
						"第 948 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 949\n",
						"第 949 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 950\n",
						"第 950 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 951\n",
						"第 951 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 952\n",
						"第 952 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 953\n",
						"第 953 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 954\n",
						"第 954 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 955\n",
						"第 955 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 956\n",
						"第 956 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 957\n",
						"第 957 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 958\n",
						"第 958 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 959\n",
						"第 959 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 960\n",
						"第 960 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 961\n",
						"第 961 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 962\n",
						"第 962 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 963\n",
						"第 963 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 964\n",
						"第 964 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 965\n",
						"第 965 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 966\n",
						"第 966 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 967\n",
						"第 967 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 968\n",
						"第 968 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 969\n",
						"第 969 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 970\n",
						"第 970 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 971\n",
						"第 971 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 972\n",
						"第 972 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 973\n",
						"第 973 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 974\n",
						"第 974 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 975\n",
						"第 975 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 976\n",
						"第 976 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 977\n",
						"第 977 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 978\n",
						"第 978 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 979\n",
						"第 979 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 980\n",
						"第 980 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 981\n",
						"第 981 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 982\n",
						"第 982 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 983\n",
						"第 983 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 984\n",
						"第 984 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 985\n",
						"第 985 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 986\n",
						"第 986 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 987\n",
						"第 987 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 988\n",
						"第 988 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 989\n",
						"第 989 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 990\n",
						"第 990 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 991\n",
						"第 991 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 992\n",
						"第 992 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 993\n",
						"第 993 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 994\n",
						"第 994 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 995\n",
						"第 995 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 996\n",
						"第 996 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 997\n",
						"第 997 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 998\n",
						"第 998 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
						"epoch： 999\n",
						"第 999 个epoch\n",
						"train loss: nan\n",
						"test loss: tensor(350.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
					]
				},
				{
					"data": {
						"image/png": "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",
						"text/plain": [
							"<Figure size 1000x500 with 1 Axes>"
						]
					},
					"metadata": {},
					"output_type": "display_data"
				},
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"(302, 1)\n",
						"(302, 1)\n"
					]
				},
				{
					"data": {
						"image/png": "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",
						"text/plain": [
							"<Figure size 1000x500 with 1 Axes>"
						]
					},
					"metadata": {},
					"output_type": "display_data"
				}
			],
			"source": [
				"from sklearn.datasets import fetch_openml\n",
				"\n",
				"\n",
				"from sklearn.preprocessing import StandardScaler\n",
				"from sklearn.utils import shuffle\n",
				"from torch import nn\n",
				"import torch\n",
				" \n",
				"import matplotlib.pyplot as plt\n",
				"import numpy as np\n",
				"import pandas as pd\n",
				" \n",
				"from sklearn.preprocessing import scale\n",
				"from torchsummary import summary\n",
				"from matplotlib.font_manager import FontProperties\n",
				"\n",
				"\n",
				"class linear(nn.Module):\n",
				"    def __init__(self,input,output):\n",
				"        super(linear, self).__init__()\n",
				"        self.net1=nn.Linear(input,100)\n",
				"        self.net2=nn.ReLU()\n",
				"        self.net3=nn.Linear(100,50)\n",
				"        self.net4=nn.ReLU()\n",
				"        self.net5=nn.Linear(50,1)\n",
				"    def forward(self,input):\n",
				"\n",
				"        x=self.net1(input)\n",
				"        x=self.net2(x)\n",
				"        x=self.net3(x)\n",
				"        x=self.net4(x)\n",
				"        x=self.net5(x)\n",
				"        return x\n",
				"        \n",
				"def tensor_condition(x):     \n",
				"    print(\"Shape:\", x.shape)\n",
				"    print(\"Data type:\", x.dtype)\n",
				"    print(\"Device:\", x.device)\n",
				"    print(\"Requires grad:\", x.requires_grad)\n",
				"\n",
				"if __name__ == '__main__':\n",
				"    hg=pd.read_csv('data\\hg1.csv')\n",
				"    #print(hg.describe())\n",
				"    y=hg['Hg_conc'].to_numpy().reshape(-1,1)# 设置因变量\n",
				"    x=hg.drop('Hg_conc',axis=1,inplace=False).to_numpy()\n",
				"    print(y.shape)\n",
				"    print(x.shape)\n",
				"\n",
				"      ################################################################\n",
				"    #数据预处理#\n",
				"    ## 1. 标准化因变量#，在此标准化非常重要，没有标准化得到模型基本不能使用\n",
				"    scaler=StandardScaler()\n",
				"    x=scaler.fit_transform(x)\n",
				"  \n",
				"    ## 2. 数据打乱顺序\n",
				"    x,y=shuffle(x,y)\n",
				"    ## 3. 划分train，test\n",
				"    x_size=x.shape[0]\n",
				"    train_size=int(x_size*0.6)\n",
				"    x_train,x_test,y_train,y_test=x[0:train_size,:],x[train_size:,:],y[0:train_size,:],y[train_size:,:]\n",
				"    print(\"训练集形状\",x_train.shape,y_train.shape)\n",
				"    print(\"测试集形状\",x_test.shape,y_test.shape)\n",
				"    #数据载入tensor\n",
				"    ## 1.转换numpy到tensor张量\n",
				"    x_train =torch.from_numpy(x_train)\n",
				"    y_train =torch.from_numpy(y_train)\n",
				"    x_test =torch.from_numpy(x_test)\n",
				"    y_test =torch.from_numpy(y_test)\n",
				"    ## 判断cuda是否可用，选择gpu或cpu载入数据处理\n",
				"    device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
				"    print(device)\n",
				"    print('实现训练集，测试集因变量、自变量的tensor转换')\n",
				"    x_train=x_train.to(torch.float32).to(device)\n",
				"    y_train=y_train.to(torch.float32).to(device)\n",
				"    x_test=x_test.to(torch.float32).to(device)\n",
				"    y_test=y_test.to(torch.float32).to(device)\n",
				"    #tensor_condition(x_train)\n",
				"    #tensor_condition(y_train)\n",
				"    #tensor_condition(x_test)\n",
				"    #tensor_condition(y_test)\n",
				"    ################################################################\n",
				"    ## 1. 构建模型实例,注意要载入gpu或cpu中与数据对应,summary输出网络的结构信息\n",
				"    net=linear(input=19,output=1).to(device)\n",
				" \n",
				"    summary(net, input_size=(19,))\n",
				"    ## 2.超参设置\n",
				"    learning_rate=0.02\n",
				"    epochs=1000\n",
				"    batch_size=20\n",
				"    total_steps=int(x_train.shape[0]/batch_size)\n",
				"    print(\"完成一个epoch，需要读取\",total_steps,\"个batchs\")\n",
				"    ## 3.创建损失函数，优化函数实例\n",
				"    loss_fn=nn.MSELoss()\n",
				"    opt=torch.optim.Adam(params=net.parameters(),lr=learning_rate)\n",
				"    ## 4.创建list记录训练loss，以及最后的test loss，作为对比\n",
				"    train_loss_list=[]\n",
				"    test_loss_list=[]\n",
				"    train_acc_list=[]\n",
				"    test_acc_list=[]\n",
				"    step_loss=[]\n",
				"    ## 4.训练模型\n",
				"    for step in range(epochs):#循环1000个epochs\n",
				"        print(\"epoch：\",step)\n",
				"        for i in range(total_steps):#内部完成基于batch的一个epochs数据读取\n",
				"            x_train_batch=x_train[step * batch_size:(step + 1) * batch_size, :]\n",
				"            y_train_batch=y_train[step * batch_size:(step + 1) * batch_size, :]\n",
				"       \n",
				" \n",
				"          \n",
				"            #y_train=y_train.to(torch.float32)\n",
				"            #x_train=x_train.to(torch.float32)\n",
				"            y_pred=net(x_train_batch.to(device))\n",
				"            loss=loss_fn(y_pred,y_train_batch)\n",
				"            #print(loss.cpu().detach().numpy())\n",
				"            step_loss.append(loss.cpu().detach().numpy())#记录每一个batch的loss值\n",
				"            opt.zero_grad()\n",
				"            loss.backward()\n",
				"            opt.step()\n",
				"       \n",
				"        train_loss=np.mean(step_loss)#计算每一个epoch的平均loss\n",
				"        train_loss_list.append(train_loss)\n",
				"        y_predict=net(x_test)\n",
				"        test_loss=loss_fn(y_predict, y_test)\n",
				"        test_loss_list.append(test_loss.cpu().detach().numpy())\n",
				"  \n",
				"        print(\"第\",step,\"个epoch\")\n",
				"        print(\"train loss:\",train_loss)\n",
				"        print(\"test loss:\",test_loss)\n",
				"        \n",
				"    fig = plt.gcf()\n",
				"    fig.set_size_inches(10, 5)\n",
				"\n",
				"    plt.xlabel('Epochs', fontsize=15)\n",
				"    plt.ylabel('Loss', fontsize=15)\n",
				"    plt.plot(train_loss_list, 'blue', label='Train loss')\n",
				"    plt.plot(test_loss_list, 'red', label='Test loss')\n",
				"    plt.legend(loc='best')\n",
				"    plt.title('Training and Test loss', fontsize=15)\n",
				"    plt.show()\n",
				"      ################################################################\n",
				"    # 通过x_test预测数据并与实际值对比\n",
				"    y_predict=net.forward(x_test)\n",
				"    y_pred=y_predict.cpu().detach().numpy()\n",
				"    y_t=y_test.cpu().detach().numpy()\n",
				"    print(y_pred.shape)\n",
				"    print(y_t.shape)\n",
				"    predciton=np.arange(len(y_pred))\n",
				"    \n",
				"    fig = plt.gcf()\n",
				"    fig.set_size_inches(10, 5)\n",
				"    plt.title('Target and prediciton value', fontsize=15)\n",
				"\n",
				"    plt.scatter(predciton,y_pred,color='red',label='Prediciton')\n",
				"    plt.scatter(predciton,y_t,color='blue',label='target')\n",
				" "
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"# Dataloader 与 DataSet \n",
				"为了统一数据加载和处理代码，pytorch 提供了两个类用于处理数据加载，分别是 torch.utils.data.DataSet 和 torch.utils.data.DataLoader，\n",
				"\n",
				"通过这两个类可以使得数据集加载和预处理代码与模型训练代码脱钩，从而获得更好的代码模块化和代码可读性。\n",
				">[pytorch中参考] https://pytorch.org/tutorials/beginner/basics/data_tutorial.html\n",
				"\n",
				"----\n",
				"Creating a Custom Dataset for your files\n",
				"为文件创建自定义数据集\n",
				"A custom Dataset class must implement three functions: __init__, __len__, and __getitem__.  "
			]
		},
		{
			"cell_type": "code",
			"execution_count": 4,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"<zip object at 0x000001F366E75680>\n"
					]
				}
			],
			"source": [
				"r=zip(([1, 2, 3], 'a'), ([4, 5, 6], 'b'), ([7, 8, 9], 'c'))\n",
				"print(r)"
			]
		},
		{
			"attachments": {},
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"### 实验1.1 多元回归函数 进阶\n",
				"\n",
				"在pytorch实现多元回归函数基础上，对函数进行进一步优化，并上传kaggle\n",
				"\n",
				"1. 使用pythroch 的 Dataloader数据包装器包装数据\n",
				"2. 加入权重衰减\n",
				"3. 加入dropout\n",
				"4. 实现k折交叉验证\n",
				"\n",
				"---\n",
				"\n",
				"参考[权重衰减 dropout](https://tangshusen.me/Dive-into-DL-PyTorch/#/chapter03_DL-basics/3.13_dropout)\n",
				"\n",
				"---\n",
				"0. 首先应该进行数据划分，再进行dataset创建和dataloader处理，可采用sklearn中数据划分方法train_test_split\n",
				"1. DataLoader Dataset\n",
				"\n",
				"* Dataset的作用是通过Dataset将现有数据进行包装；\n",
				"* 包装好的数据就可以被DataLoader调用，调用的方法中就包括确定批次batch-size，是否shuffle等，是否normalization\n",
				"#### 1. DataSet DataLoader\n",
				"1.1 Dataset\n",
				"\n",
				"torch.utils.data.Dataset是代表这一数据的抽象类（也就是基类）。我们可以通过继承和重写这个抽象类实现自己的数据类，只需要定义__len__和__getitem__这个两个函数\n",
				"\n",
				"如果在类中定义了__getitem__()方法，那么实例对象（假设为P）就可以这样P[key]取值。当实例对象做P[key]操作时，就会调用类中的__getitem__()方法。\n",
				"* The __len__ function returns the number of samples in our dataset.\n",
				"* The __getitem__ function loads and returns a sample from the dataset at the given index idx. 根据索引返回张量数据\n",
				" \n",
				"[参考1](https://blog.csdn.net/He3he3he/article/details/105441083)\n",
				"\n",
				"[参考2](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html)\n",
				"\n",
				"[magic method](https://zhuanlan.zhihu.com/p/329962624)\n",
				"\n",
				"1.2 DataLoader\n",
				"\n",
				"定义Dataset后，就可以将dataset实例喂给Dataloader，完成shuffer，batchsize工作，特别是batchsize，简化了批次夺取数据的代码。\n",
				"Preparing your data for training with DataLoaders\n",
				"The Dataset retrieves our dataset’s features and labels one sample at a time. While training a model, we typically want to pass samples in “minibatches”, reshuffle the data at every epoch to reduce model overfitting, and use Python’s multiprocessing to speed up data retrieval.\n",
				"\n",
				"DataLoader is an iterable that abstracts this complexity for us in an easy API.\n",
				"\n",
				"We have loaded that dataset into the DataLoader and can iterate through the dataset as needed. Each iteration below returns a batch of train_features and train_labels (containing batch_size=64 features and labels respectively). Because we specified shuffle=True, after we iterate over all batches the data is shuffled \n",
				"\n",
				"#### 2. weight_decay\n",
				"权重衰减参考class1，简单就是通过在loss函数权参平方和值乘以超参/2，改善方程过拟合现象\n",
				"> 权值衰减一直以来是一种经常被使用的抑制过拟合方法，该方法通过在学习过程中对大的权重进行惩罚，来抑制过拟合。\n",
				"**很多过拟合就是因为权重参数取值过大照成的**\n",
				"\n",
				"\n",
				"[参考](https://blog.csdn.net/program_developer/article/details/80867468)\n",
				"\n",
				"L2正则化的目的就是为了让权重衰减到更小的值，在一定程度上减少模型过拟合的问题，所以权重衰减也叫L2正则化。\n",
				"\n",
				"对应公式：\n",
				"\n",
				"$$C=C_0+\\frac{\\lambda}{2} \\times \\sum_w {w^2} \\cdots  (1)$$\n",
				"\n",
				"其中$C,C_0$分别为原误差函数、更新后误差函数$\\sum_w {w^2}$为所有层中权参和,n为训练集数\n",
				"\n",
				"pytorch中通过在优化函数中指定weight_decay超参的值就可以实现L2正则化\n",
				"```python\n",
				"optimizer = torch.optim.SGD(params=net.parameters(), lr=lr, weight_decay=wd)\n",
				"```\n",
				"如果只想针对某些参数，分别为它们构造一个优化器实例即可：\n",
				"```python\n",
				"optimizer_w = torch.optim.SGD(params=[net.weight], lr=lr, weight_decay=wd) # 对权重参数衰减\n",
				"optimizer_b = torch.optim.SGD(params=[net.bias], lr=lr)  # 不对偏差参数衰减\n",
				"```\n",
				"\n",
				"---\n",
				"\n",
				"#### 3. Dropout\n",
				"pytorch中推荐使用 nn.Dropout，而不使用nn.functional.dropout函数。因为一般只有训练时才使用 Dropout，在验证或测试时不需要使用 Dropout。使用 nn.Dropout时，如果调用 model.eval() ，模型的 Dropout 层都会关闭；但如果使用 nn.functional.dropout，在调用 model.eval() 时，不会关闭 Dropout。\n",
				"> * [参考](https://zhuanlan.zhihu.com/p/575456981)\n",
				"\n",
				"\n",
				"----\n",
				" **同优化前后的多元函数对比，可以发现过拟合现象得到了很大改善**\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 28,
			"metadata": {},
			"outputs": [],
			"source": [
				"def loss_fig(trian_loss_list,test_loss_list):       \n",
				"        fig = plt.gcf()\n",
				"        fig.set_size_inches(10, 5)\n",
				"\n",
				"        plt.xlabel('Epochs', fontsize=15)\n",
				"        plt.ylabel('Loss', fontsize=15)\n",
				"        plt.plot(train_loss_list, 'blue', label='Train loss')\n",
				"        plt.plot(test_loss_list, 'red', label='Test loss')\n",
				"        plt.legend(loc='best')\n",
				"        plt.title('Training and Test loss', fontsize=15)\n",
				"        plt.show()"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				" \n",
				"from torch.utils.data import Dataset, DataLoader\n",
				"import torch \n",
				"import torch.nn as nn \n",
				"import torch.functional as F\n",
				"from sklearn.model_selection import train_test_split as split\n",
				"import numpy as np \n",
				"from sklearn.preprocessing import StandardScaler\n",
				"\n",
				"class MyNet2(nn.Module):\n",
				"    def __init__(self,input,hidden,output,drop_p=0.5):\n",
				"        super(MyNet2,self).__init__()\n",
				"        \n",
				"        self.l1=nn.Linear(input,hidden)\n",
				"        self.drop1=nn.Dropout(p=drop_p)\n",
				"        self.r1=nn.ReLU()\n",
				"        self.l2=nn.Linear(hidden,hidden)\n",
				"        self.drop2=nn.Dropout(p=drop_p)\n",
				"        self.r2=nn.ReLU()\n",
				"        self.l3=nn.Linear(hidden,output)\n",
				"        self.drop3=nn.Dropout(p=drop_p)\n",
				"        self.r3=nn.ReLU()\n",
				"    \n",
				"    def forward(self,x):\n",
				"        x=self.l1(x)\n",
				"        x=self.drop1(x)\n",
				"        x=self.r1(x)\n",
				"        x=self.l2(x) \n",
				"        x=self.drop2(x)\n",
				"        x=self.r2(x)\n",
				"        x=self.drop3(x)\n",
				"        x=self.r3(x)\n",
				"        return x\n",
				"    \n",
				"class MyDataset(Dataset):\n",
				"    def __init__(self,data,target,device='cuda') -> None:\n",
				"        super().__init__()\n",
				"        self.len=len(data)\n",
				"        self.data=torch.from_numpy(data).float().to(device)#注意数据类型转换\n",
				"        self.target=torch.from_numpy(target).float().to(device)#注意数据类型转换\n",
				"        \n",
				"    def __len__(self) -> int:\n",
				"        return self.len\n",
				"    \n",
				"    def __getitem__(self,index):\n",
				"        return self.data[index],self.target[index]\n",
				"\n",
				"\n",
				"        \n",
				"if __name__ == '__main__':\n",
				"    try:\n",
				"        print(\" 载入数据tpye\",type(boston))\n",
				"    except NameError:\n",
				"        boston = load_boston()                                \n",
				"        print(\"载入数据tpye\",type(boston))\n",
				"\n",
				"    #获取数据键\n",
				"    print(boston.keys())\n",
				"    #print(\"数据集描述：\",boston['DESCR'])\n",
				"    print(\"自变量多元数据：\")\n",
				"    print(boston['feature_names'])\n",
				"    print(boston['data'][0:1])\n",
				"    #print(\"因变量：\")\n",
				"    #print(boston['target'])\n",
				"    ################################################################\n",
				"    #因变量自变量提取#\n",
				"    x=boston['data'].values\n",
				"    print(\"the shape of x\",x.shape)\n",
				"    print(\"自变量数据类型：\",type(x),\"数据形状：\",x.shape)\n",
				"     \n",
				"    y=boston['target'].values.reshape(-1,1)\n",
				"    print(\"因变量数据类型：\",type(y),\"数据形状：\",y.shape)\n",
				"    ################################################################\n",
				"    #对变量进行标准化\n",
				"    scaler=StandardScaler()\n",
				"    x=scaler.fit_transform(x)\n",
				"    #数据划分#\n",
				"    x_train,x_test,y_train,y_test=split(x,y,test_size=0.3,random_state=6)\n",
				"    #############################使用DataSet包装数据，DataLoader读取数据###################################\n",
				"    ################################并载入本机gpu或cpu################################`\n",
				"    device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
				"    print(\"current device: \" + device)\n",
				"    train_data=MyDataset(x_train,y_train,device=device)\n",
				"    test_data=MyDataset(x_test,y_test)\n",
				" \n",
				"    print(\"数据集长度：{}\".format(train_data.len))\n",
				"    train_data_loader=DataLoader(train_data,shuffle=True,batch_size=20)\n",
				"    test_data_loader=DataLoader(test_data,shuffle=False,batch_size=20)\n",
				"    #x,y=next(iter(train_data_loader))#iter调用train_data_loader de 调用__iter__()方法，该方法返回一个迭代器。然后，next()在该迭代器上调用__next__()方法以获得第一次迭代。再次运行next()将获得迭代器的第二项，依此类推。\n",
				"    print(\"dataloder 处理后，一个batch size的长度：\",len(x))\n",
				"    ################################super parameters################################\n",
				"    learning_rate=0.02\n",
				"    epochs=100\n",
				"    weight_decay=0.005\n",
				"    ################################create modle,opt,loss_fn################################\n",
				"    net=MyNet2(input=13,hidden=15,output=1)\n",
				"    net.to(device)\n",
				"    opt=torch.optim.Adam(params=net.parameters(),lr=learning_rate,weight_decay=weight_decay)\n",
				"    loss_fn=nn.MSELoss()\n",
				"    ################################create loss accury list###################################\n",
				"    test_batch_loss=[]\n",
				"    train_batch_loss=[]\n",
				"    train_epoch_loss_list=[]\n",
				"    test_epoch_loss_list=[]\n",
				"    ################################训练模型，注意载入数据时候的dataloader 方法\n",
				"    for epoch in range(epochs):\n",
				"        for x_batch,y_batch in train_data_loader:# 每次读取一个batch，循环遍历一次epoch\n",
				"  \n",
				"            y_batch_pred=net(x_batch)\n",
				"            loss=loss_fn(y_batch_pred,y_batch)\n",
				"            opt.zero_grad()\n",
				"            loss.backward()\n",
				"            opt.step()\n",
				"            train_batch_loss.append(loss.cpu().detach().numpy())\n",
				"        train_epoch_loss=np.mean(train_batch_loss)\n",
				"        train_epoch_loss_list.append(train_epoch_loss)\n",
				"        \n",
				"        \n",
				"        net.eval()# 由于dropout存在在进行test的时候，需要关闭droput层以进行测试\n",
				"        for x_batch,y_batch in test_data_loader:# 每次读取一个batch，循环遍历一次epoch\n",
				"\n",
				"            y_batch_pred=net(x_batch)\n",
				"            loss=loss_fn(y_batch_pred,y_batch)\n",
				"            opt.zero_grad()\n",
				"            loss.backward()\n",
				"            opt.step()\n",
				"            test_batch_loss.append(loss.cpu().detach().numpy())       \n",
				"        \n",
				"        test_epoch_loss=np.mean(test_batch_loss)\n",
				"        test_epoch_loss_list.append(test_epoch_loss)\n",
				"\n",
				"        if epoch%10==0:\n",
				"           print(\"第{}次epoch的train loss为：{}\".format(epoch,train_epoch_loss))\n",
				"           print(\"第{}次epoch的test loss为：{}\".format( epoch,test_epoch_loss))\n",
				"           print(\"################################\")\n",
				"    loss_fig(train_epoch_loss_list,test_epoch_loss_list)\n",
				"            \n",
				"            \n",
				"        \n",
				"    "
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"### 实验1.2  环境科学多元函数建模\n",
				"\n",
				"实验目的： \n",
				"\n",
				"在之前环境科学数据实验基础上\n",
				"\n",
				"1. 加入dropout，L2，改善过拟合现象\n",
				"2. 增加准确率曲线\n",
				"3。 使用dataset，dataloader\n",
				"4. 使用交叉验证方法（由于数据量过小）\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 7,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"the lenght of dataset 753\n",
						"the length of train size is 602,  test size is 151\n",
						"R^2 Score: -21.60496563767013\n",
						"Epoch 1/500.. Train loss: 282.4595.. Test loss: 244.1742\n",
						"R^2 Score: -7.026420394924468\n",
						"Epoch 2/500.. Train loss: 254.4564.. Test loss: 239.0384\n",
						"R^2 Score: -21.498866435698787\n",
						"Epoch 3/500.. Train loss: 231.0630.. Test loss: 257.9426\n",
						"R^2 Score: -16.730943882349205\n",
						"Epoch 4/500.. Train loss: 225.7347.. Test loss: 257.2349\n",
						"R^2 Score: -1.8549396306293255\n",
						"Epoch 5/500.. Train loss: 254.6168.. Test loss: 281.4932\n",
						"R^2 Score: -4.156304685077166\n",
						"Epoch 6/500.. Train loss: 221.7441.. Test loss: 252.1355\n",
						"R^2 Score: -8.064842055253623\n",
						"Epoch 7/500.. Train loss: 219.6005.. Test loss: 252.4756\n",
						"R^2 Score: -3.071234097266996\n",
						"Epoch 8/500.. Train loss: 229.0547.. Test loss: 269.4002\n",
						"R^2 Score: -1.165152379563497\n",
						"Epoch 9/500.. Train loss: 216.4250.. Test loss: 295.8909\n",
						"R^2 Score: -3.4360174760076667\n",
						"Epoch 10/500.. Train loss: 223.6043.. Test loss: 263.3299\n",
						"R^2 Score: -1.8718211753340421\n",
						"Epoch 11/500.. Train loss: 211.0253.. Test loss: 276.3903\n",
						"R^2 Score: -1.7149646204241003\n",
						"Epoch 12/500.. Train loss: 190.9436.. Test loss: 274.2803\n",
						"R^2 Score: -10.759553479104222\n",
						"Epoch 13/500.. Train loss: 217.6142.. Test loss: 246.2688\n",
						"R^2 Score: -2.531810613890326\n",
						"Epoch 14/500.. Train loss: 212.5024.. Test loss: 274.2182\n",
						"R^2 Score: -16.068624060561078\n",
						"Epoch 15/500.. Train loss: 194.9005.. Test loss: 256.1305\n",
						"R^2 Score: -4.2020081305898325\n",
						"Epoch 16/500.. Train loss: 222.9656.. Test loss: 282.7113\n",
						"R^2 Score: -2.8740799708124984\n",
						"Epoch 17/500.. Train loss: 189.4544.. Test loss: 268.8644\n",
						"R^2 Score: -7.678529641684962\n",
						"Epoch 18/500.. Train loss: 197.4004.. Test loss: 257.2132\n",
						"R^2 Score: -1.5179183702484358\n",
						"Epoch 19/500.. Train loss: 189.7298.. Test loss: 311.9585\n",
						"R^2 Score: -6.902131786448286\n",
						"Epoch 20/500.. Train loss: 180.4879.. Test loss: 271.5968\n",
						"R^2 Score: -4.956994323813349\n",
						"Epoch 21/500.. Train loss: 212.1713.. Test loss: 259.3324\n",
						"R^2 Score: -2.8960843091438027\n",
						"Epoch 22/500.. Train loss: 229.8508.. Test loss: 290.2560\n",
						"R^2 Score: -2.418205694698941\n",
						"Epoch 23/500.. Train loss: 182.1744.. Test loss: 282.4899\n",
						"R^2 Score: -2.4144409670491886\n",
						"Epoch 24/500.. Train loss: 181.8982.. Test loss: 264.8543\n",
						"R^2 Score: -1.2407415456538526\n",
						"Epoch 25/500.. Train loss: 187.9745.. Test loss: 309.3261\n",
						"R^2 Score: -7.555735601032675\n",
						"Epoch 26/500.. Train loss: 194.4902.. Test loss: 220.4396\n",
						"R^2 Score: -4.502673814405409\n",
						"Epoch 27/500.. Train loss: 223.0934.. Test loss: 257.3365\n",
						"R^2 Score: -7.314762223261482\n",
						"Epoch 28/500.. Train loss: 212.5320.. Test loss: 255.0127\n",
						"R^2 Score: -12.423228667843793\n",
						"Epoch 29/500.. Train loss: 206.1910.. Test loss: 262.7552\n",
						"R^2 Score: -1.5556238866914134\n",
						"Epoch 30/500.. Train loss: 188.6209.. Test loss: 289.7332\n",
						"R^2 Score: -4.476241180007166\n",
						"Epoch 31/500.. Train loss: 214.1977.. Test loss: 266.2602\n",
						"R^2 Score: -5.8978221084944\n",
						"Epoch 32/500.. Train loss: 181.5151.. Test loss: 273.8407\n",
						"R^2 Score: -5.075260457201232\n",
						"Epoch 33/500.. Train loss: 195.0134.. Test loss: 266.5316\n",
						"R^2 Score: -2.331760923104259\n",
						"Epoch 34/500.. Train loss: 203.7580.. Test loss: 253.5302\n",
						"R^2 Score: -11.351728672486805\n",
						"Epoch 35/500.. Train loss: 171.4441.. Test loss: 263.8263\n",
						"R^2 Score: -2.8818550261848968\n",
						"Epoch 36/500.. Train loss: 178.2275.. Test loss: 289.2414\n",
						"R^2 Score: -2.962976345629921\n",
						"Epoch 37/500.. Train loss: 188.6874.. Test loss: 292.7564\n",
						"R^2 Score: -3.86858325682981\n",
						"Epoch 38/500.. Train loss: 195.4067.. Test loss: 252.0163\n",
						"R^2 Score: -3.0441512532301385\n",
						"Epoch 39/500.. Train loss: 213.3966.. Test loss: 299.7042\n",
						"R^2 Score: -8.224594517900547\n",
						"Epoch 40/500.. Train loss: 214.4864.. Test loss: 263.0387\n",
						"R^2 Score: -2.3524736389072176\n",
						"Epoch 41/500.. Train loss: 204.4725.. Test loss: 261.7414\n",
						"R^2 Score: -2.68811794671181\n",
						"Epoch 42/500.. Train loss: 173.1594.. Test loss: 254.2439\n",
						"R^2 Score: -4.66644389552527\n",
						"Epoch 43/500.. Train loss: 184.5317.. Test loss: 258.2474\n",
						"R^2 Score: -1.855496838234361\n",
						"Epoch 44/500.. Train loss: 187.4108.. Test loss: 267.3925\n",
						"R^2 Score: -6.3428549700692995\n",
						"Epoch 45/500.. Train loss: 172.8152.. Test loss: 253.2414\n",
						"R^2 Score: -1.792287303837261\n",
						"Epoch 46/500.. Train loss: 185.5363.. Test loss: 307.3764\n",
						"R^2 Score: -2.758478614058957\n",
						"Epoch 47/500.. Train loss: 180.1624.. Test loss: 276.9410\n",
						"R^2 Score: -4.079078729566549\n",
						"Epoch 48/500.. Train loss: 189.8807.. Test loss: 281.9332\n",
						"R^2 Score: -1.5941056031062035\n",
						"Epoch 49/500.. Train loss: 193.4386.. Test loss: 318.3542\n",
						"R^2 Score: -8.55107640464153\n",
						"Epoch 50/500.. Train loss: 173.2254.. Test loss: 248.2264\n",
						"R^2 Score: -3.334445723860018\n",
						"Epoch 51/500.. Train loss: 171.2259.. Test loss: 266.3438\n",
						"R^2 Score: -5.511091698015958\n",
						"Epoch 52/500.. Train loss: 164.0755.. Test loss: 277.8909\n",
						"R^2 Score: -3.247478831438384\n",
						"Epoch 53/500.. Train loss: 171.0740.. Test loss: 245.9342\n",
						"R^2 Score: -8.084916412974659\n",
						"Epoch 54/500.. Train loss: 161.2770.. Test loss: 272.3103\n",
						"R^2 Score: -2.093877703574937\n",
						"Epoch 55/500.. Train loss: 149.7813.. Test loss: 303.0415\n",
						"R^2 Score: -1.3488008568577858\n",
						"Epoch 56/500.. Train loss: 160.7342.. Test loss: 317.8302\n",
						"R^2 Score: -7.801418152701817\n",
						"Epoch 57/500.. Train loss: 157.8974.. Test loss: 249.9442\n",
						"R^2 Score: -1.1810480073181449\n",
						"Epoch 58/500.. Train loss: 178.0727.. Test loss: 332.8726\n",
						"R^2 Score: -5.277152018931459\n",
						"Epoch 59/500.. Train loss: 189.2341.. Test loss: 262.5297\n",
						"R^2 Score: -4.071468020263958\n",
						"Epoch 60/500.. Train loss: 203.1533.. Test loss: 260.7492\n",
						"R^2 Score: -1.1744713736481094\n",
						"Epoch 61/500.. Train loss: 167.5466.. Test loss: 345.2706\n",
						"R^2 Score: -1.4636632910785017\n",
						"Epoch 62/500.. Train loss: 161.1280.. Test loss: 379.4138\n",
						"R^2 Score: -7.430043092968512\n",
						"Epoch 63/500.. Train loss: 196.9921.. Test loss: 257.8486\n",
						"R^2 Score: -2.6125693946124096\n",
						"Epoch 64/500.. Train loss: 155.0340.. Test loss: 297.6382\n",
						"R^2 Score: -1.8521278797039802\n",
						"Epoch 65/500.. Train loss: 163.4865.. Test loss: 300.2118\n",
						"R^2 Score: -1.2920128212318458\n",
						"Epoch 66/500.. Train loss: 162.2822.. Test loss: 235.0357\n",
						"R^2 Score: -1.8558691873463258\n",
						"Epoch 67/500.. Train loss: 141.5329.. Test loss: 273.7853\n",
						"R^2 Score: -1.5362204308722665\n",
						"Epoch 68/500.. Train loss: 156.7216.. Test loss: 311.3890\n",
						"R^2 Score: -1.3989369715184679\n",
						"Epoch 69/500.. Train loss: 152.8316.. Test loss: 322.1133\n",
						"R^2 Score: -9.352676657443062\n",
						"Epoch 70/500.. Train loss: 156.1068.. Test loss: 270.7782\n",
						"R^2 Score: -3.2771051119845227\n",
						"Epoch 71/500.. Train loss: 193.3884.. Test loss: 278.7474\n",
						"R^2 Score: -2.165427208943532\n",
						"Epoch 72/500.. Train loss: 175.3005.. Test loss: 269.5467\n",
						"R^2 Score: -2.1624227193890726\n",
						"Epoch 73/500.. Train loss: 141.2936.. Test loss: 253.6800\n",
						"R^2 Score: -2.680477684767959\n",
						"Epoch 74/500.. Train loss: 186.9867.. Test loss: 255.0692\n",
						"R^2 Score: -6.244426361574943\n",
						"Epoch 75/500.. Train loss: 193.3411.. Test loss: 243.1635\n",
						"R^2 Score: -2.478562418513499\n",
						"Epoch 76/500.. Train loss: 187.4285.. Test loss: 286.8469\n",
						"R^2 Score: -3.450003747013702\n",
						"Epoch 77/500.. Train loss: 157.4496.. Test loss: 271.1427\n",
						"R^2 Score: -3.835476978254702\n",
						"Epoch 78/500.. Train loss: 186.9674.. Test loss: 277.8165\n",
						"R^2 Score: -2.2723063586588794\n",
						"Epoch 79/500.. Train loss: 147.8039.. Test loss: 252.8475\n",
						"R^2 Score: -4.04231983650432\n",
						"Epoch 80/500.. Train loss: 148.0011.. Test loss: 246.7287\n",
						"R^2 Score: -1.3062641164061644\n",
						"Epoch 81/500.. Train loss: 117.6518.. Test loss: 382.1187\n",
						"R^2 Score: -10.458850931760892\n",
						"Epoch 82/500.. Train loss: 198.0705.. Test loss: 241.0087\n",
						"R^2 Score: -0.8566316426694587\n",
						"Epoch 83/500.. Train loss: 162.1084.. Test loss: 390.2584\n",
						"R^2 Score: -5.549201133907198\n",
						"Epoch 84/500.. Train loss: 191.1632.. Test loss: 273.5181\n",
						"R^2 Score: -2.886277778121715\n",
						"Epoch 85/500.. Train loss: 207.1862.. Test loss: 267.4684\n",
						"R^2 Score: -14.260644966807192\n",
						"Epoch 86/500.. Train loss: 228.0423.. Test loss: 245.3526\n",
						"R^2 Score: -4.960959585023079\n",
						"Epoch 87/500.. Train loss: 224.6472.. Test loss: 269.7895\n",
						"R^2 Score: -4.281003115880169\n",
						"Epoch 88/500.. Train loss: 209.7668.. Test loss: 264.5767\n",
						"R^2 Score: -1.2740229080775025\n",
						"Epoch 89/500.. Train loss: 165.9968.. Test loss: 349.3791\n",
						"R^2 Score: -2.887125090170839\n",
						"Epoch 90/500.. Train loss: 152.7979.. Test loss: 296.3607\n",
						"R^2 Score: -1.4725172097858672\n",
						"Epoch 91/500.. Train loss: 179.2694.. Test loss: 319.2209\n",
						"R^2 Score: -6.011677181954067\n",
						"Epoch 92/500.. Train loss: 167.5833.. Test loss: 246.0014\n",
						"R^2 Score: -1.5832486020517957\n",
						"Epoch 93/500.. Train loss: 173.3003.. Test loss: 336.0104\n",
						"R^2 Score: -1.5992602551878594\n",
						"Epoch 94/500.. Train loss: 154.6386.. Test loss: 310.9823\n",
						"R^2 Score: -0.8655199533425588\n",
						"Epoch 95/500.. Train loss: 146.3396.. Test loss: 390.5620\n",
						"R^2 Score: -9.994636754218398\n",
						"Epoch 96/500.. Train loss: 209.0868.. Test loss: 258.7728\n",
						"R^2 Score: -4.11653034126441\n",
						"Epoch 97/500.. Train loss: 198.7496.. Test loss: 247.7152\n",
						"R^2 Score: -3.2461214895904726\n",
						"Epoch 98/500.. Train loss: 165.1239.. Test loss: 299.1025\n",
						"R^2 Score: -2.5708519303030406\n",
						"Epoch 99/500.. Train loss: 164.9559.. Test loss: 253.9246\n",
						"R^2 Score: -3.628749475279194\n",
						"Epoch 100/500.. Train loss: 150.8948.. Test loss: 219.3587\n",
						"R^2 Score: -2.1548729456067606\n",
						"Epoch 101/500.. Train loss: 152.1579.. Test loss: 338.6244\n",
						"R^2 Score: -5.529810676439617\n",
						"Epoch 102/500.. Train loss: 158.5483.. Test loss: 263.2677\n",
						"R^2 Score: -2.3890151206167487\n",
						"Epoch 103/500.. Train loss: 165.5139.. Test loss: 248.9951\n",
						"R^2 Score: -4.572325736350288\n",
						"Epoch 104/500.. Train loss: 164.4974.. Test loss: 257.2928\n",
						"R^2 Score: -3.0108518086080753\n",
						"Epoch 105/500.. Train loss: 179.2989.. Test loss: 309.8048\n",
						"R^2 Score: -2.22743144441486\n",
						"Epoch 106/500.. Train loss: 143.5687.. Test loss: 294.7320\n",
						"R^2 Score: -1.2192727228221156\n",
						"Epoch 107/500.. Train loss: 149.6453.. Test loss: 245.7784\n",
						"R^2 Score: -3.8298387147312996\n",
						"Epoch 108/500.. Train loss: 149.5272.. Test loss: 269.3921\n",
						"R^2 Score: -3.7627940701835385\n",
						"Epoch 109/500.. Train loss: 148.3355.. Test loss: 264.2456\n",
						"R^2 Score: -3.6030756927576224\n",
						"Epoch 110/500.. Train loss: 189.9096.. Test loss: 265.6110\n",
						"R^2 Score: -1.0633199327356948\n",
						"Epoch 111/500.. Train loss: 126.8976.. Test loss: 413.3654\n",
						"R^2 Score: -1.202148744069059\n",
						"Epoch 112/500.. Train loss: 151.0220.. Test loss: 367.1739\n",
						"R^2 Score: -17.21794717738193\n",
						"Epoch 113/500.. Train loss: 175.2637.. Test loss: 261.2154\n",
						"R^2 Score: -3.837029750498748\n",
						"Epoch 114/500.. Train loss: 193.4367.. Test loss: 262.7183\n",
						"R^2 Score: -7.274932296971132\n",
						"Epoch 115/500.. Train loss: 184.4910.. Test loss: 255.3191\n",
						"R^2 Score: -2.0583514333905653\n",
						"Epoch 116/500.. Train loss: 190.0505.. Test loss: 284.4707\n",
						"R^2 Score: -2.522233462411689\n",
						"Epoch 117/500.. Train loss: 168.5686.. Test loss: 299.2672\n",
						"R^2 Score: -5.153151399608911\n",
						"Epoch 118/500.. Train loss: 175.7709.. Test loss: 220.5173\n",
						"R^2 Score: -5.13385870875373\n",
						"Epoch 119/500.. Train loss: 181.5111.. Test loss: 266.8093\n",
						"R^2 Score: -4.913519624105303\n",
						"Epoch 120/500.. Train loss: 192.3953.. Test loss: 278.9895\n",
						"R^2 Score: -2.6985908841754918\n",
						"Epoch 121/500.. Train loss: 193.0727.. Test loss: 296.8523\n",
						"R^2 Score: -8.526250602245266\n",
						"Epoch 122/500.. Train loss: 162.4384.. Test loss: 263.3907\n",
						"R^2 Score: -3.733342420833562\n",
						"Epoch 123/500.. Train loss: 155.8671.. Test loss: 288.2818\n",
						"R^2 Score: -4.560629116404527\n",
						"Epoch 124/500.. Train loss: 157.7458.. Test loss: 262.6997\n",
						"R^2 Score: -1.1060616361502107\n",
						"Epoch 125/500.. Train loss: 139.4179.. Test loss: 411.3205\n",
						"R^2 Score: -4.301334822764067\n",
						"Epoch 126/500.. Train loss: 136.9476.. Test loss: 264.0954\n",
						"R^2 Score: -6.79150188592633\n",
						"Epoch 127/500.. Train loss: 172.2167.. Test loss: 248.4354\n",
						"R^2 Score: -3.3449713381883743\n",
						"Epoch 128/500.. Train loss: 141.1889.. Test loss: 267.0856\n",
						"R^2 Score: -1.5708549829008152\n",
						"Epoch 129/500.. Train loss: 133.6908.. Test loss: 272.2228\n",
						"R^2 Score: -2.1961381006070497\n",
						"Epoch 130/500.. Train loss: 155.0992.. Test loss: 320.6415\n",
						"R^2 Score: -2.8828580197695954\n",
						"Epoch 131/500.. Train loss: 174.4638.. Test loss: 274.6526\n",
						"R^2 Score: -2.696391258469042\n",
						"Epoch 132/500.. Train loss: 164.0256.. Test loss: 265.1421\n",
						"R^2 Score: -1.441190443210846\n",
						"Epoch 133/500.. Train loss: 141.8276.. Test loss: 341.1142\n",
						"R^2 Score: -4.306446596283532\n",
						"Epoch 134/500.. Train loss: 145.8630.. Test loss: 256.9074\n",
						"R^2 Score: -1.4838295016118948\n",
						"Epoch 135/500.. Train loss: 152.1466.. Test loss: 346.5620\n",
						"R^2 Score: -2.4562240313035617\n",
						"Epoch 136/500.. Train loss: 153.6117.. Test loss: 281.8163\n",
						"R^2 Score: -1.8060466596365856\n",
						"Epoch 137/500.. Train loss: 121.7321.. Test loss: 325.3400\n",
						"R^2 Score: -2.7823807807097\n",
						"Epoch 138/500.. Train loss: 144.3051.. Test loss: 312.9945\n",
						"R^2 Score: -2.794760624065471\n",
						"Epoch 139/500.. Train loss: 123.9436.. Test loss: 295.9242\n",
						"R^2 Score: -2.459614063926179\n",
						"Epoch 140/500.. Train loss: 144.2307.. Test loss: 291.9156\n",
						"R^2 Score: -2.0565941481914694\n",
						"Epoch 141/500.. Train loss: 144.7634.. Test loss: 286.6334\n",
						"R^2 Score: -1.9924027366606545\n",
						"Epoch 142/500.. Train loss: 139.9247.. Test loss: 270.3153\n",
						"R^2 Score: -1.4445473996556255\n",
						"Epoch 143/500.. Train loss: 136.9894.. Test loss: 287.9041\n",
						"R^2 Score: -4.43925121424613\n",
						"Epoch 144/500.. Train loss: 134.7006.. Test loss: 257.1814\n",
						"R^2 Score: -2.5850659786425543\n",
						"Epoch 145/500.. Train loss: 163.9838.. Test loss: 287.0446\n",
						"R^2 Score: -3.0400628409837482\n",
						"Epoch 146/500.. Train loss: 142.1093.. Test loss: 290.6828\n",
						"R^2 Score: -3.1821644746519615\n",
						"Epoch 147/500.. Train loss: 142.8951.. Test loss: 258.1923\n",
						"R^2 Score: -2.6820169122428568\n",
						"Epoch 148/500.. Train loss: 143.3142.. Test loss: 257.5841\n",
						"R^2 Score: -2.3768405748684063\n",
						"Epoch 149/500.. Train loss: 157.5898.. Test loss: 293.1232\n",
						"R^2 Score: -1.7408027879041508\n",
						"Epoch 150/500.. Train loss: 158.2863.. Test loss: 267.5826\n",
						"R^2 Score: -3.402969167493584\n",
						"Epoch 151/500.. Train loss: 148.6988.. Test loss: 271.7195\n",
						"R^2 Score: -1.7821065659615671\n",
						"Epoch 152/500.. Train loss: 147.6979.. Test loss: 248.8970\n",
						"R^2 Score: -9.419613368015582\n",
						"Epoch 153/500.. Train loss: 164.2383.. Test loss: 248.0927\n",
						"R^2 Score: -3.830411178766635\n",
						"Epoch 154/500.. Train loss: 156.6461.. Test loss: 254.0520\n",
						"R^2 Score: -4.382490695259181\n",
						"Epoch 155/500.. Train loss: 140.6293.. Test loss: 270.9723\n",
						"R^2 Score: -7.669305428611775\n",
						"Epoch 156/500.. Train loss: 141.7117.. Test loss: 257.9794\n",
						"R^2 Score: -3.7117113559489425\n",
						"Epoch 157/500.. Train loss: 147.2663.. Test loss: 258.4982\n",
						"R^2 Score: -4.938152115920911\n",
						"Epoch 158/500.. Train loss: 135.8553.. Test loss: 247.4466\n",
						"R^2 Score: -2.376340432393925\n",
						"Epoch 159/500.. Train loss: 150.2702.. Test loss: 308.5666\n",
						"R^2 Score: -2.420151209020055\n",
						"Epoch 160/500.. Train loss: 133.8522.. Test loss: 202.5190\n",
						"R^2 Score: -5.139500784113431\n",
						"Epoch 161/500.. Train loss: 152.3353.. Test loss: 261.5876\n",
						"R^2 Score: -4.099872866666085\n",
						"Epoch 162/500.. Train loss: 170.0141.. Test loss: 262.7104\n",
						"R^2 Score: -7.5791027133156685\n",
						"Epoch 163/500.. Train loss: 145.6184.. Test loss: 267.7517\n",
						"R^2 Score: -1.8709184094765736\n",
						"Epoch 164/500.. Train loss: 156.8634.. Test loss: 307.5719\n",
						"R^2 Score: -4.235667906745251\n",
						"Epoch 165/500.. Train loss: 138.0507.. Test loss: 283.7982\n",
						"R^2 Score: -3.9413739570251485\n",
						"Epoch 166/500.. Train loss: 134.7304.. Test loss: 258.6788\n",
						"R^2 Score: -3.4965555780359\n",
						"Epoch 167/500.. Train loss: 161.7848.. Test loss: 281.7867\n",
						"R^2 Score: -2.6790567424166167\n",
						"Epoch 168/500.. Train loss: 151.8198.. Test loss: 286.6776\n",
						"R^2 Score: -1.830104409546244\n",
						"Epoch 169/500.. Train loss: 124.7828.. Test loss: 282.1518\n",
						"R^2 Score: -1.75229767573324\n",
						"Epoch 170/500.. Train loss: 114.1268.. Test loss: 338.9702\n",
						"R^2 Score: -2.916754034324859\n",
						"Epoch 171/500.. Train loss: 158.5348.. Test loss: 302.0226\n",
						"R^2 Score: -1.6290735665362535\n",
						"Epoch 172/500.. Train loss: 155.0510.. Test loss: 282.1274\n",
						"R^2 Score: -1.5875025434473637\n",
						"Epoch 173/500.. Train loss: 155.7183.. Test loss: 301.5423\n",
						"R^2 Score: -3.413183959527628\n",
						"Epoch 174/500.. Train loss: 155.7749.. Test loss: 258.9516\n",
						"R^2 Score: -1.9490465779388164\n",
						"Epoch 175/500.. Train loss: 139.9337.. Test loss: 294.9681\n",
						"R^2 Score: -6.5631725206406655\n",
						"Epoch 176/500.. Train loss: 129.8023.. Test loss: 251.6367\n",
						"R^2 Score: -3.3319771579857784\n",
						"Epoch 177/500.. Train loss: 154.4499.. Test loss: 287.6853\n",
						"R^2 Score: -10.355900767385654\n",
						"Epoch 178/500.. Train loss: 126.9732.. Test loss: 255.4709\n",
						"R^2 Score: -1.6156421274326842\n",
						"Epoch 179/500.. Train loss: 164.2474.. Test loss: 294.8884\n",
						"R^2 Score: -3.770001193383491\n",
						"Epoch 180/500.. Train loss: 143.6171.. Test loss: 267.7520\n",
						"R^2 Score: -2.7570118252311\n",
						"Epoch 181/500.. Train loss: 151.0246.. Test loss: 288.7347\n",
						"R^2 Score: -2.718924282627891\n",
						"Epoch 182/500.. Train loss: 150.7014.. Test loss: 278.2840\n",
						"R^2 Score: -3.976457755326459\n",
						"Epoch 183/500.. Train loss: 146.9502.. Test loss: 280.8138\n",
						"R^2 Score: -2.3236600100833886\n",
						"Epoch 184/500.. Train loss: 143.3113.. Test loss: 291.4474\n",
						"R^2 Score: -3.199573965381018\n",
						"Epoch 185/500.. Train loss: 120.8357.. Test loss: 252.6005\n",
						"R^2 Score: -3.1146874437818655\n",
						"Epoch 186/500.. Train loss: 130.8370.. Test loss: 274.7726\n",
						"R^2 Score: -3.3000484362654\n",
						"Epoch 187/500.. Train loss: 105.5371.. Test loss: 243.8626\n",
						"R^2 Score: -7.749714417933706\n",
						"Epoch 188/500.. Train loss: 230.7068.. Test loss: 267.3001\n",
						"R^2 Score: -7.835856293254865\n",
						"Epoch 189/500.. Train loss: 179.4697.. Test loss: 273.0391\n",
						"R^2 Score: -4.938041500227226\n",
						"Epoch 190/500.. Train loss: 168.2256.. Test loss: 265.3575\n",
						"R^2 Score: -1.974516350237932\n",
						"Epoch 191/500.. Train loss: 142.4956.. Test loss: 325.0554\n",
						"R^2 Score: -2.4614565104922477\n",
						"Epoch 192/500.. Train loss: 135.9809.. Test loss: 286.1572\n",
						"R^2 Score: -4.1677882118595875\n",
						"Epoch 193/500.. Train loss: 159.1883.. Test loss: 298.7105\n",
						"R^2 Score: -1.1564060117598909\n",
						"Epoch 194/500.. Train loss: 129.4831.. Test loss: 329.9072\n",
						"R^2 Score: -17.707609606030587\n",
						"Epoch 195/500.. Train loss: 157.4643.. Test loss: 252.6889\n",
						"R^2 Score: -0.8696062457731346\n",
						"Epoch 196/500.. Train loss: 152.9605.. Test loss: 322.4787\n",
						"R^2 Score: -1.666109716567381\n",
						"Epoch 197/500.. Train loss: 166.8207.. Test loss: 282.9711\n",
						"R^2 Score: -1.4589997220146276\n",
						"Epoch 198/500.. Train loss: 155.1205.. Test loss: 321.1671\n",
						"R^2 Score: -6.0923148033203764\n",
						"Epoch 199/500.. Train loss: 154.2441.. Test loss: 280.4794\n",
						"R^2 Score: -5.838149797191873\n",
						"Epoch 200/500.. Train loss: 155.6899.. Test loss: 252.8432\n",
						"R^2 Score: -1.53043512067042\n",
						"Epoch 201/500.. Train loss: 136.8840.. Test loss: 343.0939\n",
						"R^2 Score: -2.543597196265744\n",
						"Epoch 202/500.. Train loss: 133.5074.. Test loss: 301.9252\n",
						"R^2 Score: -5.339694697227242\n",
						"Epoch 203/500.. Train loss: 148.4970.. Test loss: 288.8635\n",
						"R^2 Score: -4.211682381054379\n",
						"Epoch 204/500.. Train loss: 188.7755.. Test loss: 282.4011\n",
						"R^2 Score: -1.1071624746443205\n",
						"Epoch 205/500.. Train loss: 140.0101.. Test loss: 396.6046\n",
						"R^2 Score: -2.062520430779052\n",
						"Epoch 206/500.. Train loss: 155.4698.. Test loss: 306.1538\n",
						"R^2 Score: -5.5123740541427475\n",
						"Epoch 207/500.. Train loss: 148.2983.. Test loss: 262.2711\n",
						"R^2 Score: -3.2991482577420728\n",
						"Epoch 208/500.. Train loss: 130.4829.. Test loss: 292.9562\n",
						"R^2 Score: -3.242734469033226\n",
						"Epoch 209/500.. Train loss: 186.5996.. Test loss: 297.9058\n",
						"R^2 Score: -1.4489859926311701\n",
						"Epoch 210/500.. Train loss: 131.2105.. Test loss: 320.7226\n",
						"R^2 Score: -2.833027321178246\n",
						"Epoch 211/500.. Train loss: 156.7909.. Test loss: 334.9171\n",
						"R^2 Score: -6.140338899597021\n",
						"Epoch 212/500.. Train loss: 125.5406.. Test loss: 281.1946\n",
						"R^2 Score: -1.884193857250334\n",
						"Epoch 213/500.. Train loss: 140.2240.. Test loss: 295.8618\n",
						"R^2 Score: -3.536398028999681\n",
						"Epoch 214/500.. Train loss: 119.8207.. Test loss: 283.1379\n",
						"R^2 Score: -1.679408745160603\n",
						"Epoch 215/500.. Train loss: 145.4173.. Test loss: 299.7664\n",
						"R^2 Score: -7.861233820402651\n",
						"Epoch 216/500.. Train loss: 118.5066.. Test loss: 275.6042\n",
						"R^2 Score: -1.7873916412424582\n",
						"Epoch 217/500.. Train loss: 173.1529.. Test loss: 315.8010\n",
						"R^2 Score: -3.1168377462100993\n",
						"Epoch 218/500.. Train loss: 134.8907.. Test loss: 273.4565\n",
						"R^2 Score: -3.98183195923885\n",
						"Epoch 219/500.. Train loss: 162.7821.. Test loss: 281.4414\n",
						"R^2 Score: -2.733366702242691\n",
						"Epoch 220/500.. Train loss: 146.3294.. Test loss: 286.9853\n",
						"R^2 Score: -2.921025689884974\n",
						"Epoch 221/500.. Train loss: 154.9259.. Test loss: 284.4459\n",
						"R^2 Score: -9.126868530060323\n",
						"Epoch 222/500.. Train loss: 161.9406.. Test loss: 264.3860\n",
						"R^2 Score: -3.036967955410238\n",
						"Epoch 223/500.. Train loss: 146.4873.. Test loss: 298.5352\n",
						"R^2 Score: -2.211753653527116\n",
						"Epoch 224/500.. Train loss: 142.3863.. Test loss: 303.9841\n",
						"R^2 Score: -2.125813355466169\n",
						"Epoch 225/500.. Train loss: 130.6397.. Test loss: 312.9014\n",
						"R^2 Score: -8.055384587194789\n",
						"Epoch 226/500.. Train loss: 132.7089.. Test loss: 255.5780\n",
						"R^2 Score: -1.4684929763543346\n",
						"Epoch 227/500.. Train loss: 156.2875.. Test loss: 313.5407\n",
						"R^2 Score: -6.190805122321672\n",
						"Epoch 228/500.. Train loss: 149.8973.. Test loss: 272.9164\n",
						"R^2 Score: -0.9818897517348115\n",
						"Epoch 229/500.. Train loss: 143.5589.. Test loss: 387.9840\n",
						"R^2 Score: -2.621849872130897\n",
						"Epoch 230/500.. Train loss: 116.3628.. Test loss: 295.7818\n",
						"R^2 Score: -1.6912644927787208\n",
						"Epoch 231/500.. Train loss: 148.8057.. Test loss: 326.9463\n",
						"R^2 Score: -3.768024228217077\n",
						"Epoch 232/500.. Train loss: 133.9884.. Test loss: 277.7250\n",
						"R^2 Score: -2.6681713657753297\n",
						"Epoch 233/500.. Train loss: 129.6393.. Test loss: 290.1639\n",
						"R^2 Score: -1.096125680278396\n",
						"Epoch 234/500.. Train loss: 134.2475.. Test loss: 362.7812\n",
						"R^2 Score: -5.395346315202543\n",
						"Epoch 235/500.. Train loss: 129.5021.. Test loss: 253.5702\n",
						"R^2 Score: -2.374771280915952\n",
						"Epoch 236/500.. Train loss: 136.3215.. Test loss: 308.3881\n",
						"R^2 Score: -0.9659915241655581\n",
						"Epoch 237/500.. Train loss: 117.2730.. Test loss: 200.7043\n",
						"R^2 Score: -4.949623891077993\n",
						"Epoch 238/500.. Train loss: 142.9091.. Test loss: 267.2350\n",
						"R^2 Score: -2.227718283126405\n",
						"Epoch 239/500.. Train loss: 144.3233.. Test loss: 268.9876\n",
						"R^2 Score: -1.8044683291543948\n",
						"Epoch 240/500.. Train loss: 163.6071.. Test loss: 301.9813\n",
						"R^2 Score: -2.418340410803347\n",
						"Epoch 241/500.. Train loss: 146.1783.. Test loss: 284.7030\n",
						"R^2 Score: -2.3425248763320354\n",
						"Epoch 242/500.. Train loss: 142.1952.. Test loss: 298.2727\n",
						"R^2 Score: -2.98905009618738\n",
						"Epoch 243/500.. Train loss: 133.3293.. Test loss: 300.8509\n",
						"R^2 Score: -6.897121651930869\n",
						"Epoch 244/500.. Train loss: 178.8262.. Test loss: 261.6158\n",
						"R^2 Score: -3.8502846461117324\n",
						"Epoch 245/500.. Train loss: 124.4783.. Test loss: 267.6977\n",
						"R^2 Score: -2.6600850529869833\n",
						"Epoch 246/500.. Train loss: 159.9343.. Test loss: 278.4568\n",
						"R^2 Score: -3.817859424610906\n",
						"Epoch 247/500.. Train loss: 158.7132.. Test loss: 288.5825\n",
						"R^2 Score: -2.8848277623221614\n",
						"Epoch 248/500.. Train loss: 139.4507.. Test loss: 283.0104\n",
						"R^2 Score: -8.319850441393907\n",
						"Epoch 249/500.. Train loss: 144.4123.. Test loss: 258.5425\n",
						"R^2 Score: -1.8186237261461842\n",
						"Epoch 250/500.. Train loss: 168.1553.. Test loss: 292.3077\n",
						"R^2 Score: -5.04914658244318\n",
						"Epoch 251/500.. Train loss: 147.4843.. Test loss: 264.1317\n",
						"R^2 Score: -3.75195724838198\n",
						"Epoch 252/500.. Train loss: 106.5833.. Test loss: 318.3052\n",
						"R^2 Score: -6.1492142999078085\n",
						"Epoch 253/500.. Train loss: 177.8859.. Test loss: 282.2007\n",
						"R^2 Score: -27.017187387632607\n",
						"Epoch 254/500.. Train loss: 198.6293.. Test loss: 261.4525\n",
						"R^2 Score: -13.904587339436281\n",
						"Epoch 255/500.. Train loss: 205.1130.. Test loss: 250.8178\n",
						"R^2 Score: -11.504721918478037\n",
						"Epoch 256/500.. Train loss: 195.3023.. Test loss: 248.5628\n",
						"R^2 Score: -9.11619419394619\n",
						"Epoch 257/500.. Train loss: 196.9492.. Test loss: 248.5847\n",
						"R^2 Score: -5.951035645022048\n",
						"Epoch 258/500.. Train loss: 173.6382.. Test loss: 241.5508\n",
						"R^2 Score: -4.680830741768014\n",
						"Epoch 259/500.. Train loss: 159.5684.. Test loss: 267.8241\n",
						"R^2 Score: -5.01804757380162\n",
						"Epoch 260/500.. Train loss: 160.8235.. Test loss: 272.3339\n",
						"R^2 Score: -2.673755876779247\n",
						"Epoch 261/500.. Train loss: 159.1147.. Test loss: 255.5149\n",
						"R^2 Score: -8.304115870773645\n",
						"Epoch 262/500.. Train loss: 181.1641.. Test loss: 265.0226\n",
						"R^2 Score: -2.8767276278643763\n",
						"Epoch 263/500.. Train loss: 160.6274.. Test loss: 268.4404\n",
						"R^2 Score: -6.966635779415316\n",
						"Epoch 264/500.. Train loss: 164.1011.. Test loss: 258.6345\n",
						"R^2 Score: -4.336801091234819\n",
						"Epoch 265/500.. Train loss: 164.0515.. Test loss: 265.4457\n",
						"R^2 Score: -3.687731746185369\n",
						"Epoch 266/500.. Train loss: 149.8664.. Test loss: 297.9118\n",
						"R^2 Score: -3.011985588158378\n",
						"Epoch 267/500.. Train loss: 157.5647.. Test loss: 272.3528\n",
						"R^2 Score: -8.34237395772654\n",
						"Epoch 268/500.. Train loss: 166.3934.. Test loss: 255.4570\n",
						"R^2 Score: -3.480928653490995\n",
						"Epoch 269/500.. Train loss: 163.7786.. Test loss: 284.6772\n",
						"R^2 Score: -2.3768586202228676\n",
						"Epoch 270/500.. Train loss: 125.4685.. Test loss: 307.1084\n",
						"R^2 Score: -1.169024574186103\n",
						"Epoch 271/500.. Train loss: 137.1438.. Test loss: 240.8198\n",
						"R^2 Score: -2.593292843554813\n",
						"Epoch 272/500.. Train loss: 130.1658.. Test loss: 281.3845\n",
						"R^2 Score: -2.7395209563092\n",
						"Epoch 273/500.. Train loss: 147.2688.. Test loss: 298.8666\n",
						"R^2 Score: -4.301601803170997\n",
						"Epoch 274/500.. Train loss: 142.8870.. Test loss: 274.7199\n",
						"R^2 Score: -1.642546877385012\n",
						"Epoch 275/500.. Train loss: 163.4029.. Test loss: 315.6439\n",
						"R^2 Score: -2.122085533062341\n",
						"Epoch 276/500.. Train loss: 150.4477.. Test loss: 319.0801\n",
						"R^2 Score: -2.185312813751181\n",
						"Epoch 277/500.. Train loss: 137.0220.. Test loss: 318.5320\n",
						"R^2 Score: -2.4425126393986765\n",
						"Epoch 278/500.. Train loss: 164.9076.. Test loss: 309.9827\n",
						"R^2 Score: -2.1356766062931234\n",
						"Epoch 279/500.. Train loss: 112.3196.. Test loss: 285.1168\n",
						"R^2 Score: -2.9323167868956816\n",
						"Epoch 280/500.. Train loss: 124.6118.. Test loss: 291.9634\n",
						"R^2 Score: -3.2892240360495553\n",
						"Epoch 281/500.. Train loss: 144.4396.. Test loss: 324.7773\n",
						"R^2 Score: -4.025479079737637\n",
						"Epoch 282/500.. Train loss: 141.2080.. Test loss: 208.2898\n",
						"R^2 Score: -1.4280599449705607\n",
						"Epoch 283/500.. Train loss: 154.6288.. Test loss: 302.1146\n",
						"R^2 Score: -3.0766380701028195\n",
						"Epoch 284/500.. Train loss: 121.5621.. Test loss: 267.9828\n",
						"R^2 Score: -1.4652528368919073\n",
						"Epoch 285/500.. Train loss: 147.1429.. Test loss: 293.8934\n",
						"R^2 Score: -1.8471078637816376\n",
						"Epoch 286/500.. Train loss: 142.2584.. Test loss: 279.6191\n",
						"R^2 Score: -2.0718391486605494\n",
						"Epoch 287/500.. Train loss: 130.8179.. Test loss: 298.1904\n",
						"R^2 Score: -2.59207748185871\n",
						"Epoch 288/500.. Train loss: 115.3733.. Test loss: 275.1696\n",
						"R^2 Score: -3.81516862228703\n",
						"Epoch 289/500.. Train loss: 149.8871.. Test loss: 266.6556\n",
						"R^2 Score: -3.4609664325043834\n",
						"Epoch 290/500.. Train loss: 137.4755.. Test loss: 264.3096\n",
						"R^2 Score: -8.338118394965496\n",
						"Epoch 291/500.. Train loss: 182.9620.. Test loss: 235.4097\n",
						"R^2 Score: -6.986793875190601\n",
						"Epoch 292/500.. Train loss: 169.2234.. Test loss: 261.0696\n",
						"R^2 Score: -1.974612847791073\n",
						"Epoch 293/500.. Train loss: 126.9160.. Test loss: 281.7268\n",
						"R^2 Score: -0.873818961505908\n",
						"Epoch 294/500.. Train loss: 106.8881.. Test loss: 341.6420\n",
						"R^2 Score: -1.7415834618022137\n",
						"Epoch 295/500.. Train loss: 161.0362.. Test loss: 290.9924\n",
						"R^2 Score: -2.3529637819778197\n",
						"Epoch 296/500.. Train loss: 143.8491.. Test loss: 289.0015\n",
						"R^2 Score: -4.160153620532855\n",
						"Epoch 297/500.. Train loss: 149.9762.. Test loss: 251.9197\n",
						"R^2 Score: -2.4723753659748797\n",
						"Epoch 298/500.. Train loss: 135.1268.. Test loss: 309.8367\n",
						"R^2 Score: -2.4119081235677204\n",
						"Epoch 299/500.. Train loss: 135.4038.. Test loss: 310.2405\n",
						"R^2 Score: -2.543271505599189\n",
						"Epoch 300/500.. Train loss: 146.5177.. Test loss: 305.8161\n",
						"R^2 Score: -3.858273827425317\n",
						"Epoch 301/500.. Train loss: 137.1492.. Test loss: 280.4703\n",
						"R^2 Score: -4.058875636558721\n",
						"Epoch 302/500.. Train loss: 169.2852.. Test loss: 260.8547\n",
						"R^2 Score: -2.7075172427234198\n",
						"Epoch 303/500.. Train loss: 167.2271.. Test loss: 272.4761\n",
						"R^2 Score: -2.0856671244641793\n",
						"Epoch 304/500.. Train loss: 140.7268.. Test loss: 283.1860\n",
						"R^2 Score: -1.956309237462135\n",
						"Epoch 305/500.. Train loss: 117.1332.. Test loss: 282.4325\n",
						"R^2 Score: -1.8981929251924043\n",
						"Epoch 306/500.. Train loss: 112.0229.. Test loss: 356.8009\n",
						"R^2 Score: -3.5157937024907353\n",
						"Epoch 307/500.. Train loss: 137.3260.. Test loss: 316.1771\n",
						"R^2 Score: -3.7243852056232116\n",
						"Epoch 308/500.. Train loss: 141.5879.. Test loss: 275.3625\n",
						"R^2 Score: -3.0346952655940864\n",
						"Epoch 309/500.. Train loss: 136.0040.. Test loss: 272.7910\n",
						"R^2 Score: -2.4361477732308323\n",
						"Epoch 310/500.. Train loss: 142.6399.. Test loss: 251.2556\n",
						"R^2 Score: -2.223529946233524\n",
						"Epoch 311/500.. Train loss: 127.5941.. Test loss: 291.3796\n",
						"R^2 Score: -1.855165888246621\n",
						"Epoch 312/500.. Train loss: 149.9003.. Test loss: 320.4059\n",
						"R^2 Score: -2.2653504457504345\n",
						"Epoch 313/500.. Train loss: 148.1165.. Test loss: 298.4994\n",
						"R^2 Score: -3.339716677508785\n",
						"Epoch 314/500.. Train loss: 169.4323.. Test loss: 298.0250\n",
						"R^2 Score: -2.5106534004977274\n",
						"Epoch 315/500.. Train loss: 146.9410.. Test loss: 307.4925\n",
						"R^2 Score: -11.752175434435497\n",
						"Epoch 316/500.. Train loss: 192.0961.. Test loss: 234.4660\n",
						"R^2 Score: -3.409774693031295\n",
						"Epoch 317/500.. Train loss: 180.7923.. Test loss: 266.6329\n",
						"R^2 Score: -5.678394089518117\n",
						"Epoch 318/500.. Train loss: 177.4324.. Test loss: 266.4193\n",
						"R^2 Score: -5.404061353149572\n",
						"Epoch 319/500.. Train loss: 156.2556.. Test loss: 252.0831\n",
						"R^2 Score: -4.547404452724478\n",
						"Epoch 320/500.. Train loss: 143.8068.. Test loss: 263.8113\n",
						"R^2 Score: -4.625661281572246\n",
						"Epoch 321/500.. Train loss: 135.4790.. Test loss: 272.4171\n",
						"R^2 Score: -4.070416772602366\n",
						"Epoch 322/500.. Train loss: 125.2309.. Test loss: 268.3826\n",
						"R^2 Score: -2.888599575234075\n",
						"Epoch 323/500.. Train loss: 134.3738.. Test loss: 313.8357\n",
						"R^2 Score: -2.176882987779528\n",
						"Epoch 324/500.. Train loss: 125.8024.. Test loss: 335.2931\n",
						"R^2 Score: -2.542733354888084\n",
						"Epoch 325/500.. Train loss: 142.6308.. Test loss: 282.6789\n",
						"R^2 Score: -2.2949064188788144\n",
						"Epoch 326/500.. Train loss: 138.4616.. Test loss: 280.0706\n",
						"R^2 Score: -1.9954830340978638\n",
						"Epoch 327/500.. Train loss: 114.2980.. Test loss: 312.3250\n",
						"R^2 Score: -2.2487013954482995\n",
						"Epoch 328/500.. Train loss: 147.7484.. Test loss: 265.6336\n",
						"R^2 Score: -5.235547036271874\n",
						"Epoch 329/500.. Train loss: 122.2803.. Test loss: 256.7380\n",
						"R^2 Score: -2.4377981201941594\n",
						"Epoch 330/500.. Train loss: 137.2450.. Test loss: 297.1453\n",
						"R^2 Score: -4.550671920529364\n",
						"Epoch 331/500.. Train loss: 165.8611.. Test loss: 276.4237\n",
						"R^2 Score: -3.1697530938587883\n",
						"Epoch 332/500.. Train loss: 159.0249.. Test loss: 273.7195\n",
						"R^2 Score: -1.3696860859728703\n",
						"Epoch 333/500.. Train loss: 136.4366.. Test loss: 296.0136\n",
						"R^2 Score: -2.179499874978756\n",
						"Epoch 334/500.. Train loss: 129.1407.. Test loss: 292.6864\n",
						"R^2 Score: -2.4654965336157075\n",
						"Epoch 335/500.. Train loss: 192.0399.. Test loss: 285.3656\n",
						"R^2 Score: -3.1876422215950804\n",
						"Epoch 336/500.. Train loss: 136.1432.. Test loss: 279.9969\n",
						"R^2 Score: -3.197268813617474\n",
						"Epoch 337/500.. Train loss: 174.2334.. Test loss: 273.3651\n",
						"R^2 Score: -1.6131457618471639\n",
						"Epoch 338/500.. Train loss: 132.8931.. Test loss: 307.0113\n",
						"R^2 Score: -4.367193643210436\n",
						"Epoch 339/500.. Train loss: 126.5932.. Test loss: 248.7627\n",
						"R^2 Score: -2.2573349944917025\n",
						"Epoch 340/500.. Train loss: 138.6423.. Test loss: 239.6621\n",
						"R^2 Score: -5.4669879707759605\n",
						"Epoch 341/500.. Train loss: 147.9324.. Test loss: 279.6926\n",
						"R^2 Score: -2.716690152652667\n",
						"Epoch 342/500.. Train loss: 129.9861.. Test loss: 293.8215\n",
						"R^2 Score: -6.830660947910624\n",
						"Epoch 343/500.. Train loss: 139.0174.. Test loss: 259.6800\n",
						"R^2 Score: -2.2507539900958817\n",
						"Epoch 344/500.. Train loss: 120.9420.. Test loss: 326.3604\n",
						"R^2 Score: -2.283369994952059\n",
						"Epoch 345/500.. Train loss: 132.5893.. Test loss: 314.5665\n",
						"R^2 Score: -1.8823751534752278\n",
						"Epoch 346/500.. Train loss: 130.2683.. Test loss: 350.2003\n",
						"R^2 Score: -3.1674848001026206\n",
						"Epoch 347/500.. Train loss: 121.4917.. Test loss: 292.0489\n",
						"R^2 Score: -5.717787461918605\n",
						"Epoch 348/500.. Train loss: 151.4477.. Test loss: 262.8350\n",
						"R^2 Score: -1.6790886464108254\n",
						"Epoch 349/500.. Train loss: 158.6179.. Test loss: 285.2397\n",
						"R^2 Score: -3.0786375864910163\n",
						"Epoch 350/500.. Train loss: 128.0861.. Test loss: 280.2177\n",
						"R^2 Score: -3.26000836160451\n",
						"Epoch 351/500.. Train loss: 126.2719.. Test loss: 285.7512\n",
						"R^2 Score: -2.5778411114509505\n",
						"Epoch 352/500.. Train loss: 132.2323.. Test loss: 267.2906\n",
						"R^2 Score: -4.621272440335109\n",
						"Epoch 353/500.. Train loss: 136.9171.. Test loss: 266.8105\n",
						"R^2 Score: -2.960507690253891\n",
						"Epoch 354/500.. Train loss: 183.7360.. Test loss: 203.9171\n",
						"R^2 Score: -2.7134939480878435\n",
						"Epoch 355/500.. Train loss: 125.1224.. Test loss: 259.0369\n",
						"R^2 Score: -1.879799985552359\n",
						"Epoch 356/500.. Train loss: 115.3271.. Test loss: 317.2898\n",
						"R^2 Score: -2.41267453014888\n",
						"Epoch 357/500.. Train loss: 102.4238.. Test loss: 316.8326\n",
						"R^2 Score: -1.070385903908293\n",
						"Epoch 358/500.. Train loss: 156.6228.. Test loss: 388.8932\n",
						"R^2 Score: -5.385913725067972\n",
						"Epoch 359/500.. Train loss: 178.4368.. Test loss: 256.1514\n",
						"R^2 Score: -3.275349747556752\n",
						"Epoch 360/500.. Train loss: 127.4429.. Test loss: 299.4838\n",
						"R^2 Score: -3.5327814212249713\n",
						"Epoch 361/500.. Train loss: 139.5862.. Test loss: 290.9280\n",
						"R^2 Score: -6.326767565511807\n",
						"Epoch 362/500.. Train loss: 139.4892.. Test loss: 279.5917\n",
						"R^2 Score: -3.3818296293380667\n",
						"Epoch 363/500.. Train loss: 145.0376.. Test loss: 291.9992\n",
						"R^2 Score: -1.5768903102142589\n",
						"Epoch 364/500.. Train loss: 118.7729.. Test loss: 265.7815\n",
						"R^2 Score: -3.393034331556123\n",
						"Epoch 365/500.. Train loss: 161.7667.. Test loss: 293.8223\n",
						"R^2 Score: -1.661085431508655\n",
						"Epoch 366/500.. Train loss: 119.8418.. Test loss: 319.2617\n",
						"R^2 Score: -2.3105640679806245\n",
						"Epoch 367/500.. Train loss: 134.6621.. Test loss: 341.9142\n",
						"R^2 Score: -2.3561699590387644\n",
						"Epoch 368/500.. Train loss: 112.4666.. Test loss: 328.2776\n",
						"R^2 Score: -2.66146335578603\n",
						"Epoch 369/500.. Train loss: 124.9965.. Test loss: 320.9597\n",
						"R^2 Score: -2.310066651038833\n",
						"Epoch 370/500.. Train loss: 146.2162.. Test loss: 276.2972\n",
						"R^2 Score: -4.155067259188403\n",
						"Epoch 371/500.. Train loss: 128.4046.. Test loss: 294.3384\n",
						"R^2 Score: -1.85021913356571\n",
						"Epoch 372/500.. Train loss: 124.5591.. Test loss: 361.1202\n",
						"R^2 Score: -2.749716149560383\n",
						"Epoch 373/500.. Train loss: 115.8294.. Test loss: 308.0697\n",
						"R^2 Score: -3.511646605680834\n",
						"Epoch 374/500.. Train loss: 79.0071.. Test loss: 305.7118\n",
						"R^2 Score: -1.2348822637286139\n",
						"Epoch 375/500.. Train loss: 117.7441.. Test loss: 382.0361\n",
						"R^2 Score: -3.6587002951534533\n",
						"Epoch 376/500.. Train loss: 227.6093.. Test loss: 302.6965\n",
						"R^2 Score: -6.359026071741458\n",
						"Epoch 377/500.. Train loss: 189.0841.. Test loss: 259.6394\n",
						"R^2 Score: -4.553151303449701\n",
						"Epoch 378/500.. Train loss: 169.6682.. Test loss: 284.5052\n",
						"R^2 Score: -3.3333933900720742\n",
						"Epoch 379/500.. Train loss: 141.3215.. Test loss: 281.4436\n",
						"R^2 Score: -3.113339229967101\n",
						"Epoch 380/500.. Train loss: 141.1245.. Test loss: 255.8190\n",
						"R^2 Score: -1.7053110968947025\n",
						"Epoch 381/500.. Train loss: 121.1676.. Test loss: 284.5908\n",
						"R^2 Score: -1.9878905372862854\n",
						"Epoch 382/500.. Train loss: 131.1220.. Test loss: 306.4175\n",
						"R^2 Score: -2.325027026456522\n",
						"Epoch 383/500.. Train loss: 109.7386.. Test loss: 323.9518\n",
						"R^2 Score: -6.000226512636884\n",
						"Epoch 384/500.. Train loss: 105.8677.. Test loss: 266.2247\n",
						"R^2 Score: -3.784541316635159\n",
						"Epoch 385/500.. Train loss: 168.8283.. Test loss: 287.0138\n",
						"R^2 Score: -2.099627028722687\n",
						"Epoch 386/500.. Train loss: 146.5921.. Test loss: 304.5732\n",
						"R^2 Score: -2.795101691975465\n",
						"Epoch 387/500.. Train loss: 116.3343.. Test loss: 273.0586\n",
						"R^2 Score: -2.792382201520324\n",
						"Epoch 388/500.. Train loss: 115.3040.. Test loss: 330.9645\n",
						"R^2 Score: -1.3868771095985841\n",
						"Epoch 389/500.. Train loss: 92.4012.. Test loss: 363.2577\n",
						"R^2 Score: -7.281994334738608\n",
						"Epoch 390/500.. Train loss: 178.7383.. Test loss: 278.9469\n",
						"R^2 Score: -3.864667359353712\n",
						"Epoch 391/500.. Train loss: 137.3989.. Test loss: 268.8848\n",
						"R^2 Score: -2.858661554369497\n",
						"Epoch 392/500.. Train loss: 141.4578.. Test loss: 275.0163\n",
						"R^2 Score: -3.4886019600104925\n",
						"Epoch 393/500.. Train loss: 111.7278.. Test loss: 280.4669\n",
						"R^2 Score: -1.3811673931589863\n",
						"Epoch 394/500.. Train loss: 98.8690.. Test loss: 327.3644\n",
						"R^2 Score: -3.901447375022099\n",
						"Epoch 395/500.. Train loss: 130.5497.. Test loss: 277.9331\n",
						"R^2 Score: -2.6997341203377623\n",
						"Epoch 396/500.. Train loss: 127.6559.. Test loss: 279.0502\n",
						"R^2 Score: -3.745279472033654\n",
						"Epoch 397/500.. Train loss: 118.5812.. Test loss: 273.9268\n",
						"R^2 Score: -1.95497036494082\n",
						"Epoch 398/500.. Train loss: 132.1964.. Test loss: 301.3667\n",
						"R^2 Score: -1.7091935753450653\n",
						"Epoch 399/500.. Train loss: 135.5100.. Test loss: 359.6976\n",
						"R^2 Score: -1.2009411780574815\n",
						"Epoch 400/500.. Train loss: 121.7687.. Test loss: 354.1200\n",
						"R^2 Score: -2.001476903291535\n",
						"Epoch 401/500.. Train loss: 130.5355.. Test loss: 339.6392\n",
						"R^2 Score: -2.2701833539166003\n",
						"Epoch 402/500.. Train loss: 131.2583.. Test loss: 289.4022\n",
						"R^2 Score: -2.1831727647311876\n",
						"Epoch 403/500.. Train loss: 108.6157.. Test loss: 296.5408\n",
						"R^2 Score: -15.194469076495835\n",
						"Epoch 404/500.. Train loss: 151.2655.. Test loss: 241.6194\n",
						"R^2 Score: -6.941269868182533\n",
						"Epoch 405/500.. Train loss: 161.0753.. Test loss: 232.5326\n",
						"R^2 Score: -4.646922785318488\n",
						"Epoch 406/500.. Train loss: 130.2316.. Test loss: 265.6342\n",
						"R^2 Score: -5.895141341947377\n",
						"Epoch 407/500.. Train loss: 130.7262.. Test loss: 276.5219\n",
						"R^2 Score: -2.51830817167739\n",
						"Epoch 408/500.. Train loss: 127.0943.. Test loss: 285.0647\n",
						"R^2 Score: -0.8517524855194756\n",
						"Epoch 409/500.. Train loss: 107.0336.. Test loss: 389.8262\n",
						"R^2 Score: -3.6629724685679657\n",
						"Epoch 410/500.. Train loss: 168.3841.. Test loss: 263.5054\n",
						"R^2 Score: -3.862822742031125\n",
						"Epoch 411/500.. Train loss: 135.3146.. Test loss: 288.0995\n",
						"R^2 Score: -3.1123706084410294\n",
						"Epoch 412/500.. Train loss: 144.6503.. Test loss: 279.9756\n",
						"R^2 Score: -3.1487869975146285\n",
						"Epoch 413/500.. Train loss: 127.2031.. Test loss: 297.2182\n",
						"R^2 Score: -3.2816757248532884\n",
						"Epoch 414/500.. Train loss: 130.9804.. Test loss: 269.3075\n",
						"R^2 Score: -1.5023844489225056\n",
						"Epoch 415/500.. Train loss: 113.9538.. Test loss: 309.5973\n",
						"R^2 Score: -2.825013290833719\n",
						"Epoch 416/500.. Train loss: 138.2113.. Test loss: 285.8129\n",
						"R^2 Score: -4.377937086279092\n",
						"Epoch 417/500.. Train loss: 119.8933.. Test loss: 280.3514\n",
						"R^2 Score: -5.491875021707431\n",
						"Epoch 418/500.. Train loss: 110.6085.. Test loss: 273.9100\n",
						"R^2 Score: -3.122223038683704\n",
						"Epoch 419/500.. Train loss: 107.5977.. Test loss: 291.4878\n",
						"R^2 Score: -2.0535368034200774\n",
						"Epoch 420/500.. Train loss: 91.6878.. Test loss: 296.6666\n",
						"R^2 Score: -1.7975340001573725\n",
						"Epoch 421/500.. Train loss: 134.9615.. Test loss: 304.9348\n",
						"R^2 Score: -2.216596864058903\n",
						"Epoch 422/500.. Train loss: 142.1699.. Test loss: 250.0498\n",
						"R^2 Score: -1.3770985032957208\n",
						"Epoch 423/500.. Train loss: 104.8312.. Test loss: 329.2595\n",
						"R^2 Score: -3.4326937082271165\n",
						"Epoch 424/500.. Train loss: 108.3243.. Test loss: 277.7672\n",
						"R^2 Score: -1.407637454659345\n",
						"Epoch 425/500.. Train loss: 125.1400.. Test loss: 333.1344\n",
						"R^2 Score: -3.576006794047567\n",
						"Epoch 426/500.. Train loss: 176.4290.. Test loss: 246.6785\n",
						"R^2 Score: -1.7659313996580832\n",
						"Epoch 427/500.. Train loss: 160.4003.. Test loss: 326.2469\n",
						"R^2 Score: -1.6272223451745944\n",
						"Epoch 428/500.. Train loss: 141.7688.. Test loss: 321.0929\n",
						"R^2 Score: -2.7847511354833454\n",
						"Epoch 429/500.. Train loss: 138.1504.. Test loss: 255.1070\n",
						"R^2 Score: -3.7081813003462765\n",
						"Epoch 430/500.. Train loss: 124.9987.. Test loss: 249.4774\n",
						"R^2 Score: -2.2404334594952315\n",
						"Epoch 431/500.. Train loss: 121.8011.. Test loss: 305.4023\n",
						"R^2 Score: -2.3488356717610017\n",
						"Epoch 432/500.. Train loss: 120.9286.. Test loss: 245.9361\n",
						"R^2 Score: -2.6533726734683167\n",
						"Epoch 433/500.. Train loss: 126.5714.. Test loss: 273.3441\n",
						"R^2 Score: -4.987176471519242\n",
						"Epoch 434/500.. Train loss: 150.9016.. Test loss: 286.4262\n",
						"R^2 Score: -4.857176316974677\n",
						"Epoch 435/500.. Train loss: 113.5754.. Test loss: 243.3706\n",
						"R^2 Score: -5.1467624204920535\n",
						"Epoch 436/500.. Train loss: 117.4916.. Test loss: 281.0638\n",
						"R^2 Score: -1.9053242562194272\n",
						"Epoch 437/500.. Train loss: 144.3844.. Test loss: 323.4069\n",
						"R^2 Score: -4.563242832813608\n",
						"Epoch 438/500.. Train loss: 114.3006.. Test loss: 280.3530\n",
						"R^2 Score: -3.959469649465132\n",
						"Epoch 439/500.. Train loss: 144.4688.. Test loss: 279.7852\n",
						"R^2 Score: -1.4467783319339693\n",
						"Epoch 440/500.. Train loss: 118.4182.. Test loss: 300.8630\n",
						"R^2 Score: -2.286328858274616\n",
						"Epoch 441/500.. Train loss: 119.0428.. Test loss: 259.8591\n",
						"R^2 Score: -1.701502471540262\n",
						"Epoch 442/500.. Train loss: 117.7636.. Test loss: 357.3231\n",
						"R^2 Score: -1.8040491855153795\n",
						"Epoch 443/500.. Train loss: 96.2090.. Test loss: 305.5240\n",
						"R^2 Score: -3.2134364778373063\n",
						"Epoch 444/500.. Train loss: 148.8100.. Test loss: 281.3888\n",
						"R^2 Score: -2.227657525411512\n",
						"Epoch 445/500.. Train loss: 133.2877.. Test loss: 304.4672\n",
						"R^2 Score: -2.0656985281289346\n",
						"Epoch 446/500.. Train loss: 123.3143.. Test loss: 295.7787\n",
						"R^2 Score: -2.405961414426288\n",
						"Epoch 447/500.. Train loss: 128.8513.. Test loss: 328.2601\n",
						"R^2 Score: -2.5346452858803827\n",
						"Epoch 448/500.. Train loss: 132.2124.. Test loss: 271.9330\n",
						"R^2 Score: -1.9937854798504673\n",
						"Epoch 449/500.. Train loss: 113.2973.. Test loss: 350.7652\n",
						"R^2 Score: -5.1696029353091495\n",
						"Epoch 450/500.. Train loss: 126.8080.. Test loss: 259.0978\n",
						"R^2 Score: -2.886420216337599\n",
						"Epoch 451/500.. Train loss: 158.1668.. Test loss: 312.4499\n",
						"R^2 Score: -4.004515722073842\n",
						"Epoch 452/500.. Train loss: 105.6826.. Test loss: 272.1316\n",
						"R^2 Score: -2.255390650525847\n",
						"Epoch 453/500.. Train loss: 137.7280.. Test loss: 269.1822\n",
						"R^2 Score: -3.892441791604486\n",
						"Epoch 454/500.. Train loss: 131.4096.. Test loss: 281.0214\n",
						"R^2 Score: -3.3707028081884536\n",
						"Epoch 455/500.. Train loss: 116.2856.. Test loss: 262.5730\n",
						"R^2 Score: -4.167153117314442\n",
						"Epoch 456/500.. Train loss: 121.4989.. Test loss: 297.0499\n",
						"R^2 Score: -2.885618780000486\n",
						"Epoch 457/500.. Train loss: 137.6696.. Test loss: 268.3779\n",
						"R^2 Score: -2.2016819286879437\n",
						"Epoch 458/500.. Train loss: 140.7422.. Test loss: 307.9618\n",
						"R^2 Score: -3.7285368491494353\n",
						"Epoch 459/500.. Train loss: 128.5974.. Test loss: 297.8679\n",
						"R^2 Score: -4.148997855468064\n",
						"Epoch 460/500.. Train loss: 123.1619.. Test loss: 268.1074\n",
						"R^2 Score: -2.2525042051885538\n",
						"Epoch 461/500.. Train loss: 108.5937.. Test loss: 301.3847\n",
						"R^2 Score: -1.0341054575945678\n",
						"Epoch 462/500.. Train loss: 123.6588.. Test loss: 359.3839\n",
						"R^2 Score: -2.843589210378117\n",
						"Epoch 463/500.. Train loss: 137.4016.. Test loss: 294.7578\n",
						"R^2 Score: -2.4668239139977213\n",
						"Epoch 464/500.. Train loss: 126.0812.. Test loss: 272.4392\n",
						"R^2 Score: -3.367972467585215\n",
						"Epoch 465/500.. Train loss: 101.2420.. Test loss: 263.8103\n",
						"R^2 Score: -2.4072942378311595\n",
						"Epoch 466/500.. Train loss: 123.0949.. Test loss: 285.4745\n",
						"R^2 Score: -2.8295781045538795\n",
						"Epoch 467/500.. Train loss: 123.6421.. Test loss: 282.3463\n",
						"R^2 Score: -2.8602449871787976\n",
						"Epoch 468/500.. Train loss: 143.5448.. Test loss: 309.1202\n",
						"R^2 Score: -4.056671058993795\n",
						"Epoch 469/500.. Train loss: 101.0187.. Test loss: 268.9465\n",
						"R^2 Score: -2.7609739697800446\n",
						"Epoch 470/500.. Train loss: 124.2196.. Test loss: 288.3219\n",
						"R^2 Score: -1.8717201421086207\n",
						"Epoch 471/500.. Train loss: 133.7669.. Test loss: 312.5315\n",
						"R^2 Score: -2.4683627816683997\n",
						"Epoch 472/500.. Train loss: 113.4599.. Test loss: 286.0589\n",
						"R^2 Score: -5.105173197622836\n",
						"Epoch 473/500.. Train loss: 147.4170.. Test loss: 258.8113\n",
						"R^2 Score: -2.5880103965304824\n",
						"Epoch 474/500.. Train loss: 140.1172.. Test loss: 267.3108\n",
						"R^2 Score: -4.366396485872731\n",
						"Epoch 475/500.. Train loss: 110.4362.. Test loss: 293.5308\n",
						"R^2 Score: -6.5028021727937855\n",
						"Epoch 476/500.. Train loss: 126.8675.. Test loss: 238.2232\n",
						"R^2 Score: -2.3391499539141485\n",
						"Epoch 477/500.. Train loss: 119.2613.. Test loss: 299.7241\n",
						"R^2 Score: -5.7499676069708014\n",
						"Epoch 478/500.. Train loss: 132.3433.. Test loss: 255.2156\n",
						"R^2 Score: -5.530681903434164\n",
						"Epoch 479/500.. Train loss: 113.7137.. Test loss: 266.5099\n",
						"R^2 Score: -3.178783139871207\n",
						"Epoch 480/500.. Train loss: 125.0865.. Test loss: 313.8498\n",
						"R^2 Score: -2.2028589738377327\n",
						"Epoch 481/500.. Train loss: 125.1210.. Test loss: 270.9907\n",
						"R^2 Score: -2.2493815963463897\n",
						"Epoch 482/500.. Train loss: 132.9010.. Test loss: 283.8827\n",
						"R^2 Score: -6.237621781908298\n",
						"Epoch 483/500.. Train loss: 120.9417.. Test loss: 268.8694\n",
						"R^2 Score: -3.183953427093056\n",
						"Epoch 484/500.. Train loss: 112.2863.. Test loss: 268.2680\n",
						"R^2 Score: -4.694857019409164\n",
						"Epoch 485/500.. Train loss: 142.0492.. Test loss: 261.3935\n",
						"R^2 Score: -1.0060366494389203\n",
						"Epoch 486/500.. Train loss: 111.5951.. Test loss: 363.1909\n",
						"R^2 Score: -2.7875904744759747\n",
						"Epoch 487/500.. Train loss: 118.7535.. Test loss: 294.1676\n",
						"R^2 Score: -2.7088227564966996\n",
						"Epoch 488/500.. Train loss: 127.7560.. Test loss: 286.6758\n",
						"R^2 Score: -2.9474864287153157\n",
						"Epoch 489/500.. Train loss: 152.9892.. Test loss: 273.6810\n",
						"R^2 Score: -1.2574126750686934\n",
						"Epoch 490/500.. Train loss: 104.7977.. Test loss: 268.3934\n",
						"R^2 Score: -2.4868572386732493\n",
						"Epoch 491/500.. Train loss: 96.4325.. Test loss: 279.8766\n",
						"R^2 Score: -2.3501670302944313\n",
						"Epoch 492/500.. Train loss: 118.5168.. Test loss: 233.6858\n",
						"R^2 Score: -1.8324863360767836\n",
						"Epoch 493/500.. Train loss: 128.7706.. Test loss: 275.9821\n",
						"R^2 Score: -1.803884887549612\n",
						"Epoch 494/500.. Train loss: 138.7444.. Test loss: 325.5139\n",
						"R^2 Score: -4.563855976862873\n",
						"Epoch 495/500.. Train loss: 128.0833.. Test loss: 249.7689\n",
						"R^2 Score: -2.1347180751522035\n",
						"Epoch 496/500.. Train loss: 97.6843.. Test loss: 299.1523\n",
						"R^2 Score: -2.9464688723083943\n",
						"Epoch 497/500.. Train loss: 111.5078.. Test loss: 278.1134\n",
						"R^2 Score: -2.9113763408366635\n",
						"Epoch 498/500.. Train loss: 91.3004.. Test loss: 256.0569\n",
						"R^2 Score: -1.6312050799374576\n",
						"Epoch 499/500.. Train loss: 119.8839.. Test loss: 356.8948\n",
						"R^2 Score: -2.5258664818191248\n",
						"Epoch 500/500.. Train loss: 116.1394.. Test loss: 304.3070\n"
					]
				},
				{
					"data": {
						"image/png": "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",
						"text/plain": [
							"<Figure size 1000x600 with 1 Axes>"
						]
					},
					"metadata": {},
					"output_type": "display_data"
				},
				{
					"data": {
						"image/png": "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",
						"text/plain": [
							"<Figure size 1000x600 with 1 Axes>"
						]
					},
					"metadata": {},
					"output_type": "display_data"
				}
			],
			"source": [
				"import os \n",
				"import pandas as pd \n",
				"import numpy as np \n",
				"import torch \n",
				"from torch import nn\n",
				"from torch.utils.data import Dataset, DataLoader, random_split\n",
				"from sklearn.preprocessing import StandardScaler\n",
				"import matplotlib.pyplot as plt\n",
				"from sklearn.metrics import r2_score\n",
				"class HgDataset(Dataset):\n",
				"    def __init__(self,file_path,tranform=None,traget_tranform=None):\n",
				"        \"\"\"_summary_\n",
				"\n",
				"        Args:\n",
				"            file_path (_type_): _description_\n",
				"            tranform (_type_, optional): _description_. Defaults to None.\n",
				"            traget_tranform (_type_, optional): _description_. Defaults to None.\n",
				"        \"\"\"\n",
				"        self.data=pd.read_csv(file_path)\n",
				"        self.y=self.data['Hg_conc'].to_numpy().reshape(-1,1)# 设置因变量\n",
				"        self.x=self.data.drop('Hg_conc',axis=1,inplace=False).to_numpy()\n",
				"        if tranform:\n",
				"            self.x=tranform(self.x)\n",
				"        if traget_tranform:\n",
				"            self.y=traget_tranform(self.y)\n",
				"    \n",
				"\n",
				"\n",
				"\n",
				"    def __len__(self):\n",
				"        return len(self.data)\n",
				"    \n",
				"    def __getitem__(self,index):\n",
				"        '''torch.is_tensor(idx): 这个函数检查idx是否是一个PyTorch张量（torch.Tensor）。在某些情况下，\n",
				"        尤其是在使用高级索引或者批处理时，索引可能会以张量的形式给出。这个检查是为了确定是否需要将张量索引转换成Python列表，以便后续处理。\n",
				"\n",
				"         idx.tolist(): 如果idx确实是一个张量，tolist()方法将这个张量转换成一个Python列表。这是必要的，\n",
				"         因为在接下来的数据检索过程中，通常需要索引作为整数或者整数列表来使用，而不是张量。'''\n",
				"        if torch.is_tensor(index):\n",
				"            index = index.tolist()\n",
				"\n",
				"        y_i=self.y[index]\n",
				"        x_i=self.x[index]\n",
				"        return x_i,y_i\n",
				"    \n",
				"\n",
				"def my_transform(batch,device):\n",
				"    x,y=zip(*batch)\n",
				"    #print(type(x))\n",
				"    x=np.array(x)\n",
				"    y=np.array(y)\n",
				"\n",
				"    scaler=StandardScaler()\n",
				"    x=scaler.fit_transform(x)\n",
				"    x=torch.tensor(x,dtype=torch.float32).to(device)\n",
				"    y=torch.tensor(y,dtype=torch.float32).to(device)\n",
				"    return x,y\n",
				"\n",
				"class MyModel(nn.Module):\n",
				"    def __init__(self,input,output,drop_p=0.3):\n",
				"      \n",
				"            super(MyModel,self).__init__()\n",
				"            self.net=nn.Sequential(\n",
				"                nn.Linear(input,100),\n",
				"                nn.BatchNorm1d(100),\n",
				"                nn.Dropout(p=drop_p),\n",
				"                nn.ReLU(),\n",
				"                nn.Linear(100,30),\n",
				"                nn.BatchNorm1d(30),\n",
				"                nn.Dropout(p=drop_p),\n",
				"                nn.ReLU(),\n",
				"                nn.Linear(30,output)\n",
				"            )\n",
				"    def forward(self,input):\n",
				"            return self.net(input)\n",
				"\n",
				"\n",
				"if __name__ == \"__main__\":\n",
				"    #设置超参\n",
				"\n",
				"    \n",
				"    dataset=HgDataset(file_path='data\\hg1.csv')\n",
				"    dataset_len=len(dataset)\n",
				"    print('the lenght of dataset',dataset_len)\n",
				"    train_size=int(0.8*dataset_len)\n",
				"    test_size=dataset_len-train_size\n",
				"    print(\"the length of train size is {},  test size is {}\".format(train_size,test_size))\n",
				"    train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
				"    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
				"    batch=20\n",
				"    train_dataloader=DataLoader(train_dataset,batch_size=batch,shuffle=True,collate_fn=lambda x:my_transform(x,device))\n",
				"    test_dataloader=DataLoader(test_dataset,batch_size=batch,shuffle=True,collate_fn=lambda x:my_transform(x,device))\n",
				"\n",
				"        ################################super parameters################################\n",
				"    learning_rate=0.02\n",
				"  \n",
				"    weight_decay=0.005\n",
				"    epochs=500\n",
				"    drop_p=0.3#drop 的概率\n",
				" \n",
				"    ################################create modle,opt,loss_fn################################\n",
				"    ### 模型构建以及参数设定\n",
				"    model=MyModel(input=19,output=1,drop_p=0.23)\n",
				"    model.to(device)\n",
				"    loss_fn=nn.MSELoss()\n",
				"    opt=torch.optim.Adam(params=model.parameters(),lr=learning_rate,weight_decay=weight_decay)\n",
				"    ##########################################\n",
				"    epoch_times=int(dataset_len/batch)\n",
				"    # 用于记录训练和测试损失的列表\n",
				"    train_losses = []\n",
				"    test_losses = []\n",
				"    epoch_r2_scores = []\n",
				"\n",
				"    #print('to read a whole dataset, need times of epoch',epoch_times)\n",
				"    for i in range(epochs):\n",
				"        train_loss=0\n",
				"        for x_batch, y_batch in train_dataloader:\n",
				"            y_pred=model(x_batch)\n",
				"            loss=loss_fn(y_pred,y_batch)\n",
				"            opt.zero_grad()\n",
				"            loss.backward()\n",
				"            opt.step()\n",
				"                # 用于记录训练和测试损失的列表\n",
				"            train_loss += loss.item() * x_batch.size(0)\n",
				"        train_loss /= len(train_dataloader.dataset)\n",
				"        train_losses.append(train_loss)\n",
				"\n",
				"        model.eval()#进入评估模式，停止dropout和bathnorm\n",
				"        test_loss=0\n",
				"        y_true=[]\n",
				"        y_pred_list=[]\n",
				"        with torch.no_grad():\n",
				"            for x_batch, y_batch in test_dataloader:\n",
				"                y_pred=model(x_batch)\n",
				"                loss=loss_fn(y_pred,y_batch)\n",
				"                test_loss += loss.item() * x_batch.size(0)\n",
				"                y_true.append(y_batch.cpu().numpy())\n",
				"                y_pred_list.append(y_pred.cpu().numpy())\n",
				"\n",
				"                # 由于对应的是回归方程，故计算r\n",
				"        test_loss /= len(test_dataloader.dataset)\n",
				"        test_losses.append(test_loss)\n",
				"\n",
				"        y_pred_list=np.concatenate(y_pred_list,axis=0)\n",
				"        y_true=np.concatenate(y_true,axis=0)\n",
				"        r2=r2_score(y_pred_list,y_true)\n",
				"        epoch_r2_scores.append(r2)\n",
				"        print(f'R^2 Score: {r2}')\n",
				"        # 打印每个epoch的损失\n",
				"        print(f\"Epoch {i+1}/{epochs}.. Train loss: {train_loss:.4f}.. Test loss: {test_loss:.4f}\")\n",
				"        # 绘制训练和测试损失\n",
				"    plt.figure(figsize=(10, 6))\n",
				"    plt.plot(train_losses, label='Training loss')\n",
				"    plt.plot(test_losses, label='Test loss')\n",
				"    plt.title('Loss vs. Epochs')\n",
				"    plt.xlabel('Epochs')\n",
				"    plt.ylabel('Loss')\n",
				"    plt.legend()\n",
				"    plt.show()\n",
				"\n",
				"    # 绘制批次R²分数曲线\n",
				"# 所有epoch完成后，绘制epoch R²分数曲线\n",
				"    plt.figure(figsize=(10, 6))\n",
				"    plt.plot(epoch_r2_scores, marker='o', linestyle='-', color='blue')\n",
				"    plt.title('Epoch-wise R² Score')\n",
				"    plt.xlabel('Epoch')\n",
				"    plt.ylabel('R² Score')\n",
				"    plt.grid(True)\n",
				"    plt.show()\n",
				" \n",
				" "
			]
		},
		{
			"attachments": {},
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"### 多元回归函数 category 类型自变量 embbding 层\n",
				" \n",
				"\n",
				"在数值型输入数据基础上，加入category类型变量，并通过embedding层进行处理\n",
				"\n",
				"category数据类型分为有序，ordinal；无序 normial 两种，在进行处理时都将其变换为one-hot编码\n",
				"\n",
				">In statistics, nominal data (also known as nominal scale) is a type of data that is used to label variables without providing any quantitative value. It is the simplest form of a scale of measure. Unlike ordinal data, nominal data cannot be ordered and cannot be measured.\n",
				"In statistics, ordinal data are the type of data in which the data values follow a natural order. One of the most notable features of ordinal data is that the differences between the data values cannot be determined or are meaningless. Generally, the data categories lack the width representing the equal increments of the underlying attribute.\n",
				" \n",
				"但由于one-hot编码矩阵过于稀疏，不利于计算，故需要embedding后再进入线性层。\n",
				"*[参考](https://towardsdatascience.com/deep-learning-for-tabular-data-using-pytorch-1807f2858320)\n",
				"*[Entity Embeddings of Categorical Variables](https://arxiv.org/pdf/1604.06737.pdf)\n",
				"Categorical embeddings are very similar to word embeddings which are commonly used in NLP. The basic idea is to have a fixed-length vector representation of each category in the column. How this is different from a one-hot encoding is that instead of having a sparse matrix, using embeddings, we get a dense matrix for each category with similar categories having values close to each other in the embedding space. Hence, this process not only saves up memory (as the one-hot encoding for columns having too many categories can really blow up the input matrix, also it is a very sparse matrix) but also reveals intrinsic properties of the categorical variables.\n",
				"\n",
				"---\n",
				"\n",
				"实验数据：\n",
				"\n",
				"[PyTorch NN with Embeddings and CatBoos](https://www.kaggle.com/code/vadbeg/pytorch-nn-with-embeddings-and-catboost)"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"#### 不同数值类型：\n",
				"\n",
				"当我们试图理解数据时，应该意识到有3种不同的数值。\n",
				"\n",
				"1. 第1种是连续值，用数字表示是最直观的，它们是严格有序的，不同值之间的差异具有严格的意义。无论A包裹的质量是3千克还是10千克，或者B包裹是来自200英里(1英里约合1.61千米）还是2000英里之外，说A包裹比B包裹重2千克，或者说B包裹比A包裹的距离远100英里都是有固定意义的。如果你用单位来计算或测量某物，它可能是一个连续的值。文献实际上进一步划分了连续值：在前面的例子中，可以说某个物体的质量或距离是一个物体的2倍或3倍，这些值被称为比例尺度。\n",
				"\n",
				"另一方面，一天中的时间确实有差异，但声称6:00是3:00的2倍是不合理的，因此一天中的时间只提供了一个区间尺度。\n",
				"\n",
				"2. 第2种是序数值。我们对连续值的严格排序仍然存在，但值之间的固定关系不再适用。一个很好的列子就是点一份小杯、中杯或大杯的饮料，将小杯映射为1、中杯为2、大杯为3。大杯饮料比中杯大，就像3比2大一样，但它没有告诉我们大了多少。如果我们将1、2、3转换为实际体积，如8、12和 21液体盎司(1液体盎司约合29.57毫升），那么它们将转换为区间值。重要的是要记住，除了对这些值生行排序，我们无法对它们进行“数学运算”，试图将大杯等于3、小杯等于1的平均值计算不会得到中不饮料的体积。\n",
				"\n",
				"3. 第3种是分类值，分类值对其值既没有排序意义，也没有数字意义，通常只是分配任意数字的可能性的枚举。将水设定为1、咖啡设定为2、苏打水设定为3、牛奶设定为4，就是一个很好的例子。把水在前面，把牛奶放在最后，这并没有什么逻辑可言，只是需要不同的值来区分它们。我们可以将咖啡没定为10，牛奶设定为-3，并不会有明显变化（尽管在 0~N-1的范围内赋值对独热编码和我们将在 4.5.4小节讨论的嵌入有好处）。因为分类数值没有意义，所以它们也被称为名义尺度。"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"One-hot 独热编码\n",
				"1. 如果是区间值，可以排序，例如 等级1，等级2，那么使用整数向量是合适的\n",
				"2. 如果分数是完全离散的，比如葡萄酒的品种，那么采用独热编码更合适，因为没有隐含的顺序和距离。独热编码也适用于分数介于整数分数之间的定量分数\n",
				"\n",
				"``` python\n",
				"import torch\n",
				"import torch.nn.functional as F\n",
				"\n",
				"# 假设我们有一个tensor，包含了整数目标值\n",
				"targets = torch.tensor([0, 1, 2, 3])\n",
				"\n",
				"# 指定类别总数\n",
				"num_classes = 4\n",
				"\n",
				"# 使用one_hot函数将targets转换成one-hot编码\n",
				"one_hot_targets = F.one_hot(targets, num_classes=num_classes)\n",
				"\n",
				"print(one_hot_targets)\n",
				"```"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 16,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"torch.Size([4])\n",
						"tensor([[0, 1, 2, 3]])\n",
						"tensor([[1, 0, 0, 0],\n",
						"        [0, 1, 0, 0],\n",
						"        [0, 0, 1, 0],\n",
						"        [0, 0, 0, 1]])\n"
					]
				}
			],
			"source": [
				"import torch\n",
				"import torch.nn.functional as F\n",
				"\n",
				" \n",
				"\n",
				"# 假设我们有一个tensor，包含了整数目标值\n",
				"targets = torch.tensor([0, 1, 2, 3])\n",
				"print(targets.shape)\n",
				"print(torch.unsqueeze(targets,0))\n",
				"\n",
				"\n",
				"# 指定类别总数\n",
				"num_classes = 4\n",
				"\n",
				"# 使用one_hot函数将targets转换成one-hot编码\n",
				"one_hot_targets = F.one_hot(targets, num_classes=num_classes)\n",
				"\n",
				"print(one_hot_targets)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 29,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"the category attribute is Raw_cooked, the Sequence attribute is background_pollu\n",
						"(753, 1)\n",
						"(753, 11)\n",
						"torch.Size([753])\n",
						"the shape of b_p_ht_hot is torch.Size([753, 12]) \n",
						"tensor([[1, 0, 0,  ..., 0, 0, 0],\n",
						"        [1, 0, 0,  ..., 0, 0, 0],\n",
						"        [1, 0, 0,  ..., 0, 0, 0],\n",
						"        ...,\n",
						"        [1, 0, 0,  ..., 0, 0, 0],\n",
						"        [1, 0, 0,  ..., 0, 0, 0],\n",
						"        [1, 0, 0,  ..., 0, 0, 0]])\n"
					]
				}
			],
			"source": [
				"import pandas as pd \n",
				"from sklearn.preprocessing import LabelBinarizer\n",
				"hg2=pd.read_csv(\"data/Hg_notime.csv\")\n",
				"hg2.columns\n",
				"print(\"the category attribute is Raw_cooked, the Sequence attribute is background_pollu\")\n",
				"b_p=hg2['Background_pollu'].to_numpy()\n",
				"r_c=hg2['Raw_cooked'].to_numpy()\n",
				"\n",
				"#使用sklearn进行ont-hot编码,在此先不考虑b_p的有序性\n",
				"one_hot=LabelBinarizer()\n",
				"r_c_h=one_hot.fit_transform(r_c)\n",
				"print(r_c_h.shape)\n",
				"b_p_h=one_hot.fit_transform(b_p)\n",
				"print(b_p_h.shape)\n",
				"\n",
				"#使用python中\n",
				"b_p_ht=torch.from_numpy(b_p)\n",
				"print(b_p_ht.shape)\n",
				"#b_p_ht2=torch.unsqueeze(b_p_ht,dim=1)\n",
				"#print(b_p_ht2.shape)\n",
				"#num_class=int(b_p_ht2.shape[1])\n",
				"#print(\"the columns of b_p_ht are {} \".format(num_class))\n",
				"#b_p_ht_hot=F.one_hot(b_p_ht2)\n",
				"b_p_ht_hot=F.one_hot(b_p_ht)\n",
				"print(\"the shape of b_p_ht_hot is {} \".format(b_p_ht_hot.shape))\n",
				"print(b_p_ht_hot)"
			]
		},
		{
			"attachments": {},
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"\n",
				"## Eembedding\n",
				"\n",
				"参考：\n",
				"[一文读懂Embedding的概念，以及它和深度学习的关系](https://zhuanlan.zhihu.com/p/164502624)\n",
				">https://blog.csdn.net/qq_41775769/article/details/121825668\n",
				"\n",
				"Embedding 常在NLP中使用。类别变量、词语形成的矩阵，都是一个稀疏矩阵，不利于深度学习训练，故首先需要将其进行转换。\n",
				"\n",
				"在提到 Embedding 时，首先想到的是“向量化”，主要作用是将高维稀疏向量转化为稠密向量，从而方便下游模型处理。那什么是 embedding 呢？下面是大家对 embedding 的定义：\n",
				"\n",
				"Embedding层，在某种程度上，就是用来降维的，降维的原理就是矩阵乘法\n",
				"\n",
				"Embedding的又一个作用体现了：对低维的数据进行升维时，可能把一些其他特征给放大了，或者把笼统的特征给分开了。\n",
				"\n",
				"同时，这个Embedding是一直在学习在优化的，就使得整个拉近拉远的过程慢慢形成一个良好的观察点。\n",
				"\n",
				"\n",
				"\n",
				"---\n",
				"以下首先将无序、有序类别变量转换为矩阵，而后通过pytorch中embedding进行处理，并观察处理结果。\n",
				"\n",
				"---\n",
				"编码：\n",
				"\n",
				"sklearn、pandas、tensor中都由one-hot编码方法，\n",
				"\n",
				"--\n",
				"参考\n",
				"[pytorch embedding](https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html#torch.nn.Embedding)\n",
				"> \n",
				"\n",
				"A simple lookup table that stores embeddings of a fixed dictionary and size.\n",
				"\n",
				"This module is often used to store word embeddings and retrieve them using indices. The input to the module is a list of indices, and the output is the corresponding word embeddings.\n",
				"\n",
				"embedding层简而言之就是实现了输入（批量 batch）矩阵的降维，通过矩阵点乘，使得输入的一个$m \\times n$的 $m$ bich-size 长度为u $n$的稀疏矩阵，"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"对比ont-hot以及embeding 的对比，可以发现，如果类别是11个，样本数据是5行那么对应的onthot矩阵会非常大，将会是$ 5 \\times 11=55 $，但是通过embeding\n",
				"\n",
				"首先设置一个矩阵$2 \\times 11$，其每行与11个类别分别对应，那么最后的矩阵将会是 $5 \\times 2$个elements，显然要减少很多，同时，对应的elements中值还可以表示语义信息"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"import numpy as np\n",
				"from sklearn.preprocessing import LabelBinarizer\n",
				"\n",
				" \n",
				"# 假设我们有11个类别\n",
				"num_classes = 11\n",
				"\n",
				"# 假设我们想为每个类别分配一个长度为2的embedding向量\n",
				"embedding_dim = 2\n",
				"\n",
				"# 创建一个embedding表，为每个类别随机生成embedding向量\n",
				"embedding_table = np.random.rand(num_classes, embedding_dim)\n",
				"\n",
				"# 显示embedding表\n",
				"print(\"Embedding table:\\n\", embedding_table)\n",
				"\n",
				"# 假设我们有一些类别数据，我们想为它们获取embedding向量\n",
				"categories = np.array([0, 1, 2, 0, 1])  # 类别索引\n",
				"\n",
				"# 从embedding表中检索对应的embedding向量\n",
				"category_embeddings = embedding_table[categories]\n",
				"print(\"Embedding matrix size:\",category_embeddings.size)\n",
				"#onehot 矩阵大小\n",
				"label=LabelBinarizer()\n",
				"onehot_table=label.fit_transform(categories)\n",
				"print(\"onehot matrix size:\",onehot_table.size)\n",
				"print(\"\\nCategory embeddings:\\n\", category_embeddings)\n",
				"print(onehot_table)"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"要使用PyTorch中的Embedding层实现类似的功能，首先需要将文本标签转换为整数索引，然后使用这些索引从Embedding层中检索嵌入向量。Embedding层允许我们学习一个更密集的向量表示，这与使用LabelBinarizer进行一次性编码不同，后者只提供了稀疏的、二进制的表示形式。\n",
				"\n",
				"\n",
				"请注意，这个示例假设你已经安装并且可以使用PyTorch。Embedding层在这里是随机初始化的，并且在一个实际的机器学习任务中，它会在训练过程中被更新以学习更有意义的表示。与one-hot编码不同，这些嵌入向量是密集的，并且其维度通常远小于类别的数量，使得它们在处理大量类别时更加有效和信息丰富。"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"from sklearn.preprocessing import LabelBinarizer,MultiLabelBinarizer\n",
				"import numpy as np\n",
				"import torch.nn as nn\n",
				"f_features=np.array(['百合','月季','百合','玫瑰','水仙','桂花','玫瑰'])\n",
				"one_hot=LabelBinarizer()\n",
				"f_1_h=one_hot.fit_transform(f_features)\n",
				"print(f_1_h)\n",
				"\n",
				"# 将文本标签转换为整数索引\n",
				"labels, levels = pd.factorize(f_features)\n",
				"print(\"Integer labels:\", labels)\n",
				"# 假设每个嵌入向量的维度为5（可以根据需要调整）\n",
				"embedding_dim = 5\n",
				"# 创建一个Embedding模块，其中num_embeddings为标签的唯一数量，embedding_dim为每个嵌入向量的大小\n",
				"embedding = nn.Embedding(num_embeddings=len(np.unique(labels)), embedding_dim=embedding_dim)\n",
				"# 将NumPy数组转换为PyTorch张量\n",
				"labels_tensor = torch.tensor(labels, dtype=torch.long)\n",
				"\n",
				"# 获取嵌入向量\n",
				"f_embeddings = embedding(labels_tensor)\n",
				"print(\"Embedding vectors:\\n\", f_embeddings)\n",
				"\n"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"将环境数据中数据改为embbding"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 59,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"the category attribute is Raw_cooked, the Sequence attribute is background_pollu\n",
						"background pollusion matirx: (753,)\n",
						"the unique of pollution :  [ 0  1  2  3  4  5  6  8  9 10 11]\n",
						"11\n",
						"torch.Size([753, 5])\n"
					]
				}
			],
			"source": [
				"import torch.nn as nn\n",
				"import pandas as pd\n",
				"\n",
				"if __name__ == \"__main__\":\n",
				" \n",
				"    hg2=pd.read_csv(\"data/Hg_notime.csv\")\n",
				"    hg2.columns\n",
				"    print(\"the category attribute is Raw_cooked, the Sequence attribute is background_pollu\")\n",
				"    b_p=hg2['Background_pollu'].to_numpy()\n",
				"    r_c=hg2['Raw_cooked'].to_numpy()\n",
				"    bp_labels,bp_unique=pd.factorize(b_p)\n",
				"    print(\"background pollusion matirx:\",bp_labels.shape)\n",
				"    print(\"the unique of pollution : \", bp_unique)\n",
				"\n",
				"    embedding_dim=5\n",
				"# 创建一个Embedding模块，其中num_embeddings为标签的唯一数量，embedding_dim为每个嵌入向量的大小\n",
				"    print(len(np.unique(bp_labels)))\n",
				"    embedding = nn.Embedding(num_embeddings=len(np.unique(bp_labels)), embedding_dim=embedding_dim)\n",
				"    t_labels=torch.from_numpy(bp_labels)\n",
				"    embedding_r=embedding(t_labels)\n",
				"    print(embedding_r.shape)\n",
				"赶紧\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 42,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"编码： [0 1 0 2 1 3]\n",
						"唯一值： ['apple' 'banana' 'orange' 'cherry']\n"
					]
				}
			],
			"source": [
				"import pandas as pd\n",
				"\n",
				"# 示例序列\n",
				"data = ['apple', 'banana', 'apple', 'orange', 'banana', 'cherry']\n",
				"\n",
				"# 使用pd.factorize进行因子化\n",
				"labels, unique = pd.factorize(data)\n",
				"\n",
				"print(\"编码：\", labels)\n",
				"print(\"唯一值：\", unique)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 37,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"torch.Size([2, 4, 3])\n",
						"tensor([[[-1.0461,  0.5028, -0.1446],\n",
						"         [ 1.3913, -0.3786, -0.3373],\n",
						"         [ 1.3104,  1.1621, -0.9709],\n",
						"         [ 1.0844, -0.0698,  1.4881]],\n",
						"\n",
						"        [[ 1.3104,  1.1621, -0.9709],\n",
						"         [ 1.8854, -0.5793,  0.0369],\n",
						"         [ 1.3913, -0.3786, -0.3373],\n",
						"         [-1.9579,  1.2799, -1.2156]]], grad_fn=<EmbeddingBackward0>)\n"
					]
				}
			],
			"source": [
				"import torch\n",
				"import torch.nn as nn\n",
				"embedding=nn.Embedding(10,3)\n",
				"input=torch.LongTensor([[1,2,4,5],[4,3,2,9]])\n",
				"output=embedding(input)\n",
				"print(output.shape)\n",
				"print(output)"
			]
		},
		{
			"attachments": {},
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"实现boston数据中，类别数据与数值型数据的分析，"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"## 实验 1.4 构建数值型、分类型混合数据类型的回归方程\n",
				"\n",
				"实验步骤\n",
				"1. 构建model，包含embedding层，对categories，numerical数据进行处理。\n",
				"   1.1 构建embbeding层，处理category attribute数据，得到对应的数值矩阵。\n",
				"   1.2 构建Linear层，输入nuercial attribute，\n",
				"   1.3 Linear层与与embbeding层得到的数值矩阵合并，作为下一层的输入值"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"cuda is avialable\n"
					]
				}
			],
			"source": [
				"import torch \n",
				"if torch.cuda.is_available() :\n",
				"    print(\"cuda is avialable\")"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 15,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"[ 0  1  2  3  4  5  6  8  9 10 11]\n",
						"the labels of category attribute is 11 and the numerical attribute dim is 19\n",
						"the lenght of dataset 753\n",
						"the length of train size is 602,  test size is 151\n",
						"R^2 Score: -21.361502476584526\n",
						"Epoch 1/500.. Train loss: 30.7563.. Test loss: 88.7110\n",
						"R^2 Score: -0.6691981435462133\n",
						"Epoch 2/500.. Train loss: 18.1816.. Test loss: 59.0197\n",
						"R^2 Score: 0.016292408190223817\n",
						"Epoch 3/500.. Train loss: 15.2595.. Test loss: 50.4780\n",
						"R^2 Score: 0.040935581831110346\n",
						"Epoch 4/500.. Train loss: 12.7533.. Test loss: 40.2855\n",
						"R^2 Score: 0.4060631006884209\n",
						"Epoch 5/500.. Train loss: 12.7742.. Test loss: 31.6485\n",
						"R^2 Score: 0.5494587485455464\n",
						"Epoch 6/500.. Train loss: 9.9206.. Test loss: 40.5093\n",
						"R^2 Score: -0.9288069997291888\n",
						"Epoch 7/500.. Train loss: 10.4202.. Test loss: 46.0775\n",
						"R^2 Score: 0.5105667238967289\n",
						"Epoch 8/500.. Train loss: 10.3204.. Test loss: 35.6713\n",
						"R^2 Score: 0.33479655690426224\n",
						"Epoch 9/500.. Train loss: 8.7421.. Test loss: 36.3695\n",
						"R^2 Score: 0.5223925770068125\n",
						"Epoch 10/500.. Train loss: 9.1141.. Test loss: 29.4069\n",
						"R^2 Score: 0.6477510608680669\n",
						"Epoch 11/500.. Train loss: 6.8049.. Test loss: 24.9945\n",
						"R^2 Score: 0.49703916385015956\n",
						"Epoch 12/500.. Train loss: 6.7547.. Test loss: 26.4265\n",
						"R^2 Score: 0.6648389786445998\n",
						"Epoch 13/500.. Train loss: 5.5737.. Test loss: 20.2923\n",
						"R^2 Score: 0.7897333015943604\n",
						"Epoch 14/500.. Train loss: 5.4916.. Test loss: 15.0726\n",
						"R^2 Score: 0.6423892739013715\n",
						"Epoch 15/500.. Train loss: 5.4772.. Test loss: 26.9075\n",
						"R^2 Score: 0.6633189455842978\n",
						"Epoch 16/500.. Train loss: 5.4004.. Test loss: 23.3053\n",
						"R^2 Score: 0.7968926698171386\n",
						"Epoch 17/500.. Train loss: 6.3773.. Test loss: 19.6842\n",
						"R^2 Score: 0.6223953027592919\n",
						"Epoch 18/500.. Train loss: 7.7676.. Test loss: 24.0247\n",
						"R^2 Score: 0.53885731511244\n",
						"Epoch 19/500.. Train loss: 7.8452.. Test loss: 23.4675\n",
						"R^2 Score: 0.6607803171047915\n",
						"Epoch 20/500.. Train loss: 5.7533.. Test loss: 19.6818\n",
						"R^2 Score: 0.8077135618203962\n",
						"Epoch 21/500.. Train loss: 5.8571.. Test loss: 15.9980\n",
						"R^2 Score: 0.7874554513924465\n",
						"Epoch 22/500.. Train loss: 5.0206.. Test loss: 12.9806\n",
						"R^2 Score: 0.7875582636262786\n",
						"Epoch 23/500.. Train loss: 5.2523.. Test loss: 17.2060\n",
						"R^2 Score: 0.695344336331414\n",
						"Epoch 24/500.. Train loss: 4.1803.. Test loss: 23.1887\n",
						"R^2 Score: 0.7274194877789486\n",
						"Epoch 25/500.. Train loss: 4.1007.. Test loss: 16.7382\n",
						"R^2 Score: 0.8290794651674069\n",
						"Epoch 26/500.. Train loss: 4.0384.. Test loss: 14.8862\n",
						"R^2 Score: 0.5865464467484143\n",
						"Epoch 27/500.. Train loss: 8.2016.. Test loss: 21.0214\n",
						"R^2 Score: -0.35753313815783594\n",
						"Epoch 28/500.. Train loss: 12.8708.. Test loss: 42.3147\n",
						"R^2 Score: 0.5811797988296981\n",
						"Epoch 29/500.. Train loss: 7.6508.. Test loss: 31.2430\n",
						"R^2 Score: 0.6095550186584282\n",
						"Epoch 30/500.. Train loss: 6.2476.. Test loss: 28.0602\n",
						"R^2 Score: 0.7534757398972955\n",
						"Epoch 31/500.. Train loss: 5.0828.. Test loss: 25.2865\n",
						"R^2 Score: 0.4778157547214331\n",
						"Epoch 32/500.. Train loss: 7.6609.. Test loss: 23.7885\n",
						"R^2 Score: 0.7356969206779038\n",
						"Epoch 33/500.. Train loss: 6.3400.. Test loss: 26.1773\n",
						"R^2 Score: 0.7471584275262333\n",
						"Epoch 34/500.. Train loss: 6.1495.. Test loss: 21.7566\n",
						"R^2 Score: 0.7952664236189039\n",
						"Epoch 35/500.. Train loss: 4.5290.. Test loss: 15.8775\n",
						"R^2 Score: 0.7928821672746837\n",
						"Epoch 36/500.. Train loss: 5.7783.. Test loss: 16.7721\n",
						"R^2 Score: 0.8694609036270805\n",
						"Epoch 37/500.. Train loss: 5.8644.. Test loss: 12.3597\n",
						"R^2 Score: 0.6678931546061911\n",
						"Epoch 38/500.. Train loss: 4.4529.. Test loss: 23.2888\n",
						"R^2 Score: 0.5120036656496898\n",
						"Epoch 39/500.. Train loss: 5.4297.. Test loss: 21.4335\n",
						"R^2 Score: 0.7496515092126568\n",
						"Epoch 40/500.. Train loss: 6.9599.. Test loss: 19.9656\n",
						"R^2 Score: 0.858451331475068\n",
						"Epoch 41/500.. Train loss: 4.8792.. Test loss: 15.9707\n",
						"R^2 Score: 0.5937885909934146\n",
						"Epoch 42/500.. Train loss: 6.0072.. Test loss: 19.6590\n",
						"R^2 Score: 0.811243432983088\n",
						"Epoch 43/500.. Train loss: 5.6366.. Test loss: 24.8959\n",
						"R^2 Score: 0.5269623518295175\n",
						"Epoch 44/500.. Train loss: 6.7028.. Test loss: 21.5479\n",
						"R^2 Score: 0.785634858410068\n",
						"Epoch 45/500.. Train loss: 7.4480.. Test loss: 30.1672\n",
						"R^2 Score: 0.6539311528458189\n",
						"Epoch 46/500.. Train loss: 6.8215.. Test loss: 19.6167\n",
						"R^2 Score: 0.7678902240008003\n",
						"Epoch 47/500.. Train loss: 7.3217.. Test loss: 21.2198\n",
						"R^2 Score: 0.7084942308192059\n",
						"Epoch 48/500.. Train loss: 5.2286.. Test loss: 21.7924\n",
						"R^2 Score: 0.7044509228377509\n",
						"Epoch 49/500.. Train loss: 5.9565.. Test loss: 23.2125\n",
						"R^2 Score: 0.8512228298536639\n",
						"Epoch 50/500.. Train loss: 3.4867.. Test loss: 12.6189\n",
						"R^2 Score: 0.16148212887755253\n",
						"Epoch 51/500.. Train loss: 10.0593.. Test loss: 28.2230\n",
						"R^2 Score: 0.8278868506621166\n",
						"Epoch 52/500.. Train loss: 5.2885.. Test loss: 15.9160\n",
						"R^2 Score: 0.7862694310973553\n",
						"Epoch 53/500.. Train loss: 4.7051.. Test loss: 20.6515\n",
						"R^2 Score: 0.684374968489823\n",
						"Epoch 54/500.. Train loss: 6.2101.. Test loss: 19.0029\n",
						"R^2 Score: 0.546895155441116\n",
						"Epoch 55/500.. Train loss: 6.6518.. Test loss: 22.3624\n",
						"R^2 Score: 0.8297736112709316\n",
						"Epoch 56/500.. Train loss: 5.3653.. Test loss: 13.5951\n",
						"R^2 Score: 0.8231738409977853\n",
						"Epoch 57/500.. Train loss: 4.1045.. Test loss: 15.8142\n",
						"R^2 Score: 0.8367726358451251\n",
						"Epoch 58/500.. Train loss: 4.1842.. Test loss: 13.6002\n",
						"R^2 Score: 0.659984159161933\n",
						"Epoch 59/500.. Train loss: 4.6344.. Test loss: 19.1978\n",
						"R^2 Score: 0.8673942934901702\n",
						"Epoch 60/500.. Train loss: 4.4845.. Test loss: 9.7591\n",
						"R^2 Score: 0.820472915492533\n",
						"Epoch 61/500.. Train loss: 3.0077.. Test loss: 26.0120\n",
						"R^2 Score: 0.7665679831105043\n",
						"Epoch 62/500.. Train loss: 7.1968.. Test loss: 14.8920\n",
						"R^2 Score: 0.3191813603504451\n",
						"Epoch 63/500.. Train loss: 7.7222.. Test loss: 34.4750\n",
						"R^2 Score: 0.7035338607451411\n",
						"Epoch 64/500.. Train loss: 7.5040.. Test loss: 29.0190\n",
						"R^2 Score: 0.7221109134917394\n",
						"Epoch 65/500.. Train loss: 4.5635.. Test loss: 16.7494\n",
						"R^2 Score: 0.8553608906238626\n",
						"Epoch 66/500.. Train loss: 4.3480.. Test loss: 15.5697\n",
						"R^2 Score: 0.8043659330931748\n",
						"Epoch 67/500.. Train loss: 4.9976.. Test loss: 12.2800\n",
						"R^2 Score: 0.5821929282616942\n",
						"Epoch 68/500.. Train loss: 5.0071.. Test loss: 31.3638\n",
						"R^2 Score: 0.7319701781997575\n",
						"Epoch 69/500.. Train loss: 7.4655.. Test loss: 16.2935\n",
						"R^2 Score: 0.71950037575929\n",
						"Epoch 70/500.. Train loss: 3.6373.. Test loss: 32.6258\n",
						"R^2 Score: 0.8702112267770649\n",
						"Epoch 71/500.. Train loss: 5.7108.. Test loss: 10.7601\n",
						"R^2 Score: 0.8275894019188944\n",
						"Epoch 72/500.. Train loss: 5.9055.. Test loss: 16.8339\n",
						"R^2 Score: 0.8428193554102962\n",
						"Epoch 73/500.. Train loss: 4.3397.. Test loss: 13.3957\n",
						"R^2 Score: 0.8455945732692988\n",
						"Epoch 74/500.. Train loss: 5.5559.. Test loss: 12.8471\n",
						"R^2 Score: 0.9035114482818244\n",
						"Epoch 75/500.. Train loss: 3.5292.. Test loss: 8.9040\n",
						"R^2 Score: 0.8884535430261449\n",
						"Epoch 76/500.. Train loss: 3.0321.. Test loss: 9.6353\n",
						"R^2 Score: 0.7226698394685167\n",
						"Epoch 77/500.. Train loss: 4.0819.. Test loss: 14.7584\n",
						"R^2 Score: 0.8677671329212958\n",
						"Epoch 78/500.. Train loss: 4.2484.. Test loss: 10.2769\n",
						"R^2 Score: 0.8528288624494691\n",
						"Epoch 79/500.. Train loss: 3.3758.. Test loss: 12.5838\n",
						"R^2 Score: 0.8413059725054296\n",
						"Epoch 80/500.. Train loss: 5.6826.. Test loss: 10.5458\n",
						"R^2 Score: 0.7115635382683783\n",
						"Epoch 81/500.. Train loss: 2.7707.. Test loss: 17.4143\n",
						"R^2 Score: 0.881185893730044\n",
						"Epoch 82/500.. Train loss: 4.3610.. Test loss: 9.8674\n",
						"R^2 Score: 0.762827812742533\n",
						"Epoch 83/500.. Train loss: 5.0848.. Test loss: 12.5881\n",
						"R^2 Score: 0.8076875291004538\n",
						"Epoch 84/500.. Train loss: 3.5072.. Test loss: 13.6597\n",
						"R^2 Score: 0.8374564464391513\n",
						"Epoch 85/500.. Train loss: 4.9780.. Test loss: 11.4602\n",
						"R^2 Score: 0.8423271053069477\n",
						"Epoch 86/500.. Train loss: 2.5104.. Test loss: 14.9669\n",
						"R^2 Score: 0.7998620400570978\n",
						"Epoch 87/500.. Train loss: 3.2048.. Test loss: 14.3463\n",
						"R^2 Score: 0.7858059694263032\n",
						"Epoch 88/500.. Train loss: 4.1904.. Test loss: 13.5023\n",
						"R^2 Score: 0.8184495608084725\n",
						"Epoch 89/500.. Train loss: 3.0378.. Test loss: 24.5190\n",
						"R^2 Score: 0.7989561874946903\n",
						"Epoch 90/500.. Train loss: 3.6571.. Test loss: 13.7437\n",
						"R^2 Score: 0.7201772060665439\n",
						"Epoch 91/500.. Train loss: 5.1749.. Test loss: 14.7543\n",
						"R^2 Score: 0.7744749631946025\n",
						"Epoch 92/500.. Train loss: 5.0563.. Test loss: 15.8687\n",
						"R^2 Score: 0.7347316403003978\n",
						"Epoch 93/500.. Train loss: 5.6087.. Test loss: 29.0504\n",
						"R^2 Score: 0.6645827040145358\n",
						"Epoch 94/500.. Train loss: 4.3456.. Test loss: 19.8622\n",
						"R^2 Score: 0.8467919188164754\n",
						"Epoch 95/500.. Train loss: 4.4868.. Test loss: 11.6065\n",
						"R^2 Score: 0.887618957461366\n",
						"Epoch 96/500.. Train loss: 2.5364.. Test loss: 10.2750\n",
						"R^2 Score: 0.8358058247409279\n",
						"Epoch 97/500.. Train loss: 2.6998.. Test loss: 11.9298\n",
						"R^2 Score: 0.8371331313668413\n",
						"Epoch 98/500.. Train loss: 2.9920.. Test loss: 11.4661\n",
						"R^2 Score: 0.7572645202299884\n",
						"Epoch 99/500.. Train loss: 5.7388.. Test loss: 14.1323\n",
						"R^2 Score: 0.8840080818623297\n",
						"Epoch 100/500.. Train loss: 3.3164.. Test loss: 10.8267\n",
						"R^2 Score: 0.8876122040021492\n",
						"Epoch 101/500.. Train loss: 3.7624.. Test loss: 12.1967\n",
						"R^2 Score: 0.9045630155976004\n",
						"Epoch 102/500.. Train loss: 1.9554.. Test loss: 11.0826\n",
						"R^2 Score: 0.9211176114541532\n",
						"Epoch 103/500.. Train loss: 2.7099.. Test loss: 7.2276\n",
						"R^2 Score: 0.8507528216412322\n",
						"Epoch 104/500.. Train loss: 3.9425.. Test loss: 11.1194\n",
						"R^2 Score: 0.9027515346266253\n",
						"Epoch 105/500.. Train loss: 4.0251.. Test loss: 10.0477\n",
						"R^2 Score: 0.8420150454544643\n",
						"Epoch 106/500.. Train loss: 2.1881.. Test loss: 13.7633\n",
						"R^2 Score: 0.850609158047448\n",
						"Epoch 107/500.. Train loss: 3.2675.. Test loss: 16.6306\n",
						"R^2 Score: 0.9013911685756113\n",
						"Epoch 108/500.. Train loss: 2.2454.. Test loss: 9.5291\n",
						"R^2 Score: 0.8834708184918328\n",
						"Epoch 109/500.. Train loss: 2.2342.. Test loss: 9.9761\n",
						"R^2 Score: 0.9213183634804455\n",
						"Epoch 110/500.. Train loss: 1.9871.. Test loss: 6.9351\n",
						"R^2 Score: 0.8769654550664157\n",
						"Epoch 111/500.. Train loss: 2.4354.. Test loss: 9.5328\n",
						"R^2 Score: 0.8705636735357154\n",
						"Epoch 112/500.. Train loss: 3.5294.. Test loss: 10.0144\n",
						"R^2 Score: 0.8916229402383594\n",
						"Epoch 113/500.. Train loss: 2.9622.. Test loss: 9.7607\n",
						"R^2 Score: 0.8979020928686497\n",
						"Epoch 114/500.. Train loss: 2.3570.. Test loss: 8.2964\n",
						"R^2 Score: 0.8088834378432004\n",
						"Epoch 115/500.. Train loss: 3.1560.. Test loss: 12.2294\n",
						"R^2 Score: 0.8254716865214906\n",
						"Epoch 116/500.. Train loss: 4.0245.. Test loss: 15.2308\n",
						"R^2 Score: 0.8545842801305465\n",
						"Epoch 117/500.. Train loss: 4.7418.. Test loss: 11.1597\n",
						"R^2 Score: 0.7805348219592492\n",
						"Epoch 118/500.. Train loss: 3.1284.. Test loss: 15.0034\n",
						"R^2 Score: 0.7898909819152702\n",
						"Epoch 119/500.. Train loss: 2.9625.. Test loss: 13.1238\n",
						"R^2 Score: 0.8548087261416368\n",
						"Epoch 120/500.. Train loss: 2.9566.. Test loss: 14.2644\n",
						"R^2 Score: 0.6839294607074959\n",
						"Epoch 121/500.. Train loss: 5.9148.. Test loss: 19.0216\n",
						"R^2 Score: 0.5361535408254707\n",
						"Epoch 122/500.. Train loss: 5.1047.. Test loss: 25.0778\n",
						"R^2 Score: 0.7239016191860841\n",
						"Epoch 123/500.. Train loss: 7.3141.. Test loss: 23.0477\n",
						"R^2 Score: 0.6066592912548743\n",
						"Epoch 124/500.. Train loss: 4.3031.. Test loss: 21.7326\n",
						"R^2 Score: 0.801349194457762\n",
						"Epoch 125/500.. Train loss: 8.2780.. Test loss: 12.7232\n",
						"R^2 Score: 0.8727599736541403\n",
						"Epoch 126/500.. Train loss: 4.1807.. Test loss: 12.6792\n",
						"R^2 Score: 0.7981221761311545\n",
						"Epoch 127/500.. Train loss: 6.5804.. Test loss: 12.9773\n",
						"R^2 Score: 0.7025144215863826\n",
						"Epoch 128/500.. Train loss: 5.3976.. Test loss: 20.6661\n",
						"R^2 Score: 0.6258127970569664\n",
						"Epoch 129/500.. Train loss: 6.2889.. Test loss: 22.0015\n",
						"R^2 Score: 0.6160460982806383\n",
						"Epoch 130/500.. Train loss: 7.7808.. Test loss: 21.0739\n",
						"R^2 Score: 0.7851929033598145\n",
						"Epoch 131/500.. Train loss: 5.6417.. Test loss: 18.4154\n",
						"R^2 Score: 0.454550623759311\n",
						"Epoch 132/500.. Train loss: 6.1484.. Test loss: 23.6102\n",
						"R^2 Score: 0.8659083854929812\n",
						"Epoch 133/500.. Train loss: 3.9030.. Test loss: 16.1333\n",
						"R^2 Score: -0.36138166479049283\n",
						"Epoch 134/500.. Train loss: 5.0482.. Test loss: 35.8827\n",
						"R^2 Score: 0.4772583860435323\n",
						"Epoch 135/500.. Train loss: 9.9668.. Test loss: 22.5217\n",
						"R^2 Score: 0.7015986763367712\n",
						"Epoch 136/500.. Train loss: 4.4571.. Test loss: 24.2532\n",
						"R^2 Score: 0.8090519022503492\n",
						"Epoch 137/500.. Train loss: 3.9524.. Test loss: 13.4323\n",
						"R^2 Score: 0.7164543511272516\n",
						"Epoch 138/500.. Train loss: 3.7143.. Test loss: 16.5628\n",
						"R^2 Score: 0.8072748312266442\n",
						"Epoch 139/500.. Train loss: 4.0643.. Test loss: 14.7267\n",
						"R^2 Score: 0.8127738599765684\n",
						"Epoch 140/500.. Train loss: 4.2156.. Test loss: 13.1412\n",
						"R^2 Score: 0.9034804938103782\n",
						"Epoch 141/500.. Train loss: 4.4264.. Test loss: 7.9523\n",
						"R^2 Score: 0.8604952232182892\n",
						"Epoch 142/500.. Train loss: 3.5356.. Test loss: 10.8430\n",
						"R^2 Score: 0.8446856269910004\n",
						"Epoch 143/500.. Train loss: 2.8889.. Test loss: 21.2879\n",
						"R^2 Score: 0.833874287038016\n",
						"Epoch 144/500.. Train loss: 5.3554.. Test loss: 16.8089\n",
						"R^2 Score: 0.3196378470359965\n",
						"Epoch 145/500.. Train loss: 4.2152.. Test loss: 25.6250\n",
						"R^2 Score: 0.8552622465626711\n",
						"Epoch 146/500.. Train loss: 5.4288.. Test loss: 10.8510\n",
						"R^2 Score: 0.8405968239336383\n",
						"Epoch 147/500.. Train loss: 4.3728.. Test loss: 17.8922\n",
						"R^2 Score: 0.8176174000637118\n",
						"Epoch 148/500.. Train loss: 3.5708.. Test loss: 14.4899\n",
						"R^2 Score: 0.8069438633483595\n",
						"Epoch 149/500.. Train loss: 4.0197.. Test loss: 13.7935\n",
						"R^2 Score: 0.8759645402152517\n",
						"Epoch 150/500.. Train loss: 3.8739.. Test loss: 10.1197\n",
						"R^2 Score: 0.8497890463726673\n",
						"Epoch 151/500.. Train loss: 2.1767.. Test loss: 10.9049\n",
						"R^2 Score: 0.840071579024582\n",
						"Epoch 152/500.. Train loss: 2.4628.. Test loss: 12.5233\n",
						"R^2 Score: 0.9010740676502086\n",
						"Epoch 153/500.. Train loss: 2.5520.. Test loss: 8.5934\n",
						"R^2 Score: 0.8457575418732459\n",
						"Epoch 154/500.. Train loss: 2.9925.. Test loss: 12.5935\n",
						"R^2 Score: 0.8873668908423118\n",
						"Epoch 155/500.. Train loss: 2.8418.. Test loss: 13.1702\n",
						"R^2 Score: 0.9017904231239271\n",
						"Epoch 156/500.. Train loss: 2.1346.. Test loss: 9.8443\n",
						"R^2 Score: 0.8846318164337577\n",
						"Epoch 157/500.. Train loss: 2.2910.. Test loss: 9.1073\n",
						"R^2 Score: 0.8564476377245367\n",
						"Epoch 158/500.. Train loss: 4.2617.. Test loss: 11.4896\n",
						"R^2 Score: 0.885980828229756\n",
						"Epoch 159/500.. Train loss: 3.0292.. Test loss: 10.7169\n",
						"R^2 Score: 0.8490698015610609\n",
						"Epoch 160/500.. Train loss: 3.7320.. Test loss: 10.2255\n",
						"R^2 Score: 0.8147510405367155\n",
						"Epoch 161/500.. Train loss: 2.5971.. Test loss: 11.2294\n",
						"R^2 Score: 0.8685720198721372\n",
						"Epoch 162/500.. Train loss: 2.7455.. Test loss: 9.8846\n",
						"R^2 Score: 0.9055816009606839\n",
						"Epoch 163/500.. Train loss: 2.1525.. Test loss: 9.0553\n",
						"R^2 Score: 0.9041176904216551\n",
						"Epoch 164/500.. Train loss: 2.4672.. Test loss: 7.3012\n",
						"R^2 Score: 0.9162165728522412\n",
						"Epoch 165/500.. Train loss: 2.2264.. Test loss: 7.6924\n",
						"R^2 Score: 0.8909697003149266\n",
						"Epoch 166/500.. Train loss: 1.7217.. Test loss: 9.0468\n",
						"R^2 Score: 0.8832837704840042\n",
						"Epoch 167/500.. Train loss: 2.1830.. Test loss: 9.3998\n",
						"R^2 Score: 0.9315526584018908\n",
						"Epoch 168/500.. Train loss: 2.0375.. Test loss: 7.4358\n",
						"R^2 Score: 0.8125821160278851\n",
						"Epoch 169/500.. Train loss: 2.8247.. Test loss: 13.1225\n",
						"R^2 Score: 0.7951416140859476\n",
						"Epoch 170/500.. Train loss: 3.0202.. Test loss: 12.6872\n",
						"R^2 Score: 0.8781928822628465\n",
						"Epoch 171/500.. Train loss: 2.2423.. Test loss: 10.4241\n",
						"R^2 Score: 0.9175041877770643\n",
						"Epoch 172/500.. Train loss: 1.8521.. Test loss: 8.4355\n",
						"R^2 Score: 0.7952537572718397\n",
						"Epoch 173/500.. Train loss: 2.5259.. Test loss: 15.2415\n",
						"R^2 Score: 0.7954372787174588\n",
						"Epoch 174/500.. Train loss: 2.2071.. Test loss: 13.1418\n",
						"R^2 Score: 0.9072232422755643\n",
						"Epoch 175/500.. Train loss: 3.4007.. Test loss: 7.4591\n",
						"R^2 Score: 0.9067511423969014\n",
						"Epoch 176/500.. Train loss: 2.0468.. Test loss: 11.4022\n",
						"R^2 Score: 0.9134698388986937\n",
						"Epoch 177/500.. Train loss: 2.8250.. Test loss: 9.4095\n",
						"R^2 Score: 0.8726940944190171\n",
						"Epoch 178/500.. Train loss: 3.2518.. Test loss: 9.5413\n",
						"R^2 Score: 0.8980564285124473\n",
						"Epoch 179/500.. Train loss: 3.5252.. Test loss: 8.0462\n",
						"R^2 Score: 0.8555954812170244\n",
						"Epoch 180/500.. Train loss: 2.4700.. Test loss: 11.2652\n",
						"R^2 Score: 0.8762562636851041\n",
						"Epoch 181/500.. Train loss: 2.1625.. Test loss: 11.1186\n",
						"R^2 Score: 0.8668483274982893\n",
						"Epoch 182/500.. Train loss: 2.2483.. Test loss: 11.7145\n",
						"R^2 Score: 0.8528785925669677\n",
						"Epoch 183/500.. Train loss: 2.3529.. Test loss: 11.8914\n",
						"R^2 Score: 0.7233412577786532\n",
						"Epoch 184/500.. Train loss: 8.1800.. Test loss: 15.5666\n",
						"R^2 Score: 0.7661151225463514\n",
						"Epoch 185/500.. Train loss: 3.7087.. Test loss: 17.0098\n",
						"R^2 Score: 0.8641306959164989\n",
						"Epoch 186/500.. Train loss: 4.3805.. Test loss: 12.5457\n",
						"R^2 Score: 0.8701277857027605\n",
						"Epoch 187/500.. Train loss: 2.7541.. Test loss: 10.5931\n",
						"R^2 Score: 0.8307818832596439\n",
						"Epoch 188/500.. Train loss: 2.1793.. Test loss: 12.2372\n",
						"R^2 Score: 0.792110736723604\n",
						"Epoch 189/500.. Train loss: 2.8141.. Test loss: 12.6502\n",
						"R^2 Score: 0.8744534956872925\n",
						"Epoch 190/500.. Train loss: 2.9008.. Test loss: 10.1312\n",
						"R^2 Score: 0.8848538072712917\n",
						"Epoch 191/500.. Train loss: 2.5629.. Test loss: 13.0949\n",
						"R^2 Score: 0.8636753982966618\n",
						"Epoch 192/500.. Train loss: 3.2660.. Test loss: 9.8721\n",
						"R^2 Score: 0.770915671759892\n",
						"Epoch 193/500.. Train loss: 3.3531.. Test loss: 12.9286\n",
						"R^2 Score: 0.7943015071827095\n",
						"Epoch 194/500.. Train loss: 3.2926.. Test loss: 13.9390\n",
						"R^2 Score: 0.8987177555124151\n",
						"Epoch 195/500.. Train loss: 2.5782.. Test loss: 10.6621\n",
						"R^2 Score: 0.6825039224699525\n",
						"Epoch 196/500.. Train loss: 2.8896.. Test loss: 16.7862\n",
						"R^2 Score: 0.8598544942312937\n",
						"Epoch 197/500.. Train loss: 2.8909.. Test loss: 10.2464\n",
						"R^2 Score: 0.9250369597784076\n",
						"Epoch 198/500.. Train loss: 3.1629.. Test loss: 6.5424\n",
						"R^2 Score: 0.8942290457577224\n",
						"Epoch 199/500.. Train loss: 2.4906.. Test loss: 12.4684\n",
						"R^2 Score: 0.9328870512253284\n",
						"Epoch 200/500.. Train loss: 3.0452.. Test loss: 6.4544\n",
						"R^2 Score: 0.8629452580307398\n",
						"Epoch 201/500.. Train loss: 2.1350.. Test loss: 9.9219\n",
						"R^2 Score: 0.8469223742816939\n",
						"Epoch 202/500.. Train loss: 1.9358.. Test loss: 9.1763\n",
						"R^2 Score: 0.8761592661609413\n",
						"Epoch 203/500.. Train loss: 3.2924.. Test loss: 17.1499\n",
						"R^2 Score: 0.9096324782592907\n",
						"Epoch 204/500.. Train loss: 2.5189.. Test loss: 7.8198\n",
						"R^2 Score: 0.8712839596771188\n",
						"Epoch 205/500.. Train loss: 3.7432.. Test loss: 9.2223\n",
						"R^2 Score: 0.8190222823309043\n",
						"Epoch 206/500.. Train loss: 3.2383.. Test loss: 11.6480\n",
						"R^2 Score: 0.8784436152020569\n",
						"Epoch 207/500.. Train loss: 3.0607.. Test loss: 11.3357\n",
						"R^2 Score: 0.834956668205492\n",
						"Epoch 208/500.. Train loss: 2.2016.. Test loss: 11.1935\n",
						"R^2 Score: 0.8953902795381631\n",
						"Epoch 209/500.. Train loss: 2.8014.. Test loss: 9.6247\n",
						"R^2 Score: 0.9242761806730311\n",
						"Epoch 210/500.. Train loss: 2.7198.. Test loss: 7.6889\n",
						"R^2 Score: 0.8443717551176684\n",
						"Epoch 211/500.. Train loss: 2.9914.. Test loss: 10.2371\n",
						"R^2 Score: 0.8020796109820998\n",
						"Epoch 212/500.. Train loss: 3.5422.. Test loss: 12.2477\n",
						"R^2 Score: 0.9169531588501219\n",
						"Epoch 213/500.. Train loss: 3.5506.. Test loss: 7.0573\n",
						"R^2 Score: 0.8628491803474986\n",
						"Epoch 214/500.. Train loss: 2.2631.. Test loss: 9.5485\n",
						"R^2 Score: 0.8988777956352848\n",
						"Epoch 215/500.. Train loss: 3.0337.. Test loss: 8.7521\n",
						"R^2 Score: 0.9304937568133398\n",
						"Epoch 216/500.. Train loss: 3.2435.. Test loss: 5.9147\n",
						"R^2 Score: 0.8344937576464303\n",
						"Epoch 217/500.. Train loss: 4.6691.. Test loss: 9.7986\n",
						"R^2 Score: 0.8878101394991289\n",
						"Epoch 218/500.. Train loss: 2.3314.. Test loss: 10.6708\n",
						"R^2 Score: 0.8288840128261701\n",
						"Epoch 219/500.. Train loss: 3.1925.. Test loss: 11.2848\n",
						"R^2 Score: 0.7855672206262454\n",
						"Epoch 220/500.. Train loss: 2.1468.. Test loss: 15.9330\n",
						"R^2 Score: 0.8727163865300072\n",
						"Epoch 221/500.. Train loss: 4.1477.. Test loss: 8.9007\n",
						"R^2 Score: 0.7783139048225483\n",
						"Epoch 222/500.. Train loss: 2.4702.. Test loss: 23.4981\n",
						"R^2 Score: 0.7529971331659642\n",
						"Epoch 223/500.. Train loss: 4.9665.. Test loss: 15.6175\n",
						"R^2 Score: 0.8653493927644358\n",
						"Epoch 224/500.. Train loss: 3.4008.. Test loss: 11.4810\n",
						"R^2 Score: 0.905726459865934\n",
						"Epoch 225/500.. Train loss: 3.7187.. Test loss: 8.3447\n",
						"R^2 Score: 0.8749092573135016\n",
						"Epoch 226/500.. Train loss: 3.9868.. Test loss: 9.4671\n",
						"R^2 Score: 0.8018536409688148\n",
						"Epoch 227/500.. Train loss: 2.9798.. Test loss: 16.0119\n",
						"R^2 Score: 0.8460892432728838\n",
						"Epoch 228/500.. Train loss: 3.8616.. Test loss: 11.9130\n",
						"R^2 Score: 0.8667405115676788\n",
						"Epoch 229/500.. Train loss: 6.1669.. Test loss: 17.1499\n",
						"R^2 Score: 0.8144785373337405\n",
						"Epoch 230/500.. Train loss: 4.9743.. Test loss: 10.8696\n",
						"R^2 Score: 0.8048007173731513\n",
						"Epoch 231/500.. Train loss: 4.1413.. Test loss: 15.4927\n",
						"R^2 Score: 0.8906394969697757\n",
						"Epoch 232/500.. Train loss: 3.9623.. Test loss: 8.5622\n",
						"R^2 Score: 0.9007452210590464\n",
						"Epoch 233/500.. Train loss: 4.7752.. Test loss: 10.0764\n",
						"R^2 Score: 0.7197617291369569\n",
						"Epoch 234/500.. Train loss: 3.0225.. Test loss: 14.6937\n",
						"R^2 Score: 0.8633213188557517\n",
						"Epoch 235/500.. Train loss: 3.6343.. Test loss: 10.6552\n",
						"R^2 Score: 0.885575993535523\n",
						"Epoch 236/500.. Train loss: 3.1226.. Test loss: 7.9332\n",
						"R^2 Score: 0.8941159331287691\n",
						"Epoch 237/500.. Train loss: 2.7145.. Test loss: 8.2631\n",
						"R^2 Score: 0.8819282600010308\n",
						"Epoch 238/500.. Train loss: 2.1102.. Test loss: 12.4613\n",
						"R^2 Score: 0.8992776253936053\n",
						"Epoch 239/500.. Train loss: 2.9601.. Test loss: 10.5445\n",
						"R^2 Score: 0.8852998417345129\n",
						"Epoch 240/500.. Train loss: 2.3963.. Test loss: 9.3889\n",
						"R^2 Score: 0.856655116374237\n",
						"Epoch 241/500.. Train loss: 5.1516.. Test loss: 10.0945\n",
						"R^2 Score: 0.7966979982823965\n",
						"Epoch 242/500.. Train loss: 3.6725.. Test loss: 12.9091\n",
						"R^2 Score: 0.8733648813323094\n",
						"Epoch 243/500.. Train loss: 3.9065.. Test loss: 9.2420\n",
						"R^2 Score: 0.8108844355052724\n",
						"Epoch 244/500.. Train loss: 2.2490.. Test loss: 11.9135\n",
						"R^2 Score: 0.8774554703214736\n",
						"Epoch 245/500.. Train loss: 2.2916.. Test loss: 9.5041\n",
						"R^2 Score: 0.9044830997378964\n",
						"Epoch 246/500.. Train loss: 1.7817.. Test loss: 7.9979\n",
						"R^2 Score: 0.8885716706136926\n",
						"Epoch 247/500.. Train loss: 2.4197.. Test loss: 10.0906\n",
						"R^2 Score: 0.8802708859607455\n",
						"Epoch 248/500.. Train loss: 2.1663.. Test loss: 10.0605\n",
						"R^2 Score: 0.8926651041236694\n",
						"Epoch 249/500.. Train loss: 3.2423.. Test loss: 10.2216\n",
						"R^2 Score: 0.847791216339328\n",
						"Epoch 250/500.. Train loss: 2.5069.. Test loss: 12.7756\n",
						"R^2 Score: 0.7145033533235405\n",
						"Epoch 251/500.. Train loss: 2.4789.. Test loss: 14.2702\n",
						"R^2 Score: 0.858505107312236\n",
						"Epoch 252/500.. Train loss: 2.6702.. Test loss: 9.3155\n",
						"R^2 Score: 0.8860198674796189\n",
						"Epoch 253/500.. Train loss: 2.2335.. Test loss: 10.7088\n",
						"R^2 Score: 0.9045143383351943\n",
						"Epoch 254/500.. Train loss: 2.8945.. Test loss: 8.7652\n",
						"R^2 Score: 0.8700145018023387\n",
						"Epoch 255/500.. Train loss: 2.5680.. Test loss: 10.2720\n",
						"R^2 Score: 0.8967752915257253\n",
						"Epoch 256/500.. Train loss: 2.5380.. Test loss: 8.0548\n",
						"R^2 Score: 0.913776685925638\n",
						"Epoch 257/500.. Train loss: 2.2587.. Test loss: 8.7191\n",
						"R^2 Score: 0.8416944170812612\n",
						"Epoch 258/500.. Train loss: 4.3733.. Test loss: 15.7223\n",
						"R^2 Score: 0.857574057307801\n",
						"Epoch 259/500.. Train loss: 2.6718.. Test loss: 11.2533\n",
						"R^2 Score: 0.9195903977228768\n",
						"Epoch 260/500.. Train loss: 2.3585.. Test loss: 8.2980\n",
						"R^2 Score: 0.9196368223763048\n",
						"Epoch 261/500.. Train loss: 1.9623.. Test loss: 6.7035\n",
						"R^2 Score: 0.9057624412968466\n",
						"Epoch 262/500.. Train loss: 1.7741.. Test loss: 7.6177\n",
						"R^2 Score: 0.9245579555189178\n",
						"Epoch 263/500.. Train loss: 2.2106.. Test loss: 6.9574\n",
						"R^2 Score: 0.9114095593894145\n",
						"Epoch 264/500.. Train loss: 2.8818.. Test loss: 7.6398\n",
						"R^2 Score: 0.9241063037360281\n",
						"Epoch 265/500.. Train loss: 1.7329.. Test loss: 9.3894\n",
						"R^2 Score: 0.9024371009392329\n",
						"Epoch 266/500.. Train loss: 2.4599.. Test loss: 8.9401\n",
						"R^2 Score: 0.777367483465614\n",
						"Epoch 267/500.. Train loss: 3.7511.. Test loss: 13.3308\n",
						"R^2 Score: 0.8679454175403962\n",
						"Epoch 268/500.. Train loss: 2.4871.. Test loss: 9.8252\n",
						"R^2 Score: 0.9195945507837142\n",
						"Epoch 269/500.. Train loss: 3.0931.. Test loss: 8.5247\n",
						"R^2 Score: 0.8460530929778021\n",
						"Epoch 270/500.. Train loss: 1.9881.. Test loss: 11.0646\n",
						"R^2 Score: 0.883405138437447\n",
						"Epoch 271/500.. Train loss: 4.4719.. Test loss: 8.1416\n",
						"R^2 Score: 0.9229499898156074\n",
						"Epoch 272/500.. Train loss: 2.3697.. Test loss: 6.3597\n",
						"R^2 Score: 0.9303028247116364\n",
						"Epoch 273/500.. Train loss: 2.3251.. Test loss: 6.4220\n",
						"R^2 Score: 0.9270134485672084\n",
						"Epoch 274/500.. Train loss: 2.6273.. Test loss: 6.4857\n",
						"R^2 Score: 0.8720364873526346\n",
						"Epoch 275/500.. Train loss: 2.1863.. Test loss: 8.8517\n",
						"R^2 Score: 0.9100907719696231\n",
						"Epoch 276/500.. Train loss: 1.7054.. Test loss: 9.0270\n",
						"R^2 Score: 0.8823119755870741\n",
						"Epoch 277/500.. Train loss: 2.1233.. Test loss: 12.4800\n",
						"R^2 Score: 0.9250707820951644\n",
						"Epoch 278/500.. Train loss: 1.7846.. Test loss: 7.1896\n",
						"R^2 Score: 0.8843567998468372\n",
						"Epoch 279/500.. Train loss: 3.5686.. Test loss: 10.5807\n",
						"R^2 Score: 0.7176900709961058\n",
						"Epoch 280/500.. Train loss: 3.3395.. Test loss: 16.3220\n",
						"R^2 Score: 0.702408784815844\n",
						"Epoch 281/500.. Train loss: 5.1998.. Test loss: 18.3032\n",
						"R^2 Score: 0.8879422955003664\n",
						"Epoch 282/500.. Train loss: 3.4910.. Test loss: 9.4304\n",
						"R^2 Score: 0.8638227869407883\n",
						"Epoch 283/500.. Train loss: 3.3848.. Test loss: 10.1840\n",
						"R^2 Score: 0.8982789544075739\n",
						"Epoch 284/500.. Train loss: 3.2586.. Test loss: 12.3565\n",
						"R^2 Score: 0.9026399159644626\n",
						"Epoch 285/500.. Train loss: 2.3894.. Test loss: 8.2181\n",
						"R^2 Score: 0.9167392483657612\n",
						"Epoch 286/500.. Train loss: 3.3946.. Test loss: 6.7572\n",
						"R^2 Score: 0.9381702613714319\n",
						"Epoch 287/500.. Train loss: 2.4722.. Test loss: 6.0060\n",
						"R^2 Score: 0.912010951407409\n",
						"Epoch 288/500.. Train loss: 1.4824.. Test loss: 7.4699\n",
						"R^2 Score: 0.7857086966837576\n",
						"Epoch 289/500.. Train loss: 2.4040.. Test loss: 11.3448\n",
						"R^2 Score: 0.8695485620177031\n",
						"Epoch 290/500.. Train loss: 3.8674.. Test loss: 8.8484\n",
						"R^2 Score: 0.9035950631122183\n",
						"Epoch 291/500.. Train loss: 2.3130.. Test loss: 7.1838\n",
						"R^2 Score: 0.8897903155317118\n",
						"Epoch 292/500.. Train loss: 2.0916.. Test loss: 8.4748\n",
						"R^2 Score: 0.9035953109372362\n",
						"Epoch 293/500.. Train loss: 2.6855.. Test loss: 9.2116\n",
						"R^2 Score: 0.8596881315254812\n",
						"Epoch 294/500.. Train loss: 2.1075.. Test loss: 17.9282\n",
						"R^2 Score: 0.9129899366229776\n",
						"Epoch 295/500.. Train loss: 2.4076.. Test loss: 7.5604\n",
						"R^2 Score: 0.9511383000395303\n",
						"Epoch 296/500.. Train loss: 2.0306.. Test loss: 4.6264\n",
						"R^2 Score: 0.8179376453813499\n",
						"Epoch 297/500.. Train loss: 1.9668.. Test loss: 11.7025\n",
						"R^2 Score: 0.8381547778218412\n",
						"Epoch 298/500.. Train loss: 3.8679.. Test loss: 11.8801\n",
						"R^2 Score: 0.8781193324779912\n",
						"Epoch 299/500.. Train loss: 3.1362.. Test loss: 13.9681\n",
						"R^2 Score: 0.8515629263778599\n",
						"Epoch 300/500.. Train loss: 3.5805.. Test loss: 10.9446\n",
						"R^2 Score: 0.8511279871480453\n",
						"Epoch 301/500.. Train loss: 2.6875.. Test loss: 10.8180\n",
						"R^2 Score: 0.9056569120744606\n",
						"Epoch 302/500.. Train loss: 6.4275.. Test loss: 7.2346\n",
						"R^2 Score: 0.40298581548560564\n",
						"Epoch 303/500.. Train loss: 5.5870.. Test loss: 24.6539\n",
						"R^2 Score: 0.8403583922083613\n",
						"Epoch 304/500.. Train loss: 6.6144.. Test loss: 14.2238\n",
						"R^2 Score: 0.8093378398851386\n",
						"Epoch 305/500.. Train loss: 2.5202.. Test loss: 12.7452\n",
						"R^2 Score: 0.9008252199227829\n",
						"Epoch 306/500.. Train loss: 3.7030.. Test loss: 8.1150\n",
						"R^2 Score: 0.7899728771282499\n",
						"Epoch 307/500.. Train loss: 3.1905.. Test loss: 12.3783\n",
						"R^2 Score: 0.803398239997602\n",
						"Epoch 308/500.. Train loss: 3.9240.. Test loss: 13.8120\n",
						"R^2 Score: 0.7568854158189224\n",
						"Epoch 309/500.. Train loss: 3.7643.. Test loss: 14.8025\n",
						"R^2 Score: 0.8846567145908945\n",
						"Epoch 310/500.. Train loss: 3.9374.. Test loss: 10.1903\n",
						"R^2 Score: 0.8482115215173714\n",
						"Epoch 311/500.. Train loss: 2.6787.. Test loss: 10.9380\n",
						"R^2 Score: 0.8910351446745347\n",
						"Epoch 312/500.. Train loss: 2.6067.. Test loss: 7.9233\n",
						"R^2 Score: 0.8145670459262107\n",
						"Epoch 313/500.. Train loss: 2.8066.. Test loss: 12.3632\n",
						"R^2 Score: 0.8912911896739695\n",
						"Epoch 314/500.. Train loss: 2.3575.. Test loss: 9.3482\n",
						"R^2 Score: 0.8595532869729424\n",
						"Epoch 315/500.. Train loss: 1.7370.. Test loss: 10.0242\n",
						"R^2 Score: 0.8213024703992325\n",
						"Epoch 316/500.. Train loss: 2.2206.. Test loss: 11.0413\n",
						"R^2 Score: 0.8630414173623338\n",
						"Epoch 317/500.. Train loss: 1.7305.. Test loss: 10.5855\n",
						"R^2 Score: 0.9051726481861618\n",
						"Epoch 318/500.. Train loss: 1.6493.. Test loss: 8.4956\n",
						"R^2 Score: 0.9216872369950201\n",
						"Epoch 319/500.. Train loss: 1.9560.. Test loss: 6.7879\n",
						"R^2 Score: 0.9124336969176592\n",
						"Epoch 320/500.. Train loss: 2.4472.. Test loss: 9.2697\n",
						"R^2 Score: 0.9349447041330099\n",
						"Epoch 321/500.. Train loss: 2.5891.. Test loss: 6.2147\n",
						"R^2 Score: 0.8826989071763867\n",
						"Epoch 322/500.. Train loss: 3.2684.. Test loss: 10.6573\n",
						"R^2 Score: 0.8853926154609055\n",
						"Epoch 323/500.. Train loss: 4.6742.. Test loss: 11.8094\n",
						"R^2 Score: 0.6959280909301713\n",
						"Epoch 324/500.. Train loss: 3.5807.. Test loss: 17.2489\n",
						"R^2 Score: 0.7291771118494397\n",
						"Epoch 325/500.. Train loss: 5.7235.. Test loss: 15.5013\n",
						"R^2 Score: 0.8735270881356819\n",
						"Epoch 326/500.. Train loss: 2.5106.. Test loss: 10.3853\n",
						"R^2 Score: 0.8973272284309524\n",
						"Epoch 327/500.. Train loss: 3.2371.. Test loss: 8.9781\n",
						"R^2 Score: 0.7907694791649321\n",
						"Epoch 328/500.. Train loss: 4.3611.. Test loss: 11.5969\n",
						"R^2 Score: 0.8734176226372938\n",
						"Epoch 329/500.. Train loss: 3.6860.. Test loss: 9.4600\n",
						"R^2 Score: 0.8673037759394336\n",
						"Epoch 330/500.. Train loss: 2.4970.. Test loss: 11.2409\n",
						"R^2 Score: 0.9113832790174672\n",
						"Epoch 331/500.. Train loss: 1.7076.. Test loss: 9.0417\n",
						"R^2 Score: 0.8890108452236078\n",
						"Epoch 332/500.. Train loss: 3.9894.. Test loss: 7.9639\n",
						"R^2 Score: 0.7011978153519605\n",
						"Epoch 333/500.. Train loss: 3.9079.. Test loss: 16.5429\n",
						"R^2 Score: 0.8909829782565014\n",
						"Epoch 334/500.. Train loss: 4.0291.. Test loss: 9.1237\n",
						"R^2 Score: 0.872654255280571\n",
						"Epoch 335/500.. Train loss: 2.9087.. Test loss: 11.1147\n",
						"R^2 Score: 0.8385630760180922\n",
						"Epoch 336/500.. Train loss: 2.1547.. Test loss: 11.6205\n",
						"R^2 Score: 0.811711473828937\n",
						"Epoch 337/500.. Train loss: 2.8700.. Test loss: 16.7035\n",
						"R^2 Score: 0.9200992466212438\n",
						"Epoch 338/500.. Train loss: 2.2720.. Test loss: 7.5804\n",
						"R^2 Score: 0.8977996571934932\n",
						"Epoch 339/500.. Train loss: 2.3205.. Test loss: 9.9093\n",
						"R^2 Score: 0.8520063924769754\n",
						"Epoch 340/500.. Train loss: 2.4061.. Test loss: 11.5626\n",
						"R^2 Score: 0.7362244753633083\n",
						"Epoch 341/500.. Train loss: 2.6421.. Test loss: 15.5112\n",
						"R^2 Score: 0.9106109104794219\n",
						"Epoch 342/500.. Train loss: 2.6431.. Test loss: 8.5226\n",
						"R^2 Score: 0.8268635820395955\n",
						"Epoch 343/500.. Train loss: 2.4727.. Test loss: 13.3442\n",
						"R^2 Score: 0.8873624427209986\n",
						"Epoch 344/500.. Train loss: 2.9553.. Test loss: 8.4904\n",
						"R^2 Score: 0.9242607597428126\n",
						"Epoch 345/500.. Train loss: 2.4030.. Test loss: 7.1449\n",
						"R^2 Score: 0.8981045989667816\n",
						"Epoch 346/500.. Train loss: 3.8918.. Test loss: 9.1616\n",
						"R^2 Score: 0.7685224439027514\n",
						"Epoch 347/500.. Train loss: 3.7083.. Test loss: 14.2318\n",
						"R^2 Score: 0.8938651726844713\n",
						"Epoch 348/500.. Train loss: 2.9963.. Test loss: 11.0884\n",
						"R^2 Score: 0.9070007060776155\n",
						"Epoch 349/500.. Train loss: 3.5537.. Test loss: 7.1436\n",
						"R^2 Score: 0.9101473557136164\n",
						"Epoch 350/500.. Train loss: 3.0077.. Test loss: 7.6026\n",
						"R^2 Score: 0.9051867156499824\n",
						"Epoch 351/500.. Train loss: 2.8176.. Test loss: 9.4783\n",
						"R^2 Score: 0.9198243957808416\n",
						"Epoch 352/500.. Train loss: 2.3790.. Test loss: 8.2489\n",
						"R^2 Score: 0.8995189035020863\n",
						"Epoch 353/500.. Train loss: 2.5749.. Test loss: 8.8449\n",
						"R^2 Score: 0.9244930852163836\n",
						"Epoch 354/500.. Train loss: 1.7347.. Test loss: 6.2077\n",
						"R^2 Score: 0.8757233607639249\n",
						"Epoch 355/500.. Train loss: 2.3075.. Test loss: 9.9809\n",
						"R^2 Score: 0.9006683076022405\n",
						"Epoch 356/500.. Train loss: 2.3056.. Test loss: 7.8574\n",
						"R^2 Score: 0.8819751301354414\n",
						"Epoch 357/500.. Train loss: 1.6443.. Test loss: 13.9787\n",
						"R^2 Score: 0.9012967085098065\n",
						"Epoch 358/500.. Train loss: 2.7418.. Test loss: 9.2612\n",
						"R^2 Score: 0.9245604494591042\n",
						"Epoch 359/500.. Train loss: 3.4992.. Test loss: 6.2741\n",
						"R^2 Score: 0.7259422452343821\n",
						"Epoch 360/500.. Train loss: 2.9576.. Test loss: 15.2206\n",
						"R^2 Score: 0.6924958448880876\n",
						"Epoch 361/500.. Train loss: 4.1889.. Test loss: 21.5945\n",
						"R^2 Score: 0.8512697254237886\n",
						"Epoch 362/500.. Train loss: 2.8819.. Test loss: 10.1566\n",
						"R^2 Score: 0.8724060462359531\n",
						"Epoch 363/500.. Train loss: 2.7426.. Test loss: 11.2457\n",
						"R^2 Score: 0.8988728510150591\n",
						"Epoch 364/500.. Train loss: 3.1268.. Test loss: 6.8888\n",
						"R^2 Score: 0.8278136774473257\n",
						"Epoch 365/500.. Train loss: 2.9199.. Test loss: 9.9520\n",
						"R^2 Score: 0.9252078482480219\n",
						"Epoch 366/500.. Train loss: 2.9495.. Test loss: 7.2225\n",
						"R^2 Score: 0.8582461534128151\n",
						"Epoch 367/500.. Train loss: 3.3393.. Test loss: 10.6065\n",
						"R^2 Score: 0.9090271591402419\n",
						"Epoch 368/500.. Train loss: 2.9178.. Test loss: 8.8425\n",
						"R^2 Score: 0.8953687870310811\n",
						"Epoch 369/500.. Train loss: 1.8781.. Test loss: 9.5327\n",
						"R^2 Score: 0.9050266135104857\n",
						"Epoch 370/500.. Train loss: 2.5878.. Test loss: 8.0911\n",
						"R^2 Score: 0.9181081459710652\n",
						"Epoch 371/500.. Train loss: 1.9025.. Test loss: 8.9796\n",
						"R^2 Score: 0.923502617846265\n",
						"Epoch 372/500.. Train loss: 2.6551.. Test loss: 6.1037\n",
						"R^2 Score: 0.8859193039910802\n",
						"Epoch 373/500.. Train loss: 1.9281.. Test loss: 9.2879\n",
						"R^2 Score: 0.9208397724013103\n",
						"Epoch 374/500.. Train loss: 2.2789.. Test loss: 7.8489\n",
						"R^2 Score: 0.8367139038349721\n",
						"Epoch 375/500.. Train loss: 1.8323.. Test loss: 14.3807\n",
						"R^2 Score: 0.8875462861667441\n",
						"Epoch 376/500.. Train loss: 1.8609.. Test loss: 8.0531\n",
						"R^2 Score: 0.8917349429720522\n",
						"Epoch 377/500.. Train loss: 1.6603.. Test loss: 8.5913\n",
						"R^2 Score: 0.9094539281631653\n",
						"Epoch 378/500.. Train loss: 1.8895.. Test loss: 7.1260\n",
						"R^2 Score: 0.8412294464311851\n",
						"Epoch 379/500.. Train loss: 3.4104.. Test loss: 10.9887\n",
						"R^2 Score: 0.8879816167839361\n",
						"Epoch 380/500.. Train loss: 3.4637.. Test loss: 8.4100\n",
						"R^2 Score: 0.8374384364669868\n",
						"Epoch 381/500.. Train loss: 1.9483.. Test loss: 11.1319\n",
						"R^2 Score: 0.8780944782514619\n",
						"Epoch 382/500.. Train loss: 3.2517.. Test loss: 10.3055\n",
						"R^2 Score: 0.8810861902923621\n",
						"Epoch 383/500.. Train loss: 2.0167.. Test loss: 9.2447\n",
						"R^2 Score: 0.9342689075986443\n",
						"Epoch 384/500.. Train loss: 1.7855.. Test loss: 5.6754\n",
						"R^2 Score: 0.9077049826001682\n",
						"Epoch 385/500.. Train loss: 3.2197.. Test loss: 7.4914\n",
						"R^2 Score: 0.9108104190746598\n",
						"Epoch 386/500.. Train loss: 1.8772.. Test loss: 7.5931\n",
						"R^2 Score: 0.9278169077887694\n",
						"Epoch 387/500.. Train loss: 1.9794.. Test loss: 7.7753\n",
						"R^2 Score: 0.9352816930616276\n",
						"Epoch 388/500.. Train loss: 1.7196.. Test loss: 6.6530\n",
						"R^2 Score: 0.9165819405801641\n",
						"Epoch 389/500.. Train loss: 2.7127.. Test loss: 8.3513\n",
						"R^2 Score: 0.7875009001470128\n",
						"Epoch 390/500.. Train loss: 2.3121.. Test loss: 12.6767\n",
						"R^2 Score: 0.8965894599993466\n",
						"Epoch 391/500.. Train loss: 3.6086.. Test loss: 10.6216\n",
						"R^2 Score: 0.8918247140184479\n",
						"Epoch 392/500.. Train loss: 2.9543.. Test loss: 7.5109\n",
						"R^2 Score: 0.7846762331525917\n",
						"Epoch 393/500.. Train loss: 4.3070.. Test loss: 17.7201\n",
						"R^2 Score: 0.853117163703147\n",
						"Epoch 394/500.. Train loss: 4.4224.. Test loss: 10.0885\n",
						"R^2 Score: 0.9149385191085301\n",
						"Epoch 395/500.. Train loss: 2.4370.. Test loss: 7.8434\n",
						"R^2 Score: 0.8641048373090306\n",
						"Epoch 396/500.. Train loss: 5.1023.. Test loss: 9.2303\n",
						"R^2 Score: 0.9122053585688699\n",
						"Epoch 397/500.. Train loss: 1.9871.. Test loss: 9.7534\n",
						"R^2 Score: 0.8735284006330287\n",
						"Epoch 398/500.. Train loss: 2.5241.. Test loss: 9.3787\n",
						"R^2 Score: 0.8978177181032073\n",
						"Epoch 399/500.. Train loss: 2.6660.. Test loss: 8.0953\n",
						"R^2 Score: 0.9021328631889933\n",
						"Epoch 400/500.. Train loss: 2.3443.. Test loss: 12.3268\n",
						"R^2 Score: 0.8652243371527025\n",
						"Epoch 401/500.. Train loss: 2.9819.. Test loss: 8.7463\n",
						"R^2 Score: 0.8376090573147851\n",
						"Epoch 402/500.. Train loss: 3.1334.. Test loss: 10.0320\n",
						"R^2 Score: 0.8910820553390975\n",
						"Epoch 403/500.. Train loss: 3.5925.. Test loss: 14.3289\n",
						"R^2 Score: 0.9031581297833707\n",
						"Epoch 404/500.. Train loss: 2.0870.. Test loss: 9.5450\n",
						"R^2 Score: 0.8901083408206745\n",
						"Epoch 405/500.. Train loss: 3.3653.. Test loss: 10.1461\n",
						"R^2 Score: 0.884328792856551\n",
						"Epoch 406/500.. Train loss: 2.4484.. Test loss: 9.0290\n",
						"R^2 Score: 0.9181400387132956\n",
						"Epoch 407/500.. Train loss: 2.2512.. Test loss: 6.8404\n",
						"R^2 Score: 0.9186831742578077\n",
						"Epoch 408/500.. Train loss: 2.1265.. Test loss: 8.8260\n",
						"R^2 Score: 0.9230405558836203\n",
						"Epoch 409/500.. Train loss: 3.3892.. Test loss: 7.3315\n",
						"R^2 Score: 0.7286008856479085\n",
						"Epoch 410/500.. Train loss: 3.5672.. Test loss: 16.1359\n",
						"R^2 Score: 0.8069767887712734\n",
						"Epoch 411/500.. Train loss: 4.2132.. Test loss: 13.2141\n",
						"R^2 Score: 0.8731598996303794\n",
						"Epoch 412/500.. Train loss: 2.1696.. Test loss: 9.1690\n",
						"R^2 Score: 0.8734176929378265\n",
						"Epoch 413/500.. Train loss: 2.5828.. Test loss: 11.5122\n",
						"R^2 Score: 0.8756088689681034\n",
						"Epoch 414/500.. Train loss: 2.4388.. Test loss: 8.8101\n",
						"R^2 Score: 0.8600236106161205\n",
						"Epoch 415/500.. Train loss: 2.3389.. Test loss: 11.2285\n",
						"R^2 Score: 0.8518412164266105\n",
						"Epoch 416/500.. Train loss: 3.0631.. Test loss: 9.0919\n",
						"R^2 Score: 0.8541205112074102\n",
						"Epoch 417/500.. Train loss: 2.6985.. Test loss: 9.2803\n",
						"R^2 Score: 0.9234263022030256\n",
						"Epoch 418/500.. Train loss: 2.7459.. Test loss: 6.7568\n",
						"R^2 Score: 0.8860968065654694\n",
						"Epoch 419/500.. Train loss: 2.9885.. Test loss: 9.7627\n",
						"R^2 Score: 0.9194041125347012\n",
						"Epoch 420/500.. Train loss: 3.5164.. Test loss: 7.5463\n",
						"R^2 Score: 0.798242632202975\n",
						"Epoch 421/500.. Train loss: 2.2330.. Test loss: 11.9738\n",
						"R^2 Score: 0.8489638549201983\n",
						"Epoch 422/500.. Train loss: 3.4701.. Test loss: 10.0220\n",
						"R^2 Score: 0.8896831930839069\n",
						"Epoch 423/500.. Train loss: 3.2382.. Test loss: 8.9282\n",
						"R^2 Score: 0.8013942587683505\n",
						"Epoch 424/500.. Train loss: 3.5607.. Test loss: 13.5960\n",
						"R^2 Score: 0.6961754208064009\n",
						"Epoch 425/500.. Train loss: 2.7204.. Test loss: 14.7648\n",
						"R^2 Score: 0.8464039516201242\n",
						"Epoch 426/500.. Train loss: 5.1929.. Test loss: 13.0884\n",
						"R^2 Score: 0.9222093635255064\n",
						"Epoch 427/500.. Train loss: 3.0484.. Test loss: 6.6499\n",
						"R^2 Score: 0.9049243561684153\n",
						"Epoch 428/500.. Train loss: 2.0718.. Test loss: 7.3073\n",
						"R^2 Score: 0.9278469554970694\n",
						"Epoch 429/500.. Train loss: 1.9503.. Test loss: 6.1350\n",
						"R^2 Score: 0.915383649337444\n",
						"Epoch 430/500.. Train loss: 2.2494.. Test loss: 8.0836\n",
						"R^2 Score: 0.8822406806033519\n",
						"Epoch 431/500.. Train loss: 1.8683.. Test loss: 11.0730\n",
						"R^2 Score: 0.9141037018753992\n",
						"Epoch 432/500.. Train loss: 1.6838.. Test loss: 8.1761\n",
						"R^2 Score: 0.918068823576703\n",
						"Epoch 433/500.. Train loss: 2.5258.. Test loss: 7.3007\n",
						"R^2 Score: 0.9014206487868697\n",
						"Epoch 434/500.. Train loss: 1.9241.. Test loss: 8.8122\n",
						"R^2 Score: 0.8935350951933789\n",
						"Epoch 435/500.. Train loss: 2.2245.. Test loss: 9.0592\n",
						"R^2 Score: 0.9008769212061615\n",
						"Epoch 436/500.. Train loss: 1.7195.. Test loss: 9.1074\n",
						"R^2 Score: 0.8470172278304631\n",
						"Epoch 437/500.. Train loss: 4.2805.. Test loss: 9.6644\n",
						"R^2 Score: 0.8149622263406122\n",
						"Epoch 438/500.. Train loss: 4.2085.. Test loss: 11.4501\n",
						"R^2 Score: 0.8960443543390411\n",
						"Epoch 439/500.. Train loss: 2.4821.. Test loss: 10.1817\n",
						"R^2 Score: 0.9110527333320307\n",
						"Epoch 440/500.. Train loss: 2.3621.. Test loss: 8.0524\n",
						"R^2 Score: 0.8464402591285213\n",
						"Epoch 441/500.. Train loss: 2.6663.. Test loss: 10.8793\n",
						"R^2 Score: 0.8768686884854727\n",
						"Epoch 442/500.. Train loss: 2.1152.. Test loss: 9.4984\n",
						"R^2 Score: 0.9440967463309845\n",
						"Epoch 443/500.. Train loss: 2.4411.. Test loss: 4.9731\n",
						"R^2 Score: 0.8586758037746653\n",
						"Epoch 444/500.. Train loss: 2.2286.. Test loss: 12.3030\n",
						"R^2 Score: 0.9135356387916604\n",
						"Epoch 445/500.. Train loss: 2.1269.. Test loss: 8.0213\n",
						"R^2 Score: 0.9125901777620931\n",
						"Epoch 446/500.. Train loss: 2.2347.. Test loss: 7.0125\n",
						"R^2 Score: 0.7238910798234175\n",
						"Epoch 447/500.. Train loss: 1.7743.. Test loss: 15.5462\n",
						"R^2 Score: 0.9182970740534946\n",
						"Epoch 448/500.. Train loss: 2.4124.. Test loss: 10.4140\n",
						"R^2 Score: 0.8866476276758861\n",
						"Epoch 449/500.. Train loss: 2.1629.. Test loss: 11.1113\n",
						"R^2 Score: 0.9207739427101113\n",
						"Epoch 450/500.. Train loss: 1.8310.. Test loss: 6.0118\n",
						"R^2 Score: 0.9028543775568655\n",
						"Epoch 451/500.. Train loss: 3.2082.. Test loss: 9.6622\n",
						"R^2 Score: 0.903512518478749\n",
						"Epoch 452/500.. Train loss: 1.8224.. Test loss: 9.9066\n",
						"R^2 Score: 0.9020705196038539\n",
						"Epoch 453/500.. Train loss: 2.4302.. Test loss: 7.5909\n",
						"R^2 Score: 0.6832141799292685\n",
						"Epoch 454/500.. Train loss: 2.6164.. Test loss: 21.6572\n",
						"R^2 Score: 0.6841505791735307\n",
						"Epoch 455/500.. Train loss: 7.6726.. Test loss: 25.4289\n",
						"R^2 Score: 0.6954396609123175\n",
						"Epoch 456/500.. Train loss: 4.0943.. Test loss: 21.0720\n",
						"R^2 Score: 0.8385522805549033\n",
						"Epoch 457/500.. Train loss: 4.3736.. Test loss: 15.2182\n",
						"R^2 Score: 0.8759162162402632\n",
						"Epoch 458/500.. Train loss: 2.8162.. Test loss: 12.4288\n",
						"R^2 Score: 0.9082940975118239\n",
						"Epoch 459/500.. Train loss: 2.9553.. Test loss: 7.7928\n",
						"R^2 Score: 0.854923996239178\n",
						"Epoch 460/500.. Train loss: 2.8183.. Test loss: 19.2121\n",
						"R^2 Score: 0.6962306548686013\n",
						"Epoch 461/500.. Train loss: 5.0594.. Test loss: 16.0444\n",
						"R^2 Score: 0.5772587771725262\n",
						"Epoch 462/500.. Train loss: 4.2387.. Test loss: 23.9222\n",
						"R^2 Score: 0.8439707750600884\n",
						"Epoch 463/500.. Train loss: 4.5810.. Test loss: 13.1361\n",
						"R^2 Score: 0.8868003515957572\n",
						"Epoch 464/500.. Train loss: 3.8615.. Test loss: 9.7967\n",
						"R^2 Score: 0.8698657940913244\n",
						"Epoch 465/500.. Train loss: 2.3979.. Test loss: 16.2747\n",
						"R^2 Score: 0.9105609852202643\n",
						"Epoch 466/500.. Train loss: 2.7126.. Test loss: 7.3392\n",
						"R^2 Score: 0.8684255520973345\n",
						"Epoch 467/500.. Train loss: 4.8478.. Test loss: 8.9326\n",
						"R^2 Score: 0.9019598536353672\n",
						"Epoch 468/500.. Train loss: 2.1738.. Test loss: 8.0220\n",
						"R^2 Score: 0.8823033325617037\n",
						"Epoch 469/500.. Train loss: 2.5593.. Test loss: 8.5315\n",
						"R^2 Score: 0.8729745289874961\n",
						"Epoch 470/500.. Train loss: 2.4012.. Test loss: 10.0522\n",
						"R^2 Score: 0.9179384023185156\n",
						"Epoch 471/500.. Train loss: 2.4450.. Test loss: 7.8921\n",
						"R^2 Score: 0.872072357024742\n",
						"Epoch 472/500.. Train loss: 2.3648.. Test loss: 9.8326\n",
						"R^2 Score: 0.8561020894916168\n",
						"Epoch 473/500.. Train loss: 2.5319.. Test loss: 11.4949\n",
						"R^2 Score: 0.8980059346497682\n",
						"Epoch 474/500.. Train loss: 2.5201.. Test loss: 8.5701\n",
						"R^2 Score: 0.8232385149602347\n",
						"Epoch 475/500.. Train loss: 2.8939.. Test loss: 10.9046\n",
						"R^2 Score: 0.9200722314822187\n",
						"Epoch 476/500.. Train loss: 2.6247.. Test loss: 7.1020\n",
						"R^2 Score: 0.9281988285356728\n",
						"Epoch 477/500.. Train loss: 2.4941.. Test loss: 6.5565\n",
						"R^2 Score: 0.91730713448372\n",
						"Epoch 478/500.. Train loss: 3.2507.. Test loss: 6.9050\n",
						"R^2 Score: 0.9177512536919675\n",
						"Epoch 479/500.. Train loss: 1.4392.. Test loss: 9.2786\n",
						"R^2 Score: 0.9346996633868546\n",
						"Epoch 480/500.. Train loss: 3.1885.. Test loss: 6.9459\n",
						"R^2 Score: 0.8877369314589043\n",
						"Epoch 481/500.. Train loss: 2.3333.. Test loss: 8.4474\n",
						"R^2 Score: 0.9095870275226063\n",
						"Epoch 482/500.. Train loss: 1.3896.. Test loss: 7.2092\n",
						"R^2 Score: 0.8973643675945251\n",
						"Epoch 483/500.. Train loss: 1.5694.. Test loss: 8.3732\n",
						"R^2 Score: 0.859564280601244\n",
						"Epoch 484/500.. Train loss: 1.9570.. Test loss: 10.6088\n",
						"R^2 Score: 0.9346608889710758\n",
						"Epoch 485/500.. Train loss: 1.7865.. Test loss: 5.6516\n",
						"R^2 Score: 0.9409633209992806\n",
						"Epoch 486/500.. Train loss: 1.7552.. Test loss: 4.7131\n",
						"R^2 Score: 0.898506399564247\n",
						"Epoch 487/500.. Train loss: 2.6210.. Test loss: 8.2356\n",
						"R^2 Score: 0.9156084537114203\n",
						"Epoch 488/500.. Train loss: 1.7331.. Test loss: 6.8536\n",
						"R^2 Score: 0.9378414071689796\n",
						"Epoch 489/500.. Train loss: 2.1892.. Test loss: 6.6091\n",
						"R^2 Score: 0.9086808138570917\n",
						"Epoch 490/500.. Train loss: 1.7692.. Test loss: 10.2852\n",
						"R^2 Score: 0.8997453294572206\n",
						"Epoch 491/500.. Train loss: 1.9075.. Test loss: 10.1238\n",
						"R^2 Score: 0.9307496170613636\n",
						"Epoch 492/500.. Train loss: 1.9352.. Test loss: 6.2876\n",
						"R^2 Score: 0.8797965608674201\n",
						"Epoch 493/500.. Train loss: 1.6967.. Test loss: 8.9215\n",
						"R^2 Score: 0.9273693137984731\n",
						"Epoch 494/500.. Train loss: 2.7074.. Test loss: 6.1441\n",
						"R^2 Score: 0.897210899902584\n",
						"Epoch 495/500.. Train loss: 2.6483.. Test loss: 7.8437\n",
						"R^2 Score: 0.8715448587783305\n",
						"Epoch 496/500.. Train loss: 1.7905.. Test loss: 10.3614\n",
						"R^2 Score: 0.8896295965564642\n",
						"Epoch 497/500.. Train loss: 2.3121.. Test loss: 7.9572\n",
						"R^2 Score: 0.8915350595767978\n",
						"Epoch 498/500.. Train loss: 2.1424.. Test loss: 11.5931\n",
						"R^2 Score: 0.9242957478196472\n",
						"Epoch 499/500.. Train loss: 2.3189.. Test loss: 6.2552\n",
						"R^2 Score: 0.9312212927801826\n",
						"Epoch 500/500.. Train loss: 1.8194.. Test loss: 7.3228\n"
					]
				},
				{
					"data": {
						"image/png": "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",
						"text/plain": [
							"<Figure size 1000x600 with 1 Axes>"
						]
					},
					"metadata": {},
					"output_type": "display_data"
				},
				{
					"data": {
						"image/png": "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",
						"text/plain": [
							"<Figure size 1000x600 with 1 Axes>"
						]
					},
					"metadata": {},
					"output_type": "display_data"
				}
			],
			"source": [
				"import os \n",
				"import pandas as pd \n",
				"import numpy as np \n",
				"import torch \n",
				"from torch import nn\n",
				"from torch.utils.data import Dataset, DataLoader, random_split\n",
				"from sklearn.preprocessing import StandardScaler\n",
				"import matplotlib.pyplot as plt\n",
				"from sklearn.metrics import r2_score\n",
				"import os\n",
				"os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
				"\n",
				"#在处理类别数据时，相关数据在dataset中处理，包括对数据分割为数值列，和类别列，并分别返回\n",
				"class HgDataset(Dataset):\n",
				"    def __init__(self,file_path,tranform=None,traget_tranform=None):\n",
				"        \"\"\"_summary_\n",
				"\n",
				"        Args:\n",
				"            file_path (_type_): _description_\n",
				"            tranform (_type_, optional): _description_. Defaults to None.\n",
				"            traget_tranform (_type_, optional): _description_. Defaults to None.\n",
				"        \"\"\"\n",
				"        self.data=pd.read_csv(file_path)\n",
				"        self.y=self.data['Hg_conc'].to_numpy().reshape(-1,1)# 设置因变量\n",
				"        self.x=self.data.drop('Hg_conc',axis=1,inplace=False) \n",
				"        #数值数据与分类数据的划分\n",
				"        self.numerical_x=self.x.drop('Background_pollu',axis=1,inplace=False).to_numpy()\n",
				"        self.category_x=self.x['Background_pollu'].to_numpy()\n",
				"\n",
				"        if tranform:\n",
				"            self.x=tranform(self.x)\n",
				"        if traget_tranform:\n",
				"            self.y=traget_tranform(self.y)\n",
				"    \n",
				"    def __len__(self):\n",
				"        return len(self.data)\n",
				"    \n",
				"    def getLabels(self):#返回分类数据分类标签的数量\n",
				"        unique_labels = np.unique(self.category_x)\n",
				"        num_labels = len(unique_labels)\n",
				"        return unique_labels,num_labels\n",
				"    \n",
				"    def getNumerAttribut(self):\n",
				"        return int(self.numerical_x.shape[1])\n",
				"\n",
				"    def __getitem__(self,index):\n",
				"        '''torch.is_tensor(idx): 这个函数检查idx是否是一个PyTorch张量（torch.Tensor）。在某些情况下，\n",
				"        尤其是在使用高级索引或者批处理时，索引可能会以张量的形式给出。这个检查是为了确定是否需要将张量索引转换成Python列表，以便后续处理。\n",
				"\n",
				"         idx.tolist(): 如果idx确实是一个张量，tolist()方法将这个张量转换成一个Python列表。这是必要的，\n",
				"         因为在接下来的数据检索过程中，通常需要索引作为整数或者整数列表来使用，而不是张量。'''\n",
				"        if torch.is_tensor(index):\n",
				"            index = index.tolist()\n",
				"\n",
				"        y_i=self.y[index]\n",
				"        nx_i=self.numerical_x[index]\n",
				"        cx_i=self.category_x[index]\n",
				"        return nx_i,cx_i,y_i\n",
				"    \n",
				"\n",
				"def my_transform(batch,device):\n",
				"    nx,cx,y=zip(*batch)\n",
				"    #print(type(x))\n",
				"    nx=np.array(nx)\n",
				"    cx=np.array(cx)\n",
				"    y=np.array(y)\n",
				"\n",
				"    scaler=StandardScaler()\n",
				"    nx=scaler.fit_transform(nx)\n",
				"    nx=torch.tensor(nx,dtype=torch.float32).to(device)\n",
				"    cx=torch.tensor(cx,dtype=torch.long).to(device)#category数据类型应该是int\n",
				"    y=torch.tensor(y,dtype=torch.float32).to(device)\n",
				"    return nx,cx,y\n",
				"################################################################\n",
				"class Mymodel(nn.Module):\n",
				"    def __init__(self,numercial_at,category_label,embed_dim,drop_p):\n",
				"        super(Mymodel, self).__init__()\n",
				"       \n",
				"        self.embedd=nn.Embedding(num_embeddings=category_label,embedding_dim=embed_dim)\n",
				"        self.l1=nn.Linear(numercial_at,100)\n",
				"        self.l2=nn.Linear(embed_dim+100,50)\n",
				"        self.b1=nn.BatchNorm1d(50)\n",
				"        self.d1=nn.Dropout(p=drop_p)\n",
				"        self.r1=nn.ReLU()\n",
				"        self.l3=nn.Linear(50,1)\n",
				"             \n",
				"    '''\n",
				"    torch.flatten(x_categorical, start_dim=1): 将嵌入向量展平。\n",
				"    start_dim=1意味着保留批次维度（假设批次维度是第0维），\n",
				"    将嵌入向量的所有维度（从第1维开始）展平为一维。\n",
				"    这一步骤是为了将每个样本的所有嵌入向量合并成一个单一的向量，以便与数值数据拼接。\n",
				"\n",
				"    torch.cat([x_numeric, x_categorical], dim=1):\n",
				"      将处理过的数值数据和展平后的类别数据嵌入向量沿着特征维度（dim=1）进行拼接。\n",
				"      这样，模型就可以同时考虑类别特征和数值特征。\n",
				"    '''\n",
				"    def forward(self,numercial_input,category_input):\n",
				"        cx=self.embedd(category_input)\n",
				"        nx=self.l1(numercial_input)\n",
				"\n",
				"        #cx=torch.flatten(cx,start_dim=1)\n",
				"        x=torch.cat([nx,cx],dim=1)# 注意保持数值和类别数据的顺序一致\n",
				"        x=self.l2(x)\n",
				"        x=self.b1(x)\n",
				"        x=self.d1(x)\n",
				"        x=self.r1(x)\n",
				"        x=self.l3(x)\n",
				"        return x\n",
				"\n",
				"         \n",
				"if __name__ == \"__main__\":\n",
				"    filename='data/Hg_notime_nocooked.csv'\n",
				"    # 得到categories 的labes数，以及numerical \n",
				"    hdataset=HgDataset(filename)\n",
				"    \n",
				"    unique_labels,categories_num=hdataset.getLabels()\n",
				"    print(unique_labels)\n",
				"    numerical_dim=hdataset.getNumerAttribut()\n",
				"    print(\"the labels of category attribute is {} and the numerical attribute dim is {}\".format(categories_num,numerical_dim,))\n",
				"    \n",
				"    #######################分割tran，test############\n",
				"    dataset_len=len(hdataset)\n",
				"    print('the lenght of dataset',dataset_len)\n",
				"    train_size=int(0.8*dataset_len)\n",
				"    test_size=dataset_len-train_size\n",
				"    print(\"the length of train size is {},  test size is {}\".format(train_size,test_size))\n",
				"    train_dataset, test_dataset = random_split(hdataset, [train_size, test_size])\n",
				"    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
				"    batch=20\n",
				"    train_dataloader=DataLoader(train_dataset,batch_size=batch,shuffle=True,collate_fn=lambda x:my_transform(x,device))\n",
				"    test_dataloader=DataLoader(test_dataset,batch_size=batch,shuffle=True,collate_fn=lambda x:my_transform(x,device))\n",
				"   \n",
				"    ################################超参等设置###################################\n",
				"    lr=0.02\n",
				"    category_dim=5\n",
				"    drop_p=0.3\n",
				"    epochs=500\n",
				"\n",
				"    #############################实例化模型，以及优化模型，损失函数######################################\n",
				"    model=Mymodel(numercial_at=numerical_dim,category_label= categories_num+1,embed_dim=5,drop_p=drop_p)\n",
				"    model.to(device)\n",
				"    loss_fn=nn.MSELoss()\n",
				"    opt=torch.optim.Adam(params=model.parameters(),lr=lr) \n",
				"    #########################实现循环梯度下降################################################################\n",
				"    train_losses = []\n",
				"    test_losses = []\n",
				"    epoch_r2_scores = []\n",
				"    for i in range(epochs):\n",
				"        train_loss=0\n",
				"        for nx_batch,cx_batch,y_batch in test_dataloader:\n",
				"            yp_batch=model.forward(nx_batch,cx_batch)\n",
				"            loss=loss_fn(yp_batch,y_batch)\n",
				"            opt.zero_grad()\n",
				"            loss.backward()\n",
				"            opt.step()\n",
				"                # 用于记录训练和测试损失的列表\n",
				"            train_loss += loss.item() * nx_batch.size(0)\n",
				"        train_loss /= len(train_dataloader.dataset)\n",
				"        train_losses.append(train_loss)\n",
				"        \n",
				"        model.eval()#进入评估模式，停止dropout和bathnorm\n",
				"        test_loss=0\n",
				"        y_true=[]\n",
				"        y_pred_list=[]\n",
				"        with torch.no_grad():\n",
				"            for nx_batch,cx_batch,y_batch in test_dataloader:\n",
				"                yp_batch=model.forward(nx_batch,cx_batch)\n",
				"                loss=loss_fn(yp_batch,y_batch)\n",
				"                test_loss += loss.item() * nx_batch.size(0)\n",
				"                y_true.append(y_batch.cpu().numpy())  # 收集真实值\n",
				"                y_pred_list.append(yp_batch.cpu().numpy())  # 收集预测值，注意此处应使用yp_batch\n",
				"\n",
				"                # 由于对应的是回归方程，故计算r\n",
				"        test_loss /= len(test_dataloader.dataset)\n",
				"        test_losses.append(test_loss)\n",
				"\n",
				"        y_pred_list=np.concatenate(y_pred_list,axis=0)\n",
				"        y_true=np.concatenate(y_true,axis=0)\n",
				"        r2=r2_score(y_pred_list,y_true)\n",
				"        epoch_r2_scores.append(r2)\n",
				"        print(f'R^2 Score: {r2}')\n",
				"        # 打印每个epoch的损失\n",
				"        print(f\"Epoch {i+1}/{epochs}.. Train loss: {train_loss:.4f}.. Test loss: {test_loss:.4f}\")\n",
				"        # 绘制训练和测试损失\n",
				"    plt.figure(figsize=(10, 6))\n",
				"    plt.plot(train_losses, label='Training loss')\n",
				"    plt.plot(test_losses, label='Test loss')\n",
				"    plt.title('Loss vs. Epochs')\n",
				"    plt.xlabel('Epochs')\n",
				"    plt.ylabel('Loss')\n",
				"    plt.legend()\n",
				"    plt.show()\n",
				"\n",
				"    # 绘制批次R²分数曲线\n",
				"# 所有epoch完成后，绘制epoch R²分数曲线\n",
				"    plt.figure(figsize=(10, 6))\n",
				"    plt.plot(epoch_r2_scores, marker='o', linestyle='-', color='blue')\n",
				"    plt.title('Epoch-wise R² Score')\n",
				"    plt.xlabel('Epoch')\n",
				"    plt.ylabel('R² Score')\n",
				"    plt.grid(True)\n",
				"    plt.show()\n"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"## K-Fold 交叉验证\n",
				"\n",
				"[深度概念]·K-Fold 交叉验证 (Cross-Validation)的理解与应用](https://zhuanlan.zhihu.com/p/67986077)\n",
				"[pytorch 结合k-fold](https://github.com/christianversloot/machine-learning-articles/blob/main/how-to-use-k-fold-cross-validation-with-pytorch.md)\n",
				"\n",
				"### 概念\n",
				"在机器学习建模过程中，通行的做法通常是将数据分为训练集和测试集。测试集是与训练独立的数据，完全不参与训练，用于最终模型的评估。在训练过程中，经常会出现过拟合的问题，就是模型可以很好的匹配训练数据，却不能很好在预测训练集外的数据。如果此时就使用测试数据来调整模型参数，就相当于在训练时已知部分测试数据的信息，会影响最终评估结果的准确性。通常的做法是在训练数据再中分出一部分做为验证(Validation)数据，用来评估模型的训练效果。\n",
				"\n",
				"验证数据取自训练数据，但不参与训练，这样可以相对客观的评估模型对于训练集之外数据的匹配程度。模型在验证数据中的评估常用的是交叉验证，又称循环验证。它将原始数据分成K组(K-Fold)，将每个子集数据分别做一次验证集，其余的K-1组子集数据作为训练集，这样会得到K个模型。这K个模型分别在验证集中评估结果，最后的误差MSE(Mean Squared Error)加和平均就得到交叉验证误差。交叉验证有效利用了有限的数据，并且评估结果能够尽可能接近模型在测试集上的表现，可以做为模型优化的指标使用。\n",
				"\n",
				"下面举一个具体的例子来说明K-Fold的过程，比如如下的数据\n",
				"\n",
				"[0.1, 0.2, 0.3, 0.4, 0.5, 0.6]\n",
				"\n",
				"分为K=3组后\n",
				"\n",
				"Fold1: [0.5, 0.2] Fold2: [0.1, 0.3] Fold3: [0.4, 0.6]\n",
				"\n",
				"交叉验证的时会使用如下三个模型，分别进行训练和测试，每个测试集误差MSE加和平均就得到了交叉验证的总评分\n",
				"\n",
				"即使用$k-1$个数据子集进行训练，使用剩下的1个子集进行验证，并进行循环抽取\n",
				"\n",
				"\n",
				"Model1: Trained on Fold1 + Fold2, Tested on Fold3\n",
				"\n",
				"Model2: Trained on Fold2 + Fold3, Tested on Fold1\n",
				"\n",
				"Model3: Trained on Fold1 + Fold3, Tested on Fold2\n",
				"\n",
				"### 使用场景\n",
				"\n",
				"k-flod一般使用在数据量不足的情况下进行使用，从而降低拟合度\n",
				"\n",
				"我们为了防止在训练过程中，出现过拟合的问题，通行的做法通常是将数据分为训练集和测试集。测试集是与训练独立的数据，完全不参与训练，用于最终模型的评估。\n",
				"\n",
				"这样的直接划分会导致一个问题就是测试集不会参与训练，这样在小的数据集上会浪费掉这部分数据，无法使模型达到最优（数据决定了程性能上限，模型与算法会逼近这个上限）。\n",
				"\n",
				"但是我们又不能划分测试集，因为需要验证网络泛化性能。采用K-Fold 多次划分的形式就可以利用全部数据集。最后采用平均的方法合理表示模型性能。\n",
				"\n"
			]
		},
		{
			"attachments": {},
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"### 实验2 图像分类（from numpy）\n",
				"\n",
				"#### 实验2.1 numpy 图像分类转换\n",
				"该实验对之前numpy版本的深度学习网络进行pytorch实现，其中数据载入、建议使用之前的方法，而非pytorch方法，在进阶实验中换为pytorch的\n",
				"Dataloder()\n",
				"\n",
				"----\n",
				"\n",
				"实验中，出现训练集loss下降，但测试集loss不变的情况，不知道是否是因为过拟合问题，同修改模型尝试解决问题。\n",
				"\n",
				"----\n",
				"实验记录\n",
				"1. pytroch 中 CrossEntropyLoss 交叉熵误差函数输入值不能是one-hot，因为其会自动在内部进行变换，故必须输入1，3，5等原始分类数据标签\n",
				"2. 输入CrossEntropyLoss中CrossEntropyLoss(pred,y),y实际值必须为long数据类型，而不能为float，可以显示通过y.long()进行转换\n",
				"3. CrossEntropyLoss 中已经集成了softmax，故不定义softmax层"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 41,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"Collecting torchsummary\n",
						"  Downloading torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\n",
						"Installing collected packages: torchsummary\n",
						"Successfully installed torchsummary-1.5.1\n"
					]
				}
			],
			"source": [
				"!pip install torchsummary"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 38,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"1\n",
						"current device: cuda\n"
					]
				},
				{
					"name": "stderr",
					"output_type": "stream",
					"text": [
						"C:\\Users\\tom\\AppData\\Local\\Temp\\ipykernel_22916\\696759573.py:91: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_numpy.cpp:212.)\n",
						"  t_train=torch.from_numpy(t_train).to(torch.float32).to(device)\n"
					]
				},
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"torch.Size([1000, 784]) torch.Size([1000])\n",
						"torch.Size([10000, 784]) torch.Size([10000])\n",
						"10\n",
						"第0次epoch的train loss为：2.2043092250823975\n",
						"第0次epoch的test loss为：2.060028076171875\n",
						"################################\n",
						"第10次epoch的train loss为：0.8260545134544373\n",
						"第10次epoch的test loss为：0.45818135142326355\n",
						"################################\n",
						"第20次epoch的train loss为：0.4711284935474396\n",
						"第20次epoch的test loss为：0.45096713304519653\n",
						"################################\n",
						"第30次epoch的train loss为：0.3263116776943207\n",
						"第30次epoch的test loss为：0.47955191135406494\n",
						"################################\n",
						"第40次epoch的train loss为：0.24883389472961426\n",
						"第40次epoch的test loss为：0.5057613849639893\n",
						"################################\n",
						"第50次epoch的train loss为：0.20087772607803345\n",
						"第50次epoch的test loss为：0.5275853872299194\n",
						"################################\n",
						"第60次epoch的train loss为：0.1683601588010788\n",
						"第60次epoch的test loss为：0.5460007190704346\n",
						"################################\n",
						"第70次epoch的train loss为：0.14488352835178375\n",
						"第70次epoch的test loss为：0.5616571307182312\n",
						"################################\n",
						"第80次epoch的train loss为：0.12714487314224243\n",
						"第80次epoch的test loss为：0.575489342212677\n",
						"################################\n",
						"第90次epoch的train loss为：0.11327209323644638\n",
						"第90次epoch的test loss为：0.587766706943512\n",
						"################################\n",
						"训练结束\n"
					]
				},
				{
					"data": {
						"image/png": "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",
						"text/plain": [
							"<Figure size 1000x500 with 1 Axes>"
						]
					},
					"metadata": {},
					"output_type": "display_data"
				}
			],
			"source": [
				"import torch\n",
				"import torch.nn as nn\n",
				"from sklearn.preprocessing import StandardScaler\n",
				"import load_data as l\n",
				"from matplotlib import pyplot as plt\n",
				"import numpy as np \n",
				"from torchsummary import summary\n",
				"import torch.nn.functional as F\n",
				"import sys, os \n",
				"from PIL import Image\n",
				"sys.path.append(os.pardir)\n",
				"import pickle\n",
				"\n",
				"def img_show(img):\n",
				"    \"\"\"显示图像函数\n",
				"\n",
				"    Args:\n",
				"        img (np.array): 载入的图像,数组格式\n",
				"    \"\"\"\n",
				"    pil_img=Image.fromarray(np.uint(img))\n",
				"    pil_img.show()\n",
				"    \n",
				"class MNet(nn.Module):\n",
				"    def __init__(self,input,hidden,output) -> None:\n",
				"        super(MNet,self).__init__()\n",
				"        \n",
				"        self.linear1=nn.Linear(in_features=input,out_features=hidden)\n",
				"        self.relu1=nn.ReLU()\n",
				"        self.linear2=nn.Linear(in_features=hidden,out_features=hidden)\n",
				"        self.relu2=nn.ReLU()\n",
				"        self.linear3=nn.Linear(in_features=hidden,out_features=hidden)\n",
				"        self.relu3=nn.ReLU()\n",
				"        self.linear4=nn.Linear(in_features=hidden,out_features=output)\n",
				"            \n",
				"  \n",
				"    def forward(self,x):\n",
				"        x=self.linear1.forward(x)\n",
				"        x=self.relu1.forward(x)\n",
				"        x=self.linear2.forward(x)\n",
				"        x=self.relu2.forward(x)\n",
				"        x=self.linear3.forward(x)\n",
				"        x=self.relu3.forward(x)\n",
				"        x=self.linear4.forward(x)\n",
				"        return x\n",
				"    \n",
				"    def accuracy(self, x, t):\n",
				"        y = self.forward(x)\n",
				"        y = torch.argmax(y, axis=1)\n",
				"        #if t.ndim != 1 : t = np.argmax(t, axis=1)\n",
				"        \n",
				"        accuracy = torch.sum(y == t) / torch.FloatTensor(x.shape[0])\n",
				"        return accuracy\n",
				"    \n",
				"class SimpleNet(nn.Module):\n",
				"    def __init__(self,input,hidden,output) -> None:\n",
				"        super(SimpleNet,self).__init__()\n",
				"        self.l1=nn.Linear(input,hidden)\n",
				"        self.l2=nn.Linear(hidden,hidden)\n",
				"        self.l3=nn.Linear(hidden,output)\n",
				"    def forward(self,x):\n",
				"        x=F.relu(self.l1(x))\n",
				"        x=F.relu(self.l2(x))\n",
				"        x=self.l3(x)\n",
				"        return x\n",
				"    \n",
				"if __name__ == '__main__':\n",
				"    ################################数据载入、数据预处理################################\n",
				"    #对所有数据进行 normalization\n",
				"    stdsc=StandardScaler()\n",
				"    (x_train,t_train),(x_test,t_test)=l.load_mnist(normalize=False ,one_hot_label=False,flatten=True)#flatten是否将矩阵变为一维数组\n",
				"    \n",
				"    \n",
				"    x_train, t_train=x_train[:1000], t_train[:1000]\n",
				"    #img_train=x_train[1]\n",
				"    #img_show(img_train.reshape(28,28))#查看图象是否正确\n",
				"    #print(t_train[1])\n",
				"    img_test=x_test[5]\n",
				"    img_show(img_test.reshape(28,28))#查看图象是否正确\n",
				"    print(t_test[5])\n",
				"    #通过standardScaler实现输入图像数据正则化处理\n",
				"    x_train=stdsc.fit_transform(x_train)\n",
				"    x_test=stdsc.fit_transform(x_test)\n",
				"    train_size=x_train.shape[0]# 获取行数\n",
				"    \n",
				"    step_loss=[]\n",
				"    train_loss_list=[]\n",
				"    test_loss_list=[]\n",
				"    test_loss_list\n",
				"    ################################numpy数据张量化，并载入本机gpu或cpu################################`\n",
				"    device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
				"    print(\"current device: \" + device)\n",
				"    x_train=torch.from_numpy(x_train).to(torch.float32).to(device)\n",
				"    t_train=torch.from_numpy(t_train).to(torch.float32).to(device)\n",
				"    x_test=torch.from_numpy(x_test).to(torch.float32).to(device)\n",
				"    t_test=torch.from_numpy(t_test).to(torch.float32).to(device)\n",
				"    #t_train=t_train.view(-1,1)\n",
				"    #t_test=t_test.view(-1,1)\n",
				"    print(x_train.shape,t_train.shape)\n",
				"    print(x_test.shape,t_test.shape)\n",
				"    ## 超参设定\n",
				"    learning_rate=0.001#学习率\n",
				"    batch_size=100# 每批次随机选取100张图像\n",
				"    epochs=100#循环epoch次数\n",
				"    steps=int(x_train.shape[0]//batch_size)#完成一个epoch需要读取多少次batch\n",
				"    print(steps)\n",
				"    ################################网络实例构建################################\n",
				"    #构建网络实例，注意在网络实例化时，权参、偏参也赋予了初始值\n",
				"    print(\"the input shape of the training data is: \",x_train.shape[1])\n",
				"    net=SimpleNet(input=int(x_train.shape[1]),hidden=40,output=10)\n",
				"\n",
				"    net.to(device)\n",
				"    loss_fn=nn.CrossEntropyLoss()\n",
				"    opt=torch.optim.Adam(params=net.parameters(),lr=learning_rate)\n",
				"    #summary(net,input_size=(784,))\n",
				"    ################################网络实例训练################################\n",
				"    for epoch in range(epochs):\n",
				"        #print(\"第{}次epoch\".format(epoch))\n",
				"        for step in range(steps):\n",
				"            x=x_train[step*batch_size:(step+1)*batch_size,:]\n",
				"            y=t_train[step*batch_size:(step+1)*batch_size]\n",
				"            \n",
				"            y_pred=net(x)\n",
				"            \n",
				"            \n",
				"            #print(y.long())\n",
				"            loss=loss_fn(y_pred,y.long())\n",
				"            step_loss.append(loss.cpu().detach().numpy())\n",
				"            opt.zero_grad()\n",
				"            loss.backward()\n",
				"            opt.step()\n",
				"        train_loss=np.mean(step_loss)\n",
				"        y_predict=net.forward(x_test)\n",
				"        test_loss=loss_fn(y_predict,t_test.long())\n",
				"        test_loss_list.append(test_loss.cpu().detach().numpy())\n",
				"        train_loss_list.append( np.mean(step_loss))\n",
				"        \n",
				"        \n",
				"        if epoch%10==0:\n",
				"            print(\"第{}次epoch的train loss为：{}\".format(epoch,train_loss))\n",
				"            print(\"第{}次epoch的test loss为：{}\".format( epoch,test_loss))\n",
				"            print(\"################################\")\n",
				"        \n",
				"    print(\"训练结束\")\n",
				"    ###############################################loss graph#################################################\n",
				"    fig = plt.gcf()\n",
				"    fig.set_size_inches(10, 5)\n",
				"    fig.set_facecolor(\"gray\")\n",
				"    plt.xlabel('Epochs', fontsize=15)\n",
				"    plt.ylabel('Loss', fontsize=15)\n",
				"    plt.plot(train_loss_list, 'blue', label='Train loss')\n",
				"    plt.plot(test_loss_list, 'red', label='Test loss')\n",
				"    plt.legend(loc='best')\n",
				"    plt.title('Training and Test loss', fontsize=15)\n",
				"    plt.show()   \n",
				" "
			]
		},
		{
			"attachments": {},
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"#### 实验2.2 基于 dataset dataloader 图像分类\n",
				"\n",
				"数据来源于torchvision.datasets，已经经过预处理可以直接通过dataloader调用\n",
				"\n",
				"---\n",
				"##### 关于图片在python中的基本处理\n",
				"* [深度学习NCHW和NHWC数据格式（由三维数据转换成一维数据的遍历方式）](https://dontla.blog.csdn.net/article/details/123141775?spm=1001.2101.3001.6650.1&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1-123141775-blog-108960632.pc_relevant_recovery_v2&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1-123141775-blog-108960632.pc_relevant_recovery_v2&utm_relevant_index=2)\n",
				"* [https://blog.csdn.net/m0_37673307/article/details/81271155](https://blog.csdn.net/m0_37673307/article/details/81271155)\n",
				"不同于灰度图片，读取的图片的格式加入了通道维度，\n",
				"\n",
				"---\n",
				"\n",
				"实验笔记：\n",
				"\n",
				"1. 在计算loss与accuracy时，应该停止梯度计算，主要是为了节约计算资源，防止内存爆炸。\n",
				"2. 同样在读取loss，accracy值时，或者通过.cup().detch().numpy() 将数据转移到cpu，并脱离梯度计算detch，然后变为numpy；\n",
				"\n",
				"使用loss += loss.detach()来获取不需要梯度回传的部分。或者使用loss.item()直接获得所对应的python数据类型。\n",
				"> 简单理解就是.item()直接返回tensor的值，而不是对象\n",
				"\n",
				"3. 由于数据量较大，可以使用from torch.utils.data import Subset，中Subset，保留索引对应的值，缩小数据量\n",
				"[dataset 划分参考](https://lewtun.github.io/blog/til/nlp/pytorch/2021/01/24/til-slicing-torch-datasets.html)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 39,
			"metadata": {},
			"outputs": [
				{
					"name": "stderr",
					"output_type": "stream",
					"text": [
						"ERROR: Could not find a version that satisfies the requirement OpenCV (from versions: none)\n",
						"ERROR: No matching distribution found for OpenCV\n"
					]
				}
			],
			"source": [
				"!pip install OpenCV"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 40,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"500\n",
						"批次 0\n",
						"########################\n",
						"一个批次对应数据量：  torch.Size([1, 28, 28])\n",
						"因变量： 5\n",
						"torch.Size([20, 1, 28, 28])\n",
						"tensor([3, 2, 3, 7, 3, 6, 9, 5, 3, 7, 0, 2, 5, 6, 9, 1, 0, 7, 8, 8])\n"
					]
				}
			],
			"source": [
				"import torchvision\n",
				"from torchvision.transforms import ToTensor\n",
				"from torch.utils.data import Subset\n",
				"train_ds=torchvision.datasets.MNIST('data/',train=True,transform=ToTensor(),download=True)\n",
				"test_ds=torchvision.datasets.MNIST('data/',train=False,transform=ToTensor(),download=True)\n",
				"\n",
				" \n",
				"import numpy as np\n",
				"\n",
				"\n",
				"num_train_examples = 500\n",
				"sample_ds = Subset(train_ds, np.arange(num_train_examples))\n",
				"assert len(sample_ds) == num_train_examples\n",
				"print(len(sample_ds))\n",
				"train_data=enumerate(train_ds)\n",
				"for  bitch_idx,(x_train,y_train) in train_data:\n",
				"     print(\"批次\",bitch_idx)\n",
				"     print(\"########################\")\n",
				"     print(\"一个批次对应数据量： \",x_train.shape)\n",
				"     print(\"因变量：\",y_train)\n",
				"     break\n",
				"x_train=torch.utils.data.DataLoader(train_ds,batch_size=20,shuffle=True)#可以通过dataloader显示指定每个batch_size,以及是否shuffle，前提是输入的数据必须是dataset\n",
				"for x,y in x_train:\n",
				"     print(x.shape)\n",
				"     print(y)\n",
				"     break"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 44,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"current device: cuda\n",
						"一个train epoch中数据长度 500\n",
						"一个test epoch中数据长度 500\n",
						"the batch 1\n",
						"the batch 2\n",
						"the batch 3\n",
						"the batch 4\n",
						"the batch 5\n",
						"the batch 6\n",
						"the batch 7\n",
						"the batch 8\n",
						"the batch 9\n",
						"the batch 10\n",
						"the batch 11\n",
						"the batch 12\n",
						"the batch 13\n",
						"the batch 14\n",
						"the batch 15\n",
						"the batch 16\n",
						"the batch 17\n",
						"the batch 18\n",
						"the batch 19\n",
						"the batch 20\n",
						"the batch 21\n",
						"the batch 22\n",
						"the batch 23\n",
						"the batch 24\n",
						"the batch 25\n",
						"##############第0次epoch#################\n",
						"train loss为：2.0000054836273193\n",
						"test loss为：1.7443774938583374\n",
						"train accuracy为：44.2%\n",
						"test accuracy为：54.6%\n",
						"the batch 1\n",
						"the batch 2\n",
						"the batch 3\n",
						"the batch 4\n",
						"the batch 5\n",
						"the batch 6\n",
						"the batch 7\n",
						"the batch 8\n",
						"the batch 9\n",
						"the batch 10\n",
						"the batch 11\n",
						"the batch 12\n",
						"the batch 13\n",
						"the batch 14\n",
						"the batch 15\n",
						"the batch 16\n",
						"the batch 17\n",
						"the batch 18\n",
						"the batch 19\n",
						"the batch 20\n",
						"the batch 21\n",
						"the batch 22\n",
						"the batch 23\n",
						"the batch 24\n",
						"the batch 25\n",
						"the batch 1\n",
						"the batch 2\n",
						"the batch 3\n",
						"the batch 4\n",
						"the batch 5\n",
						"the batch 6\n",
						"the batch 7\n",
						"the batch 8\n",
						"the batch 9\n",
						"the batch 10\n",
						"the batch 11\n",
						"the batch 12\n",
						"the batch 13\n",
						"the batch 14\n",
						"the batch 15\n",
						"the batch 16\n",
						"the batch 17\n",
						"the batch 18\n",
						"the batch 19\n",
						"the batch 20\n",
						"the batch 21\n",
						"the batch 22\n",
						"the batch 23\n",
						"the batch 24\n",
						"the batch 25\n",
						"the batch 1\n",
						"the batch 2\n",
						"the batch 3\n",
						"the batch 4\n",
						"the batch 5\n",
						"the batch 6\n",
						"the batch 7\n",
						"the batch 8\n",
						"the batch 9\n",
						"the batch 10\n",
						"the batch 11\n",
						"the batch 12\n",
						"the batch 13\n",
						"the batch 14\n",
						"the batch 15\n",
						"the batch 16\n",
						"the batch 17\n",
						"the batch 18\n",
						"the batch 19\n",
						"the batch 20\n",
						"the batch 21\n",
						"the batch 22\n",
						"the batch 23\n",
						"the batch 24\n",
						"the batch 25\n",
						"the batch 1\n",
						"the batch 2\n",
						"the batch 3\n",
						"the batch 4\n",
						"the batch 5\n",
						"the batch 6\n",
						"the batch 7\n",
						"the batch 8\n",
						"the batch 9\n",
						"the batch 10\n",
						"the batch 11\n",
						"the batch 12\n",
						"the batch 13\n",
						"the batch 14\n",
						"the batch 15\n",
						"the batch 16\n",
						"the batch 17\n",
						"the batch 18\n",
						"the batch 19\n",
						"the batch 20\n",
						"the batch 21\n",
						"the batch 22\n",
						"the batch 23\n",
						"the batch 24\n",
						"the batch 25\n",
						"the batch 1\n",
						"the batch 2\n",
						"the batch 3\n",
						"the batch 4\n",
						"the batch 5\n",
						"the batch 6\n",
						"the batch 7\n",
						"the batch 8\n",
						"the batch 9\n",
						"the batch 10\n",
						"the batch 11\n",
						"the batch 12\n",
						"the batch 13\n",
						"the batch 14\n",
						"the batch 15\n",
						"the batch 16\n",
						"the batch 17\n",
						"the batch 18\n",
						"the batch 19\n",
						"the batch 20\n",
						"the batch 21\n",
						"the batch 22\n",
						"the batch 23\n",
						"the batch 24\n",
						"the batch 25\n",
						"the batch 1\n",
						"the batch 2\n",
						"the batch 3\n",
						"the batch 4\n",
						"the batch 5\n",
						"the batch 6\n",
						"the batch 7\n",
						"the batch 8\n",
						"the batch 9\n",
						"the batch 10\n",
						"the batch 11\n",
						"the batch 12\n",
						"the batch 13\n",
						"the batch 14\n",
						"the batch 15\n",
						"the batch 16\n",
						"the batch 17\n",
						"the batch 18\n",
						"the batch 19\n",
						"the batch 20\n",
						"the batch 21\n",
						"the batch 22\n",
						"the batch 23\n",
						"the batch 24\n",
						"the batch 25\n",
						"the batch 1\n",
						"the batch 2\n",
						"the batch 3\n",
						"the batch 4\n",
						"the batch 5\n",
						"the batch 6\n",
						"the batch 7\n",
						"the batch 8\n",
						"the batch 9\n",
						"the batch 10\n",
						"the batch 11\n",
						"the batch 12\n",
						"the batch 13\n",
						"the batch 14\n",
						"the batch 15\n",
						"the batch 16\n",
						"the batch 17\n",
						"the batch 18\n",
						"the batch 19\n",
						"the batch 20\n",
						"the batch 21\n",
						"the batch 22\n",
						"the batch 23\n",
						"the batch 24\n",
						"the batch 25\n",
						"the batch 1\n",
						"the batch 2\n",
						"the batch 3\n",
						"the batch 4\n",
						"the batch 5\n",
						"the batch 6\n",
						"the batch 7\n",
						"the batch 8\n",
						"the batch 9\n",
						"the batch 10\n",
						"the batch 11\n",
						"the batch 12\n",
						"the batch 13\n",
						"the batch 14\n",
						"the batch 15\n",
						"the batch 16\n",
						"the batch 17\n",
						"the batch 18\n",
						"the batch 19\n",
						"the batch 20\n",
						"the batch 21\n",
						"the batch 22\n",
						"the batch 23\n",
						"the batch 24\n",
						"the batch 25\n",
						"the batch 1\n",
						"the batch 2\n",
						"the batch 3\n",
						"the batch 4\n",
						"the batch 5\n",
						"the batch 6\n",
						"the batch 7\n",
						"the batch 8\n",
						"the batch 9\n",
						"the batch 10\n",
						"the batch 11\n",
						"the batch 12\n",
						"the batch 13\n",
						"the batch 14\n",
						"the batch 15\n",
						"the batch 16\n",
						"the batch 17\n",
						"the batch 18\n",
						"the batch 19\n",
						"the batch 20\n",
						"the batch 21\n",
						"the batch 22\n",
						"the batch 23\n",
						"the batch 24\n",
						"the batch 25\n",
						"the batch 1\n",
						"the batch 2\n",
						"the batch 3\n",
						"the batch 4\n",
						"the batch 5\n",
						"the batch 6\n",
						"the batch 7\n",
						"the batch 8\n",
						"the batch 9\n",
						"the batch 10\n",
						"the batch 11\n",
						"the batch 12\n",
						"the batch 13\n",
						"the batch 14\n",
						"the batch 15\n",
						"the batch 16\n",
						"the batch 17\n",
						"the batch 18\n",
						"the batch 19\n",
						"the batch 20\n",
						"the batch 21\n",
						"the batch 22\n",
						"the batch 23\n",
						"the batch 24\n",
						"the batch 25\n",
						"##############第10次epoch#################\n",
						"train loss为：0.007428030949085951\n",
						"test loss为：0.29705044627189636\n",
						"train accuracy为：100.20040080158074%\n",
						"test accuracy为：85.36913987492417%\n",
						"the batch 1\n",
						"the batch 2\n",
						"the batch 3\n",
						"the batch 4\n",
						"the batch 5\n",
						"the batch 6\n",
						"the batch 7\n",
						"the batch 8\n",
						"the batch 9\n",
						"the batch 10\n",
						"the batch 11\n",
						"the batch 12\n",
						"the batch 13\n",
						"the batch 14\n",
						"the batch 15\n",
						"the batch 16\n",
						"the batch 17\n",
						"the batch 18\n",
						"the batch 19\n",
						"the batch 20\n",
						"the batch 21\n",
						"the batch 22\n",
						"the batch 23\n",
						"the batch 24\n",
						"the batch 25\n",
						"the batch 1\n",
						"the batch 2\n",
						"the batch 3\n",
						"the batch 4\n",
						"the batch 5\n",
						"the batch 6\n",
						"the batch 7\n",
						"the batch 8\n",
						"the batch 9\n",
						"the batch 10\n",
						"the batch 11\n",
						"the batch 12\n",
						"the batch 13\n",
						"the batch 14\n",
						"the batch 15\n",
						"the batch 16\n",
						"the batch 17\n",
						"the batch 18\n",
						"the batch 19\n",
						"the batch 20\n",
						"the batch 21\n",
						"the batch 22\n",
						"the batch 23\n",
						"the batch 24\n",
						"the batch 25\n",
						"the batch 1\n",
						"the batch 2\n",
						"the batch 3\n",
						"the batch 4\n",
						"the batch 5\n",
						"the batch 6\n",
						"the batch 7\n",
						"the batch 8\n",
						"the batch 9\n",
						"the batch 10\n",
						"the batch 11\n",
						"the batch 12\n",
						"the batch 13\n",
						"the batch 14\n",
						"the batch 15\n",
						"the batch 16\n",
						"the batch 17\n",
						"the batch 18\n",
						"the batch 19\n",
						"the batch 20\n",
						"the batch 21\n",
						"the batch 22\n",
						"the batch 23\n",
						"the batch 24\n",
						"the batch 25\n",
						"the batch 1\n",
						"the batch 2\n",
						"the batch 3\n",
						"the batch 4\n",
						"the batch 5\n",
						"the batch 6\n",
						"the batch 7\n",
						"the batch 8\n",
						"the batch 9\n",
						"the batch 10\n",
						"the batch 11\n",
						"the batch 12\n",
						"the batch 13\n",
						"the batch 14\n",
						"the batch 15\n",
						"the batch 16\n",
						"the batch 17\n",
						"the batch 18\n",
						"the batch 19\n",
						"the batch 20\n",
						"the batch 21\n",
						"the batch 22\n",
						"the batch 23\n",
						"the batch 24\n",
						"the batch 25\n",
						"the batch 1\n",
						"the batch 2\n",
						"the batch 3\n",
						"the batch 4\n",
						"the batch 5\n",
						"the batch 6\n",
						"the batch 7\n",
						"the batch 8\n",
						"the batch 9\n",
						"the batch 10\n",
						"the batch 11\n",
						"the batch 12\n",
						"the batch 13\n",
						"the batch 14\n",
						"the batch 15\n",
						"the batch 16\n",
						"the batch 17\n",
						"the batch 18\n",
						"the batch 19\n",
						"the batch 20\n",
						"the batch 21\n",
						"the batch 22\n",
						"the batch 23\n",
						"the batch 24\n",
						"the batch 25\n",
						"the batch 1\n",
						"the batch 2\n",
						"the batch 3\n",
						"the batch 4\n",
						"the batch 5\n",
						"the batch 6\n",
						"the batch 7\n",
						"the batch 8\n",
						"the batch 9\n",
						"the batch 10\n",
						"the batch 11\n",
						"the batch 12\n",
						"the batch 13\n",
						"the batch 14\n",
						"the batch 15\n",
						"the batch 16\n",
						"the batch 17\n",
						"the batch 18\n",
						"the batch 19\n",
						"the batch 20\n",
						"the batch 21\n",
						"the batch 22\n",
						"the batch 23\n",
						"the batch 24\n",
						"the batch 25\n",
						"the batch 1\n",
						"the batch 2\n",
						"the batch 3\n",
						"the batch 4\n",
						"the batch 5\n",
						"the batch 6\n",
						"the batch 7\n",
						"the batch 8\n",
						"the batch 9\n",
						"the batch 10\n",
						"the batch 11\n",
						"the batch 12\n",
						"the batch 13\n",
						"the batch 14\n",
						"the batch 15\n",
						"the batch 16\n",
						"the batch 17\n",
						"the batch 18\n",
						"the batch 19\n",
						"the batch 20\n",
						"the batch 21\n",
						"the batch 22\n",
						"the batch 23\n",
						"the batch 24\n",
						"the batch 25\n",
						"the batch 1\n",
						"the batch 2\n",
						"the batch 3\n",
						"the batch 4\n",
						"the batch 5\n",
						"the batch 6\n",
						"the batch 7\n",
						"the batch 8\n",
						"the batch 9\n",
						"the batch 10\n",
						"the batch 11\n",
						"the batch 12\n",
						"the batch 13\n",
						"the batch 14\n",
						"the batch 15\n",
						"the batch 16\n",
						"the batch 17\n",
						"the batch 18\n",
						"the batch 19\n",
						"the batch 20\n",
						"the batch 21\n",
						"the batch 22\n",
						"the batch 23\n",
						"the batch 24\n",
						"the batch 25\n",
						"the batch 1\n",
						"the batch 2\n",
						"the batch 3\n",
						"the batch 4\n",
						"the batch 5\n",
						"the batch 6\n",
						"the batch 7\n",
						"the batch 8\n",
						"the batch 9\n",
						"the batch 10\n",
						"the batch 11\n",
						"the batch 12\n",
						"the batch 13\n",
						"the batch 14\n",
						"the batch 15\n",
						"the batch 16\n",
						"the batch 17\n",
						"the batch 18\n",
						"the batch 19\n",
						"the batch 20\n",
						"the batch 21\n",
						"the batch 22\n",
						"the batch 23\n",
						"the batch 24\n",
						"the batch 25\n",
						"the batch 1\n",
						"the batch 2\n",
						"the batch 3\n",
						"the batch 4\n",
						"the batch 5\n",
						"the batch 6\n",
						"the batch 7\n",
						"the batch 8\n",
						"the batch 9\n",
						"the batch 10\n",
						"the batch 11\n",
						"the batch 12\n",
						"the batch 13\n",
						"the batch 14\n",
						"the batch 15\n",
						"the batch 16\n",
						"the batch 17\n",
						"the batch 18\n",
						"the batch 19\n",
						"the batch 20\n",
						"the batch 21\n",
						"the batch 22\n",
						"the batch 23\n",
						"the batch 24\n",
						"the batch 25\n",
						"##############第20次epoch#################\n",
						"train loss为：0.0011716298758983612\n",
						"test loss为：0.348969429731369\n",
						"train accuracy为：100.2004008016032%\n",
						"test accuracy为：84.96953988295952%\n",
						"the batch 1\n",
						"the batch 2\n",
						"the batch 3\n",
						"the batch 4\n",
						"the batch 5\n",
						"the batch 6\n",
						"the batch 7\n",
						"the batch 8\n",
						"the batch 9\n",
						"the batch 10\n",
						"the batch 11\n",
						"the batch 12\n",
						"the batch 13\n",
						"the batch 14\n",
						"the batch 15\n",
						"the batch 16\n",
						"the batch 17\n",
						"the batch 18\n",
						"the batch 19\n",
						"the batch 20\n",
						"the batch 21\n",
						"the batch 22\n",
						"the batch 23\n",
						"the batch 24\n",
						"the batch 25\n",
						"the batch 1\n",
						"the batch 2\n",
						"the batch 3\n",
						"the batch 4\n",
						"the batch 5\n",
						"the batch 6\n",
						"the batch 7\n",
						"the batch 8\n",
						"the batch 9\n",
						"the batch 10\n",
						"the batch 11\n",
						"the batch 12\n",
						"the batch 13\n",
						"the batch 14\n",
						"the batch 15\n",
						"the batch 16\n",
						"the batch 17\n",
						"the batch 18\n",
						"the batch 19\n",
						"the batch 20\n",
						"the batch 21\n",
						"the batch 22\n",
						"the batch 23\n",
						"the batch 24\n",
						"the batch 25\n",
						"the batch 1\n",
						"the batch 2\n",
						"the batch 3\n",
						"the batch 4\n",
						"the batch 5\n",
						"the batch 6\n",
						"the batch 7\n",
						"the batch 8\n",
						"the batch 9\n",
						"the batch 10\n",
						"the batch 11\n",
						"the batch 12\n",
						"the batch 13\n",
						"the batch 14\n",
						"the batch 15\n",
						"the batch 16\n",
						"the batch 17\n",
						"the batch 18\n",
						"the batch 19\n",
						"the batch 20\n",
						"the batch 21\n",
						"the batch 22\n",
						"the batch 23\n",
						"the batch 24\n",
						"the batch 25\n",
						"the batch 1\n",
						"the batch 2\n",
						"the batch 3\n",
						"the batch 4\n",
						"the batch 5\n",
						"the batch 6\n",
						"the batch 7\n",
						"the batch 8\n",
						"the batch 9\n",
						"the batch 10\n",
						"the batch 11\n",
						"the batch 12\n",
						"the batch 13\n",
						"the batch 14\n",
						"the batch 15\n",
						"the batch 16\n",
						"the batch 17\n",
						"the batch 18\n",
						"the batch 19\n",
						"the batch 20\n",
						"the batch 21\n",
						"the batch 22\n",
						"the batch 23\n",
						"the batch 24\n",
						"the batch 25\n",
						"the batch 1\n",
						"the batch 2\n",
						"the batch 3\n",
						"the batch 4\n",
						"the batch 5\n",
						"the batch 6\n",
						"the batch 7\n",
						"the batch 8\n",
						"the batch 9\n",
						"the batch 10\n",
						"the batch 11\n",
						"the batch 12\n",
						"the batch 13\n",
						"the batch 14\n",
						"the batch 15\n",
						"the batch 16\n",
						"the batch 17\n",
						"the batch 18\n",
						"the batch 19\n",
						"the batch 20\n",
						"the batch 21\n",
						"the batch 22\n",
						"the batch 23\n",
						"the batch 24\n",
						"the batch 25\n",
						"the batch 1\n",
						"the batch 2\n",
						"the batch 3\n",
						"the batch 4\n",
						"the batch 5\n",
						"the batch 6\n",
						"the batch 7\n",
						"the batch 8\n",
						"the batch 9\n",
						"the batch 10\n",
						"the batch 11\n",
						"the batch 12\n",
						"the batch 13\n",
						"the batch 14\n",
						"the batch 15\n",
						"the batch 16\n",
						"the batch 17\n",
						"the batch 18\n",
						"the batch 19\n",
						"the batch 20\n",
						"the batch 21\n",
						"the batch 22\n",
						"the batch 23\n",
						"the batch 24\n",
						"the batch 25\n",
						"the batch 1\n",
						"the batch 2\n",
						"the batch 3\n",
						"the batch 4\n",
						"the batch 5\n",
						"the batch 6\n",
						"the batch 7\n",
						"the batch 8\n",
						"the batch 9\n",
						"the batch 10\n",
						"the batch 11\n",
						"the batch 12\n",
						"the batch 13\n",
						"the batch 14\n",
						"the batch 15\n",
						"the batch 16\n",
						"the batch 17\n",
						"the batch 18\n",
						"the batch 19\n",
						"the batch 20\n",
						"the batch 21\n",
						"the batch 22\n",
						"the batch 23\n",
						"the batch 24\n",
						"the batch 25\n",
						"the batch 1\n",
						"the batch 2\n",
						"the batch 3\n",
						"the batch 4\n",
						"the batch 5\n",
						"the batch 6\n",
						"the batch 7\n",
						"the batch 8\n",
						"the batch 9\n",
						"the batch 10\n",
						"the batch 11\n",
						"the batch 12\n",
						"the batch 13\n",
						"the batch 14\n",
						"the batch 15\n",
						"the batch 16\n",
						"the batch 17\n",
						"the batch 18\n",
						"the batch 19\n",
						"the batch 20\n",
						"the batch 21\n",
						"the batch 22\n",
						"the batch 23\n",
						"the batch 24\n",
						"the batch 25\n",
						"the batch 1\n",
						"the batch 2\n",
						"the batch 3\n",
						"the batch 4\n",
						"the batch 5\n",
						"the batch 6\n",
						"the batch 7\n",
						"the batch 8\n",
						"the batch 9\n",
						"the batch 10\n",
						"the batch 11\n",
						"the batch 12\n",
						"the batch 13\n",
						"the batch 14\n",
						"the batch 15\n",
						"the batch 16\n",
						"the batch 17\n",
						"the batch 18\n",
						"the batch 19\n",
						"the batch 20\n",
						"the batch 21\n",
						"the batch 22\n",
						"the batch 23\n",
						"the batch 24\n",
						"the batch 25\n",
						"the batch 1\n",
						"the batch 2\n",
						"the batch 3\n",
						"the batch 4\n",
						"the batch 5\n",
						"the batch 6\n",
						"the batch 7\n",
						"the batch 8\n",
						"the batch 9\n",
						"the batch 10\n",
						"the batch 11\n",
						"the batch 12\n",
						"the batch 13\n",
						"the batch 14\n",
						"the batch 15\n",
						"the batch 16\n",
						"the batch 17\n",
						"the batch 18\n",
						"the batch 19\n",
						"the batch 20\n",
						"the batch 21\n",
						"the batch 22\n",
						"the batch 23\n",
						"the batch 24\n",
						"the batch 25\n",
						"##############第30次epoch#################\n",
						"train loss为：0.00045709044206887484\n",
						"test loss为：0.38241875171661377\n",
						"train accuracy为：100.2004008016032%\n",
						"test accuracy为：85.37034148136273%\n",
						"the batch 1\n",
						"the batch 2\n",
						"the batch 3\n",
						"the batch 4\n",
						"the batch 5\n",
						"the batch 6\n",
						"the batch 7\n",
						"the batch 8\n",
						"the batch 9\n",
						"the batch 10\n",
						"the batch 11\n",
						"the batch 12\n",
						"the batch 13\n",
						"the batch 14\n",
						"the batch 15\n",
						"the batch 16\n",
						"the batch 17\n",
						"the batch 18\n",
						"the batch 19\n",
						"the batch 20\n",
						"the batch 21\n",
						"the batch 22\n",
						"the batch 23\n",
						"the batch 24\n",
						"the batch 25\n",
						"the batch 1\n",
						"the batch 2\n",
						"the batch 3\n",
						"the batch 4\n",
						"the batch 5\n",
						"the batch 6\n",
						"the batch 7\n",
						"the batch 8\n",
						"the batch 9\n",
						"the batch 10\n",
						"the batch 11\n",
						"the batch 12\n",
						"the batch 13\n",
						"the batch 14\n",
						"the batch 15\n",
						"the batch 16\n",
						"the batch 17\n",
						"the batch 18\n",
						"the batch 19\n",
						"the batch 20\n",
						"the batch 21\n",
						"the batch 22\n",
						"the batch 23\n",
						"the batch 24\n",
						"the batch 25\n",
						"the batch 1\n",
						"the batch 2\n",
						"the batch 3\n",
						"the batch 4\n",
						"the batch 5\n",
						"the batch 6\n",
						"the batch 7\n",
						"the batch 8\n",
						"the batch 9\n",
						"the batch 10\n",
						"the batch 11\n",
						"the batch 12\n",
						"the batch 13\n",
						"the batch 14\n",
						"the batch 15\n",
						"the batch 16\n",
						"the batch 17\n",
						"the batch 18\n",
						"the batch 19\n",
						"the batch 20\n",
						"the batch 21\n",
						"the batch 22\n",
						"the batch 23\n",
						"the batch 24\n",
						"the batch 25\n",
						"the batch 1\n",
						"the batch 2\n",
						"the batch 3\n",
						"the batch 4\n",
						"the batch 5\n",
						"the batch 6\n",
						"the batch 7\n",
						"the batch 8\n",
						"the batch 9\n",
						"the batch 10\n",
						"the batch 11\n",
						"the batch 12\n",
						"the batch 13\n",
						"the batch 14\n",
						"the batch 15\n",
						"the batch 16\n",
						"the batch 17\n",
						"the batch 18\n",
						"the batch 19\n",
						"the batch 20\n",
						"the batch 21\n",
						"the batch 22\n",
						"the batch 23\n",
						"the batch 24\n",
						"the batch 25\n",
						"the batch 1\n",
						"the batch 2\n",
						"the batch 3\n",
						"the batch 4\n",
						"the batch 5\n",
						"the batch 6\n",
						"the batch 7\n",
						"the batch 8\n",
						"the batch 9\n",
						"the batch 10\n",
						"the batch 11\n",
						"the batch 12\n",
						"the batch 13\n",
						"the batch 14\n",
						"the batch 15\n",
						"the batch 16\n",
						"the batch 17\n",
						"the batch 18\n",
						"the batch 19\n",
						"the batch 20\n",
						"the batch 21\n",
						"the batch 22\n",
						"the batch 23\n",
						"the batch 24\n",
						"the batch 25\n",
						"the batch 1\n",
						"the batch 2\n",
						"the batch 3\n",
						"the batch 4\n",
						"the batch 5\n",
						"the batch 6\n",
						"the batch 7\n",
						"the batch 8\n",
						"the batch 9\n",
						"the batch 10\n",
						"the batch 11\n",
						"the batch 12\n",
						"the batch 13\n",
						"the batch 14\n",
						"the batch 15\n",
						"the batch 16\n",
						"the batch 17\n",
						"the batch 18\n",
						"the batch 19\n",
						"the batch 20\n",
						"the batch 21\n",
						"the batch 22\n",
						"the batch 23\n",
						"the batch 24\n",
						"the batch 25\n",
						"the batch 1\n",
						"the batch 2\n",
						"the batch 3\n",
						"the batch 4\n",
						"the batch 5\n",
						"the batch 6\n",
						"the batch 7\n",
						"the batch 8\n",
						"the batch 9\n",
						"the batch 10\n",
						"the batch 11\n",
						"the batch 12\n",
						"the batch 13\n",
						"the batch 14\n",
						"the batch 15\n",
						"the batch 16\n",
						"the batch 17\n",
						"the batch 18\n",
						"the batch 19\n",
						"the batch 20\n",
						"the batch 21\n",
						"the batch 22\n",
						"the batch 23\n",
						"the batch 24\n",
						"the batch 25\n",
						"the batch 1\n",
						"the batch 2\n",
						"the batch 3\n",
						"the batch 4\n",
						"the batch 5\n",
						"the batch 6\n",
						"the batch 7\n",
						"the batch 8\n",
						"the batch 9\n",
						"the batch 10\n",
						"the batch 11\n",
						"the batch 12\n",
						"the batch 13\n",
						"the batch 14\n",
						"the batch 15\n",
						"the batch 16\n",
						"the batch 17\n",
						"the batch 18\n",
						"the batch 19\n",
						"the batch 20\n",
						"the batch 21\n",
						"the batch 22\n",
						"the batch 23\n",
						"the batch 24\n",
						"the batch 25\n",
						"the batch 1\n",
						"the batch 2\n",
						"the batch 3\n",
						"the batch 4\n",
						"the batch 5\n",
						"the batch 6\n",
						"the batch 7\n",
						"the batch 8\n",
						"the batch 9\n",
						"the batch 10\n",
						"the batch 11\n",
						"the batch 12\n",
						"the batch 13\n",
						"the batch 14\n",
						"the batch 15\n",
						"the batch 16\n",
						"the batch 17\n",
						"the batch 18\n",
						"the batch 19\n",
						"the batch 20\n",
						"the batch 21\n",
						"the batch 22\n",
						"the batch 23\n",
						"the batch 24\n",
						"the batch 25\n",
						"the batch 1\n",
						"the batch 2\n",
						"the batch 3\n",
						"the batch 4\n",
						"the batch 5\n",
						"the batch 6\n",
						"the batch 7\n",
						"the batch 8\n",
						"the batch 9\n",
						"the batch 10\n",
						"the batch 11\n",
						"the batch 12\n",
						"the batch 13\n",
						"the batch 14\n",
						"the batch 15\n",
						"the batch 16\n",
						"the batch 17\n",
						"the batch 18\n",
						"the batch 19\n",
						"the batch 20\n",
						"the batch 21\n",
						"the batch 22\n",
						"the batch 23\n",
						"the batch 24\n",
						"the batch 25\n",
						"##############第40次epoch#################\n",
						"train loss为：0.0002371662121731788\n",
						"test loss为：0.40691524744033813\n",
						"train accuracy为：100.2004008016032%\n",
						"test accuracy为：85.37074148296593%\n",
						"the batch 1\n",
						"the batch 2\n",
						"the batch 3\n",
						"the batch 4\n",
						"the batch 5\n",
						"the batch 6\n",
						"the batch 7\n",
						"the batch 8\n",
						"the batch 9\n",
						"the batch 10\n",
						"the batch 11\n",
						"the batch 12\n",
						"the batch 13\n",
						"the batch 14\n",
						"the batch 15\n",
						"the batch 16\n",
						"the batch 17\n",
						"the batch 18\n",
						"the batch 19\n",
						"the batch 20\n",
						"the batch 21\n",
						"the batch 22\n",
						"the batch 23\n",
						"the batch 24\n",
						"the batch 25\n",
						"the batch 1\n",
						"the batch 2\n",
						"the batch 3\n",
						"the batch 4\n",
						"the batch 5\n",
						"the batch 6\n",
						"the batch 7\n",
						"the batch 8\n",
						"the batch 9\n",
						"the batch 10\n",
						"the batch 11\n",
						"the batch 12\n",
						"the batch 13\n",
						"the batch 14\n",
						"the batch 15\n",
						"the batch 16\n",
						"the batch 17\n",
						"the batch 18\n",
						"the batch 19\n",
						"the batch 20\n",
						"the batch 21\n",
						"the batch 22\n",
						"the batch 23\n",
						"the batch 24\n",
						"the batch 25\n",
						"the batch 1\n",
						"the batch 2\n",
						"the batch 3\n",
						"the batch 4\n",
						"the batch 5\n",
						"the batch 6\n",
						"the batch 7\n",
						"the batch 8\n",
						"the batch 9\n",
						"the batch 10\n",
						"the batch 11\n",
						"the batch 12\n",
						"the batch 13\n",
						"the batch 14\n",
						"the batch 15\n",
						"the batch 16\n",
						"the batch 17\n",
						"the batch 18\n",
						"the batch 19\n",
						"the batch 20\n",
						"the batch 21\n",
						"the batch 22\n",
						"the batch 23\n",
						"the batch 24\n",
						"the batch 25\n",
						"the batch 1\n",
						"the batch 2\n",
						"the batch 3\n",
						"the batch 4\n",
						"the batch 5\n",
						"the batch 6\n",
						"the batch 7\n",
						"the batch 8\n",
						"the batch 9\n",
						"the batch 10\n",
						"the batch 11\n",
						"the batch 12\n",
						"the batch 13\n",
						"the batch 14\n",
						"the batch 15\n",
						"the batch 16\n",
						"the batch 17\n",
						"the batch 18\n",
						"the batch 19\n",
						"the batch 20\n",
						"the batch 21\n",
						"the batch 22\n",
						"the batch 23\n",
						"the batch 24\n",
						"the batch 25\n",
						"the batch 1\n",
						"the batch 2\n",
						"the batch 3\n",
						"the batch 4\n",
						"the batch 5\n",
						"the batch 6\n",
						"the batch 7\n",
						"the batch 8\n",
						"the batch 9\n",
						"the batch 10\n",
						"the batch 11\n",
						"the batch 12\n",
						"the batch 13\n",
						"the batch 14\n",
						"the batch 15\n",
						"the batch 16\n",
						"the batch 17\n",
						"the batch 18\n",
						"the batch 19\n",
						"the batch 20\n",
						"the batch 21\n",
						"the batch 22\n",
						"the batch 23\n",
						"the batch 24\n",
						"the batch 25\n",
						"the batch 1\n",
						"the batch 2\n",
						"the batch 3\n",
						"the batch 4\n",
						"the batch 5\n",
						"the batch 6\n",
						"the batch 7\n",
						"the batch 8\n",
						"the batch 9\n",
						"the batch 10\n",
						"the batch 11\n",
						"the batch 12\n",
						"the batch 13\n",
						"the batch 14\n",
						"the batch 15\n",
						"the batch 16\n",
						"the batch 17\n",
						"the batch 18\n",
						"the batch 19\n",
						"the batch 20\n",
						"the batch 21\n",
						"the batch 22\n",
						"the batch 23\n",
						"the batch 24\n",
						"the batch 25\n",
						"the batch 1\n",
						"the batch 2\n",
						"the batch 3\n",
						"the batch 4\n",
						"the batch 5\n",
						"the batch 6\n",
						"the batch 7\n",
						"the batch 8\n",
						"the batch 9\n",
						"the batch 10\n",
						"the batch 11\n",
						"the batch 12\n",
						"the batch 13\n",
						"the batch 14\n",
						"the batch 15\n",
						"the batch 16\n",
						"the batch 17\n",
						"the batch 18\n",
						"the batch 19\n",
						"the batch 20\n",
						"the batch 21\n",
						"the batch 22\n",
						"the batch 23\n",
						"the batch 24\n",
						"the batch 25\n",
						"the batch 1\n",
						"the batch 2\n",
						"the batch 3\n",
						"the batch 4\n",
						"the batch 5\n",
						"the batch 6\n",
						"the batch 7\n",
						"the batch 8\n",
						"the batch 9\n",
						"the batch 10\n",
						"the batch 11\n",
						"the batch 12\n",
						"the batch 13\n",
						"the batch 14\n",
						"the batch 15\n",
						"the batch 16\n",
						"the batch 17\n",
						"the batch 18\n",
						"the batch 19\n",
						"the batch 20\n",
						"the batch 21\n",
						"the batch 22\n",
						"the batch 23\n",
						"the batch 24\n",
						"the batch 25\n",
						"the batch 1\n",
						"the batch 2\n",
						"the batch 3\n",
						"the batch 4\n",
						"the batch 5\n",
						"the batch 6\n",
						"the batch 7\n",
						"the batch 8\n",
						"the batch 9\n",
						"the batch 10\n",
						"the batch 11\n",
						"the batch 12\n",
						"the batch 13\n",
						"the batch 14\n",
						"the batch 15\n",
						"the batch 16\n",
						"the batch 17\n",
						"the batch 18\n",
						"the batch 19\n",
						"the batch 20\n",
						"the batch 21\n",
						"the batch 22\n",
						"the batch 23\n",
						"the batch 24\n",
						"the batch 25\n",
						"***********************fin! good luck!*******************************\n",
						"The final train loss：0.00014749060210306197\n",
						"The final train  loss为：0.4236757755279541\n",
						"The final train accuracy：100.2004008016032%\n",
						"The final test accuracy：85.17034067976272%\n"
					]
				},
				{
					"data": {
						"image/png": "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",
						"text/plain": [
							"<Figure size 1000x500 with 1 Axes>"
						]
					},
					"metadata": {},
					"output_type": "display_data"
				},
				{
					"data": {
						"image/png": "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",
						"text/plain": [
							"<Figure size 640x480 with 1 Axes>"
						]
					},
					"metadata": {},
					"output_type": "display_data"
				}
			],
			"source": [
				"import torch\n",
				"import torch.nn as nn\n",
				"import myfucntion.Function as f\n",
				"from importlib import reload\n",
				"from sklearn.preprocessing import StandardScaler\n",
				"#import load_data as l\n",
				"from matplotlib import pyplot as plt\n",
				"import numpy as np \n",
				"from torchsummary import summary\n",
				"import torch.nn.functional as F\n",
				"import torchvision\n",
				"from torchvision.transforms import ToTensor\n",
				"reload(f)\n",
				" \n",
				"class MNet(nn.Module):\n",
				"    def __init__(self,input,hidden,output) -> None:\n",
				"        super(MNet,self).__init__()\n",
				"        \n",
				"        self.linear1=nn.Linear(in_features=input,out_features=hidden)\n",
				"        self.relu1=nn.ReLU()\n",
				"        self.linear2=nn.Linear(in_features=hidden,out_features=hidden)\n",
				"        self.relu2=nn.ReLU()\n",
				"        self.linear3=nn.Linear(in_features=hidden,out_features=hidden)\n",
				"        self.relu3=nn.ReLU()\n",
				"        self.linear4=nn.Linear(in_features=hidden,out_features=output)\n",
				"            \n",
				"  \n",
				"    def forward(self,x):\n",
				"        x=x.view(-1,28*28)#将输入图像变为28*28分辨率\n",
				"        x=self.linear1(x)\n",
				"        x=self.relu1(x)\n",
				"        x=self.linear2(x)\n",
				"        x=self.relu2(x)\n",
				"        x=self.linear3(x)\n",
				"        x=self.relu3(x)\n",
				"        x=self.linear4(x)\n",
				"        return x\n",
				"    \n",
				"\n",
				"\n",
				"if __name__ == '__main__':\n",
				"    ################################数据载入、数据预处理################################\n",
				"    train_ds=torchvision.datasets.MNIST('data/',train=True,transform=ToTensor(),download=False)\n",
				"    test_ds=torchvision.datasets.MNIST('data/',train=False,transform=ToTensor(),download=False)\n",
				"    # 缩减数据量\n",
				"    num_train_examples = 500\n",
				"    num_test_examples  = 300\n",
				"    train_ds = Subset(train_ds, np.arange(num_train_examples))\n",
				"    test_ds = Subset(test_ds, np.arange(num_train_examples))\n",
				"    # 通过dataloader进行处理\n",
				"    train_data=torch.utils.data.DataLoader(train_ds,batch_size=20,shuffle=True)\n",
				"    test_data=torch.utils.data.DataLoader(test_ds,batch_size=20,shuffle=False)\n",
				"   \n",
				"\n",
				"    train_loss_list=[]\n",
				"    test_loss_list=[]\n",
				"    train_correct_list=[]\n",
				"    test_correct_list=[]\n",
				"    ################################numpy数据张量化，并载入本机gpu或cpu################################`\n",
				"    device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
				"    print(\"current device: \" + device)\n",
				" \n",
				" \n",
				"    ## 超参设定\n",
				"    learning_rate=0.001#学习率\n",
				"    batch_size=20# 每批次随机选取20张图像\n",
				"    epochs=50#循环epoch次数\n",
				" \n",
				"    ################################网络实例构建################################\n",
				"    #构建网络实例，注意在网络实例化时，权参、偏参也赋予了初始值\n",
				"    net=MNet(input=28*28,hidden=200,output=10)\n",
				"    net.to(device)\n",
				"    loss_fn=nn.CrossEntropyLoss()\n",
				"    opt=torch.optim.Adam(params=net.parameters(),lr=learning_rate)\n",
				"    #summary(net,input_size=(784,))\n",
				"    ################################网络实例训练################################\n",
				"    train_len=len(train_data.dataset)\n",
				"    print(\"一个train epoch中数据长度\",train_len)\n",
				"    test_len=len(test_data.dataset)\n",
				"    print(\"一个test epoch中数据长度\",test_len)\n",
				"    train_correct=0\n",
				"    test_correct=0\n",
				"    for epoch in range(epochs):\n",
				"        #print(\"第{}次epoch\".format(epoch))\n",
				"        step_loss=[]\n",
				"        step_correct=[]\n",
				"        batch=0\n",
				"        for x,y in train_data:#trian_data每次载入一个batch_size(20),一个epcoch包含500个图片，故需要23次循环\n",
				"            x,y=x.to(device),y.to(device)\n",
				"            pred=net(x)\n",
				"            loss=loss_fn(pred,y)\n",
				"            opt.zero_grad()\n",
				"            loss.backward()\n",
				"            opt.step()\n",
				"            step_loss.append(loss.cpu().detach().numpy())\n",
				"            #step_correct.append((pred.argmax(dim=1)==y).type(torch.float).sum().item())\n",
				"            train_correct+=(pred.argmax(1)==y).type(torch.float).sum().item()\n",
				"            #step_correct=(pred.argmax(1)==y).type(torch.float).sum().item()\n",
				"            #print(step_correct/20,\"%\")\n",
				"            batch=batch+1\n",
				"            print(\"the batch\",batch)\n",
				"        train_loss=np.mean(step_loss)\n",
				"        train_loss_list.append( train_loss)\n",
				"        #train_correct=np.sum(step_correct)/train_len\n",
				"        train_correct/=train_len\n",
				"        train_correct_list.append( train_correct)\n",
				"        \n",
				"        \n",
				"        with torch.no_grad():# since we're not training, we don't need to calculate the gradients for our outputs\n",
				"            for x,y in test_data:\n",
				"                x,y=x.to(device),y.to(device)\n",
				"                pred=net(x)\n",
				"                loss=loss_fn(pred,y)\n",
				"                step_loss.append(loss.cpu().detach().numpy())\n",
				"                test_correct+=(pred.argmax(dim=1)==y).type(torch.float).sum().item()\n",
				"                \n",
				"        test_loss=np.mean(step_loss)\n",
				"        test_loss_list.append(test_loss)\n",
				"        #test_correct=np.sum(step_correct)/test_len\n",
				"        test_correct/=test_len\n",
				"        test_correct_list.append( train_correct)\n",
				"        \n",
				"        \n",
				"        \n",
				"        if epoch%10==0 :\n",
				"            print(\"##############第{}次epoch#################\".format(epoch))\n",
				"            print(\"train loss为：{}\".format(train_loss))\n",
				"            print(\"test loss为：{}\".format( test_loss))\n",
				"            print(\"train accuracy为：{}%\".format(train_correct*100))\n",
				"            print(\"test accuracy为：{}%\".format( test_correct*100))\n",
				"        if epoch==epochs-1:\n",
				"            print(\"***********************fin! good luck!*******************************\")\n",
				"            print(\"The final train loss：{}\".format(train_loss))\n",
				"            print(\"The final train  loss为：{}\".format( test_loss))\n",
				"            print(\"The final train accuracy：{}%\".format( train_correct*100))\n",
				"            print(\"The final test accuracy：{}%\".format( test_correct*100))\n",
				"    f.loss_fig(train_loss_list,test_loss_list)\n",
				"    f.accuracy_fig(train_correct_list,test_correct_list)\n",
				"    "
			]
		},
		{
			"cell_type": "code",
			"execution_count": 11,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"50\n"
					]
				}
			],
			"source": [
				"print(epochs)"
			]
		},
		{
			"attachments": {},
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"### 实验2.3 优化实验2.2 \n",
				"\n",
				"实验目标：\n",
				"\n",
				"* 引入weight decay，dropot 降低自拟合\n",
				"* 使用batch normalization\n",
				"* 优化学习率，学习率衰减\n",
				"\n",
				"---\n",
				"1. batch normalization\n",
				"\n",
				"* [PyTorch——Batch Normalization（批量归一化）](https://blog.csdn.net/beilizhang/article/details/115416708)\n",
				"\n",
				"* [Batch Normalization and Dropout in Neural Networks with Pytorch](https://towardsdatascience.com/batch-normalization-and-dropout-in-neural-networks-explained-with-pytorch-47d7a8459bcd)\n",
				"\n",
				"[参考](https://towardsdatascience.com/weight-decay-and-its-peculiar-effects-66e0aee3e7b8)\n",
				"\n",
				"pytorch中，batch normalization也是对应加入一层，不同于dropout等层的是，对应不同维度数据（例如3维度彩色图片），Pytorch中nn模块定义的BatchNorm1d和BatchNorm2d类分别用于全连接层和卷积层，都需要指定输入的num_features参数值。\n",
				" \n",
				"* nn.BatchNorm1d——矩阵张量 Liner(intout,output)->nn.BatchNorm1d(output)->Relu()\n",
				"* nn.BatchNorm2d——3d张量（图片）\n",
				"\n",
				"\n",
				"----\n",
				"\n",
				"实验结果：\n",
				"\n",
				"> 未优化前loss accuracy：\n",
				"\n",
				"The final train loss：0.00016342761227861047\n",
				"\n",
				"The final train  loss：0.4075630307197571\n",
				"\n",
				"The final train accuracy：100.2004008016032%\n",
				"\n",
				"The final test accuracy：84.3683366733467%\n",
				"\n",
				"\n",
				"---\n",
				"\n",
				"实验结果\n",
				"1. 加入dropout层\n",
				"* (p=0.5)\n",
				"***********************fin! good luck!*******************************\n",
				"The final train loss：0.039016470313072205\n",
				"The final train  loss为：0.5459088683128357\n",
				"The final train accuracy：99.19759359998717%\n",
				"The final test accuracy：81.16793663974346%\n",
				">loss，accuracy反而没有改善，过拟合有所减低\n",
				"\n",
				"* p=0.2 效果很好，过拟合有所减轻，同时精度上升\n",
				"\n",
				"The final train loss：0.004101796541363001\n",
				"The final train  loss为：0.4097197651863098\n",
				"The final train accuracy：100.1999951887904%\n",
				"The final test accuracy：84.56713263810506%\n",
				"\n",
				">结论，加入dropout，过拟合现象有所改善，但模型拟合度降低\n",
				"\n",
				"2. 加入L2正则化，实现weight decay\n",
				"\n",
				"* weight_decay=0.001\n",
				"> 一般而言，weigt_decay由pytorch自动设置，不需要调整\n",
				"The final train loss：0.05548945069313049\n",
				"The final train  loss为：0.32841596007347107\n",
				"The final train accuracy：100.19919919837757%\n",
				"The final test accuracy：83.56632626369861%\n",
				"The final test accuracy：81.36192625570175%\n",
				">结论，加入weight decay，过拟合现象进一步所改善，但模型拟合度进一步降低\n",
				"\n",
				"3. 加入batch normalization：\n",
				"\n",
				"> 提升效果一般\n",
				"\n",
				"The final train loss：0.012145309709012508\n",
				"The final train  loss为：0.39998507499694824\n",
				"The final train accuracy：99.79920000160321%\n",
				"The final test accuracy：81.7651278781563%"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"current device: cuda\n",
						"一个train epoch中数据长度 500\n",
						"一个test epoch中数据长度 500\n",
						"##############第0次epoch#################\n",
						"train loss为：1.253820538520813\n",
						"test loss为：1.0714396238327026\n",
						"train accuracy为：65.8%\n",
						"test accuracy为：75.0%\n",
						"##############第10次epoch#################\n",
						"train loss为：0.05604599788784981\n",
						"test loss为：0.3044620752334595\n",
						"train accuracy为：98.99959999999356%\n",
						"test accuracy为：82.9643230765371%\n",
						"##############第20次epoch#################\n",
						"train loss为：0.012977584265172482\n",
						"test loss为：0.30195870995521545\n",
						"train accuracy为：99.7999991984032%\n",
						"test accuracy为：83.16552865573385%\n",
						"##############第30次epoch#################\n",
						"train loss为：0.01004707533866167\n",
						"test loss为：0.34659507870674133\n",
						"train accuracy为：99.99879356794233%\n",
						"test accuracy为：84.36392223009538%\n",
						"##############第40次epoch#################\n",
						"train loss为：0.003951424732804298\n",
						"test loss为：0.34388241171836853\n",
						"train accuracy为：100.2004000016032%\n",
						"test accuracy为：84.36713507012108%\n",
						"***********************fin! good luck!*******************************\n",
						"The final train loss：0.007990935817360878\n",
						"The final train  loss为：0.4185859262943268\n",
						"The final train accuracy：99.99960000160002%\n",
						"The final test accuracy：81.36392867494028%\n"
					]
				},
				{
					"data": {
						"image/png": "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",
						"text/plain": [
							"<Figure size 1000x500 with 1 Axes>"
						]
					},
					"metadata": {},
					"output_type": "display_data"
				},
				{
					"data": {
						"image/png": "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",
						"text/plain": [
							"<Figure size 640x480 with 1 Axes>"
						]
					},
					"metadata": {},
					"output_type": "display_data"
				}
			],
			"source": [
				"import torch\n",
				"import torch.nn as nn\n",
				"import myfucntion.Function as f\n",
				"from importlib import reload\n",
				"from sklearn.preprocessing import StandardScaler\n",
				"#import load_data as l\n",
				"from matplotlib import pyplot as plt\n",
				"import numpy as np \n",
				"from torchsummary import summary\n",
				"from torch.utils.data import Subset\n",
				"import torch.nn.functional as F\n",
				"import torchvision\n",
				"from torchvision.transforms import ToTensor\n",
				"reload(f)\n",
				" \n",
				"class MNet1(nn.Module):\n",
				"    def __init__(self,input,hidden,output) -> None:\n",
				"        super(MNet1,self).__init__()\n",
				"        \n",
				"        self.linear1=nn.Linear(in_features=input,out_features=hidden)\n",
				"        self.relu1=nn.ReLU()\n",
				"        self.linear2=nn.Linear(in_features=hidden,out_features=hidden)\n",
				"        self.relu2=nn.ReLU()\n",
				"        self.linear3=nn.Linear(in_features=hidden,out_features=hidden)\n",
				"        self.relu3=nn.ReLU()\n",
				"        self.linear4=nn.Linear(in_features=hidden,out_features=output)\n",
				"            \n",
				"  \n",
				"    def forward(self,x):\n",
				"        x=x.view(-1,28*28)\n",
				"        x=self.linear1(x)\n",
				"        x=self.relu1(x)\n",
				"        x=self.linear2(x)\n",
				"        x=self.relu2(x)\n",
				"        x=self.linear3(x)\n",
				"        x=self.relu3(x)\n",
				"        x=self.linear4(x)\n",
				"        return x\n",
				"    \n",
				"class MNet2(nn.Module):\n",
				"    \"\"\"加入drop out层\n",
				"\n",
				"    Args:\n",
				"        nn (_type_): _description_\n",
				"    \"\"\"\n",
				"    def __init__(self,input,hidden,output,drop_p=0.5) -> None:\n",
				"        \"\"\"_summary_\n",
				"\n",
				"        Args:\n",
				"            input (_type_): _description_\n",
				"            hidden (_type_): _description_\n",
				"            output (_type_): _description_\n",
				"            drop_p (float, optional): dropout层中屏蔽神经网络节点的概率. Defaults to 0.5.\n",
				"        \"\"\"\n",
				"        super(MNet2,self).__init__()\n",
				"        \n",
				"        self.linear1=nn.Linear(in_features=input,out_features=hidden)\n",
				"        self.d1=nn.Dropout(p=drop_p)\n",
				"        self.relu1=nn.ReLU()\n",
				"        self.linear2=nn.Linear(in_features=hidden,out_features=hidden)\n",
				"        self.d2=nn.Dropout(p=drop_p)\n",
				"        self.relu2=nn.ReLU()\n",
				"        self.linear3=nn.Linear(in_features=hidden,out_features=hidden)\n",
				"        self.d3=nn.Dropout(p=drop_p)\n",
				"        self.relu3=nn.ReLU()\n",
				"        self.linear4=nn.Linear(in_features=hidden,out_features=output)\n",
				"            \n",
				"  \n",
				"    def forward(self,x):\n",
				"        x=x.view(-1,28*28)\n",
				"        x=self.linear1(x)\n",
				"        x=self.d1(x)\n",
				"        x=self.relu1(x)\n",
				"        x=self.linear2(x)\n",
				"        x=self.d2(x)\n",
				"        x=self.relu2(x)\n",
				"        x=self.linear3(x)\n",
				"        x=self.d3(x)\n",
				"        x=self.relu3(x)\n",
				"        x=self.linear4(x)\n",
				"        return x\n",
				"class MNet3(nn.Module):\n",
				"    \"\"\"加入Batch normilization层\n",
				"\n",
				"    Args:\n",
				"        nn (_type_): _description_\n",
				"    \"\"\"\n",
				"    def __init__(self,input,hidden,output) -> None:\n",
				"        \"\"\"_summary_\n",
				"\n",
				"        Args:\n",
				"            input (_type_): _description_\n",
				"            hidden (_type_): _description_\n",
				"            output (_type_): _description_\n",
				"             \n",
				"        \"\"\"\n",
				"        super(MNet3,self).__init__()\n",
				"        \n",
				"        self.linear1=nn.Linear(in_features=input,out_features=hidden)\n",
				"        self.n1=nn.BatchNorm1d(hidden)\n",
				"        self.relu1=nn.ReLU()\n",
				"        self.linear2=nn.Linear(in_features=hidden,out_features=hidden)\n",
				"        self.n2=nn.BatchNorm1d(hidden)\n",
				"        self.relu2=nn.ReLU()\n",
				"        self.linear3=nn.Linear(in_features=hidden,out_features=hidden)\n",
				"        self.n3=nn.BatchNorm1d(hidden)\n",
				"        self.relu3=nn.ReLU()\n",
				"        self.linear4=nn.Linear(in_features=hidden,out_features=output)\n",
				"            \n",
				"  \n",
				"    def forward(self,x):\n",
				"        x=x.view(-1,28*28)\n",
				"        x=self.linear1(x)\n",
				"        x=self.n1(x)\n",
				"        x=self.relu1(x)\n",
				"        x=self.linear2(x)\n",
				"        x=self.n2(x)\n",
				"        x=self.relu2(x)\n",
				"        x=self.linear3(x)\n",
				"        x=self.n3(x)\n",
				"        x=self.relu3(x)\n",
				"        x=self.linear4(x)\n",
				"        return x\n",
				"if __name__ == '__main__':\n",
				"    ################################数据载入、数据预处理################################\n",
				"    train_ds=torchvision.datasets.MNIST('data/',train=True,transform=ToTensor(),download=False)\n",
				"    test_ds=torchvision.datasets.MNIST('data/',train=False,transform=ToTensor(),download=False)\n",
				"    # 缩减数据量\n",
				"    num_train_examples = 500\n",
				"    num_test_examples  = 300\n",
				"    train_ds = Subset(train_ds, np.arange(num_train_examples))\n",
				"    test_ds = Subset(test_ds, np.arange(num_train_examples))\n",
				"    # 通过dataloader进行处理\n",
				"    train_data=torch.utils.data.DataLoader(train_ds,batch_size=20,shuffle=True)\n",
				"    test_data=torch.utils.data.DataLoader(test_ds,batch_size=20,shuffle=False)\n",
				"   \n",
				"\n",
				"    train_loss_list=[]\n",
				"    test_loss_list=[]\n",
				"    train_correct_list=[]\n",
				"    test_correct_list=[]\n",
				"    ################################numpy数据张量化，并载入本机gpu或cpu################################`\n",
				"    device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
				"    print(\"current device: \" + device)\n",
				" \n",
				" \n",
				"    ## 超参设定\n",
				"    learning_rate=0.001#学习率\n",
				"    batch_size=20# 每批次随机选取100张图像\n",
				"    epochs=50#循环epoch次数\n",
				"    drop_p=0.2\n",
				"    weight_decay=0.01\n",
				"    ################################网络实例构建################################\n",
				"    #构建网络实例，注意在网络实例化时，权参、偏参也赋予了初始值\n",
				"    #net=MNet2(input=28*28,hidden=200,output=10,drop_p=drop_p)\n",
				"    #net=MNet3(input=28*28,hidden=200,output=10)\n",
				"    net=MNet3(input=28*28,hidden=200,output=10)\n",
				"    net.to(device)\n",
				"    loss_fn=nn.CrossEntropyLoss()\n",
				"    opt=torch.optim.Adam(params=net.parameters(),lr=learning_rate)\n",
				"    #summary(net,input_size=(784,))\n",
				"    ################################网络实例训练################################\n",
				"    train_len=len(train_data.dataset)\n",
				"    print(\"一个train epoch中数据长度\",train_len)\n",
				"    test_len=len(test_data.dataset)\n",
				"    print(\"一个test epoch中数据长度\",test_len)\n",
				"    train_correct=0\n",
				"    test_correct=0\n",
				"    for epoch in range(epochs):\n",
				"        #print(\"第{}次epoch\".format(epoch))\n",
				"        step_loss=[]\n",
				"        step_correct=[]\n",
				"        for x,y in train_data:\n",
				"            x,y=x.to(device),y.to(device)\n",
				"            pred=net(x)\n",
				"            loss=loss_fn(pred,y)\n",
				"            opt.zero_grad()\n",
				"            loss.backward()\n",
				"            opt.step()\n",
				"            step_loss.append(loss.cpu().detach().numpy())\n",
				"            #step_correct.append((pred.argmax(dim=1)==y).type(torch.float).sum().item())\n",
				"            train_correct+=(pred.argmax(1)==y).type(torch.float).sum().item()\n",
				"            #step_correct=(pred.argmax(1)==y).type(torch.float).sum().item()\n",
				"            #print(step_correct/20,\"%\")\n",
				"        train_loss=np.mean(step_loss)\n",
				"        train_loss_list.append( train_loss)\n",
				"        #train_correct=np.sum(step_correct)/train_len\n",
				"        train_correct/=train_len\n",
				"        train_correct_list.append( train_correct)\n",
				"        \n",
				"        \n",
				"        with torch.no_grad():# since we're not training, we don't need to calculate the gradients for our outputs\n",
				"            for x,y in test_data:\n",
				"                x,y=x.to(device),y.to(device)\n",
				"                pred=net(x)\n",
				"                loss=loss_fn(pred,y)\n",
				"                step_loss.append(loss.cpu().detach().numpy())\n",
				"                test_correct+=(pred.argmax(dim=1)==y).type(torch.float).sum().item()\n",
				"                \n",
				"        test_loss=np.mean(step_loss)\n",
				"        test_loss_list.append(test_loss)\n",
				"        #test_correct=np.sum(step_correct)/test_len\n",
				"        test_correct/=test_len\n",
				"        test_correct_list.append( train_correct)\n",
				"        \n",
				"        \n",
				"        \n",
				"        if epoch%10==0 :\n",
				"            print(\"##############第{}次epoch#################\".format(epoch))\n",
				"            print(\"train loss为：{}\".format(train_loss))\n",
				"            print(\"test loss为：{}\".format( test_loss))\n",
				"            print(\"train accuracy为：{}%\".format(train_correct*100))\n",
				"            print(\"test accuracy为：{}%\".format( test_correct*100))\n",
				"        if epoch==epochs-1:\n",
				"            print(\"***********************fin! good luck!*******************************\")\n",
				"            print(\"The final train loss：{}\".format(train_loss))\n",
				"            print(\"The final train  loss为：{}\".format( test_loss))\n",
				"            print(\"The final train accuracy：{}%\".format( train_correct*100))\n",
				"            print(\"The final test accuracy：{}%\".format( test_correct*100))\n",
				"    f.loss_fig(train_loss_list,test_loss_list)\n",
				"    f.accuracy_fig(train_correct_list,test_correct_list)"
			]
		}
	],
	"metadata": {
		"kernelspec": {
			"display_name": "Python 3 (ipykernel)",
			"language": "python",
			"name": "python3"
		},
		"language_info": {
			"codemirror_mode": {
				"name": "ipython",
				"version": 3
			},
			"file_extension": ".py",
			"mimetype": "text/x-python",
			"name": "python",
			"nbconvert_exporter": "python",
			"pygments_lexer": "ipython3",
			"version": "3.10.10"
		},
		"orig_nbformat": 4,
		"vscode": {
			"interpreter": {
				"hash": "4500649f3376875055274a6ea5762786a730155ceb79c8798b9983f2d85af345"
			}
		}
	},
	"nbformat": 4,
	"nbformat_minor": 2
}
