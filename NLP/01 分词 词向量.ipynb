{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分词池袋模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sklearn\n",
      "  Using cached sklearn-0.0.tar.gz (1.1 kB)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\tomis\\anaconda3\\lib\\site-packages (from sklearn) (1.0.2)\n",
      "Requirement already satisfied: numpy>=1.14.6 in c:\\users\\tomis\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.21.5)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\tomis\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.7.3)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\tomis\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\tomis\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (2.2.0)\n",
      "Building wheels for collected packages: sklearn\n",
      "  Building wheel for sklearn (setup.py): started\n",
      "  Building wheel for sklearn (setup.py): finished with status 'done'\n",
      "  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1310 sha256=927d5bae6c48e40187db15761d28338364ecb892537f1262dd2a6e7aa8cc6211\n",
      "  Stored in directory: c:\\users\\tomis\\appdata\\local\\pip\\cache\\wheels\\e4\\7b\\98\\b6466d71b8d738a0c547008b9eb39bf8676d1ff6ca4b22af1c\n",
      "Successfully built sklearn\n",
      "Installing collected packages: sklearn\n",
      "Successfully installed sklearn-0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 自然语言处理pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Life', 'is', 'like', 'music.', 'It', 'must', 'be', 'composed', 'by', 'ear,', 'feeling', 'and', 'instinct,', 'not', 'by', 'rule.']\n",
      "['It', 'Life', 'and', 'be', 'by', 'composed', 'ear,', 'feeling', 'instinct,', 'is', 'like', 'music.', 'must', 'not', 'rule.']\n",
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "[[0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "sentence=\"Life is like music. It must be composed by ear, feeling and instinct, not by rule.\"\n",
    "token=sentence.split()\n",
    "vocad=sorted(set(token))# 对英文文本进行排序，数字最先，大写在前，小写在后\n",
    " \n",
    "','.join(vocad)\n",
    "print(token)\n",
    "print(vocad)\n",
    "num_tokens=len(token)\n",
    "vocad_size=len(vocad)\n",
    "#print(num_tokens)\n",
    "#print(vocad_size)\n",
    "onehot_vec=np.zeros((num_tokens,vocad_size),int)\n",
    "print(onehot_vec)\n",
    "for i, word in enumerate(token):\n",
    "        onehot_vec[i,vocad.index(word)]=1\n",
    "        \n",
    "print(onehot_vec)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    It  Life  and  be  by  composed  ear,  feeling  instinct,  is  like  \\\n",
      "0    0     1    0   0   0         0     0        0          0   0     0   \n",
      "1    0     0    0   0   0         0     0        0          0   1     0   \n",
      "2    0     0    0   0   0         0     0        0          0   0     1   \n",
      "3    0     0    0   0   0         0     0        0          0   0     0   \n",
      "4    1     0    0   0   0         0     0        0          0   0     0   \n",
      "5    0     0    0   0   0         0     0        0          0   0     0   \n",
      "6    0     0    0   1   0         0     0        0          0   0     0   \n",
      "7    0     0    0   0   0         1     0        0          0   0     0   \n",
      "8    0     0    0   0   1         0     0        0          0   0     0   \n",
      "9    0     0    0   0   0         0     1        0          0   0     0   \n",
      "10   0     0    0   0   0         0     0        1          0   0     0   \n",
      "11   0     0    1   0   0         0     0        0          0   0     0   \n",
      "12   0     0    0   0   0         0     0        0          1   0     0   \n",
      "13   0     0    0   0   0         0     0        0          0   0     0   \n",
      "14   0     0    0   0   1         0     0        0          0   0     0   \n",
      "15   0     0    0   0   0         0     0        0          0   0     0   \n",
      "\n",
      "    music.  must  not  rule.  \n",
      "0        0     0    0      0  \n",
      "1        0     0    0      0  \n",
      "2        0     0    0      0  \n",
      "3        1     0    0      0  \n",
      "4        0     0    0      0  \n",
      "5        0     1    0      0  \n",
      "6        0     0    0      0  \n",
      "7        0     0    0      0  \n",
      "8        0     0    0      0  \n",
      "9        0     0    0      0  \n",
      "10       0     0    0      0  \n",
      "11       0     0    0      0  \n",
      "12       0     0    0      0  \n",
      "13       0     0    1      0  \n",
      "14       0     0    0      0  \n",
      "15       0     0    0      1  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "df=pd.DataFrame(onehot_vec,columns=vocad)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('It', 1),\n",
       " ('Life', 1),\n",
       " ('and', 1),\n",
       " ('be', 1),\n",
       " ('by', 1),\n",
       " ('composed', 1),\n",
       " ('ear,', 1),\n",
       " ('feeling', 1),\n",
       " ('instinct,', 1),\n",
       " ('is', 1),\n",
       " ('like', 1),\n",
       " ('music.', 1),\n",
       " ('must', 1),\n",
       " ('not', 1),\n",
       " ('rule.', 1)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_bow={}\n",
    "for token in sentence.split():\n",
    "    sentence_bow[token]=1\n",
    "print(type(sentence_bow))\n",
    "sorted(sentence_bow.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Life  is  like  music.  It  must  be  composed  by  ear,  feeling  and  \\\n",
      "sent     1   1     1       1   1     1   1         1   1     1        1    1   \n",
      "\n",
      "      instinct,  not  rule.  \n",
      "sent          1    1      1  \n"
     ]
    }
   ],
   "source": [
    "s=pd.Series(sentence_bow)\n",
    "df2=pd.DataFrame(s,columns=[\"sent\"])\n",
    "df2=df2.T\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To be both a speaker of words and a doer of deeds.\n",
      "Only they who fulfill their duties in everyday matters will fulfill them on great occasions.\n",
      "The shortest way to do many things is to only one thing at a time. \n",
      "Life is like music. It must be composed by ear, feeling and instinct, not by rule.\n",
      "Life is a great big canvas, and you should throw all the paint on it you can.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>To</th>\n",
       "      <th>be</th>\n",
       "      <th>both</th>\n",
       "      <th>a</th>\n",
       "      <th>speaker</th>\n",
       "      <th>of</th>\n",
       "      <th>words</th>\n",
       "      <th>and</th>\n",
       "      <th>doer</th>\n",
       "      <th>deeds.</th>\n",
       "      <th>Only</th>\n",
       "      <th>they</th>\n",
       "      <th>who</th>\n",
       "      <th>fulfill</th>\n",
       "      <th>their</th>\n",
       "      <th>duties</th>\n",
       "      <th>in</th>\n",
       "      <th>everyday</th>\n",
       "      <th>matters</th>\n",
       "      <th>will</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sent0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       To  be  both  a  speaker  of  words  and  doer  deeds.  Only  they  \\\n",
       "sent0   1   1     1  1        1   1      1    1     1       1     0     0   \n",
       "sent1   0   0     0  0        0   0      0    0     0       0     1     1   \n",
       "sent2   0   0     0  1        0   0      0    0     0       0     0     0   \n",
       "sent3   0   1     0  0        0   0      0    1     0       0     0     0   \n",
       "sent4   0   0     0  1        0   0      0    1     0       0     0     0   \n",
       "\n",
       "       who  fulfill  their  duties  in  everyday  matters  will  \n",
       "sent0    0        0      0       0   0         0        0     0  \n",
       "sent1    1        1      1       1   1         1        1     1  \n",
       "sent2    0        0      0       0   0         0        0     0  \n",
       "sent3    0        0      0       0   0         0        0     0  \n",
       "sent4    0        0      0       0   0         0        0     0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents=\"To be both a speaker of words and a doer of deeds.\\n\"\n",
    "sents+=\"Only they who fulfill their duties in everyday matters will fulfill them on great occasions.\\n\"\n",
    "sents+=\"The shortest way to do many things is to only one thing at a time. \\n\"\n",
    "sents+=\"Life is like music. It must be composed by ear, feeling and instinct, not by rule.\\n\"\n",
    "sents+=\"Life is a great big canvas, and you should throw all the paint on it you can.\"\n",
    "print(sents)\n",
    "corpus={}\n",
    "for i,sent in enumerate(sents.split(\"\\n\")):\n",
    "    corpus['sent{}'.format(i)]=dict((tok,1) for tok in sent.split())\n",
    "df=pd.DataFrame.from_records(corpus).fillna(0).astype(int).T\n",
    "df[df.columns[:20]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To            1\n",
      "be            1\n",
      "both          1\n",
      "a             1\n",
      "speaker       1\n",
      "of            1\n",
      "words         1\n",
      "and           1\n",
      "doer          1\n",
      "deeds.        1\n",
      "Only          0\n",
      "they          0\n",
      "who           0\n",
      "fulfill       0\n",
      "their         0\n",
      "duties        0\n",
      "in            0\n",
      "everyday      0\n",
      "matters       0\n",
      "will          0\n",
      "them          0\n",
      "on            0\n",
      "great         0\n",
      "occasions.    0\n",
      "The           0\n",
      "shortest      0\n",
      "way           0\n",
      "to            0\n",
      "do            0\n",
      "many          0\n",
      "things        0\n",
      "is            0\n",
      "only          0\n",
      "one           0\n",
      "thing         0\n",
      "at            0\n",
      "time.         0\n",
      "Life          0\n",
      "like          0\n",
      "music.        0\n",
      "It            0\n",
      "must          0\n",
      "composed      0\n",
      "by            0\n",
      "ear,          0\n",
      "feeling       0\n",
      "instinct,     0\n",
      "not           0\n",
      "rule.         0\n",
      "big           0\n",
      "canvas,       0\n",
      "you           0\n",
      "should        0\n",
      "throw         0\n",
      "all           0\n",
      "the           0\n",
      "paint         0\n",
      "it            0\n",
      "can.          0\n",
      "Name: sent0, dtype: int32\n",
      "To            0\n",
      "be            0\n",
      "both          0\n",
      "a             0\n",
      "speaker       0\n",
      "of            0\n",
      "words         0\n",
      "and           0\n",
      "doer          0\n",
      "deeds.        0\n",
      "Only          1\n",
      "they          1\n",
      "who           1\n",
      "fulfill       1\n",
      "their         1\n",
      "duties        1\n",
      "in            1\n",
      "everyday      1\n",
      "matters       1\n",
      "will          1\n",
      "them          1\n",
      "on            1\n",
      "great         1\n",
      "occasions.    1\n",
      "The           0\n",
      "shortest      0\n",
      "way           0\n",
      "to            0\n",
      "do            0\n",
      "many          0\n",
      "things        0\n",
      "is            0\n",
      "only          0\n",
      "one           0\n",
      "thing         0\n",
      "at            0\n",
      "time.         0\n",
      "Life          0\n",
      "like          0\n",
      "music.        0\n",
      "It            0\n",
      "must          0\n",
      "composed      0\n",
      "by            0\n",
      "ear,          0\n",
      "feeling       0\n",
      "instinct,     0\n",
      "not           0\n",
      "rule.         0\n",
      "big           0\n",
      "canvas,       0\n",
      "you           0\n",
      "should        0\n",
      "throw         0\n",
      "all           0\n",
      "the           0\n",
      "paint         0\n",
      "it            0\n",
      "can.          0\n",
      "Name: sent1, dtype: int32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent1_v=df.iloc[0,:].T\n",
    "print(sent1_v)\n",
    "sent2_v=df.iloc[1,:]\n",
    "print(sent2_v)\n",
    "sent1_v@sent2_v\n",
    "sent3_v=df.iloc[3,:]\n",
    "sent1_v@sent3_v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### n-gram\n",
    "n-gram是一个最多包含n个元素的序列，这些元素从由他们组成的序列（通常是字符）中提取而成。\n",
    "\n",
    "一般而言，n-gram的“元素”可以是字符，音节，词，甚至是“A”,\"T\",\"G\",\"C\"等DNA序列的符号\n",
    "\n",
    "> NLP，n-gram即可由词构成例如“hello you” 为词的2-gram，“yo”为字母的2-gram。n-gram不一定要求像复合词一样具有特定含义，而仅仅要求出现频率足够高以引起词条计数器的注意。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\tomis\\anaconda3\\lib\\site-packages (3.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\tomis\\anaconda3\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: click in c:\\users\\tomis\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\tomis\\anaconda3\\lib\\site-packages (from nltk) (2022.3.15)\n",
      "Requirement already satisfied: tqdm in c:\\users\\tomis\\anaconda3\\lib\\site-packages (from nltk) (4.64.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\tomis\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Life', 'is'),\n",
       " ('is', 'like'),\n",
       " ('like', 'music.'),\n",
       " ('music.', 'It'),\n",
       " ('It', 'must'),\n",
       " ('must', 'be'),\n",
       " ('be', 'composed'),\n",
       " ('composed', 'by'),\n",
       " ('by', 'ear,'),\n",
       " ('ear,', 'feeling'),\n",
       " ('feeling', 'and'),\n",
       " ('and', 'instinct,'),\n",
       " ('instinct,', 'not'),\n",
       " ('not', 'by'),\n",
       " ('by', 'rule.')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.util import ngrams\n",
    "list(ngrams(token,2))\n",
    " \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9a31ce11574d352d00236a575df6bfccd0c874de624df1cc5e0869df469a6677"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
